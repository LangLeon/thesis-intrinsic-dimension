model : reg_lenet_3
optimizer : SGD
lr : 1.0
schedule : True
schedule_gamma : 0.4
schedule_freq : 10
seed : 2
n_epochs : 50
batch_size : 64
non_wrapped : False
chunked : False
dense : False
parameter_correction : True
print_freq : 20
print_prec : 2
device : cuda
subspace_training : True
ddim_vs_acc : True
timestamp : 2020-01-22 20:51:04
nonzero elements in E: 2215
elements in E: 449900
fraction nonzero: 0.004923316292509447
Epoch 1 start
The current lr is: 1.0
/tmp/pip-req-build-4baxydiv/aten/src/ATen/native/IndexingUtils.h:20: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead.
/tmp/pip-req-build-4baxydiv/aten/src/ATen/native/IndexingUtils.h:20: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead.
Batch: 0; loss: 2.31; acc: 0.08
Batch: 20; loss: 2.29; acc: 0.06
Batch: 40; loss: 2.3; acc: 0.05
Batch: 60; loss: 2.3; acc: 0.03
Batch: 80; loss: 2.3; acc: 0.03
Batch: 100; loss: 2.3; acc: 0.08
Batch: 120; loss: 2.31; acc: 0.06
Batch: 140; loss: 2.32; acc: 0.03
Batch: 160; loss: 2.31; acc: 0.05
Batch: 180; loss: 2.3; acc: 0.11
Batch: 200; loss: 2.3; acc: 0.09
Batch: 220; loss: 2.31; acc: 0.06
Batch: 240; loss: 2.32; acc: 0.03
Batch: 260; loss: 2.31; acc: 0.08
Batch: 280; loss: 2.29; acc: 0.14
Batch: 300; loss: 2.31; acc: 0.06
Batch: 320; loss: 2.31; acc: 0.05
Batch: 340; loss: 2.3; acc: 0.09
Batch: 360; loss: 2.3; acc: 0.12
Batch: 380; loss: 2.31; acc: 0.08
Batch: 400; loss: 2.32; acc: 0.03
Batch: 420; loss: 2.32; acc: 0.03
Batch: 440; loss: 2.3; acc: 0.06
Batch: 460; loss: 2.32; acc: 0.06
Batch: 480; loss: 2.31; acc: 0.02
Batch: 500; loss: 2.31; acc: 0.06
Batch: 520; loss: 2.28; acc: 0.16
Batch: 540; loss: 2.31; acc: 0.09
Batch: 560; loss: 2.3; acc: 0.12
Batch: 580; loss: 2.29; acc: 0.05
Batch: 600; loss: 2.31; acc: 0.06
Batch: 620; loss: 2.3; acc: 0.12
Batch: 640; loss: 2.29; acc: 0.11
Batch: 660; loss: 2.3; acc: 0.09
Batch: 680; loss: 2.31; acc: 0.08
Batch: 700; loss: 2.32; acc: 0.08
Batch: 720; loss: 2.32; acc: 0.03
Batch: 740; loss: 2.3; acc: 0.08
Batch: 760; loss: 2.31; acc: 0.08
Batch: 780; loss: 2.3; acc: 0.12
Train Epoch over. train_loss: 2.3; train_accuracy: 0.08 

1.7403380070390995e-06
1.4107403956131748e-07
Batch: 0; loss: 2.3; acc: 0.12
Batch: 20; loss: 2.29; acc: 0.19
Batch: 40; loss: 2.31; acc: 0.08
Batch: 60; loss: 2.3; acc: 0.17
Batch: 80; loss: 2.29; acc: 0.06
Batch: 100; loss: 2.3; acc: 0.14
Batch: 120; loss: 2.31; acc: 0.14
Batch: 140; loss: 2.31; acc: 0.08
Val Epoch over. val_loss: 2.3028539123049208; val_accuracy: 0.09564092356687898 

The current subspace-distance is: 1.4107403956131748e-07 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 2.31; acc: 0.06
Batch: 20; loss: 2.31; acc: 0.06
Batch: 40; loss: 2.31; acc: 0.05
Batch: 60; loss: 2.29; acc: 0.17
Batch: 80; loss: 2.3; acc: 0.06
Batch: 100; loss: 2.3; acc: 0.09
Batch: 120; loss: 2.29; acc: 0.12
Batch: 140; loss: 2.31; acc: 0.12
Batch: 160; loss: 2.3; acc: 0.12
Batch: 180; loss: 2.31; acc: 0.05
Batch: 200; loss: 2.3; acc: 0.08
Batch: 220; loss: 2.29; acc: 0.09
Batch: 240; loss: 2.29; acc: 0.08
Batch: 260; loss: 2.3; acc: 0.11
Batch: 280; loss: 2.31; acc: 0.09
Batch: 300; loss: 2.31; acc: 0.11
Batch: 320; loss: 2.31; acc: 0.08
Batch: 340; loss: 2.3; acc: 0.12
Batch: 360; loss: 2.31; acc: 0.09
Batch: 380; loss: 2.3; acc: 0.11
Batch: 400; loss: 2.29; acc: 0.12
Batch: 420; loss: 2.29; acc: 0.16
Batch: 440; loss: 2.3; acc: 0.08
Batch: 460; loss: 2.3; acc: 0.09
Batch: 480; loss: 2.3; acc: 0.06
Batch: 500; loss: 2.29; acc: 0.12
Batch: 520; loss: 2.32; acc: 0.06
Batch: 540; loss: 2.3; acc: 0.12
Batch: 560; loss: 2.3; acc: 0.17
Batch: 580; loss: 2.3; acc: 0.05
Batch: 600; loss: 2.3; acc: 0.12
Batch: 620; loss: 2.29; acc: 0.17
Batch: 640; loss: 2.29; acc: 0.09
Batch: 660; loss: 2.31; acc: 0.09
Batch: 680; loss: 2.31; acc: 0.16
Batch: 700; loss: 2.3; acc: 0.06
Batch: 720; loss: 2.29; acc: 0.12
Batch: 740; loss: 2.3; acc: 0.06
Batch: 760; loss: 2.3; acc: 0.09
Batch: 780; loss: 2.29; acc: 0.12
Train Epoch over. train_loss: 2.3; train_accuracy: 0.1 

2.1496614408533787e-06
1.3854558744696988e-07
Batch: 0; loss: 2.3; acc: 0.14
Batch: 20; loss: 2.29; acc: 0.23
Batch: 40; loss: 2.31; acc: 0.12
Batch: 60; loss: 2.3; acc: 0.12
Batch: 80; loss: 2.29; acc: 0.03
Batch: 100; loss: 2.3; acc: 0.2
Batch: 120; loss: 2.31; acc: 0.16
Batch: 140; loss: 2.31; acc: 0.08
Val Epoch over. val_loss: 2.30219541233816; val_accuracy: 0.10828025477707007 

The current subspace-distance is: 1.3854558744696988e-07 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.12
Batch: 20; loss: 2.31; acc: 0.17
Batch: 40; loss: 2.31; acc: 0.06
Batch: 60; loss: 2.3; acc: 0.12
Batch: 80; loss: 2.31; acc: 0.08
Batch: 100; loss: 2.29; acc: 0.14
Batch: 120; loss: 2.31; acc: 0.12
Batch: 140; loss: 2.31; acc: 0.06
Batch: 160; loss: 2.3; acc: 0.14
Batch: 180; loss: 2.31; acc: 0.09
Batch: 200; loss: 2.31; acc: 0.14
Batch: 220; loss: 2.3; acc: 0.12
Batch: 240; loss: 2.31; acc: 0.03
Batch: 260; loss: 2.3; acc: 0.16
Batch: 280; loss: 2.31; acc: 0.12
Batch: 300; loss: 2.3; acc: 0.11
Batch: 320; loss: 2.3; acc: 0.05
Batch: 340; loss: 2.3; acc: 0.17
Batch: 360; loss: 2.32; acc: 0.06
Batch: 380; loss: 2.31; acc: 0.09
Batch: 400; loss: 2.29; acc: 0.16
Batch: 420; loss: 2.31; acc: 0.11
Batch: 440; loss: 2.3; acc: 0.08
Batch: 460; loss: 2.3; acc: 0.11
Batch: 480; loss: 2.29; acc: 0.19
Batch: 500; loss: 2.3; acc: 0.11
Batch: 520; loss: 2.31; acc: 0.05
Batch: 540; loss: 2.29; acc: 0.19
Batch: 560; loss: 2.28; acc: 0.17
Batch: 580; loss: 2.32; acc: 0.09
Batch: 600; loss: 2.31; acc: 0.08
Batch: 620; loss: 2.31; acc: 0.17
Batch: 640; loss: 2.31; acc: 0.12
Batch: 660; loss: 2.29; acc: 0.16
Batch: 680; loss: 2.29; acc: 0.11
Batch: 700; loss: 2.29; acc: 0.12
Batch: 720; loss: 2.3; acc: 0.17
Batch: 740; loss: 2.3; acc: 0.16
Batch: 760; loss: 2.3; acc: 0.12
Batch: 780; loss: 2.3; acc: 0.14
Train Epoch over. train_loss: 2.3; train_accuracy: 0.11 

2.5548044959577965e-06
2.161133778599833e-07
Batch: 0; loss: 2.3; acc: 0.11
Batch: 20; loss: 2.29; acc: 0.17
Batch: 40; loss: 2.31; acc: 0.12
Batch: 60; loss: 2.3; acc: 0.12
Batch: 80; loss: 2.29; acc: 0.05
Batch: 100; loss: 2.3; acc: 0.17
Batch: 120; loss: 2.31; acc: 0.17
Batch: 140; loss: 2.31; acc: 0.08
Val Epoch over. val_loss: 2.3017374117662954; val_accuracy: 0.10370222929936306 

The current subspace-distance is: 2.161133778599833e-07 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 2.31; acc: 0.14
Batch: 20; loss: 2.3; acc: 0.16
Batch: 40; loss: 2.31; acc: 0.06
Batch: 60; loss: 2.3; acc: 0.14
Batch: 80; loss: 2.3; acc: 0.08
Batch: 100; loss: 2.3; acc: 0.06
Batch: 120; loss: 2.3; acc: 0.08
Batch: 140; loss: 2.28; acc: 0.22
Batch: 160; loss: 2.32; acc: 0.08
Batch: 180; loss: 2.29; acc: 0.09
Batch: 200; loss: 2.3; acc: 0.11
Batch: 220; loss: 2.33; acc: 0.02
Batch: 240; loss: 2.29; acc: 0.12
Batch: 260; loss: 2.29; acc: 0.09
Batch: 280; loss: 2.32; acc: 0.06
Batch: 300; loss: 2.29; acc: 0.14
Batch: 320; loss: 2.31; acc: 0.09
Batch: 340; loss: 2.3; acc: 0.03
Batch: 360; loss: 2.3; acc: 0.08
Batch: 380; loss: 2.29; acc: 0.16
Batch: 400; loss: 2.3; acc: 0.09
Batch: 420; loss: 2.32; acc: 0.06
Batch: 440; loss: 2.31; acc: 0.08
Batch: 460; loss: 2.31; acc: 0.06
Batch: 480; loss: 2.32; acc: 0.05
Batch: 500; loss: 2.29; acc: 0.09
Batch: 520; loss: 2.31; acc: 0.05
Batch: 540; loss: 2.29; acc: 0.08
Batch: 560; loss: 2.29; acc: 0.14
Batch: 580; loss: 2.29; acc: 0.05
Batch: 600; loss: 2.28; acc: 0.19
Batch: 620; loss: 2.29; acc: 0.14
Batch: 640; loss: 2.29; acc: 0.08
Batch: 660; loss: 2.31; acc: 0.02
Batch: 680; loss: 2.29; acc: 0.16
Batch: 700; loss: 2.29; acc: 0.09
Batch: 720; loss: 2.28; acc: 0.09
Batch: 740; loss: 2.3; acc: 0.11
Batch: 760; loss: 2.3; acc: 0.08
Batch: 780; loss: 2.3; acc: 0.12
Train Epoch over. train_loss: 2.3; train_accuracy: 0.1 

2.0019867861265084e-06
6.683094397885725e-07
Batch: 0; loss: 2.3; acc: 0.11
Batch: 20; loss: 2.29; acc: 0.17
Batch: 40; loss: 2.31; acc: 0.12
Batch: 60; loss: 2.3; acc: 0.12
Batch: 80; loss: 2.29; acc: 0.05
Batch: 100; loss: 2.3; acc: 0.17
Batch: 120; loss: 2.3; acc: 0.17
Batch: 140; loss: 2.31; acc: 0.08
Val Epoch over. val_loss: 2.3003349820519707; val_accuracy: 0.10290605095541401 

The current subspace-distance is: 6.683094397885725e-07 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 2.31; acc: 0.12
Batch: 20; loss: 2.3; acc: 0.11
Batch: 40; loss: 2.3; acc: 0.06
Batch: 60; loss: 2.29; acc: 0.2
Batch: 80; loss: 2.29; acc: 0.16
Batch: 100; loss: 2.29; acc: 0.11
Batch: 120; loss: 2.32; acc: 0.03
Batch: 140; loss: 2.3; acc: 0.11
Batch: 160; loss: 2.31; acc: 0.05
Batch: 180; loss: 2.3; acc: 0.12
Batch: 200; loss: 2.3; acc: 0.08
Batch: 220; loss: 2.29; acc: 0.16
Batch: 240; loss: 2.28; acc: 0.14
Batch: 260; loss: 2.28; acc: 0.12
Batch: 280; loss: 2.31; acc: 0.08
Batch: 300; loss: 2.31; acc: 0.06
Batch: 320; loss: 2.3; acc: 0.14
Batch: 340; loss: 2.3; acc: 0.11
Batch: 360; loss: 2.3; acc: 0.09
Batch: 380; loss: 2.3; acc: 0.16
Batch: 400; loss: 2.31; acc: 0.09
Batch: 420; loss: 2.29; acc: 0.14
Batch: 440; loss: 2.31; acc: 0.14
Batch: 460; loss: 2.3; acc: 0.14
Batch: 480; loss: 2.29; acc: 0.12
Batch: 500; loss: 2.28; acc: 0.2
Batch: 520; loss: 2.3; acc: 0.14
Batch: 540; loss: 2.31; acc: 0.05
Batch: 560; loss: 2.3; acc: 0.08
Batch: 580; loss: 2.31; acc: 0.08
Batch: 600; loss: 2.31; acc: 0.08
Batch: 620; loss: 2.28; acc: 0.08
Batch: 640; loss: 2.31; acc: 0.05
Batch: 660; loss: 2.3; acc: 0.09
Batch: 680; loss: 2.3; acc: 0.12
Batch: 700; loss: 2.3; acc: 0.11
Batch: 720; loss: 2.28; acc: 0.14
Batch: 740; loss: 2.3; acc: 0.09
Batch: 760; loss: 2.3; acc: 0.09
Batch: 780; loss: 2.29; acc: 0.11
Train Epoch over. train_loss: 2.3; train_accuracy: 0.1 

2.7160101581102936e-06
9.9011583643005e-07
Batch: 0; loss: 2.3; acc: 0.16
Batch: 20; loss: 2.28; acc: 0.23
Batch: 40; loss: 2.3; acc: 0.14
Batch: 60; loss: 2.29; acc: 0.14
Batch: 80; loss: 2.29; acc: 0.09
Batch: 100; loss: 2.29; acc: 0.19
Batch: 120; loss: 2.3; acc: 0.19
Batch: 140; loss: 2.31; acc: 0.12
Val Epoch over. val_loss: 2.298839222853351; val_accuracy: 0.11315684713375797 

The current subspace-distance is: 9.9011583643005e-07 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 2.31; acc: 0.11
Batch: 20; loss: 2.31; acc: 0.12
Batch: 40; loss: 2.29; acc: 0.17
Batch: 60; loss: 2.29; acc: 0.14
Batch: 80; loss: 2.29; acc: 0.16
Batch: 100; loss: 2.3; acc: 0.16
Batch: 120; loss: 2.31; acc: 0.11
Batch: 140; loss: 2.32; acc: 0.05
Batch: 160; loss: 2.29; acc: 0.19
Batch: 180; loss: 2.3; acc: 0.11
Batch: 200; loss: 2.29; acc: 0.12
Batch: 220; loss: 2.3; acc: 0.08
Batch: 240; loss: 2.29; acc: 0.23
Batch: 260; loss: 2.3; acc: 0.14
Batch: 280; loss: 2.3; acc: 0.12
Batch: 300; loss: 2.31; acc: 0.05
Batch: 320; loss: 2.3; acc: 0.09
Batch: 340; loss: 2.3; acc: 0.12
Batch: 360; loss: 2.3; acc: 0.06
Batch: 380; loss: 2.28; acc: 0.12
Batch: 400; loss: 2.3; acc: 0.09
Batch: 420; loss: 2.31; acc: 0.19
Batch: 440; loss: 2.29; acc: 0.08
Batch: 460; loss: 2.29; acc: 0.11
Batch: 480; loss: 2.31; acc: 0.14
Batch: 500; loss: 2.3; acc: 0.12
Batch: 520; loss: 2.28; acc: 0.09
Batch: 540; loss: 2.27; acc: 0.11
Batch: 560; loss: 2.32; acc: 0.03
Batch: 580; loss: 2.32; acc: 0.08
Batch: 600; loss: 2.3; acc: 0.12
Batch: 620; loss: 2.3; acc: 0.08
Batch: 640; loss: 2.3; acc: 0.09
Batch: 660; loss: 2.28; acc: 0.12
Batch: 680; loss: 2.29; acc: 0.09
Batch: 700; loss: 2.31; acc: 0.11
Batch: 720; loss: 2.31; acc: 0.12
Batch: 740; loss: 2.3; acc: 0.19
Batch: 760; loss: 2.3; acc: 0.14
Batch: 780; loss: 2.32; acc: 0.06
Train Epoch over. train_loss: 2.3; train_accuracy: 0.11 

2.3917332327982876e-06
6.307419653239776e-07
Batch: 0; loss: 2.3; acc: 0.14
Batch: 20; loss: 2.28; acc: 0.22
Batch: 40; loss: 2.3; acc: 0.16
Batch: 60; loss: 2.29; acc: 0.16
Batch: 80; loss: 2.28; acc: 0.11
Batch: 100; loss: 2.29; acc: 0.19
Batch: 120; loss: 2.3; acc: 0.19
Batch: 140; loss: 2.3; acc: 0.14
Val Epoch over. val_loss: 2.2977119722184103; val_accuracy: 0.1191281847133758 

The current subspace-distance is: 6.307419653239776e-07 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 2.29; acc: 0.09
Batch: 20; loss: 2.3; acc: 0.03
Batch: 40; loss: 2.32; acc: 0.11
Batch: 60; loss: 2.3; acc: 0.12
Batch: 80; loss: 2.31; acc: 0.16
Batch: 100; loss: 2.3; acc: 0.11
Batch: 120; loss: 2.31; acc: 0.08
Batch: 140; loss: 2.3; acc: 0.11
Batch: 160; loss: 2.29; acc: 0.14
Batch: 180; loss: 2.3; acc: 0.05
Batch: 200; loss: 2.31; acc: 0.08
Batch: 220; loss: 2.29; acc: 0.11
Batch: 240; loss: 2.31; acc: 0.05
Batch: 260; loss: 2.31; acc: 0.11
Batch: 280; loss: 2.32; acc: 0.08
Batch: 300; loss: 2.29; acc: 0.09
Batch: 320; loss: 2.28; acc: 0.14
Batch: 340; loss: 2.28; acc: 0.17
Batch: 360; loss: 2.3; acc: 0.09
Batch: 380; loss: 2.29; acc: 0.16
Batch: 400; loss: 2.3; acc: 0.12
Batch: 420; loss: 2.31; acc: 0.12
Batch: 440; loss: 2.31; acc: 0.12
Batch: 460; loss: 2.29; acc: 0.06
Batch: 480; loss: 2.28; acc: 0.2
Batch: 500; loss: 2.3; acc: 0.11
Batch: 520; loss: 2.31; acc: 0.09
Batch: 540; loss: 2.28; acc: 0.11
Batch: 560; loss: 2.28; acc: 0.19
Batch: 580; loss: 2.3; acc: 0.11
Batch: 600; loss: 2.29; acc: 0.11
Batch: 620; loss: 2.28; acc: 0.22
Batch: 640; loss: 2.31; acc: 0.06
Batch: 660; loss: 2.28; acc: 0.2
Batch: 680; loss: 2.3; acc: 0.14
Batch: 700; loss: 2.3; acc: 0.14
Batch: 720; loss: 2.28; acc: 0.14
Batch: 740; loss: 2.31; acc: 0.09
Batch: 760; loss: 2.29; acc: 0.14
Batch: 780; loss: 2.31; acc: 0.12
Train Epoch over. train_loss: 2.3; train_accuracy: 0.12 

2.338928197787027e-06
6.063576734050002e-07
Batch: 0; loss: 2.3; acc: 0.12
Batch: 20; loss: 2.28; acc: 0.2
Batch: 40; loss: 2.3; acc: 0.16
Batch: 60; loss: 2.29; acc: 0.16
Batch: 80; loss: 2.28; acc: 0.11
Batch: 100; loss: 2.29; acc: 0.2
Batch: 120; loss: 2.3; acc: 0.19
Batch: 140; loss: 2.3; acc: 0.11
Val Epoch over. val_loss: 2.2964774134812083; val_accuracy: 0.12539808917197454 

The current subspace-distance is: 6.063576734050002e-07 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 2.31; acc: 0.11
Batch: 20; loss: 2.3; acc: 0.12
Batch: 40; loss: 2.28; acc: 0.11
Batch: 60; loss: 2.3; acc: 0.14
Batch: 80; loss: 2.29; acc: 0.12
Batch: 100; loss: 2.28; acc: 0.09
Batch: 120; loss: 2.28; acc: 0.2
Batch: 140; loss: 2.3; acc: 0.12
Batch: 160; loss: 2.29; acc: 0.16
Batch: 180; loss: 2.29; acc: 0.16
Batch: 200; loss: 2.29; acc: 0.17
Batch: 220; loss: 2.32; acc: 0.14
Batch: 240; loss: 2.32; acc: 0.08
Batch: 260; loss: 2.31; acc: 0.16
Batch: 280; loss: 2.31; acc: 0.11
Batch: 300; loss: 2.31; acc: 0.11
Batch: 320; loss: 2.3; acc: 0.09
Batch: 340; loss: 2.29; acc: 0.17
Batch: 360; loss: 2.29; acc: 0.14
Batch: 380; loss: 2.31; acc: 0.11
Batch: 400; loss: 2.29; acc: 0.11
Batch: 420; loss: 2.29; acc: 0.17
Batch: 440; loss: 2.32; acc: 0.08
Batch: 460; loss: 2.29; acc: 0.11
Batch: 480; loss: 2.31; acc: 0.06
Batch: 500; loss: 2.3; acc: 0.14
Batch: 520; loss: 2.31; acc: 0.09
Batch: 540; loss: 2.3; acc: 0.11
Batch: 560; loss: 2.3; acc: 0.12
Batch: 580; loss: 2.3; acc: 0.11
Batch: 600; loss: 2.31; acc: 0.06
Batch: 620; loss: 2.26; acc: 0.14
Batch: 640; loss: 2.31; acc: 0.09
Batch: 660; loss: 2.29; acc: 0.16
Batch: 680; loss: 2.3; acc: 0.14
Batch: 700; loss: 2.29; acc: 0.14
Batch: 720; loss: 2.31; acc: 0.05
Batch: 740; loss: 2.28; acc: 0.17
Batch: 760; loss: 2.32; acc: 0.06
Batch: 780; loss: 2.29; acc: 0.12
Train Epoch over. train_loss: 2.3; train_accuracy: 0.14 

3.1601530281477608e-06
8.709235430615081e-07
Batch: 0; loss: 2.29; acc: 0.14
Batch: 20; loss: 2.28; acc: 0.2
Batch: 40; loss: 2.29; acc: 0.19
Batch: 60; loss: 2.28; acc: 0.17
Batch: 80; loss: 2.28; acc: 0.14
Batch: 100; loss: 2.28; acc: 0.23
Batch: 120; loss: 2.29; acc: 0.2
Batch: 140; loss: 2.3; acc: 0.14
Val Epoch over. val_loss: 2.2929994847364488; val_accuracy: 0.1523686305732484 

The current subspace-distance is: 8.709235430615081e-07 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 2.28; acc: 0.23
Batch: 20; loss: 2.29; acc: 0.16
Batch: 40; loss: 2.31; acc: 0.14
Batch: 60; loss: 2.29; acc: 0.19
Batch: 80; loss: 2.29; acc: 0.16
Batch: 100; loss: 2.28; acc: 0.2
Batch: 120; loss: 2.27; acc: 0.14
Batch: 140; loss: 2.3; acc: 0.2
Batch: 160; loss: 2.27; acc: 0.2
Batch: 180; loss: 2.31; acc: 0.14
Batch: 200; loss: 2.28; acc: 0.22
Batch: 220; loss: 2.28; acc: 0.2
Batch: 240; loss: 2.3; acc: 0.14
Batch: 260; loss: 2.31; acc: 0.14
Batch: 280; loss: 2.3; acc: 0.12
Batch: 300; loss: 2.31; acc: 0.11
Batch: 320; loss: 2.28; acc: 0.12
Batch: 340; loss: 2.3; acc: 0.11
Batch: 360; loss: 2.29; acc: 0.2
Batch: 380; loss: 2.29; acc: 0.19
Batch: 400; loss: 2.32; acc: 0.08
Batch: 420; loss: 2.27; acc: 0.19
Batch: 440; loss: 2.28; acc: 0.19
Batch: 460; loss: 2.3; acc: 0.19
Batch: 480; loss: 2.29; acc: 0.12
Batch: 500; loss: 2.29; acc: 0.2
Batch: 520; loss: 2.31; acc: 0.14
Batch: 540; loss: 2.28; acc: 0.2
Batch: 560; loss: 2.29; acc: 0.16
Batch: 580; loss: 2.28; acc: 0.23
Batch: 600; loss: 2.29; acc: 0.12
Batch: 620; loss: 2.3; acc: 0.09
Batch: 640; loss: 2.28; acc: 0.17
Batch: 660; loss: 2.28; acc: 0.14
Batch: 680; loss: 2.3; acc: 0.12
Batch: 700; loss: 2.27; acc: 0.23
Batch: 720; loss: 2.31; acc: 0.09
Batch: 740; loss: 2.29; acc: 0.2
Batch: 760; loss: 2.3; acc: 0.23
Batch: 780; loss: 2.3; acc: 0.16
Train Epoch over. train_loss: 2.29; train_accuracy: 0.16 

4.635198365576798e-06
1.4188613022270147e-06
Batch: 0; loss: 2.28; acc: 0.19
Batch: 20; loss: 2.26; acc: 0.22
Batch: 40; loss: 2.28; acc: 0.2
Batch: 60; loss: 2.27; acc: 0.2
Batch: 80; loss: 2.27; acc: 0.19
Batch: 100; loss: 2.27; acc: 0.25
Batch: 120; loss: 2.28; acc: 0.2
Batch: 140; loss: 2.29; acc: 0.14
Val Epoch over. val_loss: 2.285754269095743; val_accuracy: 0.16918789808917198 

The current subspace-distance is: 1.4188613022270147e-06 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 2.29; acc: 0.17
Batch: 20; loss: 2.28; acc: 0.2
Batch: 40; loss: 2.28; acc: 0.2
Batch: 60; loss: 2.3; acc: 0.14
Batch: 80; loss: 2.27; acc: 0.22
Batch: 100; loss: 2.3; acc: 0.14
Batch: 120; loss: 2.27; acc: 0.12
Batch: 140; loss: 2.27; acc: 0.19
Batch: 160; loss: 2.29; acc: 0.2
Batch: 180; loss: 2.27; acc: 0.17
Batch: 200; loss: 2.3; acc: 0.14
Batch: 220; loss: 2.3; acc: 0.22
Batch: 240; loss: 2.26; acc: 0.2
Batch: 260; loss: 2.27; acc: 0.23
Batch: 280; loss: 2.26; acc: 0.23
Batch: 300; loss: 2.28; acc: 0.25
Batch: 320; loss: 2.29; acc: 0.17
Batch: 340; loss: 2.3; acc: 0.14
Batch: 360; loss: 2.3; acc: 0.11
Batch: 380; loss: 2.29; acc: 0.19
Batch: 400; loss: 2.28; acc: 0.16
Batch: 420; loss: 2.25; acc: 0.23
Batch: 440; loss: 2.28; acc: 0.16
Batch: 460; loss: 2.27; acc: 0.16
Batch: 480; loss: 2.29; acc: 0.14
Batch: 500; loss: 2.26; acc: 0.17
Batch: 520; loss: 2.28; acc: 0.17
Batch: 540; loss: 2.27; acc: 0.23
Batch: 560; loss: 2.27; acc: 0.19
Batch: 580; loss: 2.25; acc: 0.2
Batch: 600; loss: 2.28; acc: 0.09
Batch: 620; loss: 2.3; acc: 0.16
Batch: 640; loss: 2.27; acc: 0.16
Batch: 660; loss: 2.25; acc: 0.23
Batch: 680; loss: 2.27; acc: 0.17
Batch: 700; loss: 2.24; acc: 0.22
Batch: 720; loss: 2.28; acc: 0.19
Batch: 740; loss: 2.28; acc: 0.12
Batch: 760; loss: 2.3; acc: 0.17
Batch: 780; loss: 2.3; acc: 0.16
Train Epoch over. train_loss: 2.28; train_accuracy: 0.17 

6.641331765422365e-06
1.249455976903846e-06
Batch: 0; loss: 2.27; acc: 0.19
Batch: 20; loss: 2.24; acc: 0.22
Batch: 40; loss: 2.26; acc: 0.22
Batch: 60; loss: 2.25; acc: 0.2
Batch: 80; loss: 2.25; acc: 0.19
Batch: 100; loss: 2.24; acc: 0.27
Batch: 120; loss: 2.26; acc: 0.2
Batch: 140; loss: 2.27; acc: 0.14
Val Epoch over. val_loss: 2.272891044616699; val_accuracy: 0.17724920382165604 

The current subspace-distance is: 1.249455976903846e-06 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 2.27; acc: 0.14
Batch: 20; loss: 2.27; acc: 0.16
Batch: 40; loss: 2.32; acc: 0.09
Batch: 60; loss: 2.32; acc: 0.09
Batch: 80; loss: 2.27; acc: 0.08
Batch: 100; loss: 2.24; acc: 0.25
Batch: 120; loss: 2.25; acc: 0.23
Batch: 140; loss: 2.28; acc: 0.16
Batch: 160; loss: 2.26; acc: 0.2
Batch: 180; loss: 2.28; acc: 0.2
Batch: 200; loss: 2.29; acc: 0.16
Batch: 220; loss: 2.3; acc: 0.11
Batch: 240; loss: 2.25; acc: 0.23
Batch: 260; loss: 2.28; acc: 0.16
Batch: 280; loss: 2.29; acc: 0.16
Batch: 300; loss: 2.27; acc: 0.17
Batch: 320; loss: 2.29; acc: 0.16
Batch: 340; loss: 2.26; acc: 0.22
Batch: 360; loss: 2.3; acc: 0.12
Batch: 380; loss: 2.26; acc: 0.22
Batch: 400; loss: 2.26; acc: 0.23
Batch: 420; loss: 2.27; acc: 0.22
Batch: 440; loss: 2.27; acc: 0.17
Batch: 460; loss: 2.26; acc: 0.2
Batch: 480; loss: 2.29; acc: 0.16
Batch: 500; loss: 2.3; acc: 0.14
Batch: 520; loss: 2.25; acc: 0.14
Batch: 540; loss: 2.23; acc: 0.3
Batch: 560; loss: 2.32; acc: 0.11
Batch: 580; loss: 2.28; acc: 0.14
Batch: 600; loss: 2.3; acc: 0.12
Batch: 620; loss: 2.26; acc: 0.16
Batch: 640; loss: 2.27; acc: 0.19
Batch: 660; loss: 2.25; acc: 0.19
Batch: 680; loss: 2.28; acc: 0.12
Batch: 700; loss: 2.24; acc: 0.23
Batch: 720; loss: 2.21; acc: 0.22
Batch: 740; loss: 2.29; acc: 0.14
Batch: 760; loss: 2.26; acc: 0.23
Batch: 780; loss: 2.23; acc: 0.23
Train Epoch over. train_loss: 2.27; train_accuracy: 0.18 

6.274239240156021e-06
2.9732368602708448e-06
Batch: 0; loss: 2.26; acc: 0.19
Batch: 20; loss: 2.23; acc: 0.23
Batch: 40; loss: 2.24; acc: 0.22
Batch: 60; loss: 2.23; acc: 0.2
Batch: 80; loss: 2.24; acc: 0.19
Batch: 100; loss: 2.22; acc: 0.27
Batch: 120; loss: 2.25; acc: 0.2
Batch: 140; loss: 2.26; acc: 0.16
Val Epoch over. val_loss: 2.265091923391743; val_accuracy: 0.1793391719745223 

The current subspace-distance is: 2.9732368602708448e-06 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 2.26; acc: 0.23
Batch: 20; loss: 2.29; acc: 0.16
Batch: 40; loss: 2.28; acc: 0.12
Batch: 60; loss: 2.29; acc: 0.19
Batch: 80; loss: 2.28; acc: 0.17
Batch: 100; loss: 2.27; acc: 0.19
Batch: 120; loss: 2.23; acc: 0.19
Batch: 140; loss: 2.25; acc: 0.28
Batch: 160; loss: 2.23; acc: 0.22
Batch: 180; loss: 2.23; acc: 0.23
Batch: 200; loss: 2.3; acc: 0.19
Batch: 220; loss: 2.26; acc: 0.16
Batch: 240; loss: 2.28; acc: 0.12
Batch: 260; loss: 2.25; acc: 0.23
Batch: 280; loss: 2.24; acc: 0.22
Batch: 300; loss: 2.25; acc: 0.22
Batch: 320; loss: 2.28; acc: 0.17
Batch: 340; loss: 2.29; acc: 0.17
Batch: 360; loss: 2.24; acc: 0.16
Batch: 380; loss: 2.21; acc: 0.25
Batch: 400; loss: 2.3; acc: 0.14
Batch: 420; loss: 2.25; acc: 0.2
Batch: 440; loss: 2.26; acc: 0.17
Batch: 460; loss: 2.26; acc: 0.16
Batch: 480; loss: 2.25; acc: 0.27
Batch: 500; loss: 2.26; acc: 0.22
Batch: 520; loss: 2.25; acc: 0.23
Batch: 540; loss: 2.25; acc: 0.19
Batch: 560; loss: 2.27; acc: 0.19
Batch: 580; loss: 2.22; acc: 0.22
Batch: 600; loss: 2.27; acc: 0.14
Batch: 620; loss: 2.21; acc: 0.23
Batch: 640; loss: 2.2; acc: 0.25
Batch: 660; loss: 2.26; acc: 0.2
Batch: 680; loss: 2.24; acc: 0.2
Batch: 700; loss: 2.27; acc: 0.17
Batch: 720; loss: 2.24; acc: 0.19
Batch: 740; loss: 2.2; acc: 0.27
Batch: 760; loss: 2.27; acc: 0.17
Batch: 780; loss: 2.26; acc: 0.22
Train Epoch over. train_loss: 2.26; train_accuracy: 0.19 

6.481724994955584e-06
2.3565112314827275e-06
Batch: 0; loss: 2.24; acc: 0.17
Batch: 20; loss: 2.21; acc: 0.23
Batch: 40; loss: 2.22; acc: 0.23
Batch: 60; loss: 2.21; acc: 0.23
Batch: 80; loss: 2.23; acc: 0.19
Batch: 100; loss: 2.2; acc: 0.23
Batch: 120; loss: 2.23; acc: 0.3
Batch: 140; loss: 2.25; acc: 0.17
Val Epoch over. val_loss: 2.253922757069776; val_accuracy: 0.19247611464968153 

The current subspace-distance is: 2.3565112314827275e-06 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 2.26; acc: 0.19
Batch: 20; loss: 2.24; acc: 0.22
Batch: 40; loss: 2.2; acc: 0.31
Batch: 60; loss: 2.25; acc: 0.2
Batch: 80; loss: 2.24; acc: 0.25
Batch: 100; loss: 2.24; acc: 0.19
Batch: 120; loss: 2.27; acc: 0.22
Batch: 140; loss: 2.31; acc: 0.05
Batch: 160; loss: 2.24; acc: 0.22
Batch: 180; loss: 2.21; acc: 0.2
Batch: 200; loss: 2.23; acc: 0.31
Batch: 220; loss: 2.26; acc: 0.19
Batch: 240; loss: 2.28; acc: 0.25
Batch: 260; loss: 2.23; acc: 0.27
Batch: 280; loss: 2.27; acc: 0.11
Batch: 300; loss: 2.3; acc: 0.12
Batch: 320; loss: 2.23; acc: 0.17
Batch: 340; loss: 2.21; acc: 0.27
Batch: 360; loss: 2.21; acc: 0.27
Batch: 380; loss: 2.28; acc: 0.17
Batch: 400; loss: 2.23; acc: 0.22
Batch: 420; loss: 2.25; acc: 0.17
Batch: 440; loss: 2.3; acc: 0.14
Batch: 460; loss: 2.22; acc: 0.28
Batch: 480; loss: 2.16; acc: 0.33
Batch: 500; loss: 2.27; acc: 0.19
Batch: 520; loss: 2.23; acc: 0.25
Batch: 540; loss: 2.23; acc: 0.3
Batch: 560; loss: 2.26; acc: 0.23
Batch: 580; loss: 2.22; acc: 0.25
Batch: 600; loss: 2.29; acc: 0.16
Batch: 620; loss: 2.3; acc: 0.16
Batch: 640; loss: 2.25; acc: 0.23
Batch: 660; loss: 2.21; acc: 0.2
Batch: 680; loss: 2.19; acc: 0.36
Batch: 700; loss: 2.26; acc: 0.14
Batch: 720; loss: 2.23; acc: 0.25
Batch: 740; loss: 2.21; acc: 0.3
Batch: 760; loss: 2.21; acc: 0.25
Batch: 780; loss: 2.23; acc: 0.22
Train Epoch over. train_loss: 2.25; train_accuracy: 0.21 

6.620908152399352e-06
3.4188926747447113e-06
Batch: 0; loss: 2.22; acc: 0.23
Batch: 20; loss: 2.19; acc: 0.25
Batch: 40; loss: 2.19; acc: 0.28
Batch: 60; loss: 2.18; acc: 0.25
Batch: 80; loss: 2.21; acc: 0.27
Batch: 100; loss: 2.17; acc: 0.28
Batch: 120; loss: 2.2; acc: 0.31
Batch: 140; loss: 2.23; acc: 0.23
Val Epoch over. val_loss: 2.2367138027385542; val_accuracy: 0.2220342356687898 

The current subspace-distance is: 3.4188926747447113e-06 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 2.21; acc: 0.25
Batch: 20; loss: 2.27; acc: 0.12
Batch: 40; loss: 2.22; acc: 0.27
Batch: 60; loss: 2.21; acc: 0.27
Batch: 80; loss: 2.27; acc: 0.2
Batch: 100; loss: 2.21; acc: 0.33
Batch: 120; loss: 2.21; acc: 0.28
Batch: 140; loss: 2.26; acc: 0.19
Batch: 160; loss: 2.2; acc: 0.3
Batch: 180; loss: 2.23; acc: 0.28
Batch: 200; loss: 2.24; acc: 0.22
Batch: 220; loss: 2.25; acc: 0.2
Batch: 240; loss: 2.22; acc: 0.28
Batch: 260; loss: 2.2; acc: 0.33
Batch: 280; loss: 2.28; acc: 0.25
Batch: 300; loss: 2.22; acc: 0.31
Batch: 320; loss: 2.18; acc: 0.3
Batch: 340; loss: 2.24; acc: 0.16
Batch: 360; loss: 2.24; acc: 0.27
Batch: 380; loss: 2.18; acc: 0.28
Batch: 400; loss: 2.21; acc: 0.2
Batch: 420; loss: 2.27; acc: 0.25
Batch: 440; loss: 2.23; acc: 0.23
Batch: 460; loss: 2.18; acc: 0.23
Batch: 480; loss: 2.22; acc: 0.22
Batch: 500; loss: 2.22; acc: 0.33
Batch: 520; loss: 2.18; acc: 0.28
Batch: 540; loss: 2.21; acc: 0.27
Batch: 560; loss: 2.28; acc: 0.22
Batch: 580; loss: 2.23; acc: 0.27
Batch: 600; loss: 2.17; acc: 0.23
Batch: 620; loss: 2.26; acc: 0.22
Batch: 640; loss: 2.3; acc: 0.19
Batch: 660; loss: 2.2; acc: 0.23
Batch: 680; loss: 2.3; acc: 0.16
Batch: 700; loss: 2.22; acc: 0.22
Batch: 720; loss: 2.31; acc: 0.25
Batch: 740; loss: 2.25; acc: 0.22
Batch: 760; loss: 2.27; acc: 0.2
Batch: 780; loss: 2.16; acc: 0.34
Train Epoch over. train_loss: 2.23; train_accuracy: 0.25 

6.070612016628729e-06
2.296671709700604e-06
Batch: 0; loss: 2.19; acc: 0.3
Batch: 20; loss: 2.17; acc: 0.23
Batch: 40; loss: 2.15; acc: 0.31
Batch: 60; loss: 2.13; acc: 0.36
Batch: 80; loss: 2.19; acc: 0.31
Batch: 100; loss: 2.13; acc: 0.27
Batch: 120; loss: 2.17; acc: 0.34
Batch: 140; loss: 2.2; acc: 0.31
Val Epoch over. val_loss: 2.2138560380146; val_accuracy: 0.26025079617834396 

The current subspace-distance is: 2.296671709700604e-06 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 2.31; acc: 0.2
Batch: 20; loss: 2.19; acc: 0.23
Batch: 40; loss: 2.16; acc: 0.25
Batch: 60; loss: 2.23; acc: 0.28
Batch: 80; loss: 2.19; acc: 0.31
Batch: 100; loss: 2.14; acc: 0.28
Batch: 120; loss: 2.18; acc: 0.31
Batch: 140; loss: 2.21; acc: 0.22
Batch: 160; loss: 2.21; acc: 0.33
Batch: 180; loss: 2.22; acc: 0.27
Batch: 200; loss: 2.22; acc: 0.22
Batch: 220; loss: 2.15; acc: 0.34
Batch: 240; loss: 2.22; acc: 0.31
Batch: 260; loss: 2.23; acc: 0.27
Batch: 280; loss: 2.3; acc: 0.19
Batch: 300; loss: 2.3; acc: 0.23
Batch: 320; loss: 2.14; acc: 0.31
Batch: 340; loss: 2.13; acc: 0.36
Batch: 360; loss: 2.23; acc: 0.28
Batch: 380; loss: 2.21; acc: 0.17
Batch: 400; loss: 2.23; acc: 0.25
Batch: 420; loss: 2.17; acc: 0.27
Batch: 440; loss: 2.34; acc: 0.19
Batch: 460; loss: 2.22; acc: 0.27
Batch: 480; loss: 2.28; acc: 0.28
Batch: 500; loss: 2.2; acc: 0.25
Batch: 520; loss: 2.22; acc: 0.25
Batch: 540; loss: 2.19; acc: 0.27
Batch: 560; loss: 2.15; acc: 0.31
Batch: 580; loss: 2.27; acc: 0.22
Batch: 600; loss: 2.14; acc: 0.34
Batch: 620; loss: 2.19; acc: 0.2
Batch: 640; loss: 2.26; acc: 0.27
Batch: 660; loss: 2.13; acc: 0.31
Batch: 680; loss: 2.33; acc: 0.19
Batch: 700; loss: 2.18; acc: 0.33
Batch: 720; loss: 2.19; acc: 0.27
Batch: 740; loss: 2.15; acc: 0.28
Batch: 760; loss: 2.17; acc: 0.27
Batch: 780; loss: 2.16; acc: 0.3
Train Epoch over. train_loss: 2.21; train_accuracy: 0.26 

7.593670943606412e-06
3.059258233406581e-06
Batch: 0; loss: 2.15; acc: 0.34
Batch: 20; loss: 2.15; acc: 0.25
Batch: 40; loss: 2.11; acc: 0.36
Batch: 60; loss: 2.09; acc: 0.38
Batch: 80; loss: 2.17; acc: 0.25
Batch: 100; loss: 2.08; acc: 0.27
Batch: 120; loss: 2.15; acc: 0.31
Batch: 140; loss: 2.18; acc: 0.34
Val Epoch over. val_loss: 2.193551327772201; val_accuracy: 0.26681926751592355 

The current subspace-distance is: 3.059258233406581e-06 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 2.21; acc: 0.19
Batch: 20; loss: 2.24; acc: 0.27
Batch: 40; loss: 2.11; acc: 0.3
Batch: 60; loss: 2.19; acc: 0.25
Batch: 80; loss: 2.13; acc: 0.34
Batch: 100; loss: 2.12; acc: 0.33
Batch: 120; loss: 2.25; acc: 0.22
Batch: 140; loss: 2.23; acc: 0.27
Batch: 160; loss: 2.25; acc: 0.25
Batch: 180; loss: 2.17; acc: 0.27
Batch: 200; loss: 2.19; acc: 0.31
Batch: 220; loss: 2.14; acc: 0.28
Batch: 240; loss: 2.19; acc: 0.27
Batch: 260; loss: 2.22; acc: 0.27
Batch: 280; loss: 2.19; acc: 0.27
Batch: 300; loss: 2.24; acc: 0.31
Batch: 320; loss: 2.06; acc: 0.34
Batch: 340; loss: 2.22; acc: 0.27
Batch: 360; loss: 2.17; acc: 0.3
Batch: 380; loss: 2.23; acc: 0.2
Batch: 400; loss: 2.23; acc: 0.27
Batch: 420; loss: 2.1; acc: 0.38
Batch: 440; loss: 2.24; acc: 0.28
Batch: 460; loss: 2.17; acc: 0.28
Batch: 480; loss: 2.2; acc: 0.27
Batch: 500; loss: 2.23; acc: 0.25
Batch: 520; loss: 2.24; acc: 0.17
Batch: 540; loss: 2.18; acc: 0.23
Batch: 560; loss: 2.22; acc: 0.22
Batch: 580; loss: 2.18; acc: 0.23
Batch: 600; loss: 2.18; acc: 0.22
Batch: 620; loss: 2.12; acc: 0.3
Batch: 640; loss: 2.16; acc: 0.23
Batch: 660; loss: 2.21; acc: 0.28
Batch: 680; loss: 2.14; acc: 0.28
Batch: 700; loss: 2.04; acc: 0.41
Batch: 720; loss: 2.2; acc: 0.31
Batch: 740; loss: 2.21; acc: 0.22
Batch: 760; loss: 2.12; acc: 0.34
Batch: 780; loss: 2.17; acc: 0.25
Train Epoch over. train_loss: 2.19; train_accuracy: 0.26 

1.0627351002767682e-05
2.04613047571911e-06
Batch: 0; loss: 2.13; acc: 0.34
Batch: 20; loss: 2.13; acc: 0.25
Batch: 40; loss: 2.09; acc: 0.38
Batch: 60; loss: 2.06; acc: 0.33
Batch: 80; loss: 2.15; acc: 0.27
Batch: 100; loss: 2.05; acc: 0.3
Batch: 120; loss: 2.13; acc: 0.34
Batch: 140; loss: 2.16; acc: 0.33
Val Epoch over. val_loss: 2.179200098013422; val_accuracy: 0.24751194267515925 

The current subspace-distance is: 2.04613047571911e-06 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 2.08; acc: 0.33
Batch: 20; loss: 2.21; acc: 0.25
Batch: 40; loss: 2.31; acc: 0.11
Batch: 60; loss: 2.13; acc: 0.27
Batch: 80; loss: 2.14; acc: 0.27
Batch: 100; loss: 2.24; acc: 0.12
Batch: 120; loss: 2.23; acc: 0.2
Batch: 140; loss: 2.2; acc: 0.25
Batch: 160; loss: 2.16; acc: 0.25
Batch: 180; loss: 2.11; acc: 0.3
Batch: 200; loss: 2.25; acc: 0.16
Batch: 220; loss: 2.12; acc: 0.27
Batch: 240; loss: 2.24; acc: 0.2
Batch: 260; loss: 2.16; acc: 0.2
Batch: 280; loss: 2.2; acc: 0.22
Batch: 300; loss: 2.17; acc: 0.19
Batch: 320; loss: 2.19; acc: 0.19
Batch: 340; loss: 2.22; acc: 0.22
Batch: 360; loss: 2.2; acc: 0.2
Batch: 380; loss: 2.25; acc: 0.22
Batch: 400; loss: 2.27; acc: 0.17
Batch: 420; loss: 2.15; acc: 0.31
Batch: 440; loss: 2.17; acc: 0.25
Batch: 460; loss: 2.15; acc: 0.22
Batch: 480; loss: 2.21; acc: 0.23
Batch: 500; loss: 2.19; acc: 0.27
Batch: 520; loss: 2.06; acc: 0.31
Batch: 540; loss: 2.19; acc: 0.23
Batch: 560; loss: 2.13; acc: 0.25
Batch: 580; loss: 2.26; acc: 0.17
Batch: 600; loss: 2.13; acc: 0.23
Batch: 620; loss: 2.09; acc: 0.28
Batch: 640; loss: 2.08; acc: 0.31
Batch: 660; loss: 2.05; acc: 0.38
Batch: 680; loss: 2.18; acc: 0.22
Batch: 700; loss: 2.15; acc: 0.27
Batch: 720; loss: 2.14; acc: 0.3
Batch: 740; loss: 2.18; acc: 0.25
Batch: 760; loss: 2.13; acc: 0.2
Batch: 780; loss: 2.21; acc: 0.2
Train Epoch over. train_loss: 2.18; train_accuracy: 0.24 

7.607646693941206e-06
4.060672381456243e-06
Batch: 0; loss: 2.11; acc: 0.25
Batch: 20; loss: 2.12; acc: 0.25
Batch: 40; loss: 2.07; acc: 0.28
Batch: 60; loss: 2.05; acc: 0.27
Batch: 80; loss: 2.14; acc: 0.25
Batch: 100; loss: 2.02; acc: 0.33
Batch: 120; loss: 2.12; acc: 0.28
Batch: 140; loss: 2.14; acc: 0.27
Val Epoch over. val_loss: 2.1660569974571278; val_accuracy: 0.23417595541401273 

The current subspace-distance is: 4.060672381456243e-06 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 2.17; acc: 0.16
Batch: 20; loss: 2.18; acc: 0.25
Batch: 40; loss: 2.1; acc: 0.28
Batch: 60; loss: 2.18; acc: 0.27
Batch: 80; loss: 2.17; acc: 0.23
Batch: 100; loss: 2.15; acc: 0.25
Batch: 120; loss: 2.24; acc: 0.19
Batch: 140; loss: 2.27; acc: 0.17
Batch: 160; loss: 2.19; acc: 0.22
Batch: 180; loss: 2.11; acc: 0.23
Batch: 200; loss: 2.13; acc: 0.25
Batch: 220; loss: 2.13; acc: 0.23
Batch: 240; loss: 2.17; acc: 0.2
Batch: 260; loss: 2.16; acc: 0.3
Batch: 280; loss: 2.27; acc: 0.19
Batch: 300; loss: 2.1; acc: 0.31
Batch: 320; loss: 2.2; acc: 0.19
Batch: 340; loss: 2.31; acc: 0.14
Batch: 360; loss: 2.13; acc: 0.27
Batch: 380; loss: 2.12; acc: 0.28
Batch: 400; loss: 2.32; acc: 0.14
Batch: 420; loss: 2.12; acc: 0.25
Batch: 440; loss: 2.2; acc: 0.25
Batch: 460; loss: 2.16; acc: 0.27
Batch: 480; loss: 2.11; acc: 0.22
Batch: 500; loss: 2.15; acc: 0.22
Batch: 520; loss: 2.07; acc: 0.27
Batch: 540; loss: 2.13; acc: 0.28
Batch: 560; loss: 2.1; acc: 0.27
Batch: 580; loss: 2.1; acc: 0.33
Batch: 600; loss: 2.13; acc: 0.3
Batch: 620; loss: 2.12; acc: 0.23
Batch: 640; loss: 2.08; acc: 0.28
Batch: 660; loss: 2.23; acc: 0.16
Batch: 680; loss: 2.1; acc: 0.2
Batch: 700; loss: 2.16; acc: 0.23
Batch: 720; loss: 2.13; acc: 0.23
Batch: 740; loss: 2.06; acc: 0.27
Batch: 760; loss: 2.08; acc: 0.33
Batch: 780; loss: 2.24; acc: 0.16
Train Epoch over. train_loss: 2.17; train_accuracy: 0.23 

1.0440508049214259e-05
2.8951671993127093e-06
Batch: 0; loss: 2.11; acc: 0.23
Batch: 20; loss: 2.12; acc: 0.23
Batch: 40; loss: 2.05; acc: 0.25
Batch: 60; loss: 2.03; acc: 0.31
Batch: 80; loss: 2.13; acc: 0.25
Batch: 100; loss: 2.0; acc: 0.34
Batch: 120; loss: 2.1; acc: 0.27
Batch: 140; loss: 2.12; acc: 0.23
Val Epoch over. val_loss: 2.156863470745694; val_accuracy: 0.23636544585987262 

The current subspace-distance is: 2.8951671993127093e-06 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 2.04; acc: 0.3
Batch: 20; loss: 2.14; acc: 0.27
Batch: 40; loss: 2.2; acc: 0.2
Batch: 60; loss: 2.1; acc: 0.3
Batch: 80; loss: 2.23; acc: 0.16
Batch: 100; loss: 2.25; acc: 0.16
Batch: 120; loss: 2.2; acc: 0.25
Batch: 140; loss: 2.18; acc: 0.23
Batch: 160; loss: 2.16; acc: 0.23
Batch: 180; loss: 2.24; acc: 0.16
Batch: 200; loss: 2.16; acc: 0.23
Batch: 220; loss: 2.09; acc: 0.28
Batch: 240; loss: 2.18; acc: 0.27
Batch: 260; loss: 2.19; acc: 0.19
Batch: 280; loss: 2.17; acc: 0.27
Batch: 300; loss: 2.17; acc: 0.25
Batch: 320; loss: 2.04; acc: 0.31
Batch: 340; loss: 2.15; acc: 0.28
Batch: 360; loss: 2.14; acc: 0.23
Batch: 380; loss: 2.19; acc: 0.19
Batch: 400; loss: 2.19; acc: 0.22
Batch: 420; loss: 2.16; acc: 0.23
Batch: 440; loss: 2.29; acc: 0.17
Batch: 460; loss: 2.21; acc: 0.22
Batch: 480; loss: 2.09; acc: 0.25
Batch: 500; loss: 2.05; acc: 0.34
Batch: 520; loss: 2.26; acc: 0.27
Batch: 540; loss: 2.18; acc: 0.2
Batch: 560; loss: 2.17; acc: 0.27
Batch: 580; loss: 2.25; acc: 0.14
Batch: 600; loss: 2.2; acc: 0.17
Batch: 620; loss: 2.18; acc: 0.16
Batch: 640; loss: 2.19; acc: 0.22
Batch: 660; loss: 2.16; acc: 0.2
Batch: 680; loss: 2.11; acc: 0.23
Batch: 700; loss: 2.04; acc: 0.3
Batch: 720; loss: 2.14; acc: 0.23
Batch: 740; loss: 2.14; acc: 0.19
Batch: 760; loss: 2.26; acc: 0.12
Batch: 780; loss: 2.12; acc: 0.28
Train Epoch over. train_loss: 2.16; train_accuracy: 0.23 

9.70893870544387e-06
3.823008682957152e-06
Batch: 0; loss: 2.11; acc: 0.22
Batch: 20; loss: 2.11; acc: 0.23
Batch: 40; loss: 2.05; acc: 0.28
Batch: 60; loss: 2.02; acc: 0.28
Batch: 80; loss: 2.12; acc: 0.25
Batch: 100; loss: 1.99; acc: 0.36
Batch: 120; loss: 2.1; acc: 0.25
Batch: 140; loss: 2.12; acc: 0.23
Val Epoch over. val_loss: 2.1519490138740296; val_accuracy: 0.2402468152866242 

The current subspace-distance is: 3.823008682957152e-06 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 2.23; acc: 0.16
Batch: 20; loss: 2.15; acc: 0.23
Batch: 40; loss: 2.12; acc: 0.28
Batch: 60; loss: 2.23; acc: 0.16
Batch: 80; loss: 2.15; acc: 0.22
Batch: 100; loss: 2.15; acc: 0.25
Batch: 120; loss: 2.08; acc: 0.25
Batch: 140; loss: 2.12; acc: 0.28
Batch: 160; loss: 2.21; acc: 0.19
Batch: 180; loss: 2.19; acc: 0.2
Batch: 200; loss: 2.26; acc: 0.12
Batch: 220; loss: 2.21; acc: 0.25
Batch: 240; loss: 2.16; acc: 0.25
Batch: 260; loss: 2.1; acc: 0.38
Batch: 280; loss: 2.2; acc: 0.22
Batch: 300; loss: 2.14; acc: 0.2
Batch: 320; loss: 2.16; acc: 0.27
Batch: 340; loss: 2.1; acc: 0.33
Batch: 360; loss: 2.18; acc: 0.17
Batch: 380; loss: 2.18; acc: 0.2
Batch: 400; loss: 2.1; acc: 0.33
Batch: 420; loss: 2.09; acc: 0.28
Batch: 440; loss: 2.25; acc: 0.14
Batch: 460; loss: 2.18; acc: 0.2
Batch: 480; loss: 2.17; acc: 0.25
Batch: 500; loss: 2.21; acc: 0.23
Batch: 520; loss: 2.09; acc: 0.31
Batch: 540; loss: 2.13; acc: 0.28
Batch: 560; loss: 2.14; acc: 0.28
Batch: 580; loss: 2.07; acc: 0.3
Batch: 600; loss: 2.19; acc: 0.2
Batch: 620; loss: 2.2; acc: 0.19
Batch: 640; loss: 2.19; acc: 0.25
Batch: 660; loss: 2.14; acc: 0.3
Batch: 680; loss: 2.21; acc: 0.25
Batch: 700; loss: 2.18; acc: 0.23
Batch: 720; loss: 2.18; acc: 0.23
Batch: 740; loss: 2.28; acc: 0.17
Batch: 760; loss: 2.17; acc: 0.23
Batch: 780; loss: 2.11; acc: 0.27
Train Epoch over. train_loss: 2.16; train_accuracy: 0.23 

7.746300980215892e-06
4.83539361084695e-06
Batch: 0; loss: 2.12; acc: 0.19
Batch: 20; loss: 2.11; acc: 0.23
Batch: 40; loss: 2.05; acc: 0.28
Batch: 60; loss: 2.02; acc: 0.28
Batch: 80; loss: 2.12; acc: 0.23
Batch: 100; loss: 1.98; acc: 0.33
Batch: 120; loss: 2.1; acc: 0.27
Batch: 140; loss: 2.12; acc: 0.22
Val Epoch over. val_loss: 2.1489364387123446; val_accuracy: 0.23964968152866242 

The current subspace-distance is: 4.83539361084695e-06 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 2.23; acc: 0.23
Batch: 20; loss: 1.93; acc: 0.41
Batch: 40; loss: 2.21; acc: 0.23
Batch: 60; loss: 2.15; acc: 0.19
Batch: 80; loss: 2.14; acc: 0.28
Batch: 100; loss: 2.21; acc: 0.2
Batch: 120; loss: 2.11; acc: 0.27
Batch: 140; loss: 2.16; acc: 0.2
Batch: 160; loss: 2.1; acc: 0.3
Batch: 180; loss: 2.16; acc: 0.27
Batch: 200; loss: 2.15; acc: 0.27
Batch: 220; loss: 2.12; acc: 0.23
Batch: 240; loss: 2.06; acc: 0.34
Batch: 260; loss: 2.11; acc: 0.31
Batch: 280; loss: 2.08; acc: 0.25
Batch: 300; loss: 2.18; acc: 0.16
Batch: 320; loss: 2.19; acc: 0.14
Batch: 340; loss: 2.07; acc: 0.27
Batch: 360; loss: 2.17; acc: 0.22
Batch: 380; loss: 2.18; acc: 0.17
Batch: 400; loss: 2.16; acc: 0.2
Batch: 420; loss: 2.26; acc: 0.17
Batch: 440; loss: 2.12; acc: 0.23
Batch: 460; loss: 2.2; acc: 0.17
Batch: 480; loss: 2.24; acc: 0.12
Batch: 500; loss: 2.17; acc: 0.25
Batch: 520; loss: 2.12; acc: 0.25
Batch: 540; loss: 2.17; acc: 0.27
Batch: 560; loss: 2.11; acc: 0.23
Batch: 580; loss: 2.09; acc: 0.23
Batch: 600; loss: 2.25; acc: 0.22
Batch: 620; loss: 2.16; acc: 0.25
Batch: 640; loss: 2.23; acc: 0.16
Batch: 660; loss: 2.12; acc: 0.25
Batch: 680; loss: 2.12; acc: 0.25
Batch: 700; loss: 2.09; acc: 0.25
Batch: 720; loss: 2.19; acc: 0.14
Batch: 740; loss: 2.22; acc: 0.17
Batch: 760; loss: 2.15; acc: 0.27
Batch: 780; loss: 2.21; acc: 0.23
Train Epoch over. train_loss: 2.15; train_accuracy: 0.23 

5.5664572755631525e-06
2.0720017346320674e-06
Batch: 0; loss: 2.12; acc: 0.2
Batch: 20; loss: 2.11; acc: 0.23
Batch: 40; loss: 2.05; acc: 0.3
Batch: 60; loss: 2.02; acc: 0.3
Batch: 80; loss: 2.12; acc: 0.23
Batch: 100; loss: 1.98; acc: 0.34
Batch: 120; loss: 2.09; acc: 0.28
Batch: 140; loss: 2.12; acc: 0.23
Val Epoch over. val_loss: 2.1478747030731977; val_accuracy: 0.24004777070063693 

The current subspace-distance is: 2.0720017346320674e-06 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 2.26; acc: 0.22
Batch: 20; loss: 2.12; acc: 0.22
Batch: 40; loss: 2.16; acc: 0.28
Batch: 60; loss: 2.11; acc: 0.31
Batch: 80; loss: 2.11; acc: 0.27
Batch: 100; loss: 2.09; acc: 0.19
Batch: 120; loss: 2.19; acc: 0.2
Batch: 140; loss: 2.11; acc: 0.28
Batch: 160; loss: 2.19; acc: 0.22
Batch: 180; loss: 2.17; acc: 0.2
Batch: 200; loss: 2.27; acc: 0.17
Batch: 220; loss: 2.11; acc: 0.3
Batch: 240; loss: 2.22; acc: 0.23
Batch: 260; loss: 2.15; acc: 0.28
Batch: 280; loss: 2.19; acc: 0.28
Batch: 300; loss: 2.14; acc: 0.19
Batch: 320; loss: 2.21; acc: 0.2
Batch: 340; loss: 2.17; acc: 0.22
Batch: 360; loss: 2.1; acc: 0.3
Batch: 380; loss: 2.29; acc: 0.2
Batch: 400; loss: 2.15; acc: 0.2
Batch: 420; loss: 2.07; acc: 0.3
Batch: 440; loss: 2.21; acc: 0.23
Batch: 460; loss: 2.21; acc: 0.23
Batch: 480; loss: 2.27; acc: 0.19
Batch: 500; loss: 2.22; acc: 0.19
Batch: 520; loss: 2.18; acc: 0.28
Batch: 540; loss: 2.17; acc: 0.27
Batch: 560; loss: 2.03; acc: 0.3
Batch: 580; loss: 2.19; acc: 0.19
Batch: 600; loss: 2.23; acc: 0.2
Batch: 620; loss: 2.03; acc: 0.33
Batch: 640; loss: 2.15; acc: 0.2
Batch: 660; loss: 2.06; acc: 0.28
Batch: 680; loss: 2.13; acc: 0.22
Batch: 700; loss: 2.22; acc: 0.16
Batch: 720; loss: 2.17; acc: 0.19
Batch: 740; loss: 2.08; acc: 0.3
Batch: 760; loss: 2.08; acc: 0.27
Batch: 780; loss: 2.25; acc: 0.17
Train Epoch over. train_loss: 2.15; train_accuracy: 0.23 

1.0564217518549412e-05
1.1819682868008385e-06
Batch: 0; loss: 2.12; acc: 0.2
Batch: 20; loss: 2.12; acc: 0.23
Batch: 40; loss: 2.05; acc: 0.3
Batch: 60; loss: 2.02; acc: 0.28
Batch: 80; loss: 2.12; acc: 0.23
Batch: 100; loss: 1.98; acc: 0.34
Batch: 120; loss: 2.09; acc: 0.28
Batch: 140; loss: 2.12; acc: 0.23
Val Epoch over. val_loss: 2.146975434509812; val_accuracy: 0.24144108280254778 

The current subspace-distance is: 1.1819682868008385e-06 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 2.31; acc: 0.11
Batch: 20; loss: 2.14; acc: 0.27
Batch: 40; loss: 2.19; acc: 0.17
Batch: 60; loss: 2.19; acc: 0.25
Batch: 80; loss: 2.15; acc: 0.2
Batch: 100; loss: 2.15; acc: 0.28
Batch: 120; loss: 2.2; acc: 0.2
Batch: 140; loss: 2.22; acc: 0.17
Batch: 160; loss: 2.22; acc: 0.17
Batch: 180; loss: 2.18; acc: 0.2
Batch: 200; loss: 2.14; acc: 0.22
Batch: 220; loss: 2.28; acc: 0.17
Batch: 240; loss: 2.22; acc: 0.2
Batch: 260; loss: 2.26; acc: 0.19
Batch: 280; loss: 2.13; acc: 0.25
Batch: 300; loss: 2.2; acc: 0.19
Batch: 320; loss: 2.1; acc: 0.33
Batch: 340; loss: 2.17; acc: 0.19
Batch: 360; loss: 2.18; acc: 0.25
Batch: 380; loss: 2.1; acc: 0.23
Batch: 400; loss: 2.07; acc: 0.3
Batch: 420; loss: 2.01; acc: 0.31
Batch: 440; loss: 2.01; acc: 0.33
Batch: 460; loss: 2.17; acc: 0.25
Batch: 480; loss: 2.14; acc: 0.28
Batch: 500; loss: 2.21; acc: 0.17
Batch: 520; loss: 2.2; acc: 0.14
Batch: 540; loss: 2.26; acc: 0.11
Batch: 560; loss: 2.12; acc: 0.23
Batch: 580; loss: 2.2; acc: 0.22
Batch: 600; loss: 2.07; acc: 0.23
Batch: 620; loss: 2.17; acc: 0.16
Batch: 640; loss: 2.13; acc: 0.23
Batch: 660; loss: 2.05; acc: 0.31
Batch: 680; loss: 2.17; acc: 0.2
Batch: 700; loss: 2.17; acc: 0.23
Batch: 720; loss: 2.11; acc: 0.3
Batch: 740; loss: 2.1; acc: 0.25
Batch: 760; loss: 2.14; acc: 0.25
Batch: 780; loss: 2.11; acc: 0.27
Train Epoch over. train_loss: 2.15; train_accuracy: 0.23 

9.329682143288665e-06
1.1284371339570498e-06
Batch: 0; loss: 2.12; acc: 0.17
Batch: 20; loss: 2.12; acc: 0.23
Batch: 40; loss: 2.05; acc: 0.31
Batch: 60; loss: 2.01; acc: 0.28
Batch: 80; loss: 2.11; acc: 0.23
Batch: 100; loss: 1.98; acc: 0.34
Batch: 120; loss: 2.09; acc: 0.28
Batch: 140; loss: 2.12; acc: 0.23
Val Epoch over. val_loss: 2.146218482096484; val_accuracy: 0.24094347133757962 

The current subspace-distance is: 1.1284371339570498e-06 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 2.18; acc: 0.16
Batch: 20; loss: 2.13; acc: 0.27
Batch: 40; loss: 2.22; acc: 0.27
Batch: 60; loss: 2.1; acc: 0.23
Batch: 80; loss: 2.19; acc: 0.27
Batch: 100; loss: 2.32; acc: 0.12
Batch: 120; loss: 2.15; acc: 0.22
Batch: 140; loss: 2.12; acc: 0.28
Batch: 160; loss: 2.2; acc: 0.16
Batch: 180; loss: 2.2; acc: 0.2
Batch: 200; loss: 2.08; acc: 0.33
Batch: 220; loss: 2.24; acc: 0.19
Batch: 240; loss: 2.22; acc: 0.2
Batch: 260; loss: 2.16; acc: 0.23
Batch: 280; loss: 2.24; acc: 0.14
Batch: 300; loss: 2.08; acc: 0.28
Batch: 320; loss: 2.09; acc: 0.23
Batch: 340; loss: 2.19; acc: 0.19
Batch: 360; loss: 2.1; acc: 0.27
Batch: 380; loss: 2.17; acc: 0.2
Batch: 400; loss: 2.14; acc: 0.2
Batch: 420; loss: 2.19; acc: 0.17
Batch: 440; loss: 2.18; acc: 0.23
Batch: 460; loss: 2.13; acc: 0.22
Batch: 480; loss: 2.04; acc: 0.33
Batch: 500; loss: 2.1; acc: 0.25
Batch: 520; loss: 2.06; acc: 0.28
Batch: 540; loss: 2.09; acc: 0.23
Batch: 560; loss: 2.18; acc: 0.19
Batch: 580; loss: 2.24; acc: 0.23
Batch: 600; loss: 2.12; acc: 0.25
Batch: 620; loss: 2.21; acc: 0.14
Batch: 640; loss: 2.21; acc: 0.22
Batch: 660; loss: 2.16; acc: 0.2
Batch: 680; loss: 2.21; acc: 0.28
Batch: 700; loss: 2.16; acc: 0.2
Batch: 720; loss: 2.2; acc: 0.22
Batch: 740; loss: 2.03; acc: 0.31
Batch: 760; loss: 2.05; acc: 0.28
Batch: 780; loss: 2.26; acc: 0.17
Train Epoch over. train_loss: 2.15; train_accuracy: 0.23 

1.2593785868375562e-05
3.381381702638464e-06
Batch: 0; loss: 2.12; acc: 0.16
Batch: 20; loss: 2.12; acc: 0.23
Batch: 40; loss: 2.05; acc: 0.31
Batch: 60; loss: 2.01; acc: 0.28
Batch: 80; loss: 2.11; acc: 0.25
Batch: 100; loss: 1.98; acc: 0.34
Batch: 120; loss: 2.09; acc: 0.28
Batch: 140; loss: 2.12; acc: 0.23
Val Epoch over. val_loss: 2.1456118062802942; val_accuracy: 0.2398487261146497 

The current subspace-distance is: 3.381381702638464e-06 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 2.13; acc: 0.23
Batch: 20; loss: 2.16; acc: 0.19
Batch: 40; loss: 2.17; acc: 0.14
Batch: 60; loss: 2.11; acc: 0.23
Batch: 80; loss: 2.08; acc: 0.28
Batch: 100; loss: 2.08; acc: 0.27
Batch: 120; loss: 2.14; acc: 0.22
Batch: 140; loss: 2.02; acc: 0.28
Batch: 160; loss: 2.06; acc: 0.3
Batch: 180; loss: 2.22; acc: 0.16
Batch: 200; loss: 2.12; acc: 0.28
Batch: 220; loss: 2.15; acc: 0.25
Batch: 240; loss: 2.09; acc: 0.28
Batch: 260; loss: 2.2; acc: 0.2
Batch: 280; loss: 2.2; acc: 0.17
Batch: 300; loss: 2.03; acc: 0.33
Batch: 320; loss: 2.22; acc: 0.16
Batch: 340; loss: 2.1; acc: 0.27
Batch: 360; loss: 2.15; acc: 0.27
Batch: 380; loss: 2.1; acc: 0.23
Batch: 400; loss: 2.19; acc: 0.23
Batch: 420; loss: 2.05; acc: 0.3
Batch: 440; loss: 2.2; acc: 0.22
Batch: 460; loss: 2.21; acc: 0.2
Batch: 480; loss: 2.1; acc: 0.25
Batch: 500; loss: 2.15; acc: 0.22
Batch: 520; loss: 2.22; acc: 0.22
Batch: 540; loss: 2.16; acc: 0.2
Batch: 560; loss: 2.11; acc: 0.3
Batch: 580; loss: 2.05; acc: 0.25
Batch: 600; loss: 2.22; acc: 0.17
Batch: 620; loss: 2.13; acc: 0.22
Batch: 640; loss: 2.24; acc: 0.17
Batch: 660; loss: 2.16; acc: 0.22
Batch: 680; loss: 2.12; acc: 0.27
Batch: 700; loss: 2.16; acc: 0.28
Batch: 720; loss: 2.12; acc: 0.25
Batch: 740; loss: 2.17; acc: 0.23
Batch: 760; loss: 2.07; acc: 0.33
Batch: 780; loss: 2.13; acc: 0.23
Train Epoch over. train_loss: 2.15; train_accuracy: 0.23 

1.0792331522679888e-05
5.785168468719348e-06
Batch: 0; loss: 2.12; acc: 0.16
Batch: 20; loss: 2.12; acc: 0.23
Batch: 40; loss: 2.05; acc: 0.33
Batch: 60; loss: 2.01; acc: 0.28
Batch: 80; loss: 2.11; acc: 0.23
Batch: 100; loss: 1.98; acc: 0.34
Batch: 120; loss: 2.09; acc: 0.28
Batch: 140; loss: 2.12; acc: 0.23
Val Epoch over. val_loss: 2.1452054491468298; val_accuracy: 0.23935111464968153 

The current subspace-distance is: 5.785168468719348e-06 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 2.21; acc: 0.23
Batch: 20; loss: 2.18; acc: 0.27
Batch: 40; loss: 2.23; acc: 0.23
Batch: 60; loss: 2.21; acc: 0.12
Batch: 80; loss: 2.2; acc: 0.23
Batch: 100; loss: 2.16; acc: 0.2
Batch: 120; loss: 2.14; acc: 0.22
Batch: 140; loss: 2.06; acc: 0.25
Batch: 160; loss: 2.16; acc: 0.28
Batch: 180; loss: 2.13; acc: 0.25
Batch: 200; loss: 2.23; acc: 0.19
Batch: 220; loss: 2.12; acc: 0.27
Batch: 240; loss: 2.16; acc: 0.22
Batch: 260; loss: 2.1; acc: 0.25
Batch: 280; loss: 2.07; acc: 0.31
Batch: 300; loss: 2.26; acc: 0.2
Batch: 320; loss: 2.16; acc: 0.17
Batch: 340; loss: 2.18; acc: 0.2
Batch: 360; loss: 2.14; acc: 0.23
Batch: 380; loss: 2.15; acc: 0.25
Batch: 400; loss: 2.04; acc: 0.34
Batch: 420; loss: 2.28; acc: 0.11
Batch: 440; loss: 2.14; acc: 0.25
Batch: 460; loss: 2.16; acc: 0.27
Batch: 480; loss: 2.03; acc: 0.25
Batch: 500; loss: 2.18; acc: 0.22
Batch: 520; loss: 2.17; acc: 0.27
Batch: 540; loss: 2.08; acc: 0.27
Batch: 560; loss: 2.12; acc: 0.27
Batch: 580; loss: 2.05; acc: 0.31
Batch: 600; loss: 2.19; acc: 0.17
Batch: 620; loss: 2.21; acc: 0.16
Batch: 640; loss: 2.04; acc: 0.25
Batch: 660; loss: 2.21; acc: 0.2
Batch: 680; loss: 2.18; acc: 0.19
Batch: 700; loss: 2.19; acc: 0.25
Batch: 720; loss: 2.23; acc: 0.19
Batch: 740; loss: 2.24; acc: 0.14
Batch: 760; loss: 2.1; acc: 0.28
Batch: 780; loss: 2.11; acc: 0.23
Train Epoch over. train_loss: 2.15; train_accuracy: 0.23 

1.5856101526878774e-05
3.806342647294514e-06
Batch: 0; loss: 2.12; acc: 0.17
Batch: 20; loss: 2.12; acc: 0.23
Batch: 40; loss: 2.05; acc: 0.33
Batch: 60; loss: 2.01; acc: 0.28
Batch: 80; loss: 2.11; acc: 0.23
Batch: 100; loss: 1.98; acc: 0.34
Batch: 120; loss: 2.09; acc: 0.28
Batch: 140; loss: 2.12; acc: 0.25
Val Epoch over. val_loss: 2.144917036317716; val_accuracy: 0.2385549363057325 

The current subspace-distance is: 3.806342647294514e-06 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 2.09; acc: 0.3
Batch: 20; loss: 2.23; acc: 0.17
Batch: 40; loss: 2.05; acc: 0.31
Batch: 60; loss: 2.14; acc: 0.22
Batch: 80; loss: 2.06; acc: 0.27
Batch: 100; loss: 2.04; acc: 0.23
Batch: 120; loss: 2.3; acc: 0.17
Batch: 140; loss: 2.28; acc: 0.14
Batch: 160; loss: 2.23; acc: 0.22
Batch: 180; loss: 2.14; acc: 0.22
Batch: 200; loss: 2.19; acc: 0.25
Batch: 220; loss: 2.17; acc: 0.12
Batch: 240; loss: 2.03; acc: 0.31
Batch: 260; loss: 2.07; acc: 0.31
Batch: 280; loss: 2.12; acc: 0.23
Batch: 300; loss: 2.21; acc: 0.22
Batch: 320; loss: 2.18; acc: 0.17
Batch: 340; loss: 2.18; acc: 0.2
Batch: 360; loss: 2.11; acc: 0.27
Batch: 380; loss: 2.17; acc: 0.19
Batch: 400; loss: 2.19; acc: 0.2
Batch: 420; loss: 2.16; acc: 0.25
Batch: 440; loss: 2.05; acc: 0.27
Batch: 460; loss: 2.06; acc: 0.22
Batch: 480; loss: 2.2; acc: 0.22
Batch: 500; loss: 2.24; acc: 0.16
Batch: 520; loss: 2.06; acc: 0.3
Batch: 540; loss: 2.14; acc: 0.2
Batch: 560; loss: 2.07; acc: 0.27
Batch: 580; loss: 2.16; acc: 0.25
Batch: 600; loss: 2.21; acc: 0.22
Batch: 620; loss: 2.0; acc: 0.28
Batch: 640; loss: 2.18; acc: 0.2
Batch: 660; loss: 2.14; acc: 0.23
Batch: 680; loss: 2.09; acc: 0.19
Batch: 700; loss: 2.11; acc: 0.23
Batch: 720; loss: 2.18; acc: 0.2
Batch: 740; loss: 2.24; acc: 0.19
Batch: 760; loss: 2.16; acc: 0.25
Batch: 780; loss: 2.16; acc: 0.23
Train Epoch over. train_loss: 2.15; train_accuracy: 0.23 

9.704564945423044e-06
6.158449195936555e-06
Batch: 0; loss: 2.12; acc: 0.17
Batch: 20; loss: 2.12; acc: 0.23
Batch: 40; loss: 2.05; acc: 0.33
Batch: 60; loss: 2.01; acc: 0.25
Batch: 80; loss: 2.11; acc: 0.23
Batch: 100; loss: 1.98; acc: 0.34
Batch: 120; loss: 2.09; acc: 0.28
Batch: 140; loss: 2.12; acc: 0.25
Val Epoch over. val_loss: 2.144688971483024; val_accuracy: 0.23716162420382167 

The current subspace-distance is: 6.158449195936555e-06 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 2.27; acc: 0.19
Batch: 20; loss: 2.09; acc: 0.3
Batch: 40; loss: 2.16; acc: 0.22
Batch: 60; loss: 2.14; acc: 0.23
Batch: 80; loss: 2.13; acc: 0.22
Batch: 100; loss: 2.26; acc: 0.14
Batch: 120; loss: 2.08; acc: 0.28
Batch: 140; loss: 2.13; acc: 0.22
Batch: 160; loss: 2.21; acc: 0.2
Batch: 180; loss: 2.22; acc: 0.19
Batch: 200; loss: 2.18; acc: 0.28
Batch: 220; loss: 2.15; acc: 0.22
Batch: 240; loss: 2.22; acc: 0.2
Batch: 260; loss: 1.99; acc: 0.34
Batch: 280; loss: 2.16; acc: 0.23
Batch: 300; loss: 2.13; acc: 0.23
Batch: 320; loss: 2.16; acc: 0.25
Batch: 340; loss: 2.03; acc: 0.25
Batch: 360; loss: 2.16; acc: 0.25
Batch: 380; loss: 2.15; acc: 0.25
Batch: 400; loss: 2.12; acc: 0.28
Batch: 420; loss: 2.18; acc: 0.19
Batch: 440; loss: 2.25; acc: 0.2
Batch: 460; loss: 2.2; acc: 0.2
Batch: 480; loss: 2.13; acc: 0.27
Batch: 500; loss: 2.12; acc: 0.22
Batch: 520; loss: 2.21; acc: 0.28
Batch: 540; loss: 2.21; acc: 0.16
Batch: 560; loss: 2.15; acc: 0.19
Batch: 580; loss: 2.15; acc: 0.2
Batch: 600; loss: 2.13; acc: 0.31
Batch: 620; loss: 2.1; acc: 0.25
Batch: 640; loss: 2.14; acc: 0.25
Batch: 660; loss: 2.15; acc: 0.25
Batch: 680; loss: 2.19; acc: 0.17
Batch: 700; loss: 2.15; acc: 0.23
Batch: 720; loss: 2.24; acc: 0.16
Batch: 740; loss: 2.04; acc: 0.31
Batch: 760; loss: 2.19; acc: 0.22
Batch: 780; loss: 2.18; acc: 0.23
Train Epoch over. train_loss: 2.15; train_accuracy: 0.23 

1.3263610526337288e-05
1.0516409929550719e-06
Batch: 0; loss: 2.12; acc: 0.17
Batch: 20; loss: 2.12; acc: 0.25
Batch: 40; loss: 2.05; acc: 0.33
Batch: 60; loss: 2.01; acc: 0.27
Batch: 80; loss: 2.11; acc: 0.25
Batch: 100; loss: 1.98; acc: 0.31
Batch: 120; loss: 2.09; acc: 0.28
Batch: 140; loss: 2.12; acc: 0.25
Val Epoch over. val_loss: 2.1444974932700966; val_accuracy: 0.23616640127388536 

The current subspace-distance is: 1.0516409929550719e-06 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 2.25; acc: 0.16
Batch: 20; loss: 2.22; acc: 0.14
Batch: 40; loss: 2.13; acc: 0.22
Batch: 60; loss: 2.14; acc: 0.2
Batch: 80; loss: 2.25; acc: 0.17
Batch: 100; loss: 2.09; acc: 0.23
Batch: 120; loss: 2.24; acc: 0.17
Batch: 140; loss: 1.96; acc: 0.38
Batch: 160; loss: 2.15; acc: 0.23
Batch: 180; loss: 2.15; acc: 0.22
Batch: 200; loss: 2.18; acc: 0.23
Batch: 220; loss: 2.23; acc: 0.14
Batch: 240; loss: 2.17; acc: 0.2
Batch: 260; loss: 2.27; acc: 0.28
Batch: 280; loss: 2.13; acc: 0.25
Batch: 300; loss: 2.17; acc: 0.27
Batch: 320; loss: 2.15; acc: 0.17
Batch: 340; loss: 2.12; acc: 0.22
Batch: 360; loss: 2.12; acc: 0.25
Batch: 380; loss: 2.25; acc: 0.2
Batch: 400; loss: 2.21; acc: 0.22
Batch: 420; loss: 1.96; acc: 0.38
Batch: 440; loss: 2.26; acc: 0.09
Batch: 460; loss: 2.22; acc: 0.19
Batch: 480; loss: 2.1; acc: 0.27
Batch: 500; loss: 2.11; acc: 0.19
Batch: 520; loss: 2.18; acc: 0.27
Batch: 540; loss: 2.13; acc: 0.23
Batch: 560; loss: 2.21; acc: 0.14
Batch: 580; loss: 2.11; acc: 0.23
Batch: 600; loss: 2.23; acc: 0.2
Batch: 620; loss: 2.21; acc: 0.22
Batch: 640; loss: 2.12; acc: 0.25
Batch: 660; loss: 2.18; acc: 0.16
Batch: 680; loss: 2.12; acc: 0.25
Batch: 700; loss: 2.16; acc: 0.22
Batch: 720; loss: 2.22; acc: 0.19
Batch: 740; loss: 2.18; acc: 0.23
Batch: 760; loss: 2.01; acc: 0.25
Batch: 780; loss: 2.27; acc: 0.16
Train Epoch over. train_loss: 2.15; train_accuracy: 0.23 

6.649337592534721e-06
1.81984148639458e-06
Batch: 0; loss: 2.12; acc: 0.17
Batch: 20; loss: 2.11; acc: 0.25
Batch: 40; loss: 2.05; acc: 0.33
Batch: 60; loss: 2.01; acc: 0.27
Batch: 80; loss: 2.11; acc: 0.25
Batch: 100; loss: 1.98; acc: 0.31
Batch: 120; loss: 2.08; acc: 0.28
Batch: 140; loss: 2.12; acc: 0.25
Val Epoch over. val_loss: 2.144399025637633; val_accuracy: 0.23517117834394904 

The current subspace-distance is: 1.81984148639458e-06 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 2.24; acc: 0.17
Batch: 20; loss: 2.02; acc: 0.33
Batch: 40; loss: 2.21; acc: 0.17
Batch: 60; loss: 2.11; acc: 0.31
Batch: 80; loss: 2.11; acc: 0.23
Batch: 100; loss: 2.23; acc: 0.19
Batch: 120; loss: 2.05; acc: 0.31
Batch: 140; loss: 2.09; acc: 0.28
Batch: 160; loss: 2.2; acc: 0.2
Batch: 180; loss: 2.06; acc: 0.25
Batch: 200; loss: 2.1; acc: 0.22
Batch: 220; loss: 2.05; acc: 0.3
Batch: 240; loss: 2.03; acc: 0.28
Batch: 260; loss: 2.1; acc: 0.22
Batch: 280; loss: 2.22; acc: 0.22
Batch: 300; loss: 2.25; acc: 0.17
Batch: 320; loss: 2.15; acc: 0.27
Batch: 340; loss: 2.23; acc: 0.2
Batch: 360; loss: 2.14; acc: 0.27
Batch: 380; loss: 2.24; acc: 0.16
Batch: 400; loss: 2.13; acc: 0.22
Batch: 420; loss: 2.1; acc: 0.2
Batch: 440; loss: 2.09; acc: 0.2
Batch: 460; loss: 2.27; acc: 0.17
Batch: 480; loss: 2.06; acc: 0.28
Batch: 500; loss: 2.1; acc: 0.25
Batch: 520; loss: 2.14; acc: 0.25
Batch: 540; loss: 2.14; acc: 0.22
Batch: 560; loss: 2.19; acc: 0.2
Batch: 580; loss: 2.07; acc: 0.3
Batch: 600; loss: 2.11; acc: 0.31
Batch: 620; loss: 2.16; acc: 0.27
Batch: 640; loss: 2.24; acc: 0.17
Batch: 660; loss: 2.23; acc: 0.2
Batch: 680; loss: 2.13; acc: 0.23
Batch: 700; loss: 2.2; acc: 0.23
Batch: 720; loss: 2.11; acc: 0.2
Batch: 740; loss: 2.15; acc: 0.22
Batch: 760; loss: 2.25; acc: 0.2
Batch: 780; loss: 2.03; acc: 0.3
Train Epoch over. train_loss: 2.15; train_accuracy: 0.23 

1.5487354176002555e-05
4.871255441685207e-06
Batch: 0; loss: 2.12; acc: 0.16
Batch: 20; loss: 2.11; acc: 0.25
Batch: 40; loss: 2.05; acc: 0.33
Batch: 60; loss: 2.01; acc: 0.27
Batch: 80; loss: 2.11; acc: 0.25
Batch: 100; loss: 1.98; acc: 0.31
Batch: 120; loss: 2.08; acc: 0.28
Batch: 140; loss: 2.12; acc: 0.25
Val Epoch over. val_loss: 2.1443048176492097; val_accuracy: 0.23367834394904458 

The current subspace-distance is: 4.871255441685207e-06 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 2.23; acc: 0.19
Batch: 20; loss: 2.19; acc: 0.16
Batch: 40; loss: 2.08; acc: 0.3
Batch: 60; loss: 2.03; acc: 0.31
Batch: 80; loss: 2.22; acc: 0.23
Batch: 100; loss: 2.21; acc: 0.16
Batch: 120; loss: 2.18; acc: 0.16
Batch: 140; loss: 2.19; acc: 0.17
Batch: 160; loss: 2.12; acc: 0.25
Batch: 180; loss: 2.07; acc: 0.28
Batch: 200; loss: 2.08; acc: 0.2
Batch: 220; loss: 2.22; acc: 0.2
Batch: 240; loss: 2.2; acc: 0.17
Batch: 260; loss: 2.17; acc: 0.25
Batch: 280; loss: 2.26; acc: 0.17
Batch: 300; loss: 2.18; acc: 0.22
Batch: 320; loss: 2.29; acc: 0.16
Batch: 340; loss: 2.17; acc: 0.12
Batch: 360; loss: 2.15; acc: 0.2
Batch: 380; loss: 2.14; acc: 0.22
Batch: 400; loss: 2.17; acc: 0.25
Batch: 420; loss: 2.21; acc: 0.16
Batch: 440; loss: 2.28; acc: 0.14
Batch: 460; loss: 2.07; acc: 0.28
Batch: 480; loss: 2.14; acc: 0.23
Batch: 500; loss: 2.2; acc: 0.25
Batch: 520; loss: 2.2; acc: 0.19
Batch: 540; loss: 2.08; acc: 0.3
Batch: 560; loss: 2.09; acc: 0.3
Batch: 580; loss: 2.17; acc: 0.2
Batch: 600; loss: 2.16; acc: 0.23
Batch: 620; loss: 2.14; acc: 0.23
Batch: 640; loss: 2.21; acc: 0.25
Batch: 660; loss: 2.13; acc: 0.22
Batch: 680; loss: 2.12; acc: 0.27
Batch: 700; loss: 2.09; acc: 0.2
Batch: 720; loss: 2.09; acc: 0.23
Batch: 740; loss: 2.14; acc: 0.25
Batch: 760; loss: 2.15; acc: 0.19
Batch: 780; loss: 2.05; acc: 0.27
Train Epoch over. train_loss: 2.15; train_accuracy: 0.23 

7.339051990129519e-06
3.7655074720532866e-06
Batch: 0; loss: 2.12; acc: 0.16
Batch: 20; loss: 2.11; acc: 0.25
Batch: 40; loss: 2.05; acc: 0.33
Batch: 60; loss: 2.01; acc: 0.27
Batch: 80; loss: 2.11; acc: 0.25
Batch: 100; loss: 1.98; acc: 0.31
Batch: 120; loss: 2.08; acc: 0.28
Batch: 140; loss: 2.12; acc: 0.25
Val Epoch over. val_loss: 2.144279009976964; val_accuracy: 0.2340764331210191 

The current subspace-distance is: 3.7655074720532866e-06 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 2.23; acc: 0.14
Batch: 20; loss: 2.19; acc: 0.19
Batch: 40; loss: 2.22; acc: 0.08
Batch: 60; loss: 2.21; acc: 0.2
Batch: 80; loss: 2.28; acc: 0.16
Batch: 100; loss: 2.05; acc: 0.23
Batch: 120; loss: 2.06; acc: 0.23
Batch: 140; loss: 2.22; acc: 0.22
Batch: 160; loss: 2.23; acc: 0.22
Batch: 180; loss: 2.01; acc: 0.28
Batch: 200; loss: 2.1; acc: 0.27
Batch: 220; loss: 2.23; acc: 0.17
Batch: 240; loss: 2.04; acc: 0.31
Batch: 260; loss: 2.12; acc: 0.2
Batch: 280; loss: 2.02; acc: 0.33
Batch: 300; loss: 2.25; acc: 0.2
Batch: 320; loss: 2.03; acc: 0.28
Batch: 340; loss: 2.26; acc: 0.17
Batch: 360; loss: 2.16; acc: 0.33
Batch: 380; loss: 2.2; acc: 0.2
Batch: 400; loss: 2.2; acc: 0.23
Batch: 420; loss: 2.15; acc: 0.27
Batch: 440; loss: 2.1; acc: 0.25
Batch: 460; loss: 2.17; acc: 0.27
Batch: 480; loss: 2.13; acc: 0.22
Batch: 500; loss: 2.2; acc: 0.17
Batch: 520; loss: 2.08; acc: 0.25
Batch: 540; loss: 2.07; acc: 0.3
Batch: 560; loss: 2.12; acc: 0.2
Batch: 580; loss: 2.21; acc: 0.11
Batch: 600; loss: 2.08; acc: 0.34
Batch: 620; loss: 2.24; acc: 0.11
Batch: 640; loss: 2.18; acc: 0.19
Batch: 660; loss: 2.24; acc: 0.23
Batch: 680; loss: 2.27; acc: 0.14
Batch: 700; loss: 2.14; acc: 0.19
Batch: 720; loss: 2.21; acc: 0.22
Batch: 740; loss: 2.22; acc: 0.2
Batch: 760; loss: 2.11; acc: 0.17
Batch: 780; loss: 2.23; acc: 0.16
Train Epoch over. train_loss: 2.15; train_accuracy: 0.23 

5.967694505670806e-06
2.5821798317338107e-06
Batch: 0; loss: 2.12; acc: 0.14
Batch: 20; loss: 2.11; acc: 0.25
Batch: 40; loss: 2.05; acc: 0.33
Batch: 60; loss: 2.01; acc: 0.27
Batch: 80; loss: 2.11; acc: 0.25
Batch: 100; loss: 1.98; acc: 0.31
Batch: 120; loss: 2.08; acc: 0.28
Batch: 140; loss: 2.12; acc: 0.25
Val Epoch over. val_loss: 2.144255998028312; val_accuracy: 0.23347929936305734 

The current subspace-distance is: 2.5821798317338107e-06 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 2.23; acc: 0.11
Batch: 20; loss: 2.23; acc: 0.2
Batch: 40; loss: 2.13; acc: 0.27
Batch: 60; loss: 2.12; acc: 0.3
Batch: 80; loss: 2.1; acc: 0.25
Batch: 100; loss: 2.19; acc: 0.16
Batch: 120; loss: 2.17; acc: 0.28
Batch: 140; loss: 2.18; acc: 0.22
Batch: 160; loss: 2.16; acc: 0.23
Batch: 180; loss: 2.2; acc: 0.23
Batch: 200; loss: 2.26; acc: 0.19
Batch: 220; loss: 2.21; acc: 0.12
Batch: 240; loss: 2.25; acc: 0.16
Batch: 260; loss: 2.18; acc: 0.19
Batch: 280; loss: 2.09; acc: 0.33
Batch: 300; loss: 2.06; acc: 0.3
Batch: 320; loss: 2.1; acc: 0.27
Batch: 340; loss: 2.2; acc: 0.22
Batch: 360; loss: 2.23; acc: 0.22
Batch: 380; loss: 2.21; acc: 0.17
Batch: 400; loss: 2.16; acc: 0.19
Batch: 420; loss: 2.13; acc: 0.25
Batch: 440; loss: 2.12; acc: 0.22
Batch: 460; loss: 2.09; acc: 0.28
Batch: 480; loss: 2.25; acc: 0.08
Batch: 500; loss: 2.25; acc: 0.17
Batch: 520; loss: 2.15; acc: 0.19
Batch: 540; loss: 2.12; acc: 0.25
Batch: 560; loss: 2.11; acc: 0.23
Batch: 580; loss: 2.18; acc: 0.25
Batch: 600; loss: 2.09; acc: 0.27
Batch: 620; loss: 2.09; acc: 0.22
Batch: 640; loss: 2.05; acc: 0.27
Batch: 660; loss: 2.04; acc: 0.33
Batch: 680; loss: 2.2; acc: 0.22
Batch: 700; loss: 2.29; acc: 0.12
Batch: 720; loss: 2.18; acc: 0.22
Batch: 740; loss: 2.17; acc: 0.16
Batch: 760; loss: 2.19; acc: 0.2
Batch: 780; loss: 2.09; acc: 0.25
Train Epoch over. train_loss: 2.15; train_accuracy: 0.23 

1.0506138096388895e-05
5.993425929773366e-06
Batch: 0; loss: 2.12; acc: 0.14
Batch: 20; loss: 2.11; acc: 0.25
Batch: 40; loss: 2.05; acc: 0.33
Batch: 60; loss: 2.01; acc: 0.27
Batch: 80; loss: 2.11; acc: 0.23
Batch: 100; loss: 1.98; acc: 0.31
Batch: 120; loss: 2.08; acc: 0.28
Batch: 140; loss: 2.12; acc: 0.25
Val Epoch over. val_loss: 2.1442411037007716; val_accuracy: 0.2330812101910828 

The current subspace-distance is: 5.993425929773366e-06 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 2.18; acc: 0.19
Batch: 20; loss: 2.19; acc: 0.19
Batch: 40; loss: 2.12; acc: 0.22
Batch: 60; loss: 2.1; acc: 0.2
Batch: 80; loss: 2.07; acc: 0.25
Batch: 100; loss: 2.11; acc: 0.23
Batch: 120; loss: 2.03; acc: 0.34
Batch: 140; loss: 2.27; acc: 0.2
Batch: 160; loss: 2.1; acc: 0.25
Batch: 180; loss: 2.2; acc: 0.23
Batch: 200; loss: 2.05; acc: 0.28
Batch: 220; loss: 2.27; acc: 0.19
Batch: 240; loss: 2.23; acc: 0.22
Batch: 260; loss: 2.1; acc: 0.28
Batch: 280; loss: 2.18; acc: 0.17
Batch: 300; loss: 2.11; acc: 0.22
Batch: 320; loss: 2.31; acc: 0.11
Batch: 340; loss: 2.18; acc: 0.25
Batch: 360; loss: 2.1; acc: 0.23
Batch: 380; loss: 2.08; acc: 0.27
Batch: 400; loss: 2.3; acc: 0.12
Batch: 420; loss: 2.09; acc: 0.25
Batch: 440; loss: 2.2; acc: 0.16
Batch: 460; loss: 2.21; acc: 0.2
Batch: 480; loss: 2.14; acc: 0.22
Batch: 500; loss: 2.22; acc: 0.17
Batch: 520; loss: 2.19; acc: 0.19
Batch: 540; loss: 2.23; acc: 0.23
Batch: 560; loss: 2.18; acc: 0.25
Batch: 580; loss: 2.08; acc: 0.3
Batch: 600; loss: 2.18; acc: 0.2
Batch: 620; loss: 2.09; acc: 0.23
Batch: 640; loss: 2.03; acc: 0.23
Batch: 660; loss: 2.21; acc: 0.19
Batch: 680; loss: 2.12; acc: 0.23
Batch: 700; loss: 2.21; acc: 0.12
Batch: 720; loss: 2.09; acc: 0.27
Batch: 740; loss: 2.15; acc: 0.23
Batch: 760; loss: 2.21; acc: 0.19
Batch: 780; loss: 2.14; acc: 0.17
Train Epoch over. train_loss: 2.15; train_accuracy: 0.22 

1.0406482942926232e-05
7.439955993504554e-07
Batch: 0; loss: 2.12; acc: 0.14
Batch: 20; loss: 2.11; acc: 0.25
Batch: 40; loss: 2.05; acc: 0.33
Batch: 60; loss: 2.01; acc: 0.27
Batch: 80; loss: 2.1; acc: 0.23
Batch: 100; loss: 1.98; acc: 0.31
Batch: 120; loss: 2.08; acc: 0.28
Batch: 140; loss: 2.12; acc: 0.25
Val Epoch over. val_loss: 2.144228607985624; val_accuracy: 0.2330812101910828 

The current subspace-distance is: 7.439955993504554e-07 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 2.09; acc: 0.27
Batch: 20; loss: 2.03; acc: 0.34
Batch: 40; loss: 2.13; acc: 0.25
Batch: 60; loss: 2.21; acc: 0.19
Batch: 80; loss: 2.22; acc: 0.23
Batch: 100; loss: 2.1; acc: 0.27
Batch: 120; loss: 2.13; acc: 0.19
Batch: 140; loss: 2.18; acc: 0.19
Batch: 160; loss: 2.15; acc: 0.25
Batch: 180; loss: 2.07; acc: 0.16
Batch: 200; loss: 2.13; acc: 0.27
Batch: 220; loss: 2.0; acc: 0.42
Batch: 240; loss: 2.27; acc: 0.16
Batch: 260; loss: 2.13; acc: 0.22
Batch: 280; loss: 2.22; acc: 0.22
Batch: 300; loss: 2.2; acc: 0.23
Batch: 320; loss: 2.22; acc: 0.19
Batch: 340; loss: 2.18; acc: 0.2
Batch: 360; loss: 2.23; acc: 0.16
Batch: 380; loss: 2.06; acc: 0.28
Batch: 400; loss: 2.07; acc: 0.28
Batch: 420; loss: 2.15; acc: 0.2
Batch: 440; loss: 1.99; acc: 0.33
Batch: 460; loss: 2.22; acc: 0.2
Batch: 480; loss: 2.1; acc: 0.22
Batch: 500; loss: 2.06; acc: 0.31
Batch: 520; loss: 2.08; acc: 0.33
Batch: 540; loss: 2.22; acc: 0.17
Batch: 560; loss: 2.15; acc: 0.27
Batch: 580; loss: 2.09; acc: 0.27
Batch: 600; loss: 2.19; acc: 0.2
Batch: 620; loss: 2.1; acc: 0.22
Batch: 640; loss: 2.28; acc: 0.19
Batch: 660; loss: 2.23; acc: 0.16
Batch: 680; loss: 2.13; acc: 0.22
Batch: 700; loss: 2.26; acc: 0.19
Batch: 720; loss: 2.08; acc: 0.23
Batch: 740; loss: 2.19; acc: 0.14
Batch: 760; loss: 2.12; acc: 0.28
Batch: 780; loss: 2.19; acc: 0.2
Train Epoch over. train_loss: 2.15; train_accuracy: 0.22 

8.227948455896694e-06
2.7201890588912647e-06
Batch: 0; loss: 2.12; acc: 0.14
Batch: 20; loss: 2.11; acc: 0.25
Batch: 40; loss: 2.05; acc: 0.33
Batch: 60; loss: 2.01; acc: 0.27
Batch: 80; loss: 2.1; acc: 0.23
Batch: 100; loss: 1.98; acc: 0.31
Batch: 120; loss: 2.08; acc: 0.28
Batch: 140; loss: 2.12; acc: 0.25
Val Epoch over. val_loss: 2.1442216209545255; val_accuracy: 0.23248407643312102 

The current subspace-distance is: 2.7201890588912647e-06 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 2.09; acc: 0.25
Batch: 20; loss: 2.16; acc: 0.23
Batch: 40; loss: 2.2; acc: 0.14
Batch: 60; loss: 2.08; acc: 0.27
Batch: 80; loss: 2.06; acc: 0.28
Batch: 100; loss: 2.19; acc: 0.19
Batch: 120; loss: 2.16; acc: 0.22
Batch: 140; loss: 2.23; acc: 0.22
Batch: 160; loss: 2.09; acc: 0.3
Batch: 180; loss: 2.25; acc: 0.14
Batch: 200; loss: 2.2; acc: 0.23
Batch: 220; loss: 2.15; acc: 0.27
Batch: 240; loss: 2.18; acc: 0.19
Batch: 260; loss: 2.3; acc: 0.2
Batch: 280; loss: 2.25; acc: 0.19
Batch: 300; loss: 2.08; acc: 0.3
Batch: 320; loss: 2.0; acc: 0.33
Batch: 340; loss: 2.1; acc: 0.2
Batch: 360; loss: 2.13; acc: 0.28
Batch: 380; loss: 2.33; acc: 0.14
Batch: 400; loss: 2.2; acc: 0.12
Batch: 420; loss: 2.23; acc: 0.16
Batch: 440; loss: 2.22; acc: 0.17
Batch: 460; loss: 2.17; acc: 0.25
Batch: 480; loss: 2.03; acc: 0.27
Batch: 500; loss: 2.12; acc: 0.27
Batch: 520; loss: 2.22; acc: 0.22
Batch: 540; loss: 2.16; acc: 0.2
Batch: 560; loss: 2.01; acc: 0.23
Batch: 580; loss: 2.18; acc: 0.19
Batch: 600; loss: 2.16; acc: 0.28
Batch: 620; loss: 2.11; acc: 0.23
Batch: 640; loss: 2.17; acc: 0.2
Batch: 660; loss: 2.13; acc: 0.23
Batch: 680; loss: 2.24; acc: 0.14
Batch: 700; loss: 2.25; acc: 0.19
Batch: 720; loss: 2.17; acc: 0.25
Batch: 740; loss: 2.11; acc: 0.25
Batch: 760; loss: 2.25; acc: 0.19
Batch: 780; loss: 2.16; acc: 0.19
Train Epoch over. train_loss: 2.15; train_accuracy: 0.22 

7.790920790284872e-06
4.529726084001595e-06
Batch: 0; loss: 2.12; acc: 0.14
Batch: 20; loss: 2.11; acc: 0.25
Batch: 40; loss: 2.05; acc: 0.33
Batch: 60; loss: 2.01; acc: 0.27
Batch: 80; loss: 2.1; acc: 0.23
Batch: 100; loss: 1.98; acc: 0.31
Batch: 120; loss: 2.08; acc: 0.28
Batch: 140; loss: 2.12; acc: 0.25
Val Epoch over. val_loss: 2.144220748524757; val_accuracy: 0.2320859872611465 

The current subspace-distance is: 4.529726084001595e-06 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 2.15; acc: 0.25
Batch: 20; loss: 2.17; acc: 0.19
Batch: 40; loss: 2.24; acc: 0.12
Batch: 60; loss: 2.08; acc: 0.23
Batch: 80; loss: 2.14; acc: 0.25
Batch: 100; loss: 2.21; acc: 0.22
Batch: 120; loss: 2.23; acc: 0.16
Batch: 140; loss: 2.05; acc: 0.33
Batch: 160; loss: 1.99; acc: 0.28
Batch: 180; loss: 2.17; acc: 0.22
Batch: 200; loss: 2.21; acc: 0.17
Batch: 220; loss: 2.1; acc: 0.22
Batch: 240; loss: 2.19; acc: 0.16
Batch: 260; loss: 2.1; acc: 0.2
Batch: 280; loss: 2.17; acc: 0.2
Batch: 300; loss: 2.15; acc: 0.27
Batch: 320; loss: 2.2; acc: 0.17
Batch: 340; loss: 2.14; acc: 0.3
Batch: 360; loss: 2.06; acc: 0.17
Batch: 380; loss: 2.2; acc: 0.12
Batch: 400; loss: 2.12; acc: 0.28
Batch: 420; loss: 2.15; acc: 0.23
Batch: 440; loss: 2.23; acc: 0.09
Batch: 460; loss: 2.19; acc: 0.2
Batch: 480; loss: 2.16; acc: 0.27
Batch: 500; loss: 2.28; acc: 0.14
Batch: 520; loss: 2.17; acc: 0.28
Batch: 540; loss: 2.2; acc: 0.23
Batch: 560; loss: 2.27; acc: 0.12
Batch: 580; loss: 2.22; acc: 0.17
Batch: 600; loss: 2.05; acc: 0.27
Batch: 620; loss: 2.07; acc: 0.28
Batch: 640; loss: 2.23; acc: 0.23
Batch: 660; loss: 2.15; acc: 0.25
Batch: 680; loss: 2.23; acc: 0.19
Batch: 700; loss: 2.13; acc: 0.28
Batch: 720; loss: 2.24; acc: 0.14
Batch: 740; loss: 2.05; acc: 0.28
Batch: 760; loss: 2.15; acc: 0.22
Batch: 780; loss: 2.15; acc: 0.22
Train Epoch over. train_loss: 2.15; train_accuracy: 0.22 

1.3892075003241189e-05
4.851674020756036e-06
Batch: 0; loss: 2.12; acc: 0.14
Batch: 20; loss: 2.11; acc: 0.25
Batch: 40; loss: 2.05; acc: 0.33
Batch: 60; loss: 2.01; acc: 0.27
Batch: 80; loss: 2.1; acc: 0.23
Batch: 100; loss: 1.98; acc: 0.31
Batch: 120; loss: 2.08; acc: 0.28
Batch: 140; loss: 2.12; acc: 0.25
Val Epoch over. val_loss: 2.1442220112320722; val_accuracy: 0.23238455414012738 

The current subspace-distance is: 4.851674020756036e-06 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 2.06; acc: 0.31
Batch: 20; loss: 2.17; acc: 0.25
Batch: 40; loss: 2.13; acc: 0.2
Batch: 60; loss: 1.99; acc: 0.23
Batch: 80; loss: 2.22; acc: 0.14
Batch: 100; loss: 2.15; acc: 0.23
Batch: 120; loss: 2.13; acc: 0.22
Batch: 140; loss: 2.17; acc: 0.25
Batch: 160; loss: 2.19; acc: 0.17
Batch: 180; loss: 2.1; acc: 0.27
Batch: 200; loss: 2.24; acc: 0.19
Batch: 220; loss: 2.18; acc: 0.22
Batch: 240; loss: 2.12; acc: 0.28
Batch: 260; loss: 2.0; acc: 0.33
Batch: 280; loss: 2.22; acc: 0.2
Batch: 300; loss: 2.04; acc: 0.31
Batch: 320; loss: 2.05; acc: 0.28
Batch: 340; loss: 2.2; acc: 0.17
Batch: 360; loss: 2.21; acc: 0.14
Batch: 380; loss: 2.14; acc: 0.27
Batch: 400; loss: 2.16; acc: 0.19
Batch: 420; loss: 2.2; acc: 0.19
Batch: 440; loss: 2.16; acc: 0.23
Batch: 460; loss: 2.19; acc: 0.2
Batch: 480; loss: 2.07; acc: 0.23
Batch: 500; loss: 2.2; acc: 0.2
Batch: 520; loss: 2.12; acc: 0.23
Batch: 540; loss: 2.23; acc: 0.22
Batch: 560; loss: 2.11; acc: 0.23
Batch: 580; loss: 2.12; acc: 0.22
Batch: 600; loss: 2.21; acc: 0.14
Batch: 620; loss: 2.21; acc: 0.25
Batch: 640; loss: 2.11; acc: 0.25
Batch: 660; loss: 2.23; acc: 0.16
Batch: 680; loss: 2.07; acc: 0.25
Batch: 700; loss: 2.25; acc: 0.22
Batch: 720; loss: 2.09; acc: 0.25
Batch: 740; loss: 2.22; acc: 0.19
Batch: 760; loss: 2.03; acc: 0.3
Batch: 780; loss: 2.08; acc: 0.28
Train Epoch over. train_loss: 2.15; train_accuracy: 0.22 

7.30473857402103e-06
1.935524096552399e-06
Batch: 0; loss: 2.12; acc: 0.14
Batch: 20; loss: 2.11; acc: 0.25
Batch: 40; loss: 2.05; acc: 0.33
Batch: 60; loss: 2.01; acc: 0.27
Batch: 80; loss: 2.1; acc: 0.23
Batch: 100; loss: 1.98; acc: 0.31
Batch: 120; loss: 2.08; acc: 0.28
Batch: 140; loss: 2.12; acc: 0.25
Val Epoch over. val_loss: 2.1442226543548; val_accuracy: 0.23218550955414013 

The current subspace-distance is: 1.935524096552399e-06 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 2.19; acc: 0.23
Batch: 20; loss: 2.23; acc: 0.19
Batch: 40; loss: 2.0; acc: 0.34
Batch: 60; loss: 2.04; acc: 0.33
Batch: 80; loss: 2.22; acc: 0.19
Batch: 100; loss: 2.11; acc: 0.28
Batch: 120; loss: 2.24; acc: 0.2
Batch: 140; loss: 2.13; acc: 0.27
Batch: 160; loss: 2.11; acc: 0.23
Batch: 180; loss: 2.11; acc: 0.17
Batch: 200; loss: 2.27; acc: 0.17
Batch: 220; loss: 2.18; acc: 0.19
Batch: 240; loss: 2.06; acc: 0.25
Batch: 260; loss: 2.1; acc: 0.25
Batch: 280; loss: 2.21; acc: 0.22
Batch: 300; loss: 2.07; acc: 0.31
Batch: 320; loss: 2.15; acc: 0.28
Batch: 340; loss: 2.2; acc: 0.19
Batch: 360; loss: 2.11; acc: 0.25
Batch: 380; loss: 2.18; acc: 0.22
Batch: 400; loss: 2.09; acc: 0.23
Batch: 420; loss: 2.22; acc: 0.16
Batch: 440; loss: 2.07; acc: 0.22
Batch: 460; loss: 2.12; acc: 0.23
Batch: 480; loss: 2.03; acc: 0.31
Batch: 500; loss: 2.12; acc: 0.28
Batch: 520; loss: 2.15; acc: 0.17
Batch: 540; loss: 2.24; acc: 0.11
Batch: 560; loss: 2.28; acc: 0.17
Batch: 580; loss: 2.19; acc: 0.23
Batch: 600; loss: 2.13; acc: 0.28
Batch: 620; loss: 2.21; acc: 0.22
Batch: 640; loss: 2.15; acc: 0.17
Batch: 660; loss: 2.03; acc: 0.25
Batch: 680; loss: 2.03; acc: 0.36
Batch: 700; loss: 2.2; acc: 0.2
Batch: 720; loss: 2.15; acc: 0.2
Batch: 740; loss: 2.31; acc: 0.16
Batch: 760; loss: 2.2; acc: 0.14
Batch: 780; loss: 2.11; acc: 0.23
Train Epoch over. train_loss: 2.15; train_accuracy: 0.22 

7.839198588044383e-06
7.996099157026038e-06
Batch: 0; loss: 2.12; acc: 0.14
Batch: 20; loss: 2.11; acc: 0.25
Batch: 40; loss: 2.05; acc: 0.33
Batch: 60; loss: 2.01; acc: 0.27
Batch: 80; loss: 2.1; acc: 0.23
Batch: 100; loss: 1.98; acc: 0.31
Batch: 120; loss: 2.08; acc: 0.27
Batch: 140; loss: 2.12; acc: 0.25
Val Epoch over. val_loss: 2.1442297567987136; val_accuracy: 0.23198646496815287 

The current subspace-distance is: 7.996099157026038e-06 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 2.0; acc: 0.36
Batch: 20; loss: 2.2; acc: 0.12
Batch: 40; loss: 2.1; acc: 0.25
Batch: 60; loss: 2.15; acc: 0.17
Batch: 80; loss: 2.21; acc: 0.2
Batch: 100; loss: 2.1; acc: 0.23
Batch: 120; loss: 2.11; acc: 0.22
Batch: 140; loss: 2.12; acc: 0.2
Batch: 160; loss: 2.14; acc: 0.27
Batch: 180; loss: 2.22; acc: 0.19
Batch: 200; loss: 2.1; acc: 0.2
Batch: 220; loss: 2.1; acc: 0.27
Batch: 240; loss: 2.13; acc: 0.27
Batch: 260; loss: 2.03; acc: 0.34
Batch: 280; loss: 2.17; acc: 0.22
Batch: 300; loss: 2.1; acc: 0.25
Batch: 320; loss: 2.19; acc: 0.2
Batch: 340; loss: 2.14; acc: 0.19
Batch: 360; loss: 2.11; acc: 0.3
Batch: 380; loss: 2.17; acc: 0.25
Batch: 400; loss: 2.04; acc: 0.23
Batch: 420; loss: 2.2; acc: 0.23
Batch: 440; loss: 2.23; acc: 0.17
Batch: 460; loss: 2.2; acc: 0.16
Batch: 480; loss: 2.07; acc: 0.25
Batch: 500; loss: 2.09; acc: 0.14
Batch: 520; loss: 2.23; acc: 0.19
Batch: 540; loss: 2.15; acc: 0.28
Batch: 560; loss: 2.21; acc: 0.17
Batch: 580; loss: 2.23; acc: 0.19
Batch: 600; loss: 2.23; acc: 0.14
Batch: 620; loss: 2.08; acc: 0.33
Batch: 640; loss: 2.14; acc: 0.22
Batch: 660; loss: 2.15; acc: 0.25
Batch: 680; loss: 2.22; acc: 0.17
Batch: 700; loss: 2.15; acc: 0.25
Batch: 720; loss: 2.16; acc: 0.25
Batch: 740; loss: 2.07; acc: 0.23
Batch: 760; loss: 2.08; acc: 0.25
Batch: 780; loss: 2.08; acc: 0.22
Train Epoch over. train_loss: 2.15; train_accuracy: 0.22 

9.854928975983057e-06
4.561786226986442e-06
Batch: 0; loss: 2.12; acc: 0.14
Batch: 20; loss: 2.11; acc: 0.25
Batch: 40; loss: 2.05; acc: 0.33
Batch: 60; loss: 2.01; acc: 0.27
Batch: 80; loss: 2.1; acc: 0.23
Batch: 100; loss: 1.98; acc: 0.31
Batch: 120; loss: 2.08; acc: 0.27
Batch: 140; loss: 2.12; acc: 0.25
Val Epoch over. val_loss: 2.14423124881307; val_accuracy: 0.23188694267515925 

The current subspace-distance is: 4.561786226986442e-06 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 2.14; acc: 0.25
Batch: 20; loss: 2.17; acc: 0.2
Batch: 40; loss: 1.99; acc: 0.36
Batch: 60; loss: 2.12; acc: 0.25
Batch: 80; loss: 1.97; acc: 0.45
Batch: 100; loss: 2.24; acc: 0.16
Batch: 120; loss: 2.14; acc: 0.3
Batch: 140; loss: 2.27; acc: 0.2
Batch: 160; loss: 2.06; acc: 0.34
Batch: 180; loss: 2.12; acc: 0.27
Batch: 200; loss: 2.25; acc: 0.12
Batch: 220; loss: 2.04; acc: 0.33
Batch: 240; loss: 2.23; acc: 0.23
Batch: 260; loss: 2.13; acc: 0.22
Batch: 280; loss: 2.25; acc: 0.14
Batch: 300; loss: 2.17; acc: 0.22
Batch: 320; loss: 2.2; acc: 0.2
Batch: 340; loss: 2.07; acc: 0.23
Batch: 360; loss: 2.15; acc: 0.3
Batch: 380; loss: 2.19; acc: 0.2
Batch: 400; loss: 2.18; acc: 0.2
Batch: 420; loss: 2.2; acc: 0.16
Batch: 440; loss: 2.15; acc: 0.19
Batch: 460; loss: 2.13; acc: 0.19
Batch: 480; loss: 2.1; acc: 0.25
Batch: 500; loss: 2.12; acc: 0.22
Batch: 520; loss: 2.14; acc: 0.28
Batch: 540; loss: 2.25; acc: 0.17
Batch: 560; loss: 2.15; acc: 0.22
Batch: 580; loss: 2.3; acc: 0.08
Batch: 600; loss: 2.26; acc: 0.11
Batch: 620; loss: 2.19; acc: 0.17
Batch: 640; loss: 2.13; acc: 0.2
Batch: 660; loss: 2.11; acc: 0.16
Batch: 680; loss: 2.27; acc: 0.14
Batch: 700; loss: 2.14; acc: 0.2
Batch: 720; loss: 2.22; acc: 0.12
Batch: 740; loss: 2.13; acc: 0.22
Batch: 760; loss: 2.2; acc: 0.25
Batch: 780; loss: 2.21; acc: 0.22
Train Epoch over. train_loss: 2.15; train_accuracy: 0.22 

7.644170182175003e-06
2.1198277408984723e-06
Batch: 0; loss: 2.12; acc: 0.14
Batch: 20; loss: 2.11; acc: 0.25
Batch: 40; loss: 2.05; acc: 0.33
Batch: 60; loss: 2.01; acc: 0.27
Batch: 80; loss: 2.1; acc: 0.23
Batch: 100; loss: 1.98; acc: 0.31
Batch: 120; loss: 2.08; acc: 0.27
Batch: 140; loss: 2.12; acc: 0.25
Val Epoch over. val_loss: 2.144231337650566; val_accuracy: 0.23168789808917198 

The current subspace-distance is: 2.1198277408984723e-06 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 2.08; acc: 0.2
Batch: 20; loss: 2.19; acc: 0.23
Batch: 40; loss: 2.12; acc: 0.2
Batch: 60; loss: 2.16; acc: 0.22
Batch: 80; loss: 2.23; acc: 0.17
Batch: 100; loss: 2.22; acc: 0.22
Batch: 120; loss: 2.23; acc: 0.19
Batch: 140; loss: 2.13; acc: 0.2
Batch: 160; loss: 2.15; acc: 0.22
Batch: 180; loss: 2.17; acc: 0.2
Batch: 200; loss: 2.08; acc: 0.25
Batch: 220; loss: 2.19; acc: 0.2
Batch: 240; loss: 2.06; acc: 0.27
Batch: 260; loss: 2.21; acc: 0.23
Batch: 280; loss: 2.26; acc: 0.16
Batch: 300; loss: 2.22; acc: 0.17
Batch: 320; loss: 2.04; acc: 0.19
Batch: 340; loss: 2.21; acc: 0.2
Batch: 360; loss: 2.19; acc: 0.22
Batch: 380; loss: 2.03; acc: 0.28
Batch: 400; loss: 2.15; acc: 0.19
Batch: 420; loss: 2.04; acc: 0.28
Batch: 440; loss: 2.2; acc: 0.16
Batch: 460; loss: 2.11; acc: 0.3
Batch: 480; loss: 2.07; acc: 0.3
Batch: 500; loss: 2.11; acc: 0.27
Batch: 520; loss: 2.23; acc: 0.2
Batch: 540; loss: 2.19; acc: 0.2
Batch: 560; loss: 2.08; acc: 0.23
Batch: 580; loss: 2.24; acc: 0.17
Batch: 600; loss: 2.22; acc: 0.17
Batch: 620; loss: 2.16; acc: 0.25
Batch: 640; loss: 2.09; acc: 0.22
Batch: 660; loss: 2.12; acc: 0.2
Batch: 680; loss: 2.12; acc: 0.23
Batch: 700; loss: 2.27; acc: 0.12
Batch: 720; loss: 2.21; acc: 0.19
Batch: 740; loss: 2.19; acc: 0.16
Batch: 760; loss: 2.14; acc: 0.23
Batch: 780; loss: 2.14; acc: 0.25
Train Epoch over. train_loss: 2.15; train_accuracy: 0.22 

8.919799256545957e-06
4.430405624589184e-06
Batch: 0; loss: 2.12; acc: 0.14
Batch: 20; loss: 2.11; acc: 0.25
Batch: 40; loss: 2.05; acc: 0.33
Batch: 60; loss: 2.01; acc: 0.27
Batch: 80; loss: 2.1; acc: 0.23
Batch: 100; loss: 1.98; acc: 0.31
Batch: 120; loss: 2.08; acc: 0.27
Batch: 140; loss: 2.12; acc: 0.25
Val Epoch over. val_loss: 2.1442303057688816; val_accuracy: 0.23158837579617833 

The current subspace-distance is: 4.430405624589184e-06 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 2.07; acc: 0.25
Batch: 20; loss: 2.31; acc: 0.2
Batch: 40; loss: 2.13; acc: 0.25
Batch: 60; loss: 2.17; acc: 0.2
Batch: 80; loss: 2.17; acc: 0.19
Batch: 100; loss: 2.15; acc: 0.27
Batch: 120; loss: 2.2; acc: 0.2
Batch: 140; loss: 2.12; acc: 0.3
Batch: 160; loss: 2.13; acc: 0.27
Batch: 180; loss: 2.08; acc: 0.31
Batch: 200; loss: 2.18; acc: 0.22
Batch: 220; loss: 2.24; acc: 0.16
Batch: 240; loss: 2.16; acc: 0.22
Batch: 260; loss: 2.07; acc: 0.23
Batch: 280; loss: 2.3; acc: 0.12
Batch: 300; loss: 2.14; acc: 0.19
Batch: 320; loss: 2.13; acc: 0.2
Batch: 340; loss: 2.23; acc: 0.2
Batch: 360; loss: 2.27; acc: 0.22
Batch: 380; loss: 2.17; acc: 0.17
Batch: 400; loss: 2.14; acc: 0.23
Batch: 420; loss: 2.21; acc: 0.25
Batch: 440; loss: 2.19; acc: 0.17
Batch: 460; loss: 2.22; acc: 0.23
Batch: 480; loss: 2.11; acc: 0.28
Batch: 500; loss: 2.09; acc: 0.28
Batch: 520; loss: 2.12; acc: 0.27
Batch: 540; loss: 2.15; acc: 0.22
Batch: 560; loss: 2.02; acc: 0.34
Batch: 580; loss: 2.24; acc: 0.17
Batch: 600; loss: 2.16; acc: 0.17
Batch: 620; loss: 2.29; acc: 0.14
Batch: 640; loss: 2.15; acc: 0.23
Batch: 660; loss: 2.05; acc: 0.25
Batch: 680; loss: 2.06; acc: 0.27
Batch: 700; loss: 2.15; acc: 0.23
Batch: 720; loss: 2.05; acc: 0.3
Batch: 740; loss: 2.12; acc: 0.25
Batch: 760; loss: 2.29; acc: 0.16
Batch: 780; loss: 2.15; acc: 0.17
Train Epoch over. train_loss: 2.15; train_accuracy: 0.22 

8.773060471867211e-06
2.7177952688361984e-06
Batch: 0; loss: 2.12; acc: 0.14
Batch: 20; loss: 2.11; acc: 0.25
Batch: 40; loss: 2.05; acc: 0.33
Batch: 60; loss: 2.01; acc: 0.27
Batch: 80; loss: 2.1; acc: 0.23
Batch: 100; loss: 1.98; acc: 0.31
Batch: 120; loss: 2.08; acc: 0.27
Batch: 140; loss: 2.12; acc: 0.25
Val Epoch over. val_loss: 2.144227769724123; val_accuracy: 0.23168789808917198 

The current subspace-distance is: 2.7177952688361984e-06 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 2.1; acc: 0.25
Batch: 20; loss: 2.18; acc: 0.19
Batch: 40; loss: 2.18; acc: 0.28
Batch: 60; loss: 2.15; acc: 0.19
Batch: 80; loss: 2.24; acc: 0.16
Batch: 100; loss: 2.19; acc: 0.14
Batch: 120; loss: 2.08; acc: 0.23
Batch: 140; loss: 2.16; acc: 0.2
Batch: 160; loss: 2.18; acc: 0.14
Batch: 180; loss: 2.19; acc: 0.12
Batch: 200; loss: 2.12; acc: 0.25
Batch: 220; loss: 2.27; acc: 0.17
Batch: 240; loss: 2.13; acc: 0.27
Batch: 260; loss: 2.12; acc: 0.23
Batch: 280; loss: 2.2; acc: 0.19
Batch: 300; loss: 2.32; acc: 0.11
Batch: 320; loss: 2.09; acc: 0.27
Batch: 340; loss: 2.14; acc: 0.22
Batch: 360; loss: 2.23; acc: 0.19
Batch: 380; loss: 2.14; acc: 0.25
Batch: 400; loss: 2.31; acc: 0.14
Batch: 420; loss: 2.14; acc: 0.31
Batch: 440; loss: 2.2; acc: 0.25
Batch: 460; loss: 2.06; acc: 0.28
Batch: 480; loss: 2.13; acc: 0.19
Batch: 500; loss: 2.19; acc: 0.2
Batch: 520; loss: 2.1; acc: 0.25
Batch: 540; loss: 2.23; acc: 0.16
Batch: 560; loss: 2.02; acc: 0.22
Batch: 580; loss: 2.33; acc: 0.12
Batch: 600; loss: 2.1; acc: 0.3
Batch: 620; loss: 2.08; acc: 0.2
Batch: 640; loss: 2.04; acc: 0.25
Batch: 660; loss: 2.14; acc: 0.27
Batch: 680; loss: 2.0; acc: 0.31
Batch: 700; loss: 2.21; acc: 0.2
Batch: 720; loss: 2.16; acc: 0.25
Batch: 740; loss: 2.17; acc: 0.23
Batch: 760; loss: 2.14; acc: 0.2
Batch: 780; loss: 2.17; acc: 0.19
Train Epoch over. train_loss: 2.15; train_accuracy: 0.22 

9.014033821586054e-06
3.4658817185118096e-06
Batch: 0; loss: 2.12; acc: 0.14
Batch: 20; loss: 2.11; acc: 0.25
Batch: 40; loss: 2.05; acc: 0.31
Batch: 60; loss: 2.01; acc: 0.27
Batch: 80; loss: 2.1; acc: 0.23
Batch: 100; loss: 1.98; acc: 0.31
Batch: 120; loss: 2.08; acc: 0.27
Batch: 140; loss: 2.12; acc: 0.25
Val Epoch over. val_loss: 2.144227301239208; val_accuracy: 0.2314888535031847 

The current subspace-distance is: 3.4658817185118096e-06 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 2.04; acc: 0.3
Batch: 20; loss: 2.23; acc: 0.17
Batch: 40; loss: 2.07; acc: 0.28
Batch: 60; loss: 2.11; acc: 0.25
Batch: 80; loss: 2.09; acc: 0.27
Batch: 100; loss: 2.07; acc: 0.2
Batch: 120; loss: 2.21; acc: 0.17
Batch: 140; loss: 2.16; acc: 0.2
Batch: 160; loss: 2.2; acc: 0.22
Batch: 180; loss: 2.08; acc: 0.28
Batch: 200; loss: 2.21; acc: 0.19
Batch: 220; loss: 2.16; acc: 0.19
Batch: 240; loss: 2.26; acc: 0.12
Batch: 260; loss: 2.08; acc: 0.27
Batch: 280; loss: 2.18; acc: 0.14
Batch: 300; loss: 2.13; acc: 0.19
Batch: 320; loss: 2.13; acc: 0.25
Batch: 340; loss: 2.09; acc: 0.27
Batch: 360; loss: 2.19; acc: 0.2
Batch: 380; loss: 2.15; acc: 0.22
Batch: 400; loss: 2.23; acc: 0.22
Batch: 420; loss: 2.27; acc: 0.2
Batch: 440; loss: 2.26; acc: 0.17
Batch: 460; loss: 2.15; acc: 0.17
Batch: 480; loss: 2.11; acc: 0.27
Batch: 500; loss: 2.12; acc: 0.23
Batch: 520; loss: 2.07; acc: 0.27
Batch: 540; loss: 2.1; acc: 0.28
Batch: 560; loss: 2.09; acc: 0.25
Batch: 580; loss: 2.12; acc: 0.27
Batch: 600; loss: 2.15; acc: 0.19
Batch: 620; loss: 2.15; acc: 0.22
Batch: 640; loss: 2.13; acc: 0.22
Batch: 660; loss: 2.25; acc: 0.09
Batch: 680; loss: 2.14; acc: 0.23
Batch: 700; loss: 2.34; acc: 0.16
Batch: 720; loss: 2.05; acc: 0.3
Batch: 740; loss: 2.17; acc: 0.25
Batch: 760; loss: 2.17; acc: 0.27
Batch: 780; loss: 2.01; acc: 0.23
Train Epoch over. train_loss: 2.15; train_accuracy: 0.22 

9.701862836664077e-06
6.31325156064122e-06
Batch: 0; loss: 2.12; acc: 0.14
Batch: 20; loss: 2.11; acc: 0.25
Batch: 40; loss: 2.05; acc: 0.31
Batch: 60; loss: 2.01; acc: 0.27
Batch: 80; loss: 2.1; acc: 0.23
Batch: 100; loss: 1.98; acc: 0.31
Batch: 120; loss: 2.08; acc: 0.27
Batch: 140; loss: 2.12; acc: 0.25
Val Epoch over. val_loss: 2.1442262769504716; val_accuracy: 0.23119028662420382 

The current subspace-distance is: 6.31325156064122e-06 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 2.18; acc: 0.22
Batch: 20; loss: 2.23; acc: 0.22
Batch: 40; loss: 2.15; acc: 0.3
Batch: 60; loss: 2.22; acc: 0.2
Batch: 80; loss: 2.05; acc: 0.27
Batch: 100; loss: 2.12; acc: 0.2
Batch: 120; loss: 2.12; acc: 0.25
Batch: 140; loss: 2.12; acc: 0.28
Batch: 160; loss: 2.11; acc: 0.23
Batch: 180; loss: 2.12; acc: 0.19
Batch: 200; loss: 2.21; acc: 0.16
Batch: 220; loss: 2.15; acc: 0.19
Batch: 240; loss: 2.18; acc: 0.16
Batch: 260; loss: 2.07; acc: 0.27
Batch: 280; loss: 2.22; acc: 0.23
Batch: 300; loss: 2.18; acc: 0.19
Batch: 320; loss: 2.26; acc: 0.16
Batch: 340; loss: 2.16; acc: 0.2
Batch: 360; loss: 2.05; acc: 0.28
Batch: 380; loss: 2.14; acc: 0.31
Batch: 400; loss: 2.13; acc: 0.25
Batch: 420; loss: 2.11; acc: 0.22
Batch: 440; loss: 2.08; acc: 0.25
Batch: 460; loss: 2.17; acc: 0.19
Batch: 480; loss: 2.13; acc: 0.16
Batch: 500; loss: 2.16; acc: 0.23
Batch: 520; loss: 2.21; acc: 0.23
Batch: 540; loss: 2.21; acc: 0.25
Batch: 560; loss: 2.06; acc: 0.25
Batch: 580; loss: 2.21; acc: 0.17
Batch: 600; loss: 2.18; acc: 0.2
Batch: 620; loss: 2.28; acc: 0.22
Batch: 640; loss: 2.06; acc: 0.27
Batch: 660; loss: 2.07; acc: 0.23
Batch: 680; loss: 2.19; acc: 0.19
Batch: 700; loss: 2.06; acc: 0.31
Batch: 720; loss: 2.24; acc: 0.17
Batch: 740; loss: 2.09; acc: 0.28
Batch: 760; loss: 2.14; acc: 0.14
Batch: 780; loss: 2.04; acc: 0.34
Train Epoch over. train_loss: 2.15; train_accuracy: 0.22 

1.0237178685201798e-05
1.907672412926331e-06
Batch: 0; loss: 2.12; acc: 0.14
Batch: 20; loss: 2.11; acc: 0.25
Batch: 40; loss: 2.05; acc: 0.31
Batch: 60; loss: 2.01; acc: 0.27
Batch: 80; loss: 2.1; acc: 0.23
Batch: 100; loss: 1.98; acc: 0.31
Batch: 120; loss: 2.08; acc: 0.27
Batch: 140; loss: 2.12; acc: 0.25
Val Epoch over. val_loss: 2.144226323267457; val_accuracy: 0.2310907643312102 

The current subspace-distance is: 1.907672412926331e-06 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 2.04; acc: 0.27
Batch: 20; loss: 2.05; acc: 0.28
Batch: 40; loss: 2.1; acc: 0.27
Batch: 60; loss: 2.12; acc: 0.28
Batch: 80; loss: 2.25; acc: 0.17
Batch: 100; loss: 2.07; acc: 0.28
Batch: 120; loss: 2.18; acc: 0.16
Batch: 140; loss: 2.29; acc: 0.19
Batch: 160; loss: 2.16; acc: 0.17
Batch: 180; loss: 2.03; acc: 0.33
Batch: 200; loss: 2.18; acc: 0.19
Batch: 220; loss: 2.11; acc: 0.28
Batch: 240; loss: 2.09; acc: 0.27
Batch: 260; loss: 2.06; acc: 0.25
Batch: 280; loss: 2.1; acc: 0.23
Batch: 300; loss: 2.04; acc: 0.34
Batch: 320; loss: 2.19; acc: 0.17
Batch: 340; loss: 2.18; acc: 0.23
Batch: 360; loss: 2.22; acc: 0.23
Batch: 380; loss: 2.09; acc: 0.22
Batch: 400; loss: 2.09; acc: 0.28
Batch: 420; loss: 2.16; acc: 0.22
Batch: 440; loss: 2.2; acc: 0.22
Batch: 460; loss: 2.24; acc: 0.12
Batch: 480; loss: 2.14; acc: 0.23
Batch: 500; loss: 2.12; acc: 0.27
Batch: 520; loss: 2.17; acc: 0.2
Batch: 540; loss: 2.18; acc: 0.23
Batch: 560; loss: 2.07; acc: 0.25
Batch: 580; loss: 2.16; acc: 0.22
Batch: 600; loss: 2.08; acc: 0.2
Batch: 620; loss: 2.21; acc: 0.25
Batch: 640; loss: 2.1; acc: 0.3
Batch: 660; loss: 2.25; acc: 0.14
Batch: 680; loss: 2.09; acc: 0.25
Batch: 700; loss: 2.22; acc: 0.14
Batch: 720; loss: 2.02; acc: 0.31
Batch: 740; loss: 2.22; acc: 0.23
Batch: 760; loss: 2.13; acc: 0.19
Batch: 780; loss: 2.15; acc: 0.23
Train Epoch over. train_loss: 2.15; train_accuracy: 0.22 

1.0257542271574493e-05
5.6343474170716945e-06
Batch: 0; loss: 2.12; acc: 0.14
Batch: 20; loss: 2.11; acc: 0.25
Batch: 40; loss: 2.05; acc: 0.31
Batch: 60; loss: 2.01; acc: 0.27
Batch: 80; loss: 2.1; acc: 0.23
Batch: 100; loss: 1.98; acc: 0.31
Batch: 120; loss: 2.08; acc: 0.27
Batch: 140; loss: 2.12; acc: 0.25
Val Epoch over. val_loss: 2.144226693044043; val_accuracy: 0.23099124203821655 

The current subspace-distance is: 5.6343474170716945e-06 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 2.09; acc: 0.25
Batch: 20; loss: 2.01; acc: 0.34
Batch: 40; loss: 2.15; acc: 0.23
Batch: 60; loss: 2.21; acc: 0.22
Batch: 80; loss: 2.23; acc: 0.17
Batch: 100; loss: 2.09; acc: 0.25
Batch: 120; loss: 2.04; acc: 0.23
Batch: 140; loss: 2.13; acc: 0.25
Batch: 160; loss: 2.09; acc: 0.22
Batch: 180; loss: 2.26; acc: 0.19
Batch: 200; loss: 2.14; acc: 0.25
Batch: 220; loss: 2.24; acc: 0.19
Batch: 240; loss: 2.1; acc: 0.25
Batch: 260; loss: 2.31; acc: 0.09
Batch: 280; loss: 2.14; acc: 0.22
Batch: 300; loss: 2.12; acc: 0.3
Batch: 320; loss: 2.05; acc: 0.25
Batch: 340; loss: 2.19; acc: 0.23
Batch: 360; loss: 2.09; acc: 0.23
Batch: 380; loss: 2.19; acc: 0.16
Batch: 400; loss: 2.21; acc: 0.16
Batch: 420; loss: 2.16; acc: 0.2
Batch: 440; loss: 2.2; acc: 0.22
Batch: 460; loss: 2.09; acc: 0.27
Batch: 480; loss: 2.2; acc: 0.27
Batch: 500; loss: 2.17; acc: 0.22
Batch: 520; loss: 2.09; acc: 0.23
Batch: 540; loss: 2.1; acc: 0.28
Batch: 560; loss: 2.19; acc: 0.11
Batch: 580; loss: 2.21; acc: 0.19
Batch: 600; loss: 2.17; acc: 0.27
Batch: 620; loss: 2.1; acc: 0.23
Batch: 640; loss: 2.08; acc: 0.28
Batch: 660; loss: 2.17; acc: 0.22
Batch: 680; loss: 2.0; acc: 0.31
Batch: 700; loss: 2.11; acc: 0.22
Batch: 720; loss: 2.18; acc: 0.27
Batch: 740; loss: 2.17; acc: 0.2
Batch: 760; loss: 2.19; acc: 0.2
Batch: 780; loss: 1.96; acc: 0.39
Train Epoch over. train_loss: 2.15; train_accuracy: 0.22 

1.1953873581660446e-05
5.075817171018571e-06
Batch: 0; loss: 2.12; acc: 0.14
Batch: 20; loss: 2.11; acc: 0.25
Batch: 40; loss: 2.05; acc: 0.31
Batch: 60; loss: 2.01; acc: 0.27
Batch: 80; loss: 2.1; acc: 0.23
Batch: 100; loss: 1.98; acc: 0.31
Batch: 120; loss: 2.08; acc: 0.27
Batch: 140; loss: 2.12; acc: 0.25
Val Epoch over. val_loss: 2.144228730991388; val_accuracy: 0.23099124203821655 

The current subspace-distance is: 5.075817171018571e-06 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 2.16; acc: 0.2
Batch: 20; loss: 2.22; acc: 0.2
Batch: 40; loss: 2.16; acc: 0.19
Batch: 60; loss: 2.09; acc: 0.25
Batch: 80; loss: 2.22; acc: 0.19
Batch: 100; loss: 2.17; acc: 0.22
Batch: 120; loss: 2.19; acc: 0.19
Batch: 140; loss: 2.17; acc: 0.22
Batch: 160; loss: 2.08; acc: 0.28
Batch: 180; loss: 2.08; acc: 0.31
Batch: 200; loss: 2.13; acc: 0.2
Batch: 220; loss: 2.19; acc: 0.14
Batch: 240; loss: 2.11; acc: 0.28
Batch: 260; loss: 2.18; acc: 0.22
Batch: 280; loss: 2.26; acc: 0.14
Batch: 300; loss: 2.26; acc: 0.16
Batch: 320; loss: 2.15; acc: 0.22
Batch: 340; loss: 2.16; acc: 0.22
Batch: 360; loss: 2.12; acc: 0.25
Batch: 380; loss: 2.06; acc: 0.27
Batch: 400; loss: 2.16; acc: 0.19
Batch: 420; loss: 2.16; acc: 0.2
Batch: 440; loss: 2.03; acc: 0.27
Batch: 460; loss: 2.16; acc: 0.2
Batch: 480; loss: 2.11; acc: 0.33
Batch: 500; loss: 2.27; acc: 0.12
Batch: 520; loss: 2.18; acc: 0.22
Batch: 540; loss: 2.07; acc: 0.2
Batch: 560; loss: 2.11; acc: 0.33
Batch: 580; loss: 2.2; acc: 0.16
Batch: 600; loss: 2.21; acc: 0.16
Batch: 620; loss: 2.07; acc: 0.28
Batch: 640; loss: 2.12; acc: 0.27
Batch: 660; loss: 2.05; acc: 0.23
Batch: 680; loss: 2.19; acc: 0.23
Batch: 700; loss: 2.18; acc: 0.2
Batch: 720; loss: 2.22; acc: 0.12
Batch: 740; loss: 2.08; acc: 0.28
Batch: 760; loss: 2.15; acc: 0.2
Batch: 780; loss: 2.05; acc: 0.27
Train Epoch over. train_loss: 2.15; train_accuracy: 0.22 

7.836212716938462e-06
1.41183090818231e-06
Batch: 0; loss: 2.12; acc: 0.14
Batch: 20; loss: 2.11; acc: 0.25
Batch: 40; loss: 2.05; acc: 0.31
Batch: 60; loss: 2.01; acc: 0.27
Batch: 80; loss: 2.1; acc: 0.23
Batch: 100; loss: 1.98; acc: 0.31
Batch: 120; loss: 2.08; acc: 0.27
Batch: 140; loss: 2.12; acc: 0.25
Val Epoch over. val_loss: 2.1442271440651766; val_accuracy: 0.23119028662420382 

The current subspace-distance is: 1.41183090818231e-06 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 2.07; acc: 0.31
Batch: 20; loss: 2.26; acc: 0.17
Batch: 40; loss: 2.18; acc: 0.17
Batch: 60; loss: 2.05; acc: 0.23
Batch: 80; loss: 2.15; acc: 0.19
Batch: 100; loss: 2.24; acc: 0.2
Batch: 120; loss: 2.2; acc: 0.16
Batch: 140; loss: 2.19; acc: 0.23
Batch: 160; loss: 2.13; acc: 0.19
Batch: 180; loss: 2.12; acc: 0.28
Batch: 200; loss: 2.25; acc: 0.2
Batch: 220; loss: 2.01; acc: 0.34
Batch: 240; loss: 2.19; acc: 0.22
Batch: 260; loss: 2.26; acc: 0.17
Batch: 280; loss: 2.05; acc: 0.28
Batch: 300; loss: 2.13; acc: 0.23
Batch: 320; loss: 2.14; acc: 0.2
Batch: 340; loss: 2.1; acc: 0.39
Batch: 360; loss: 2.21; acc: 0.2
Batch: 380; loss: 2.19; acc: 0.27
Batch: 400; loss: 2.12; acc: 0.25
Batch: 420; loss: 2.27; acc: 0.12
Batch: 440; loss: 2.19; acc: 0.19
Batch: 460; loss: 2.11; acc: 0.2
Batch: 480; loss: 2.21; acc: 0.17
Batch: 500; loss: 1.99; acc: 0.34
Batch: 520; loss: 2.28; acc: 0.14
Batch: 540; loss: 2.17; acc: 0.23
Batch: 560; loss: 2.11; acc: 0.25
Batch: 580; loss: 2.16; acc: 0.2
Batch: 600; loss: 2.13; acc: 0.23
Batch: 620; loss: 2.26; acc: 0.14
Batch: 640; loss: 2.13; acc: 0.25
Batch: 660; loss: 2.26; acc: 0.14
Batch: 680; loss: 2.22; acc: 0.2
Batch: 700; loss: 2.13; acc: 0.2
Batch: 720; loss: 2.16; acc: 0.19
Batch: 740; loss: 2.12; acc: 0.25
Batch: 760; loss: 2.11; acc: 0.19
Batch: 780; loss: 2.11; acc: 0.25
Train Epoch over. train_loss: 2.15; train_accuracy: 0.22 

8.592196536483243e-06
5.6401349866064265e-06
Batch: 0; loss: 2.12; acc: 0.14
Batch: 20; loss: 2.11; acc: 0.25
Batch: 40; loss: 2.05; acc: 0.31
Batch: 60; loss: 2.01; acc: 0.27
Batch: 80; loss: 2.1; acc: 0.23
Batch: 100; loss: 1.98; acc: 0.31
Batch: 120; loss: 2.08; acc: 0.27
Batch: 140; loss: 2.12; acc: 0.25
Val Epoch over. val_loss: 2.1442279868824468; val_accuracy: 0.23099124203821655 

The current subspace-distance is: 5.6401349866064265e-06 

plots/subspace_training/reg_lenet_3/2020-01-22 20:51:04/d_dim_10_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
nonzero elements in E: 5266
elements in E: 1124750
fraction nonzero: 0.004681929317626139
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.31; acc: 0.08
Batch: 20; loss: 2.29; acc: 0.06
Batch: 40; loss: 2.3; acc: 0.06
Batch: 60; loss: 2.3; acc: 0.02
Batch: 80; loss: 2.3; acc: 0.03
Batch: 100; loss: 2.3; acc: 0.09
Batch: 120; loss: 2.31; acc: 0.09
Batch: 140; loss: 2.32; acc: 0.06
Batch: 160; loss: 2.31; acc: 0.08
Batch: 180; loss: 2.3; acc: 0.11
Batch: 200; loss: 2.3; acc: 0.14
Batch: 220; loss: 2.31; acc: 0.06
Batch: 240; loss: 2.32; acc: 0.05
Batch: 260; loss: 2.31; acc: 0.08
Batch: 280; loss: 2.29; acc: 0.05
Batch: 300; loss: 2.3; acc: 0.05
Batch: 320; loss: 2.31; acc: 0.05
Batch: 340; loss: 2.3; acc: 0.05
Batch: 360; loss: 2.3; acc: 0.16
Batch: 380; loss: 2.31; acc: 0.06
Batch: 400; loss: 2.31; acc: 0.14
Batch: 420; loss: 2.32; acc: 0.05
Batch: 440; loss: 2.3; acc: 0.12
Batch: 460; loss: 2.31; acc: 0.11
Batch: 480; loss: 2.31; acc: 0.06
Batch: 500; loss: 2.3; acc: 0.06
Batch: 520; loss: 2.28; acc: 0.14
Batch: 540; loss: 2.3; acc: 0.11
Batch: 560; loss: 2.3; acc: 0.09
Batch: 580; loss: 2.29; acc: 0.11
Batch: 600; loss: 2.3; acc: 0.17
Batch: 620; loss: 2.29; acc: 0.12
Batch: 640; loss: 2.29; acc: 0.16
Batch: 660; loss: 2.3; acc: 0.05
Batch: 680; loss: 2.31; acc: 0.03
Batch: 700; loss: 2.31; acc: 0.06
Batch: 720; loss: 2.31; acc: 0.06
Batch: 740; loss: 2.3; acc: 0.11
Batch: 760; loss: 2.3; acc: 0.06
Batch: 780; loss: 2.3; acc: 0.12
Train Epoch over. train_loss: 2.3; train_accuracy: 0.09 

2.535524117774912e-06
2.837909391928406e-07
Batch: 0; loss: 2.3; acc: 0.14
Batch: 20; loss: 2.29; acc: 0.14
Batch: 40; loss: 2.3; acc: 0.08
Batch: 60; loss: 2.29; acc: 0.11
Batch: 80; loss: 2.28; acc: 0.16
Batch: 100; loss: 2.3; acc: 0.09
Batch: 120; loss: 2.3; acc: 0.11
Batch: 140; loss: 2.3; acc: 0.12
Val Epoch over. val_loss: 2.2987991336044993; val_accuracy: 0.10131369426751592 

The current subspace-distance is: 2.837909391928406e-07 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.05
Batch: 20; loss: 2.31; acc: 0.08
Batch: 40; loss: 2.31; acc: 0.11
Batch: 60; loss: 2.29; acc: 0.09
Batch: 80; loss: 2.29; acc: 0.09
Batch: 100; loss: 2.3; acc: 0.08
Batch: 120; loss: 2.29; acc: 0.12
Batch: 140; loss: 2.31; acc: 0.02
Batch: 160; loss: 2.3; acc: 0.03
Batch: 180; loss: 2.3; acc: 0.14
Batch: 200; loss: 2.29; acc: 0.05
Batch: 220; loss: 2.29; acc: 0.11
Batch: 240; loss: 2.28; acc: 0.19
Batch: 260; loss: 2.29; acc: 0.14
Batch: 280; loss: 2.3; acc: 0.11
Batch: 300; loss: 2.3; acc: 0.05
Batch: 320; loss: 2.3; acc: 0.16
Batch: 340; loss: 2.29; acc: 0.08
Batch: 360; loss: 2.29; acc: 0.08
Batch: 380; loss: 2.3; acc: 0.08
Batch: 400; loss: 2.28; acc: 0.19
Batch: 420; loss: 2.29; acc: 0.14
Batch: 440; loss: 2.3; acc: 0.08
Batch: 460; loss: 2.29; acc: 0.08
Batch: 480; loss: 2.3; acc: 0.09
Batch: 500; loss: 2.28; acc: 0.14
Batch: 520; loss: 2.3; acc: 0.09
Batch: 540; loss: 2.3; acc: 0.05
Batch: 560; loss: 2.29; acc: 0.12
Batch: 580; loss: 2.29; acc: 0.14
Batch: 600; loss: 2.3; acc: 0.06
Batch: 620; loss: 2.29; acc: 0.12
Batch: 640; loss: 2.28; acc: 0.12
Batch: 660; loss: 2.3; acc: 0.09
Batch: 680; loss: 2.3; acc: 0.05
Batch: 700; loss: 2.3; acc: 0.12
Batch: 720; loss: 2.28; acc: 0.16
Batch: 740; loss: 2.29; acc: 0.17
Batch: 760; loss: 2.29; acc: 0.08
Batch: 780; loss: 2.29; acc: 0.11
Train Epoch over. train_loss: 2.3; train_accuracy: 0.1 

2.8307522370596416e-06
5.428412350738654e-07
Batch: 0; loss: 2.29; acc: 0.14
Batch: 20; loss: 2.29; acc: 0.14
Batch: 40; loss: 2.3; acc: 0.08
Batch: 60; loss: 2.29; acc: 0.11
Batch: 80; loss: 2.28; acc: 0.16
Batch: 100; loss: 2.3; acc: 0.09
Batch: 120; loss: 2.3; acc: 0.11
Batch: 140; loss: 2.3; acc: 0.12
Val Epoch over. val_loss: 2.2937907413312586; val_accuracy: 0.10131369426751592 

The current subspace-distance is: 5.428412350738654e-07 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 2.29; acc: 0.11
Batch: 20; loss: 2.3; acc: 0.06
Batch: 40; loss: 2.3; acc: 0.09
Batch: 60; loss: 2.29; acc: 0.08
Batch: 80; loss: 2.3; acc: 0.12
Batch: 100; loss: 2.28; acc: 0.12
Batch: 120; loss: 2.3; acc: 0.08
Batch: 140; loss: 2.3; acc: 0.14
Batch: 160; loss: 2.3; acc: 0.05
Batch: 180; loss: 2.3; acc: 0.08
Batch: 200; loss: 2.29; acc: 0.12
Batch: 220; loss: 2.29; acc: 0.09
Batch: 240; loss: 2.28; acc: 0.2
Batch: 260; loss: 2.3; acc: 0.05
Batch: 280; loss: 2.3; acc: 0.03
Batch: 300; loss: 2.28; acc: 0.09
Batch: 320; loss: 2.3; acc: 0.03
Batch: 340; loss: 2.29; acc: 0.06
Batch: 360; loss: 2.3; acc: 0.08
Batch: 380; loss: 2.3; acc: 0.05
Batch: 400; loss: 2.28; acc: 0.16
Batch: 420; loss: 2.29; acc: 0.11
Batch: 440; loss: 2.29; acc: 0.09
Batch: 460; loss: 2.3; acc: 0.08
Batch: 480; loss: 2.28; acc: 0.11
Batch: 500; loss: 2.29; acc: 0.12
Batch: 520; loss: 2.29; acc: 0.09
Batch: 540; loss: 2.27; acc: 0.17
Batch: 560; loss: 2.28; acc: 0.12
Batch: 580; loss: 2.3; acc: 0.09
Batch: 600; loss: 2.29; acc: 0.08
Batch: 620; loss: 2.3; acc: 0.05
Batch: 640; loss: 2.29; acc: 0.14
Batch: 660; loss: 2.29; acc: 0.06
Batch: 680; loss: 2.28; acc: 0.11
Batch: 700; loss: 2.28; acc: 0.12
Batch: 720; loss: 2.28; acc: 0.11
Batch: 740; loss: 2.29; acc: 0.06
Batch: 760; loss: 2.29; acc: 0.11
Batch: 780; loss: 2.29; acc: 0.14
Train Epoch over. train_loss: 2.29; train_accuracy: 0.1 

3.4518770917202346e-06
8.099548836071335e-07
Batch: 0; loss: 2.28; acc: 0.14
Batch: 20; loss: 2.28; acc: 0.14
Batch: 40; loss: 2.29; acc: 0.08
Batch: 60; loss: 2.28; acc: 0.11
Batch: 80; loss: 2.27; acc: 0.16
Batch: 100; loss: 2.29; acc: 0.09
Batch: 120; loss: 2.29; acc: 0.11
Batch: 140; loss: 2.29; acc: 0.12
Val Epoch over. val_loss: 2.2894383767607867; val_accuracy: 0.10131369426751592 

The current subspace-distance is: 8.099548836071335e-07 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.08
Batch: 20; loss: 2.3; acc: 0.06
Batch: 40; loss: 2.29; acc: 0.16
Batch: 60; loss: 2.29; acc: 0.08
Batch: 80; loss: 2.29; acc: 0.09
Batch: 100; loss: 2.29; acc: 0.14
Batch: 120; loss: 2.3; acc: 0.11
Batch: 140; loss: 2.29; acc: 0.08
Batch: 160; loss: 2.3; acc: 0.05
Batch: 180; loss: 2.28; acc: 0.16
Batch: 200; loss: 2.29; acc: 0.11
Batch: 220; loss: 2.3; acc: 0.08
Batch: 240; loss: 2.27; acc: 0.14
Batch: 260; loss: 2.28; acc: 0.11
Batch: 280; loss: 2.29; acc: 0.12
Batch: 300; loss: 2.28; acc: 0.08
Batch: 320; loss: 2.29; acc: 0.09
Batch: 340; loss: 2.28; acc: 0.17
Batch: 360; loss: 2.29; acc: 0.08
Batch: 380; loss: 2.3; acc: 0.03
Batch: 400; loss: 2.29; acc: 0.12
Batch: 420; loss: 2.29; acc: 0.11
Batch: 440; loss: 2.29; acc: 0.06
Batch: 460; loss: 2.29; acc: 0.14
Batch: 480; loss: 2.29; acc: 0.16
Batch: 500; loss: 2.28; acc: 0.16
Batch: 520; loss: 2.29; acc: 0.05
Batch: 540; loss: 2.29; acc: 0.11
Batch: 560; loss: 2.27; acc: 0.12
Batch: 580; loss: 2.29; acc: 0.09
Batch: 600; loss: 2.28; acc: 0.11
Batch: 620; loss: 2.29; acc: 0.11
Batch: 640; loss: 2.29; acc: 0.08
Batch: 660; loss: 2.31; acc: 0.02
Batch: 680; loss: 2.28; acc: 0.05
Batch: 700; loss: 2.29; acc: 0.11
Batch: 720; loss: 2.28; acc: 0.14
Batch: 740; loss: 2.29; acc: 0.12
Batch: 760; loss: 2.28; acc: 0.16
Batch: 780; loss: 2.27; acc: 0.11
Train Epoch over. train_loss: 2.29; train_accuracy: 0.1 

3.791323479163111e-06
9.740417681314284e-07
Batch: 0; loss: 2.28; acc: 0.14
Batch: 20; loss: 2.28; acc: 0.14
Batch: 40; loss: 2.28; acc: 0.08
Batch: 60; loss: 2.28; acc: 0.11
Batch: 80; loss: 2.27; acc: 0.16
Batch: 100; loss: 2.29; acc: 0.09
Batch: 120; loss: 2.28; acc: 0.11
Batch: 140; loss: 2.29; acc: 0.12
Val Epoch over. val_loss: 2.286703222116847; val_accuracy: 0.10131369426751592 

The current subspace-distance is: 9.740417681314284e-07 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 2.29; acc: 0.09
Batch: 20; loss: 2.29; acc: 0.08
Batch: 40; loss: 2.29; acc: 0.12
Batch: 60; loss: 2.28; acc: 0.12
Batch: 80; loss: 2.28; acc: 0.09
Batch: 100; loss: 2.28; acc: 0.11
Batch: 120; loss: 2.29; acc: 0.08
Batch: 140; loss: 2.29; acc: 0.06
Batch: 160; loss: 2.29; acc: 0.11
Batch: 180; loss: 2.29; acc: 0.08
Batch: 200; loss: 2.28; acc: 0.12
Batch: 220; loss: 2.29; acc: 0.06
Batch: 240; loss: 2.27; acc: 0.17
Batch: 260; loss: 2.28; acc: 0.08
Batch: 280; loss: 2.29; acc: 0.09
Batch: 300; loss: 2.29; acc: 0.09
Batch: 320; loss: 2.29; acc: 0.05
Batch: 340; loss: 2.29; acc: 0.09
Batch: 360; loss: 2.29; acc: 0.09
Batch: 380; loss: 2.28; acc: 0.11
Batch: 400; loss: 2.28; acc: 0.16
Batch: 420; loss: 2.27; acc: 0.12
Batch: 440; loss: 2.3; acc: 0.02
Batch: 460; loss: 2.28; acc: 0.09
Batch: 480; loss: 2.27; acc: 0.17
Batch: 500; loss: 2.28; acc: 0.06
Batch: 520; loss: 2.27; acc: 0.12
Batch: 540; loss: 2.28; acc: 0.14
Batch: 560; loss: 2.28; acc: 0.11
Batch: 580; loss: 2.27; acc: 0.11
Batch: 600; loss: 2.29; acc: 0.08
Batch: 620; loss: 2.26; acc: 0.17
Batch: 640; loss: 2.3; acc: 0.11
Batch: 660; loss: 2.28; acc: 0.11
Batch: 680; loss: 2.28; acc: 0.08
Batch: 700; loss: 2.28; acc: 0.14
Batch: 720; loss: 2.29; acc: 0.08
Batch: 740; loss: 2.29; acc: 0.06
Batch: 760; loss: 2.29; acc: 0.11
Batch: 780; loss: 2.27; acc: 0.11
Train Epoch over. train_loss: 2.29; train_accuracy: 0.1 

4.022734628961189e-06
1.2437437817425234e-06
Batch: 0; loss: 2.27; acc: 0.14
Batch: 20; loss: 2.28; acc: 0.14
Batch: 40; loss: 2.28; acc: 0.08
Batch: 60; loss: 2.28; acc: 0.11
Batch: 80; loss: 2.26; acc: 0.16
Batch: 100; loss: 2.28; acc: 0.09
Batch: 120; loss: 2.28; acc: 0.11
Batch: 140; loss: 2.29; acc: 0.12
Val Epoch over. val_loss: 2.284214589246519; val_accuracy: 0.10131369426751592 

The current subspace-distance is: 1.2437437817425234e-06 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.08
Batch: 20; loss: 2.29; acc: 0.11
Batch: 40; loss: 2.28; acc: 0.11
Batch: 60; loss: 2.29; acc: 0.11
Batch: 80; loss: 2.28; acc: 0.12
Batch: 100; loss: 2.28; acc: 0.06
Batch: 120; loss: 2.3; acc: 0.08
Batch: 140; loss: 2.3; acc: 0.08
Batch: 160; loss: 2.29; acc: 0.05
Batch: 180; loss: 2.29; acc: 0.12
Batch: 200; loss: 2.28; acc: 0.12
Batch: 220; loss: 2.29; acc: 0.08
Batch: 240; loss: 2.26; acc: 0.12
Batch: 260; loss: 2.27; acc: 0.14
Batch: 280; loss: 2.29; acc: 0.05
Batch: 300; loss: 2.28; acc: 0.12
Batch: 320; loss: 2.27; acc: 0.11
Batch: 340; loss: 2.28; acc: 0.11
Batch: 360; loss: 2.28; acc: 0.11
Batch: 380; loss: 2.27; acc: 0.16
Batch: 400; loss: 2.29; acc: 0.08
Batch: 420; loss: 2.29; acc: 0.08
Batch: 440; loss: 2.28; acc: 0.16
Batch: 460; loss: 2.29; acc: 0.12
Batch: 480; loss: 2.29; acc: 0.11
Batch: 500; loss: 2.3; acc: 0.06
Batch: 520; loss: 2.27; acc: 0.19
Batch: 540; loss: 2.28; acc: 0.08
Batch: 560; loss: 2.32; acc: 0.03
Batch: 580; loss: 2.29; acc: 0.09
Batch: 600; loss: 2.29; acc: 0.08
Batch: 620; loss: 2.29; acc: 0.09
Batch: 640; loss: 2.29; acc: 0.11
Batch: 660; loss: 2.28; acc: 0.11
Batch: 680; loss: 2.29; acc: 0.09
Batch: 700; loss: 2.3; acc: 0.06
Batch: 720; loss: 2.3; acc: 0.11
Batch: 740; loss: 2.28; acc: 0.08
Batch: 760; loss: 2.27; acc: 0.12
Batch: 780; loss: 2.28; acc: 0.09
Train Epoch over. train_loss: 2.28; train_accuracy: 0.1 

5.456041890283814e-06
1.6703560277164797e-06
Batch: 0; loss: 2.27; acc: 0.14
Batch: 20; loss: 2.27; acc: 0.14
Batch: 40; loss: 2.27; acc: 0.08
Batch: 60; loss: 2.27; acc: 0.11
Batch: 80; loss: 2.25; acc: 0.16
Batch: 100; loss: 2.28; acc: 0.09
Batch: 120; loss: 2.27; acc: 0.11
Batch: 140; loss: 2.28; acc: 0.12
Val Epoch over. val_loss: 2.2803718557782995; val_accuracy: 0.10131369426751592 

The current subspace-distance is: 1.6703560277164797e-06 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 2.29; acc: 0.05
Batch: 20; loss: 2.28; acc: 0.11
Batch: 40; loss: 2.28; acc: 0.06
Batch: 60; loss: 2.3; acc: 0.03
Batch: 80; loss: 2.28; acc: 0.08
Batch: 100; loss: 2.27; acc: 0.14
Batch: 120; loss: 2.28; acc: 0.08
Batch: 140; loss: 2.28; acc: 0.16
Batch: 160; loss: 2.28; acc: 0.12
Batch: 180; loss: 2.28; acc: 0.05
Batch: 200; loss: 2.29; acc: 0.14
Batch: 220; loss: 2.26; acc: 0.12
Batch: 240; loss: 2.3; acc: 0.09
Batch: 260; loss: 2.28; acc: 0.06
Batch: 280; loss: 2.28; acc: 0.06
Batch: 300; loss: 2.29; acc: 0.12
Batch: 320; loss: 2.3; acc: 0.06
Batch: 340; loss: 2.26; acc: 0.16
Batch: 360; loss: 2.29; acc: 0.09
Batch: 380; loss: 2.25; acc: 0.14
Batch: 400; loss: 2.28; acc: 0.06
Batch: 420; loss: 2.26; acc: 0.09
Batch: 440; loss: 2.3; acc: 0.08
Batch: 460; loss: 2.31; acc: 0.06
Batch: 480; loss: 2.27; acc: 0.16
Batch: 500; loss: 2.27; acc: 0.06
Batch: 520; loss: 2.28; acc: 0.11
Batch: 540; loss: 2.28; acc: 0.09
Batch: 560; loss: 2.26; acc: 0.12
Batch: 580; loss: 2.29; acc: 0.12
Batch: 600; loss: 2.29; acc: 0.11
Batch: 620; loss: 2.3; acc: 0.05
Batch: 640; loss: 2.27; acc: 0.06
Batch: 660; loss: 2.24; acc: 0.22
Batch: 680; loss: 2.26; acc: 0.14
Batch: 700; loss: 2.28; acc: 0.09
Batch: 720; loss: 2.25; acc: 0.14
Batch: 740; loss: 2.27; acc: 0.05
Batch: 760; loss: 2.29; acc: 0.09
Batch: 780; loss: 2.3; acc: 0.06
Train Epoch over. train_loss: 2.28; train_accuracy: 0.1 

4.645160061045317e-06
2.1435873804875882e-06
Batch: 0; loss: 2.26; acc: 0.14
Batch: 20; loss: 2.27; acc: 0.14
Batch: 40; loss: 2.25; acc: 0.08
Batch: 60; loss: 2.26; acc: 0.11
Batch: 80; loss: 2.25; acc: 0.16
Batch: 100; loss: 2.28; acc: 0.11
Batch: 120; loss: 2.26; acc: 0.11
Batch: 140; loss: 2.28; acc: 0.12
Val Epoch over. val_loss: 2.2746925399561597; val_accuracy: 0.1032046178343949 

The current subspace-distance is: 2.1435873804875882e-06 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 2.32; acc: 0.03
Batch: 20; loss: 2.26; acc: 0.12
Batch: 40; loss: 2.3; acc: 0.06
Batch: 60; loss: 2.29; acc: 0.08
Batch: 80; loss: 2.26; acc: 0.16
Batch: 100; loss: 2.29; acc: 0.12
Batch: 120; loss: 2.26; acc: 0.14
Batch: 140; loss: 2.28; acc: 0.08
Batch: 160; loss: 2.28; acc: 0.11
Batch: 180; loss: 2.23; acc: 0.19
Batch: 200; loss: 2.24; acc: 0.12
Batch: 220; loss: 2.27; acc: 0.09
Batch: 240; loss: 2.32; acc: 0.08
Batch: 260; loss: 2.27; acc: 0.09
Batch: 280; loss: 2.27; acc: 0.19
Batch: 300; loss: 2.29; acc: 0.06
Batch: 320; loss: 2.24; acc: 0.14
Batch: 340; loss: 2.28; acc: 0.08
Batch: 360; loss: 2.25; acc: 0.11
Batch: 380; loss: 2.22; acc: 0.23
Batch: 400; loss: 2.26; acc: 0.2
Batch: 420; loss: 2.27; acc: 0.14
Batch: 440; loss: 2.29; acc: 0.12
Batch: 460; loss: 2.27; acc: 0.16
Batch: 480; loss: 2.28; acc: 0.11
Batch: 500; loss: 2.27; acc: 0.19
Batch: 520; loss: 2.29; acc: 0.14
Batch: 540; loss: 2.28; acc: 0.17
Batch: 560; loss: 2.28; acc: 0.14
Batch: 580; loss: 2.25; acc: 0.2
Batch: 600; loss: 2.24; acc: 0.17
Batch: 620; loss: 2.23; acc: 0.25
Batch: 640; loss: 2.3; acc: 0.12
Batch: 660; loss: 2.26; acc: 0.16
Batch: 680; loss: 2.25; acc: 0.23
Batch: 700; loss: 2.24; acc: 0.25
Batch: 720; loss: 2.28; acc: 0.16
Batch: 740; loss: 2.26; acc: 0.22
Batch: 760; loss: 2.29; acc: 0.17
Batch: 780; loss: 2.29; acc: 0.12
Train Epoch over. train_loss: 2.27; train_accuracy: 0.14 

7.153393653425155e-06
2.427628942314186e-06
Batch: 0; loss: 2.25; acc: 0.23
Batch: 20; loss: 2.26; acc: 0.27
Batch: 40; loss: 2.23; acc: 0.22
Batch: 60; loss: 2.24; acc: 0.2
Batch: 80; loss: 2.23; acc: 0.3
Batch: 100; loss: 2.26; acc: 0.22
Batch: 120; loss: 2.24; acc: 0.22
Batch: 140; loss: 2.27; acc: 0.28
Val Epoch over. val_loss: 2.261994518292178; val_accuracy: 0.2008359872611465 

The current subspace-distance is: 2.427628942314186e-06 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 2.22; acc: 0.2
Batch: 20; loss: 2.28; acc: 0.09
Batch: 40; loss: 2.29; acc: 0.16
Batch: 60; loss: 2.22; acc: 0.17
Batch: 80; loss: 2.27; acc: 0.17
Batch: 100; loss: 2.27; acc: 0.2
Batch: 120; loss: 2.26; acc: 0.23
Batch: 140; loss: 2.24; acc: 0.14
Batch: 160; loss: 2.24; acc: 0.2
Batch: 180; loss: 2.32; acc: 0.11
Batch: 200; loss: 2.25; acc: 0.22
Batch: 220; loss: 2.29; acc: 0.11
Batch: 240; loss: 2.3; acc: 0.23
Batch: 260; loss: 2.24; acc: 0.22
Batch: 280; loss: 2.26; acc: 0.17
Batch: 300; loss: 2.3; acc: 0.17
Batch: 320; loss: 2.24; acc: 0.27
Batch: 340; loss: 2.3; acc: 0.19
Batch: 360; loss: 2.26; acc: 0.27
Batch: 380; loss: 2.3; acc: 0.25
Batch: 400; loss: 2.28; acc: 0.27
Batch: 420; loss: 2.26; acc: 0.17
Batch: 440; loss: 2.24; acc: 0.25
Batch: 460; loss: 2.19; acc: 0.36
Batch: 480; loss: 2.27; acc: 0.25
Batch: 500; loss: 2.2; acc: 0.3
Batch: 520; loss: 2.24; acc: 0.25
Batch: 540; loss: 2.24; acc: 0.23
Batch: 560; loss: 2.23; acc: 0.28
Batch: 580; loss: 2.27; acc: 0.19
Batch: 600; loss: 2.24; acc: 0.28
Batch: 620; loss: 2.28; acc: 0.25
Batch: 640; loss: 2.26; acc: 0.34
Batch: 660; loss: 2.24; acc: 0.33
Batch: 680; loss: 2.27; acc: 0.38
Batch: 700; loss: 2.21; acc: 0.31
Batch: 720; loss: 2.28; acc: 0.27
Batch: 740; loss: 2.22; acc: 0.23
Batch: 760; loss: 2.26; acc: 0.23
Batch: 780; loss: 2.25; acc: 0.33
Train Epoch over. train_loss: 2.26; train_accuracy: 0.24 

6.700322501274059e-06
2.368694595134002e-06
Batch: 0; loss: 2.22; acc: 0.33
Batch: 20; loss: 2.26; acc: 0.36
Batch: 40; loss: 2.18; acc: 0.36
Batch: 60; loss: 2.22; acc: 0.34
Batch: 80; loss: 2.2; acc: 0.36
Batch: 100; loss: 2.25; acc: 0.36
Batch: 120; loss: 2.21; acc: 0.39
Batch: 140; loss: 2.26; acc: 0.31
Val Epoch over. val_loss: 2.238365416314192; val_accuracy: 0.3244426751592357 

The current subspace-distance is: 2.368694595134002e-06 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 2.23; acc: 0.28
Batch: 20; loss: 2.25; acc: 0.31
Batch: 40; loss: 2.24; acc: 0.3
Batch: 60; loss: 2.25; acc: 0.36
Batch: 80; loss: 2.19; acc: 0.48
Batch: 100; loss: 2.23; acc: 0.3
Batch: 120; loss: 2.32; acc: 0.19
Batch: 140; loss: 2.25; acc: 0.23
Batch: 160; loss: 2.23; acc: 0.28
Batch: 180; loss: 2.16; acc: 0.44
Batch: 200; loss: 2.22; acc: 0.34
Batch: 220; loss: 2.26; acc: 0.3
Batch: 240; loss: 2.18; acc: 0.36
Batch: 260; loss: 2.25; acc: 0.31
Batch: 280; loss: 2.12; acc: 0.41
Batch: 300; loss: 2.28; acc: 0.31
Batch: 320; loss: 2.29; acc: 0.27
Batch: 340; loss: 2.16; acc: 0.38
Batch: 360; loss: 2.24; acc: 0.36
Batch: 380; loss: 2.17; acc: 0.36
Batch: 400; loss: 2.23; acc: 0.34
Batch: 420; loss: 2.26; acc: 0.27
Batch: 440; loss: 2.2; acc: 0.44
Batch: 460; loss: 2.2; acc: 0.31
Batch: 480; loss: 2.25; acc: 0.34
Batch: 500; loss: 2.2; acc: 0.22
Batch: 520; loss: 2.13; acc: 0.39
Batch: 540; loss: 2.26; acc: 0.17
Batch: 560; loss: 2.12; acc: 0.31
Batch: 580; loss: 2.15; acc: 0.3
Batch: 600; loss: 2.17; acc: 0.31
Batch: 620; loss: 2.19; acc: 0.34
Batch: 640; loss: 2.2; acc: 0.27
Batch: 660; loss: 2.17; acc: 0.3
Batch: 680; loss: 2.19; acc: 0.31
Batch: 700; loss: 2.22; acc: 0.25
Batch: 720; loss: 2.24; acc: 0.3
Batch: 740; loss: 2.13; acc: 0.34
Batch: 760; loss: 2.2; acc: 0.27
Batch: 780; loss: 2.21; acc: 0.27
Train Epoch over. train_loss: 2.21; train_accuracy: 0.32 

9.696351298771333e-06
3.569146429072134e-06
Batch: 0; loss: 2.12; acc: 0.31
Batch: 20; loss: 2.26; acc: 0.22
Batch: 40; loss: 2.07; acc: 0.36
Batch: 60; loss: 2.15; acc: 0.25
Batch: 80; loss: 2.13; acc: 0.31
Batch: 100; loss: 2.22; acc: 0.31
Batch: 120; loss: 2.16; acc: 0.28
Batch: 140; loss: 2.25; acc: 0.22
Val Epoch over. val_loss: 2.154994802110514; val_accuracy: 0.2796576433121019 

The current subspace-distance is: 3.569146429072134e-06 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 2.13; acc: 0.28
Batch: 20; loss: 2.23; acc: 0.23
Batch: 40; loss: 2.12; acc: 0.33
Batch: 60; loss: 2.12; acc: 0.3
Batch: 80; loss: 2.2; acc: 0.28
Batch: 100; loss: 2.09; acc: 0.33
Batch: 120; loss: 2.19; acc: 0.27
Batch: 140; loss: 2.07; acc: 0.33
Batch: 160; loss: 2.18; acc: 0.28
Batch: 180; loss: 2.09; acc: 0.22
Batch: 200; loss: 2.18; acc: 0.27
Batch: 220; loss: 2.17; acc: 0.23
Batch: 240; loss: 2.15; acc: 0.25
Batch: 260; loss: 2.15; acc: 0.28
Batch: 280; loss: 2.06; acc: 0.41
Batch: 300; loss: 2.02; acc: 0.33
Batch: 320; loss: 2.12; acc: 0.34
Batch: 340; loss: 2.02; acc: 0.38
Batch: 360; loss: 2.19; acc: 0.33
Batch: 380; loss: 2.11; acc: 0.23
Batch: 400; loss: 2.15; acc: 0.3
Batch: 420; loss: 2.1; acc: 0.3
Batch: 440; loss: 2.14; acc: 0.27
Batch: 460; loss: 2.05; acc: 0.3
Batch: 480; loss: 2.12; acc: 0.3
Batch: 500; loss: 2.18; acc: 0.28
Batch: 520; loss: 2.02; acc: 0.31
Batch: 540; loss: 2.04; acc: 0.36
Batch: 560; loss: 2.23; acc: 0.2
Batch: 580; loss: 2.1; acc: 0.27
Batch: 600; loss: 2.0; acc: 0.28
Batch: 620; loss: 2.16; acc: 0.27
Batch: 640; loss: 2.17; acc: 0.31
Batch: 660; loss: 2.08; acc: 0.28
Batch: 680; loss: 2.01; acc: 0.38
Batch: 700; loss: 2.25; acc: 0.23
Batch: 720; loss: 2.06; acc: 0.28
Batch: 740; loss: 2.03; acc: 0.22
Batch: 760; loss: 2.12; acc: 0.3
Batch: 780; loss: 1.98; acc: 0.39
Train Epoch over. train_loss: 2.12; train_accuracy: 0.29 

1.2079790394636802e-05
4.718438958661864e-06
Batch: 0; loss: 2.0; acc: 0.36
Batch: 20; loss: 2.25; acc: 0.16
Batch: 40; loss: 1.97; acc: 0.44
Batch: 60; loss: 2.07; acc: 0.31
Batch: 80; loss: 2.05; acc: 0.33
Batch: 100; loss: 2.16; acc: 0.33
Batch: 120; loss: 2.08; acc: 0.34
Batch: 140; loss: 2.16; acc: 0.25
Val Epoch over. val_loss: 2.076528923526691; val_accuracy: 0.3057324840764331 

The current subspace-distance is: 4.718438958661864e-06 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 2.11; acc: 0.36
Batch: 20; loss: 1.98; acc: 0.33
Batch: 40; loss: 2.05; acc: 0.34
Batch: 60; loss: 1.92; acc: 0.42
Batch: 80; loss: 2.11; acc: 0.41
Batch: 100; loss: 1.96; acc: 0.38
Batch: 120; loss: 2.05; acc: 0.27
Batch: 140; loss: 2.13; acc: 0.22
Batch: 160; loss: 2.07; acc: 0.31
Batch: 180; loss: 1.97; acc: 0.34
Batch: 200; loss: 1.97; acc: 0.34
Batch: 220; loss: 2.18; acc: 0.33
Batch: 240; loss: 2.11; acc: 0.31
Batch: 260; loss: 2.07; acc: 0.36
Batch: 280; loss: 2.06; acc: 0.31
Batch: 300; loss: 1.93; acc: 0.39
Batch: 320; loss: 2.24; acc: 0.33
Batch: 340; loss: 1.99; acc: 0.41
Batch: 360; loss: 2.01; acc: 0.34
Batch: 380; loss: 2.12; acc: 0.3
Batch: 400; loss: 2.0; acc: 0.44
Batch: 420; loss: 1.96; acc: 0.41
Batch: 440; loss: 2.15; acc: 0.27
Batch: 460; loss: 2.09; acc: 0.3
Batch: 480; loss: 1.99; acc: 0.28
Batch: 500; loss: 2.11; acc: 0.36
Batch: 520; loss: 2.13; acc: 0.31
Batch: 540; loss: 1.95; acc: 0.38
Batch: 560; loss: 1.85; acc: 0.42
Batch: 580; loss: 2.06; acc: 0.31
Batch: 600; loss: 2.15; acc: 0.31
Batch: 620; loss: 2.0; acc: 0.38
Batch: 640; loss: 1.92; acc: 0.33
Batch: 660; loss: 1.91; acc: 0.39
Batch: 680; loss: 2.09; acc: 0.34
Batch: 700; loss: 2.08; acc: 0.27
Batch: 720; loss: 1.99; acc: 0.39
Batch: 740; loss: 2.03; acc: 0.36
Batch: 760; loss: 2.24; acc: 0.3
Batch: 780; loss: 2.08; acc: 0.27
Train Epoch over. train_loss: 2.04; train_accuracy: 0.34 

1.2320991118031088e-05
2.5948054371838225e-06
Batch: 0; loss: 1.92; acc: 0.33
Batch: 20; loss: 2.27; acc: 0.28
Batch: 40; loss: 1.81; acc: 0.44
Batch: 60; loss: 1.99; acc: 0.3
Batch: 80; loss: 1.98; acc: 0.34
Batch: 100; loss: 2.1; acc: 0.33
Batch: 120; loss: 1.99; acc: 0.33
Batch: 140; loss: 2.01; acc: 0.36
Val Epoch over. val_loss: 1.9962791098151238; val_accuracy: 0.354796974522293 

The current subspace-distance is: 2.5948054371838225e-06 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 1.98; acc: 0.38
Batch: 20; loss: 2.01; acc: 0.31
Batch: 40; loss: 2.12; acc: 0.28
Batch: 60; loss: 1.89; acc: 0.34
Batch: 80; loss: 2.03; acc: 0.41
Batch: 100; loss: 1.95; acc: 0.36
Batch: 120; loss: 2.02; acc: 0.42
Batch: 140; loss: 2.17; acc: 0.28
Batch: 160; loss: 1.84; acc: 0.5
Batch: 180; loss: 2.06; acc: 0.25
Batch: 200; loss: 1.83; acc: 0.47
Batch: 220; loss: 1.85; acc: 0.42
Batch: 240; loss: 1.94; acc: 0.33
Batch: 260; loss: 1.88; acc: 0.39
Batch: 280; loss: 2.08; acc: 0.39
Batch: 300; loss: 2.07; acc: 0.44
Batch: 320; loss: 1.96; acc: 0.38
Batch: 340; loss: 1.97; acc: 0.39
Batch: 360; loss: 2.16; acc: 0.28
Batch: 380; loss: 2.15; acc: 0.28
Batch: 400; loss: 2.01; acc: 0.38
Batch: 420; loss: 1.95; acc: 0.31
Batch: 440; loss: 2.16; acc: 0.31
Batch: 460; loss: 1.96; acc: 0.45
Batch: 480; loss: 2.12; acc: 0.3
Batch: 500; loss: 1.79; acc: 0.42
Batch: 520; loss: 2.12; acc: 0.31
Batch: 540; loss: 1.9; acc: 0.41
Batch: 560; loss: 2.11; acc: 0.31
Batch: 580; loss: 1.95; acc: 0.45
Batch: 600; loss: 1.86; acc: 0.44
Batch: 620; loss: 1.98; acc: 0.36
Batch: 640; loss: 1.89; acc: 0.36
Batch: 660; loss: 1.89; acc: 0.39
Batch: 680; loss: 2.07; acc: 0.27
Batch: 700; loss: 2.18; acc: 0.3
Batch: 720; loss: 1.82; acc: 0.44
Batch: 740; loss: 2.1; acc: 0.27
Batch: 760; loss: 2.1; acc: 0.23
Batch: 780; loss: 2.07; acc: 0.28
Train Epoch over. train_loss: 1.99; train_accuracy: 0.37 

1.0508862033020705e-05
4.5219985622679815e-06
Batch: 0; loss: 1.89; acc: 0.34
Batch: 20; loss: 2.24; acc: 0.33
Batch: 40; loss: 1.72; acc: 0.47
Batch: 60; loss: 1.95; acc: 0.3
Batch: 80; loss: 1.97; acc: 0.31
Batch: 100; loss: 2.04; acc: 0.34
Batch: 120; loss: 1.96; acc: 0.38
Batch: 140; loss: 1.96; acc: 0.33
Val Epoch over. val_loss: 1.9518901033765952; val_accuracy: 0.368531050955414 

The current subspace-distance is: 4.5219985622679815e-06 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 2.05; acc: 0.36
Batch: 20; loss: 1.98; acc: 0.33
Batch: 40; loss: 1.98; acc: 0.33
Batch: 60; loss: 1.84; acc: 0.41
Batch: 80; loss: 1.95; acc: 0.44
Batch: 100; loss: 1.74; acc: 0.5
Batch: 120; loss: 2.06; acc: 0.34
Batch: 140; loss: 2.03; acc: 0.33
Batch: 160; loss: 1.98; acc: 0.36
Batch: 180; loss: 1.82; acc: 0.42
Batch: 200; loss: 1.97; acc: 0.39
Batch: 220; loss: 2.01; acc: 0.38
Batch: 240; loss: 1.93; acc: 0.38
Batch: 260; loss: 2.0; acc: 0.36
Batch: 280; loss: 2.03; acc: 0.38
Batch: 300; loss: 2.02; acc: 0.34
Batch: 320; loss: 1.79; acc: 0.42
Batch: 340; loss: 1.94; acc: 0.36
Batch: 360; loss: 2.16; acc: 0.28
Batch: 380; loss: 1.92; acc: 0.34
Batch: 400; loss: 1.88; acc: 0.34
Batch: 420; loss: 1.96; acc: 0.36
Batch: 440; loss: 1.93; acc: 0.47
Batch: 460; loss: 1.95; acc: 0.33
Batch: 480; loss: 1.84; acc: 0.39
Batch: 500; loss: 1.84; acc: 0.45
Batch: 520; loss: 1.97; acc: 0.38
Batch: 540; loss: 2.05; acc: 0.34
Batch: 560; loss: 2.04; acc: 0.33
Batch: 580; loss: 2.17; acc: 0.23
Batch: 600; loss: 1.89; acc: 0.34
Batch: 620; loss: 1.93; acc: 0.33
Batch: 640; loss: 1.88; acc: 0.42
Batch: 660; loss: 1.91; acc: 0.39
Batch: 680; loss: 1.99; acc: 0.33
Batch: 700; loss: 1.87; acc: 0.38
Batch: 720; loss: 1.81; acc: 0.41
Batch: 740; loss: 1.88; acc: 0.44
Batch: 760; loss: 1.94; acc: 0.36
Batch: 780; loss: 2.01; acc: 0.33
Train Epoch over. train_loss: 1.95; train_accuracy: 0.37 

1.682575930317398e-05
5.630806299450342e-06
Batch: 0; loss: 1.89; acc: 0.36
Batch: 20; loss: 2.19; acc: 0.38
Batch: 40; loss: 1.66; acc: 0.48
Batch: 60; loss: 1.92; acc: 0.36
Batch: 80; loss: 1.95; acc: 0.33
Batch: 100; loss: 1.96; acc: 0.41
Batch: 120; loss: 1.92; acc: 0.44
Batch: 140; loss: 1.92; acc: 0.3
Val Epoch over. val_loss: 1.9204336230162602; val_accuracy: 0.3783837579617834 

The current subspace-distance is: 5.630806299450342e-06 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 1.95; acc: 0.39
Batch: 20; loss: 1.84; acc: 0.48
Batch: 40; loss: 1.71; acc: 0.44
Batch: 60; loss: 1.89; acc: 0.38
Batch: 80; loss: 1.92; acc: 0.41
Batch: 100; loss: 1.94; acc: 0.38
Batch: 120; loss: 1.86; acc: 0.39
Batch: 140; loss: 1.99; acc: 0.33
Batch: 160; loss: 1.86; acc: 0.33
Batch: 180; loss: 1.9; acc: 0.31
Batch: 200; loss: 2.12; acc: 0.31
Batch: 220; loss: 2.01; acc: 0.31
Batch: 240; loss: 2.03; acc: 0.31
Batch: 260; loss: 1.87; acc: 0.36
Batch: 280; loss: 1.96; acc: 0.39
Batch: 300; loss: 2.09; acc: 0.34
Batch: 320; loss: 1.93; acc: 0.38
Batch: 340; loss: 1.85; acc: 0.47
Batch: 360; loss: 1.94; acc: 0.34
Batch: 380; loss: 2.05; acc: 0.28
Batch: 400; loss: 1.69; acc: 0.55
Batch: 420; loss: 2.01; acc: 0.23
Batch: 440; loss: 1.93; acc: 0.41
Batch: 460; loss: 2.03; acc: 0.41
Batch: 480; loss: 1.73; acc: 0.55
Batch: 500; loss: 1.83; acc: 0.5
Batch: 520; loss: 2.05; acc: 0.39
Batch: 540; loss: 1.78; acc: 0.45
Batch: 560; loss: 1.97; acc: 0.44
Batch: 580; loss: 1.84; acc: 0.44
Batch: 600; loss: 2.12; acc: 0.28
Batch: 620; loss: 1.9; acc: 0.39
Batch: 640; loss: 1.91; acc: 0.47
Batch: 660; loss: 1.88; acc: 0.31
Batch: 680; loss: 1.96; acc: 0.34
Batch: 700; loss: 1.86; acc: 0.38
Batch: 720; loss: 1.82; acc: 0.41
Batch: 740; loss: 1.9; acc: 0.44
Batch: 760; loss: 2.07; acc: 0.23
Batch: 780; loss: 1.83; acc: 0.52
Train Epoch over. train_loss: 1.93; train_accuracy: 0.38 

1.171147232525982e-05
6.552805643877946e-06
Batch: 0; loss: 1.89; acc: 0.38
Batch: 20; loss: 2.17; acc: 0.39
Batch: 40; loss: 1.63; acc: 0.47
Batch: 60; loss: 1.9; acc: 0.39
Batch: 80; loss: 1.92; acc: 0.33
Batch: 100; loss: 1.93; acc: 0.42
Batch: 120; loss: 1.9; acc: 0.44
Batch: 140; loss: 1.9; acc: 0.33
Val Epoch over. val_loss: 1.9004044320173323; val_accuracy: 0.38395700636942676 

The current subspace-distance is: 6.552805643877946e-06 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 1.86; acc: 0.44
Batch: 20; loss: 1.92; acc: 0.39
Batch: 40; loss: 1.71; acc: 0.47
Batch: 60; loss: 2.19; acc: 0.33
Batch: 80; loss: 1.89; acc: 0.38
Batch: 100; loss: 2.04; acc: 0.28
Batch: 120; loss: 1.98; acc: 0.31
Batch: 140; loss: 1.78; acc: 0.45
Batch: 160; loss: 1.96; acc: 0.36
Batch: 180; loss: 1.82; acc: 0.39
Batch: 200; loss: 1.98; acc: 0.33
Batch: 220; loss: 2.09; acc: 0.33
Batch: 240; loss: 1.85; acc: 0.38
Batch: 260; loss: 2.06; acc: 0.27
Batch: 280; loss: 2.02; acc: 0.3
Batch: 300; loss: 1.82; acc: 0.45
Batch: 320; loss: 2.0; acc: 0.38
Batch: 340; loss: 2.12; acc: 0.38
Batch: 360; loss: 2.13; acc: 0.25
Batch: 380; loss: 1.87; acc: 0.41
Batch: 400; loss: 2.05; acc: 0.33
Batch: 420; loss: 1.66; acc: 0.47
Batch: 440; loss: 1.95; acc: 0.44
Batch: 460; loss: 1.83; acc: 0.39
Batch: 480; loss: 1.76; acc: 0.44
Batch: 500; loss: 2.02; acc: 0.33
Batch: 520; loss: 1.8; acc: 0.47
Batch: 540; loss: 1.8; acc: 0.44
Batch: 560; loss: 1.87; acc: 0.39
Batch: 580; loss: 1.9; acc: 0.45
Batch: 600; loss: 2.03; acc: 0.28
Batch: 620; loss: 1.86; acc: 0.41
Batch: 640; loss: 1.76; acc: 0.47
Batch: 660; loss: 1.87; acc: 0.44
Batch: 680; loss: 2.06; acc: 0.31
Batch: 700; loss: 2.03; acc: 0.36
Batch: 720; loss: 1.89; acc: 0.41
Batch: 740; loss: 1.88; acc: 0.38
Batch: 760; loss: 1.79; acc: 0.48
Batch: 780; loss: 1.83; acc: 0.38
Train Epoch over. train_loss: 1.92; train_accuracy: 0.38 

1.363357478112448e-05
7.122428996808594e-06
Batch: 0; loss: 1.89; acc: 0.34
Batch: 20; loss: 2.13; acc: 0.39
Batch: 40; loss: 1.6; acc: 0.5
Batch: 60; loss: 1.89; acc: 0.41
Batch: 80; loss: 1.9; acc: 0.36
Batch: 100; loss: 1.88; acc: 0.45
Batch: 120; loss: 1.9; acc: 0.47
Batch: 140; loss: 1.87; acc: 0.34
Val Epoch over. val_loss: 1.8875154780734116; val_accuracy: 0.38525079617834396 

The current subspace-distance is: 7.122428996808594e-06 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 1.93; acc: 0.47
Batch: 20; loss: 2.11; acc: 0.3
Batch: 40; loss: 1.93; acc: 0.27
Batch: 60; loss: 2.05; acc: 0.31
Batch: 80; loss: 1.79; acc: 0.41
Batch: 100; loss: 2.09; acc: 0.22
Batch: 120; loss: 1.88; acc: 0.33
Batch: 140; loss: 1.88; acc: 0.36
Batch: 160; loss: 1.75; acc: 0.44
Batch: 180; loss: 1.87; acc: 0.44
Batch: 200; loss: 1.78; acc: 0.47
Batch: 220; loss: 1.91; acc: 0.34
Batch: 240; loss: 2.05; acc: 0.33
Batch: 260; loss: 1.67; acc: 0.55
Batch: 280; loss: 1.89; acc: 0.39
Batch: 300; loss: 2.0; acc: 0.23
Batch: 320; loss: 1.92; acc: 0.41
Batch: 340; loss: 1.91; acc: 0.41
Batch: 360; loss: 2.05; acc: 0.3
Batch: 380; loss: 1.77; acc: 0.42
Batch: 400; loss: 1.95; acc: 0.34
Batch: 420; loss: 2.12; acc: 0.36
Batch: 440; loss: 1.85; acc: 0.39
Batch: 460; loss: 1.79; acc: 0.44
Batch: 480; loss: 1.93; acc: 0.38
Batch: 500; loss: 2.14; acc: 0.38
Batch: 520; loss: 1.95; acc: 0.33
Batch: 540; loss: 1.91; acc: 0.44
Batch: 560; loss: 1.83; acc: 0.42
Batch: 580; loss: 1.81; acc: 0.41
Batch: 600; loss: 1.9; acc: 0.38
Batch: 620; loss: 1.99; acc: 0.31
Batch: 640; loss: 1.84; acc: 0.41
Batch: 660; loss: 1.73; acc: 0.42
Batch: 680; loss: 1.97; acc: 0.31
Batch: 700; loss: 2.0; acc: 0.34
Batch: 720; loss: 1.87; acc: 0.41
Batch: 740; loss: 2.0; acc: 0.36
Batch: 760; loss: 1.81; acc: 0.41
Batch: 780; loss: 1.75; acc: 0.5
Train Epoch over. train_loss: 1.91; train_accuracy: 0.38 

1.241864993062336e-05
5.173720182938268e-06
Batch: 0; loss: 1.9; acc: 0.36
Batch: 20; loss: 2.11; acc: 0.39
Batch: 40; loss: 1.58; acc: 0.52
Batch: 60; loss: 1.89; acc: 0.39
Batch: 80; loss: 1.89; acc: 0.38
Batch: 100; loss: 1.86; acc: 0.45
Batch: 120; loss: 1.91; acc: 0.47
Batch: 140; loss: 1.85; acc: 0.34
Val Epoch over. val_loss: 1.8805453329329278; val_accuracy: 0.3831608280254777 

The current subspace-distance is: 5.173720182938268e-06 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 1.88; acc: 0.33
Batch: 20; loss: 1.95; acc: 0.33
Batch: 40; loss: 1.82; acc: 0.33
Batch: 60; loss: 1.77; acc: 0.45
Batch: 80; loss: 1.97; acc: 0.28
Batch: 100; loss: 1.94; acc: 0.31
Batch: 120; loss: 1.93; acc: 0.36
Batch: 140; loss: 1.86; acc: 0.33
Batch: 160; loss: 1.8; acc: 0.34
Batch: 180; loss: 1.92; acc: 0.31
Batch: 200; loss: 1.84; acc: 0.39
Batch: 220; loss: 2.17; acc: 0.28
Batch: 240; loss: 1.79; acc: 0.45
Batch: 260; loss: 1.89; acc: 0.42
Batch: 280; loss: 1.98; acc: 0.41
Batch: 300; loss: 1.88; acc: 0.39
Batch: 320; loss: 2.03; acc: 0.33
Batch: 340; loss: 2.0; acc: 0.28
Batch: 360; loss: 1.76; acc: 0.44
Batch: 380; loss: 1.89; acc: 0.42
Batch: 400; loss: 1.71; acc: 0.44
Batch: 420; loss: 1.96; acc: 0.33
Batch: 440; loss: 1.87; acc: 0.38
Batch: 460; loss: 1.97; acc: 0.41
Batch: 480; loss: 1.86; acc: 0.42
Batch: 500; loss: 1.81; acc: 0.39
Batch: 520; loss: 1.93; acc: 0.33
Batch: 540; loss: 1.97; acc: 0.36
Batch: 560; loss: 2.09; acc: 0.31
Batch: 580; loss: 2.1; acc: 0.3
Batch: 600; loss: 1.78; acc: 0.41
Batch: 620; loss: 1.91; acc: 0.39
Batch: 640; loss: 1.84; acc: 0.47
Batch: 660; loss: 1.82; acc: 0.47
Batch: 680; loss: 1.73; acc: 0.42
Batch: 700; loss: 1.89; acc: 0.34
Batch: 720; loss: 1.95; acc: 0.34
Batch: 740; loss: 1.62; acc: 0.52
Batch: 760; loss: 1.72; acc: 0.42
Batch: 780; loss: 1.75; acc: 0.39
Train Epoch over. train_loss: 1.9; train_accuracy: 0.38 

1.1182057278347202e-05
4.856516625295626e-06
Batch: 0; loss: 1.9; acc: 0.38
Batch: 20; loss: 2.11; acc: 0.3
Batch: 40; loss: 1.56; acc: 0.53
Batch: 60; loss: 1.89; acc: 0.39
Batch: 80; loss: 1.89; acc: 0.39
Batch: 100; loss: 1.83; acc: 0.45
Batch: 120; loss: 1.92; acc: 0.45
Batch: 140; loss: 1.83; acc: 0.38
Val Epoch over. val_loss: 1.8745552233070324; val_accuracy: 0.383359872611465 

The current subspace-distance is: 4.856516625295626e-06 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 1.9; acc: 0.36
Batch: 20; loss: 2.03; acc: 0.34
Batch: 40; loss: 1.76; acc: 0.41
Batch: 60; loss: 1.83; acc: 0.38
Batch: 80; loss: 1.91; acc: 0.36
Batch: 100; loss: 2.06; acc: 0.33
Batch: 120; loss: 2.0; acc: 0.34
Batch: 140; loss: 1.76; acc: 0.45
Batch: 160; loss: 1.69; acc: 0.41
Batch: 180; loss: 2.03; acc: 0.34
Batch: 200; loss: 1.96; acc: 0.38
Batch: 220; loss: 1.63; acc: 0.45
Batch: 240; loss: 1.8; acc: 0.36
Batch: 260; loss: 2.23; acc: 0.3
Batch: 280; loss: 1.74; acc: 0.41
Batch: 300; loss: 1.96; acc: 0.3
Batch: 320; loss: 1.78; acc: 0.41
Batch: 340; loss: 1.94; acc: 0.34
Batch: 360; loss: 1.83; acc: 0.36
Batch: 380; loss: 2.05; acc: 0.28
Batch: 400; loss: 2.16; acc: 0.27
Batch: 420; loss: 1.84; acc: 0.41
Batch: 440; loss: 1.89; acc: 0.39
Batch: 460; loss: 1.76; acc: 0.38
Batch: 480; loss: 1.63; acc: 0.47
Batch: 500; loss: 1.75; acc: 0.42
Batch: 520; loss: 2.0; acc: 0.33
Batch: 540; loss: 1.83; acc: 0.45
Batch: 560; loss: 1.91; acc: 0.36
Batch: 580; loss: 1.72; acc: 0.5
Batch: 600; loss: 1.83; acc: 0.41
Batch: 620; loss: 2.03; acc: 0.36
Batch: 640; loss: 1.93; acc: 0.41
Batch: 660; loss: 1.82; acc: 0.36
Batch: 680; loss: 1.7; acc: 0.45
Batch: 700; loss: 1.76; acc: 0.38
Batch: 720; loss: 1.72; acc: 0.41
Batch: 740; loss: 1.8; acc: 0.36
Batch: 760; loss: 1.64; acc: 0.48
Batch: 780; loss: 1.74; acc: 0.41
Train Epoch over. train_loss: 1.9; train_accuracy: 0.37 

1.2775114555552136e-05
7.223837656056276e-06
Batch: 0; loss: 1.91; acc: 0.36
Batch: 20; loss: 2.09; acc: 0.3
Batch: 40; loss: 1.56; acc: 0.53
Batch: 60; loss: 1.89; acc: 0.39
Batch: 80; loss: 1.88; acc: 0.39
Batch: 100; loss: 1.82; acc: 0.45
Batch: 120; loss: 1.92; acc: 0.47
Batch: 140; loss: 1.81; acc: 0.38
Val Epoch over. val_loss: 1.8717909785592632; val_accuracy: 0.38166799363057324 

The current subspace-distance is: 7.223837656056276e-06 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 1.88; acc: 0.41
Batch: 20; loss: 1.9; acc: 0.38
Batch: 40; loss: 1.95; acc: 0.31
Batch: 60; loss: 1.6; acc: 0.52
Batch: 80; loss: 1.86; acc: 0.33
Batch: 100; loss: 2.01; acc: 0.38
Batch: 120; loss: 1.81; acc: 0.39
Batch: 140; loss: 1.85; acc: 0.44
Batch: 160; loss: 1.99; acc: 0.28
Batch: 180; loss: 1.87; acc: 0.38
Batch: 200; loss: 1.98; acc: 0.31
Batch: 220; loss: 1.92; acc: 0.36
Batch: 240; loss: 1.89; acc: 0.39
Batch: 260; loss: 1.82; acc: 0.38
Batch: 280; loss: 1.98; acc: 0.39
Batch: 300; loss: 1.79; acc: 0.47
Batch: 320; loss: 1.94; acc: 0.33
Batch: 340; loss: 1.76; acc: 0.41
Batch: 360; loss: 1.65; acc: 0.47
Batch: 380; loss: 1.84; acc: 0.39
Batch: 400; loss: 2.01; acc: 0.39
Batch: 420; loss: 1.73; acc: 0.45
Batch: 440; loss: 1.87; acc: 0.41
Batch: 460; loss: 1.93; acc: 0.31
Batch: 480; loss: 1.76; acc: 0.41
Batch: 500; loss: 1.91; acc: 0.36
Batch: 520; loss: 1.85; acc: 0.38
Batch: 540; loss: 1.73; acc: 0.45
Batch: 560; loss: 1.98; acc: 0.33
Batch: 580; loss: 1.82; acc: 0.38
Batch: 600; loss: 2.06; acc: 0.23
Batch: 620; loss: 2.01; acc: 0.31
Batch: 640; loss: 1.82; acc: 0.36
Batch: 660; loss: 1.75; acc: 0.5
Batch: 680; loss: 1.97; acc: 0.3
Batch: 700; loss: 1.92; acc: 0.36
Batch: 720; loss: 1.98; acc: 0.28
Batch: 740; loss: 1.91; acc: 0.31
Batch: 760; loss: 1.9; acc: 0.34
Batch: 780; loss: 1.83; acc: 0.44
Train Epoch over. train_loss: 1.89; train_accuracy: 0.37 

1.2202018297102768e-05
4.296273800719064e-06
Batch: 0; loss: 1.9; acc: 0.36
Batch: 20; loss: 2.09; acc: 0.31
Batch: 40; loss: 1.55; acc: 0.55
Batch: 60; loss: 1.89; acc: 0.41
Batch: 80; loss: 1.87; acc: 0.39
Batch: 100; loss: 1.81; acc: 0.45
Batch: 120; loss: 1.92; acc: 0.45
Batch: 140; loss: 1.81; acc: 0.42
Val Epoch over. val_loss: 1.8680945452611157; val_accuracy: 0.3752985668789809 

The current subspace-distance is: 4.296273800719064e-06 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 2.03; acc: 0.3
Batch: 20; loss: 1.83; acc: 0.42
Batch: 40; loss: 1.99; acc: 0.34
Batch: 60; loss: 1.79; acc: 0.36
Batch: 80; loss: 1.89; acc: 0.36
Batch: 100; loss: 1.66; acc: 0.55
Batch: 120; loss: 1.91; acc: 0.31
Batch: 140; loss: 1.98; acc: 0.31
Batch: 160; loss: 1.9; acc: 0.34
Batch: 180; loss: 1.96; acc: 0.39
Batch: 200; loss: 2.03; acc: 0.31
Batch: 220; loss: 1.87; acc: 0.34
Batch: 240; loss: 1.85; acc: 0.36
Batch: 260; loss: 1.69; acc: 0.52
Batch: 280; loss: 1.99; acc: 0.38
Batch: 300; loss: 1.73; acc: 0.44
Batch: 320; loss: 1.84; acc: 0.39
Batch: 340; loss: 1.86; acc: 0.38
Batch: 360; loss: 1.87; acc: 0.41
Batch: 380; loss: 1.89; acc: 0.39
Batch: 400; loss: 1.86; acc: 0.27
Batch: 420; loss: 1.95; acc: 0.41
Batch: 440; loss: 1.95; acc: 0.34
Batch: 460; loss: 1.93; acc: 0.36
Batch: 480; loss: 1.9; acc: 0.38
Batch: 500; loss: 2.19; acc: 0.28
Batch: 520; loss: 2.09; acc: 0.34
Batch: 540; loss: 1.87; acc: 0.44
Batch: 560; loss: 1.67; acc: 0.38
Batch: 580; loss: 2.02; acc: 0.31
Batch: 600; loss: 1.89; acc: 0.34
Batch: 620; loss: 1.93; acc: 0.28
Batch: 640; loss: 2.07; acc: 0.34
Batch: 660; loss: 1.68; acc: 0.45
Batch: 680; loss: 1.84; acc: 0.36
Batch: 700; loss: 2.04; acc: 0.27
Batch: 720; loss: 1.85; acc: 0.39
Batch: 740; loss: 1.88; acc: 0.34
Batch: 760; loss: 2.1; acc: 0.19
Batch: 780; loss: 1.76; acc: 0.34
Train Epoch over. train_loss: 1.89; train_accuracy: 0.37 

1.9441333279246464e-05
3.876710252370685e-06
Batch: 0; loss: 1.9; acc: 0.36
Batch: 20; loss: 2.09; acc: 0.31
Batch: 40; loss: 1.55; acc: 0.55
Batch: 60; loss: 1.89; acc: 0.41
Batch: 80; loss: 1.87; acc: 0.39
Batch: 100; loss: 1.8; acc: 0.44
Batch: 120; loss: 1.92; acc: 0.44
Batch: 140; loss: 1.8; acc: 0.41
Val Epoch over. val_loss: 1.8664670537231833; val_accuracy: 0.37480095541401276 

The current subspace-distance is: 3.876710252370685e-06 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.95; acc: 0.39
Batch: 20; loss: 1.89; acc: 0.3
Batch: 40; loss: 1.82; acc: 0.34
Batch: 60; loss: 1.73; acc: 0.33
Batch: 80; loss: 1.74; acc: 0.45
Batch: 100; loss: 1.77; acc: 0.41
Batch: 120; loss: 1.98; acc: 0.33
Batch: 140; loss: 1.92; acc: 0.3
Batch: 160; loss: 1.74; acc: 0.44
Batch: 180; loss: 1.88; acc: 0.41
Batch: 200; loss: 1.93; acc: 0.27
Batch: 220; loss: 1.93; acc: 0.36
Batch: 240; loss: 2.08; acc: 0.34
Batch: 260; loss: 1.89; acc: 0.44
Batch: 280; loss: 1.86; acc: 0.38
Batch: 300; loss: 1.91; acc: 0.36
Batch: 320; loss: 1.96; acc: 0.36
Batch: 340; loss: 1.77; acc: 0.42
Batch: 360; loss: 2.0; acc: 0.39
Batch: 380; loss: 2.07; acc: 0.31
Batch: 400; loss: 1.85; acc: 0.44
Batch: 420; loss: 1.83; acc: 0.38
Batch: 440; loss: 1.84; acc: 0.28
Batch: 460; loss: 1.85; acc: 0.45
Batch: 480; loss: 2.06; acc: 0.3
Batch: 500; loss: 1.81; acc: 0.45
Batch: 520; loss: 1.94; acc: 0.41
Batch: 540; loss: 2.02; acc: 0.34
Batch: 560; loss: 1.78; acc: 0.41
Batch: 580; loss: 1.76; acc: 0.45
Batch: 600; loss: 1.87; acc: 0.38
Batch: 620; loss: 1.85; acc: 0.38
Batch: 640; loss: 1.93; acc: 0.39
Batch: 660; loss: 1.92; acc: 0.33
Batch: 680; loss: 1.75; acc: 0.42
Batch: 700; loss: 1.93; acc: 0.38
Batch: 720; loss: 1.91; acc: 0.36
Batch: 740; loss: 1.92; acc: 0.34
Batch: 760; loss: 1.76; acc: 0.39
Batch: 780; loss: 1.79; acc: 0.36
Train Epoch over. train_loss: 1.89; train_accuracy: 0.37 

1.3645231774717104e-05
4.2193282752123196e-06
Batch: 0; loss: 1.9; acc: 0.36
Batch: 20; loss: 2.09; acc: 0.3
Batch: 40; loss: 1.55; acc: 0.56
Batch: 60; loss: 1.88; acc: 0.39
Batch: 80; loss: 1.87; acc: 0.39
Batch: 100; loss: 1.8; acc: 0.42
Batch: 120; loss: 1.93; acc: 0.44
Batch: 140; loss: 1.8; acc: 0.42
Val Epoch over. val_loss: 1.8660139870491756; val_accuracy: 0.37261146496815284 

The current subspace-distance is: 4.2193282752123196e-06 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.85; acc: 0.36
Batch: 20; loss: 1.85; acc: 0.33
Batch: 40; loss: 1.83; acc: 0.36
Batch: 60; loss: 1.91; acc: 0.36
Batch: 80; loss: 1.94; acc: 0.39
Batch: 100; loss: 1.77; acc: 0.41
Batch: 120; loss: 2.05; acc: 0.33
Batch: 140; loss: 1.83; acc: 0.36
Batch: 160; loss: 2.04; acc: 0.33
Batch: 180; loss: 2.02; acc: 0.34
Batch: 200; loss: 1.83; acc: 0.39
Batch: 220; loss: 2.0; acc: 0.28
Batch: 240; loss: 1.72; acc: 0.42
Batch: 260; loss: 1.9; acc: 0.38
Batch: 280; loss: 1.78; acc: 0.41
Batch: 300; loss: 1.98; acc: 0.41
Batch: 320; loss: 1.87; acc: 0.38
Batch: 340; loss: 1.8; acc: 0.42
Batch: 360; loss: 1.91; acc: 0.33
Batch: 380; loss: 1.9; acc: 0.34
Batch: 400; loss: 1.98; acc: 0.28
Batch: 420; loss: 1.68; acc: 0.48
Batch: 440; loss: 1.88; acc: 0.3
Batch: 460; loss: 1.86; acc: 0.36
Batch: 480; loss: 1.71; acc: 0.47
Batch: 500; loss: 1.97; acc: 0.31
Batch: 520; loss: 1.93; acc: 0.38
Batch: 540; loss: 2.02; acc: 0.23
Batch: 560; loss: 1.95; acc: 0.34
Batch: 580; loss: 1.95; acc: 0.33
Batch: 600; loss: 1.78; acc: 0.39
Batch: 620; loss: 1.7; acc: 0.44
Batch: 640; loss: 1.84; acc: 0.38
Batch: 660; loss: 2.01; acc: 0.31
Batch: 680; loss: 1.94; acc: 0.33
Batch: 700; loss: 1.83; acc: 0.47
Batch: 720; loss: 1.82; acc: 0.38
Batch: 740; loss: 1.61; acc: 0.5
Batch: 760; loss: 1.94; acc: 0.28
Batch: 780; loss: 1.83; acc: 0.36
Train Epoch over. train_loss: 1.88; train_accuracy: 0.37 

1.2847053767472971e-05
5.4878410082892515e-06
Batch: 0; loss: 1.9; acc: 0.36
Batch: 20; loss: 2.08; acc: 0.3
Batch: 40; loss: 1.54; acc: 0.56
Batch: 60; loss: 1.88; acc: 0.39
Batch: 80; loss: 1.86; acc: 0.39
Batch: 100; loss: 1.8; acc: 0.42
Batch: 120; loss: 1.93; acc: 0.44
Batch: 140; loss: 1.79; acc: 0.42
Val Epoch over. val_loss: 1.8645596656070393; val_accuracy: 0.3718152866242038 

The current subspace-distance is: 5.4878410082892515e-06 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.77; acc: 0.44
Batch: 20; loss: 1.72; acc: 0.44
Batch: 40; loss: 1.85; acc: 0.38
Batch: 60; loss: 2.01; acc: 0.27
Batch: 80; loss: 1.91; acc: 0.3
Batch: 100; loss: 2.04; acc: 0.33
Batch: 120; loss: 1.78; acc: 0.47
Batch: 140; loss: 1.88; acc: 0.42
Batch: 160; loss: 1.81; acc: 0.39
Batch: 180; loss: 1.92; acc: 0.31
Batch: 200; loss: 1.8; acc: 0.44
Batch: 220; loss: 2.08; acc: 0.31
Batch: 240; loss: 1.74; acc: 0.34
Batch: 260; loss: 1.76; acc: 0.39
Batch: 280; loss: 1.97; acc: 0.39
Batch: 300; loss: 1.89; acc: 0.33
Batch: 320; loss: 1.89; acc: 0.44
Batch: 340; loss: 1.94; acc: 0.28
Batch: 360; loss: 1.89; acc: 0.33
Batch: 380; loss: 1.93; acc: 0.34
Batch: 400; loss: 1.98; acc: 0.27
Batch: 420; loss: 1.99; acc: 0.3
Batch: 440; loss: 1.87; acc: 0.42
Batch: 460; loss: 1.88; acc: 0.41
Batch: 480; loss: 1.91; acc: 0.36
Batch: 500; loss: 1.88; acc: 0.39
Batch: 520; loss: 1.76; acc: 0.48
Batch: 540; loss: 1.97; acc: 0.33
Batch: 560; loss: 1.79; acc: 0.47
Batch: 580; loss: 1.96; acc: 0.41
Batch: 600; loss: 2.04; acc: 0.25
Batch: 620; loss: 1.89; acc: 0.31
Batch: 640; loss: 1.91; acc: 0.33
Batch: 660; loss: 1.73; acc: 0.48
Batch: 680; loss: 1.96; acc: 0.41
Batch: 700; loss: 1.89; acc: 0.38
Batch: 720; loss: 1.88; acc: 0.39
Batch: 740; loss: 1.81; acc: 0.44
Batch: 760; loss: 1.59; acc: 0.56
Batch: 780; loss: 1.85; acc: 0.34
Train Epoch over. train_loss: 1.88; train_accuracy: 0.37 

1.3726074939768296e-05
5.857902579009533e-06
Batch: 0; loss: 1.9; acc: 0.34
Batch: 20; loss: 2.08; acc: 0.3
Batch: 40; loss: 1.54; acc: 0.58
Batch: 60; loss: 1.88; acc: 0.39
Batch: 80; loss: 1.86; acc: 0.39
Batch: 100; loss: 1.8; acc: 0.42
Batch: 120; loss: 1.92; acc: 0.44
Batch: 140; loss: 1.78; acc: 0.42
Val Epoch over. val_loss: 1.86315100587857; val_accuracy: 0.37191480891719747 

The current subspace-distance is: 5.857902579009533e-06 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.87; acc: 0.36
Batch: 20; loss: 1.93; acc: 0.39
Batch: 40; loss: 1.73; acc: 0.38
Batch: 60; loss: 1.92; acc: 0.39
Batch: 80; loss: 1.91; acc: 0.36
Batch: 100; loss: 1.91; acc: 0.42
Batch: 120; loss: 2.04; acc: 0.31
Batch: 140; loss: 1.69; acc: 0.56
Batch: 160; loss: 1.73; acc: 0.41
Batch: 180; loss: 1.89; acc: 0.34
Batch: 200; loss: 1.96; acc: 0.27
Batch: 220; loss: 1.79; acc: 0.41
Batch: 240; loss: 1.92; acc: 0.39
Batch: 260; loss: 1.89; acc: 0.36
Batch: 280; loss: 1.87; acc: 0.39
Batch: 300; loss: 2.07; acc: 0.33
Batch: 320; loss: 1.99; acc: 0.3
Batch: 340; loss: 1.98; acc: 0.42
Batch: 360; loss: 1.75; acc: 0.42
Batch: 380; loss: 1.92; acc: 0.34
Batch: 400; loss: 1.82; acc: 0.41
Batch: 420; loss: 1.92; acc: 0.36
Batch: 440; loss: 1.81; acc: 0.45
Batch: 460; loss: 1.92; acc: 0.25
Batch: 480; loss: 1.91; acc: 0.34
Batch: 500; loss: 1.9; acc: 0.38
Batch: 520; loss: 1.96; acc: 0.33
Batch: 540; loss: 2.04; acc: 0.33
Batch: 560; loss: 2.0; acc: 0.31
Batch: 580; loss: 1.92; acc: 0.36
Batch: 600; loss: 1.84; acc: 0.38
Batch: 620; loss: 1.98; acc: 0.34
Batch: 640; loss: 1.77; acc: 0.44
Batch: 660; loss: 1.89; acc: 0.38
Batch: 680; loss: 1.91; acc: 0.39
Batch: 700; loss: 1.84; acc: 0.36
Batch: 720; loss: 1.98; acc: 0.33
Batch: 740; loss: 2.14; acc: 0.34
Batch: 760; loss: 1.68; acc: 0.47
Batch: 780; loss: 1.82; acc: 0.42
Train Epoch over. train_loss: 1.88; train_accuracy: 0.37 

1.8570121028460562e-05
6.094227501307614e-06
Batch: 0; loss: 1.9; acc: 0.34
Batch: 20; loss: 2.07; acc: 0.28
Batch: 40; loss: 1.54; acc: 0.58
Batch: 60; loss: 1.88; acc: 0.36
Batch: 80; loss: 1.86; acc: 0.39
Batch: 100; loss: 1.79; acc: 0.41
Batch: 120; loss: 1.92; acc: 0.42
Batch: 140; loss: 1.78; acc: 0.41
Val Epoch over. val_loss: 1.8624030237744569; val_accuracy: 0.37330812101910826 

The current subspace-distance is: 6.094227501307614e-06 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.84; acc: 0.34
Batch: 20; loss: 2.03; acc: 0.3
Batch: 40; loss: 1.98; acc: 0.36
Batch: 60; loss: 2.07; acc: 0.22
Batch: 80; loss: 1.94; acc: 0.33
Batch: 100; loss: 1.91; acc: 0.38
Batch: 120; loss: 1.79; acc: 0.44
Batch: 140; loss: 1.99; acc: 0.33
Batch: 160; loss: 2.12; acc: 0.28
Batch: 180; loss: 1.88; acc: 0.39
Batch: 200; loss: 1.96; acc: 0.38
Batch: 220; loss: 2.24; acc: 0.27
Batch: 240; loss: 1.76; acc: 0.39
Batch: 260; loss: 1.84; acc: 0.47
Batch: 280; loss: 1.8; acc: 0.39
Batch: 300; loss: 2.02; acc: 0.27
Batch: 320; loss: 1.96; acc: 0.33
Batch: 340; loss: 1.86; acc: 0.38
Batch: 360; loss: 1.91; acc: 0.34
Batch: 380; loss: 1.86; acc: 0.36
Batch: 400; loss: 1.76; acc: 0.38
Batch: 420; loss: 2.02; acc: 0.38
Batch: 440; loss: 1.65; acc: 0.48
Batch: 460; loss: 1.71; acc: 0.38
Batch: 480; loss: 1.57; acc: 0.58
Batch: 500; loss: 1.97; acc: 0.31
Batch: 520; loss: 1.79; acc: 0.5
Batch: 540; loss: 1.78; acc: 0.33
Batch: 560; loss: 1.94; acc: 0.34
Batch: 580; loss: 1.85; acc: 0.41
Batch: 600; loss: 1.85; acc: 0.31
Batch: 620; loss: 1.9; acc: 0.31
Batch: 640; loss: 1.9; acc: 0.36
Batch: 660; loss: 1.88; acc: 0.33
Batch: 680; loss: 1.69; acc: 0.45
Batch: 700; loss: 1.9; acc: 0.33
Batch: 720; loss: 1.84; acc: 0.31
Batch: 740; loss: 1.83; acc: 0.38
Batch: 760; loss: 1.73; acc: 0.38
Batch: 780; loss: 1.64; acc: 0.52
Train Epoch over. train_loss: 1.88; train_accuracy: 0.37 

1.395961589878425e-05
6.807424597354839e-06
Batch: 0; loss: 1.9; acc: 0.36
Batch: 20; loss: 2.06; acc: 0.27
Batch: 40; loss: 1.54; acc: 0.58
Batch: 60; loss: 1.87; acc: 0.38
Batch: 80; loss: 1.85; acc: 0.39
Batch: 100; loss: 1.79; acc: 0.44
Batch: 120; loss: 1.92; acc: 0.42
Batch: 140; loss: 1.78; acc: 0.42
Val Epoch over. val_loss: 1.8605826189563532; val_accuracy: 0.3743033439490446 

The current subspace-distance is: 6.807424597354839e-06 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.8; acc: 0.47
Batch: 20; loss: 2.0; acc: 0.38
Batch: 40; loss: 2.05; acc: 0.3
Batch: 60; loss: 2.01; acc: 0.36
Batch: 80; loss: 2.01; acc: 0.28
Batch: 100; loss: 1.61; acc: 0.47
Batch: 120; loss: 1.94; acc: 0.34
Batch: 140; loss: 1.8; acc: 0.38
Batch: 160; loss: 1.99; acc: 0.39
Batch: 180; loss: 1.91; acc: 0.34
Batch: 200; loss: 1.86; acc: 0.42
Batch: 220; loss: 1.83; acc: 0.31
Batch: 240; loss: 1.71; acc: 0.47
Batch: 260; loss: 1.96; acc: 0.36
Batch: 280; loss: 1.78; acc: 0.39
Batch: 300; loss: 2.03; acc: 0.3
Batch: 320; loss: 2.1; acc: 0.28
Batch: 340; loss: 1.96; acc: 0.39
Batch: 360; loss: 1.88; acc: 0.33
Batch: 380; loss: 1.82; acc: 0.42
Batch: 400; loss: 1.79; acc: 0.38
Batch: 420; loss: 1.69; acc: 0.5
Batch: 440; loss: 1.8; acc: 0.33
Batch: 460; loss: 1.94; acc: 0.38
Batch: 480; loss: 1.86; acc: 0.38
Batch: 500; loss: 1.83; acc: 0.42
Batch: 520; loss: 1.92; acc: 0.38
Batch: 540; loss: 1.84; acc: 0.36
Batch: 560; loss: 2.05; acc: 0.31
Batch: 580; loss: 1.87; acc: 0.45
Batch: 600; loss: 1.88; acc: 0.39
Batch: 620; loss: 1.72; acc: 0.36
Batch: 640; loss: 1.98; acc: 0.34
Batch: 660; loss: 1.61; acc: 0.53
Batch: 680; loss: 2.01; acc: 0.38
Batch: 700; loss: 1.92; acc: 0.39
Batch: 720; loss: 1.87; acc: 0.41
Batch: 740; loss: 1.98; acc: 0.41
Batch: 760; loss: 1.92; acc: 0.31
Batch: 780; loss: 1.71; acc: 0.42
Train Epoch over. train_loss: 1.88; train_accuracy: 0.37 

1.4917011867510155e-05
5.033855813962873e-06
Batch: 0; loss: 1.9; acc: 0.34
Batch: 20; loss: 2.06; acc: 0.27
Batch: 40; loss: 1.54; acc: 0.58
Batch: 60; loss: 1.87; acc: 0.38
Batch: 80; loss: 1.85; acc: 0.39
Batch: 100; loss: 1.79; acc: 0.42
Batch: 120; loss: 1.93; acc: 0.42
Batch: 140; loss: 1.78; acc: 0.42
Val Epoch over. val_loss: 1.85937139334952; val_accuracy: 0.3737062101910828 

The current subspace-distance is: 5.033855813962873e-06 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.73; acc: 0.48
Batch: 20; loss: 1.72; acc: 0.45
Batch: 40; loss: 1.82; acc: 0.39
Batch: 60; loss: 1.84; acc: 0.39
Batch: 80; loss: 1.87; acc: 0.36
Batch: 100; loss: 1.82; acc: 0.33
Batch: 120; loss: 2.04; acc: 0.31
Batch: 140; loss: 1.93; acc: 0.39
Batch: 160; loss: 1.86; acc: 0.34
Batch: 180; loss: 2.03; acc: 0.33
Batch: 200; loss: 1.91; acc: 0.34
Batch: 220; loss: 1.97; acc: 0.3
Batch: 240; loss: 1.65; acc: 0.53
Batch: 260; loss: 1.88; acc: 0.36
Batch: 280; loss: 2.16; acc: 0.22
Batch: 300; loss: 1.87; acc: 0.39
Batch: 320; loss: 1.7; acc: 0.41
Batch: 340; loss: 1.79; acc: 0.41
Batch: 360; loss: 1.95; acc: 0.42
Batch: 380; loss: 1.92; acc: 0.39
Batch: 400; loss: 1.76; acc: 0.34
Batch: 420; loss: 1.87; acc: 0.33
Batch: 440; loss: 1.95; acc: 0.3
Batch: 460; loss: 2.06; acc: 0.34
Batch: 480; loss: 1.86; acc: 0.38
Batch: 500; loss: 1.9; acc: 0.31
Batch: 520; loss: 2.09; acc: 0.27
Batch: 540; loss: 1.95; acc: 0.36
Batch: 560; loss: 1.74; acc: 0.45
Batch: 580; loss: 1.91; acc: 0.34
Batch: 600; loss: 1.93; acc: 0.38
Batch: 620; loss: 1.42; acc: 0.64
Batch: 640; loss: 1.84; acc: 0.33
Batch: 660; loss: 1.77; acc: 0.47
Batch: 680; loss: 1.97; acc: 0.28
Batch: 700; loss: 2.01; acc: 0.31
Batch: 720; loss: 1.98; acc: 0.31
Batch: 740; loss: 2.01; acc: 0.33
Batch: 760; loss: 1.91; acc: 0.31
Batch: 780; loss: 1.95; acc: 0.38
Train Epoch over. train_loss: 1.88; train_accuracy: 0.37 

1.5384232028736733e-05
5.0949511205544695e-06
Batch: 0; loss: 1.9; acc: 0.34
Batch: 20; loss: 2.06; acc: 0.28
Batch: 40; loss: 1.54; acc: 0.58
Batch: 60; loss: 1.87; acc: 0.38
Batch: 80; loss: 1.84; acc: 0.38
Batch: 100; loss: 1.79; acc: 0.42
Batch: 120; loss: 1.93; acc: 0.41
Batch: 140; loss: 1.78; acc: 0.42
Val Epoch over. val_loss: 1.858611699122532; val_accuracy: 0.37490047770700635 

The current subspace-distance is: 5.0949511205544695e-06 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.86; acc: 0.31
Batch: 20; loss: 1.82; acc: 0.34
Batch: 40; loss: 1.93; acc: 0.33
Batch: 60; loss: 2.02; acc: 0.34
Batch: 80; loss: 1.73; acc: 0.36
Batch: 100; loss: 1.55; acc: 0.5
Batch: 120; loss: 2.12; acc: 0.27
Batch: 140; loss: 1.72; acc: 0.47
Batch: 160; loss: 1.9; acc: 0.38
Batch: 180; loss: 1.86; acc: 0.34
Batch: 200; loss: 1.66; acc: 0.47
Batch: 220; loss: 1.93; acc: 0.45
Batch: 240; loss: 1.74; acc: 0.45
Batch: 260; loss: 2.32; acc: 0.22
Batch: 280; loss: 1.86; acc: 0.34
Batch: 300; loss: 1.69; acc: 0.52
Batch: 320; loss: 1.73; acc: 0.45
Batch: 340; loss: 1.62; acc: 0.5
Batch: 360; loss: 1.7; acc: 0.42
Batch: 380; loss: 2.08; acc: 0.23
Batch: 400; loss: 1.9; acc: 0.36
Batch: 420; loss: 1.85; acc: 0.38
Batch: 440; loss: 1.93; acc: 0.3
Batch: 460; loss: 1.9; acc: 0.38
Batch: 480; loss: 1.98; acc: 0.31
Batch: 500; loss: 1.67; acc: 0.48
Batch: 520; loss: 1.83; acc: 0.44
Batch: 540; loss: 1.84; acc: 0.31
Batch: 560; loss: 1.81; acc: 0.36
Batch: 580; loss: 1.81; acc: 0.39
Batch: 600; loss: 2.03; acc: 0.33
Batch: 620; loss: 2.09; acc: 0.25
Batch: 640; loss: 1.86; acc: 0.38
Batch: 660; loss: 1.97; acc: 0.36
Batch: 680; loss: 1.71; acc: 0.45
Batch: 700; loss: 2.02; acc: 0.31
Batch: 720; loss: 1.82; acc: 0.42
Batch: 740; loss: 1.78; acc: 0.41
Batch: 760; loss: 1.86; acc: 0.39
Batch: 780; loss: 1.95; acc: 0.31
Train Epoch over. train_loss: 1.88; train_accuracy: 0.37 

1.7227846910827793e-05
5.292528385325568e-06
Batch: 0; loss: 1.9; acc: 0.33
Batch: 20; loss: 2.06; acc: 0.28
Batch: 40; loss: 1.53; acc: 0.58
Batch: 60; loss: 1.87; acc: 0.38
Batch: 80; loss: 1.84; acc: 0.38
Batch: 100; loss: 1.79; acc: 0.41
Batch: 120; loss: 1.92; acc: 0.41
Batch: 140; loss: 1.78; acc: 0.41
Val Epoch over. val_loss: 1.8567553477682126; val_accuracy: 0.37281050955414013 

The current subspace-distance is: 5.292528385325568e-06 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 2.07; acc: 0.27
Batch: 20; loss: 2.04; acc: 0.36
Batch: 40; loss: 1.81; acc: 0.36
Batch: 60; loss: 1.93; acc: 0.33
Batch: 80; loss: 1.76; acc: 0.47
Batch: 100; loss: 1.9; acc: 0.31
Batch: 120; loss: 1.67; acc: 0.44
Batch: 140; loss: 1.75; acc: 0.39
Batch: 160; loss: 2.09; acc: 0.25
Batch: 180; loss: 1.73; acc: 0.45
Batch: 200; loss: 1.74; acc: 0.42
Batch: 220; loss: 1.92; acc: 0.33
Batch: 240; loss: 1.71; acc: 0.47
Batch: 260; loss: 1.7; acc: 0.38
Batch: 280; loss: 1.79; acc: 0.44
Batch: 300; loss: 1.98; acc: 0.3
Batch: 320; loss: 1.75; acc: 0.42
Batch: 340; loss: 1.89; acc: 0.41
Batch: 360; loss: 1.78; acc: 0.38
Batch: 380; loss: 1.79; acc: 0.34
Batch: 400; loss: 1.9; acc: 0.36
Batch: 420; loss: 1.74; acc: 0.53
Batch: 440; loss: 2.02; acc: 0.3
Batch: 460; loss: 1.75; acc: 0.45
Batch: 480; loss: 1.95; acc: 0.39
Batch: 500; loss: 1.9; acc: 0.41
Batch: 520; loss: 1.87; acc: 0.36
Batch: 540; loss: 1.96; acc: 0.31
Batch: 560; loss: 1.85; acc: 0.38
Batch: 580; loss: 1.97; acc: 0.38
Batch: 600; loss: 1.72; acc: 0.45
Batch: 620; loss: 1.78; acc: 0.33
Batch: 640; loss: 1.92; acc: 0.39
Batch: 660; loss: 1.75; acc: 0.47
Batch: 680; loss: 1.97; acc: 0.34
Batch: 700; loss: 1.9; acc: 0.41
Batch: 720; loss: 1.89; acc: 0.36
Batch: 740; loss: 1.9; acc: 0.39
Batch: 760; loss: 1.75; acc: 0.44
Batch: 780; loss: 1.89; acc: 0.41
Train Epoch over. train_loss: 1.87; train_accuracy: 0.37 

1.3841271538694855e-05
3.6003712011734024e-06
Batch: 0; loss: 1.89; acc: 0.33
Batch: 20; loss: 2.05; acc: 0.27
Batch: 40; loss: 1.53; acc: 0.58
Batch: 60; loss: 1.87; acc: 0.38
Batch: 80; loss: 1.84; acc: 0.38
Batch: 100; loss: 1.78; acc: 0.41
Batch: 120; loss: 1.92; acc: 0.41
Batch: 140; loss: 1.77; acc: 0.41
Val Epoch over. val_loss: 1.85472632745269; val_accuracy: 0.3752985668789809 

The current subspace-distance is: 3.6003712011734024e-06 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 2.0; acc: 0.25
Batch: 20; loss: 1.88; acc: 0.38
Batch: 40; loss: 1.92; acc: 0.3
Batch: 60; loss: 1.99; acc: 0.34
Batch: 80; loss: 1.62; acc: 0.5
Batch: 100; loss: 1.78; acc: 0.36
Batch: 120; loss: 1.92; acc: 0.36
Batch: 140; loss: 1.89; acc: 0.36
Batch: 160; loss: 2.06; acc: 0.3
Batch: 180; loss: 1.86; acc: 0.38
Batch: 200; loss: 1.88; acc: 0.44
Batch: 220; loss: 1.85; acc: 0.39
Batch: 240; loss: 1.67; acc: 0.36
Batch: 260; loss: 1.82; acc: 0.42
Batch: 280; loss: 1.96; acc: 0.3
Batch: 300; loss: 1.81; acc: 0.41
Batch: 320; loss: 1.98; acc: 0.36
Batch: 340; loss: 1.7; acc: 0.47
Batch: 360; loss: 1.93; acc: 0.42
Batch: 380; loss: 1.76; acc: 0.39
Batch: 400; loss: 1.86; acc: 0.39
Batch: 420; loss: 1.92; acc: 0.34
Batch: 440; loss: 1.97; acc: 0.27
Batch: 460; loss: 1.73; acc: 0.44
Batch: 480; loss: 1.82; acc: 0.42
Batch: 500; loss: 1.93; acc: 0.28
Batch: 520; loss: 1.99; acc: 0.33
Batch: 540; loss: 1.71; acc: 0.42
Batch: 560; loss: 1.76; acc: 0.48
Batch: 580; loss: 1.85; acc: 0.38
Batch: 600; loss: 1.94; acc: 0.36
Batch: 620; loss: 1.98; acc: 0.41
Batch: 640; loss: 1.92; acc: 0.41
Batch: 660; loss: 1.98; acc: 0.34
Batch: 680; loss: 1.76; acc: 0.36
Batch: 700; loss: 1.74; acc: 0.45
Batch: 720; loss: 1.96; acc: 0.34
Batch: 740; loss: 1.8; acc: 0.39
Batch: 760; loss: 2.03; acc: 0.31
Batch: 780; loss: 1.8; acc: 0.41
Train Epoch over. train_loss: 1.87; train_accuracy: 0.37 

1.6119020074256696e-05
8.16930150904227e-06
Batch: 0; loss: 1.89; acc: 0.33
Batch: 20; loss: 2.06; acc: 0.27
Batch: 40; loss: 1.53; acc: 0.58
Batch: 60; loss: 1.87; acc: 0.38
Batch: 80; loss: 1.83; acc: 0.38
Batch: 100; loss: 1.78; acc: 0.41
Batch: 120; loss: 1.92; acc: 0.41
Batch: 140; loss: 1.77; acc: 0.41
Val Epoch over. val_loss: 1.854304130669612; val_accuracy: 0.37509952229299365 

The current subspace-distance is: 8.16930150904227e-06 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.81; acc: 0.42
Batch: 20; loss: 1.85; acc: 0.36
Batch: 40; loss: 1.9; acc: 0.44
Batch: 60; loss: 1.96; acc: 0.28
Batch: 80; loss: 2.0; acc: 0.36
Batch: 100; loss: 1.95; acc: 0.34
Batch: 120; loss: 2.08; acc: 0.3
Batch: 140; loss: 1.76; acc: 0.45
Batch: 160; loss: 2.08; acc: 0.27
Batch: 180; loss: 1.9; acc: 0.44
Batch: 200; loss: 1.94; acc: 0.3
Batch: 220; loss: 1.88; acc: 0.38
Batch: 240; loss: 1.83; acc: 0.41
Batch: 260; loss: 1.69; acc: 0.44
Batch: 280; loss: 1.7; acc: 0.44
Batch: 300; loss: 1.95; acc: 0.39
Batch: 320; loss: 1.84; acc: 0.41
Batch: 340; loss: 2.07; acc: 0.34
Batch: 360; loss: 1.76; acc: 0.41
Batch: 380; loss: 1.8; acc: 0.38
Batch: 400; loss: 1.96; acc: 0.33
Batch: 420; loss: 1.72; acc: 0.47
Batch: 440; loss: 1.72; acc: 0.47
Batch: 460; loss: 1.95; acc: 0.39
Batch: 480; loss: 1.78; acc: 0.45
Batch: 500; loss: 1.92; acc: 0.38
Batch: 520; loss: 1.61; acc: 0.52
Batch: 540; loss: 1.76; acc: 0.52
Batch: 560; loss: 1.85; acc: 0.38
Batch: 580; loss: 1.88; acc: 0.41
Batch: 600; loss: 1.85; acc: 0.42
Batch: 620; loss: 2.12; acc: 0.3
Batch: 640; loss: 1.56; acc: 0.52
Batch: 660; loss: 1.64; acc: 0.44
Batch: 680; loss: 1.88; acc: 0.39
Batch: 700; loss: 1.81; acc: 0.39
Batch: 720; loss: 1.8; acc: 0.34
Batch: 740; loss: 1.91; acc: 0.33
Batch: 760; loss: 1.89; acc: 0.44
Batch: 780; loss: 1.77; acc: 0.41
Train Epoch over. train_loss: 1.87; train_accuracy: 0.37 

1.476346096751513e-05
7.533230473200092e-06
Batch: 0; loss: 1.89; acc: 0.33
Batch: 20; loss: 2.06; acc: 0.25
Batch: 40; loss: 1.54; acc: 0.58
Batch: 60; loss: 1.87; acc: 0.39
Batch: 80; loss: 1.83; acc: 0.36
Batch: 100; loss: 1.78; acc: 0.41
Batch: 120; loss: 1.92; acc: 0.41
Batch: 140; loss: 1.77; acc: 0.41
Val Epoch over. val_loss: 1.853524159473978; val_accuracy: 0.3762937898089172 

The current subspace-distance is: 7.533230473200092e-06 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.96; acc: 0.34
Batch: 20; loss: 1.84; acc: 0.34
Batch: 40; loss: 1.73; acc: 0.39
Batch: 60; loss: 1.71; acc: 0.44
Batch: 80; loss: 1.67; acc: 0.48
Batch: 100; loss: 1.7; acc: 0.42
Batch: 120; loss: 1.88; acc: 0.36
Batch: 140; loss: 2.18; acc: 0.25
Batch: 160; loss: 1.69; acc: 0.47
Batch: 180; loss: 1.71; acc: 0.45
Batch: 200; loss: 1.97; acc: 0.36
Batch: 220; loss: 1.84; acc: 0.33
Batch: 240; loss: 1.91; acc: 0.36
Batch: 260; loss: 1.74; acc: 0.44
Batch: 280; loss: 2.0; acc: 0.31
Batch: 300; loss: 1.79; acc: 0.42
Batch: 320; loss: 1.95; acc: 0.31
Batch: 340; loss: 1.95; acc: 0.28
Batch: 360; loss: 2.01; acc: 0.28
Batch: 380; loss: 1.91; acc: 0.36
Batch: 400; loss: 2.11; acc: 0.31
Batch: 420; loss: 1.95; acc: 0.3
Batch: 440; loss: 1.98; acc: 0.31
Batch: 460; loss: 1.91; acc: 0.28
Batch: 480; loss: 1.79; acc: 0.39
Batch: 500; loss: 2.12; acc: 0.28
Batch: 520; loss: 1.89; acc: 0.36
Batch: 540; loss: 1.92; acc: 0.41
Batch: 560; loss: 1.65; acc: 0.42
Batch: 580; loss: 1.96; acc: 0.36
Batch: 600; loss: 1.83; acc: 0.41
Batch: 620; loss: 1.79; acc: 0.39
Batch: 640; loss: 1.91; acc: 0.36
Batch: 660; loss: 1.9; acc: 0.38
Batch: 680; loss: 1.89; acc: 0.34
Batch: 700; loss: 1.8; acc: 0.36
Batch: 720; loss: 2.07; acc: 0.34
Batch: 740; loss: 1.83; acc: 0.34
Batch: 760; loss: 2.08; acc: 0.3
Batch: 780; loss: 1.86; acc: 0.36
Train Epoch over. train_loss: 1.87; train_accuracy: 0.37 

1.4055522115086205e-05
5.373151452658931e-06
Batch: 0; loss: 1.89; acc: 0.33
Batch: 20; loss: 2.05; acc: 0.25
Batch: 40; loss: 1.54; acc: 0.58
Batch: 60; loss: 1.86; acc: 0.39
Batch: 80; loss: 1.83; acc: 0.36
Batch: 100; loss: 1.78; acc: 0.41
Batch: 120; loss: 1.92; acc: 0.41
Batch: 140; loss: 1.77; acc: 0.39
Val Epoch over. val_loss: 1.8529080031024423; val_accuracy: 0.37579617834394907 

The current subspace-distance is: 5.373151452658931e-06 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.94; acc: 0.39
Batch: 20; loss: 2.0; acc: 0.3
Batch: 40; loss: 1.69; acc: 0.45
Batch: 60; loss: 1.87; acc: 0.31
Batch: 80; loss: 1.81; acc: 0.31
Batch: 100; loss: 1.94; acc: 0.34
Batch: 120; loss: 1.71; acc: 0.45
Batch: 140; loss: 1.79; acc: 0.38
Batch: 160; loss: 2.02; acc: 0.38
Batch: 180; loss: 1.83; acc: 0.39
Batch: 200; loss: 1.68; acc: 0.42
Batch: 220; loss: 2.21; acc: 0.25
Batch: 240; loss: 1.74; acc: 0.41
Batch: 260; loss: 1.86; acc: 0.41
Batch: 280; loss: 1.85; acc: 0.38
Batch: 300; loss: 1.92; acc: 0.36
Batch: 320; loss: 2.05; acc: 0.33
Batch: 340; loss: 1.88; acc: 0.41
Batch: 360; loss: 1.94; acc: 0.33
Batch: 380; loss: 1.84; acc: 0.39
Batch: 400; loss: 1.95; acc: 0.28
Batch: 420; loss: 1.87; acc: 0.28
Batch: 440; loss: 1.78; acc: 0.39
Batch: 460; loss: 1.94; acc: 0.27
Batch: 480; loss: 1.79; acc: 0.39
Batch: 500; loss: 1.87; acc: 0.39
Batch: 520; loss: 1.64; acc: 0.48
Batch: 540; loss: 1.79; acc: 0.36
Batch: 560; loss: 1.86; acc: 0.31
Batch: 580; loss: 1.78; acc: 0.44
Batch: 600; loss: 1.89; acc: 0.38
Batch: 620; loss: 1.73; acc: 0.47
Batch: 640; loss: 2.06; acc: 0.27
Batch: 660; loss: 2.07; acc: 0.25
Batch: 680; loss: 1.86; acc: 0.38
Batch: 700; loss: 1.96; acc: 0.36
Batch: 720; loss: 1.75; acc: 0.45
Batch: 740; loss: 2.18; acc: 0.22
Batch: 760; loss: 1.79; acc: 0.41
Batch: 780; loss: 1.89; acc: 0.34
Train Epoch over. train_loss: 1.87; train_accuracy: 0.37 

2.0266474166419357e-05
5.0447042667656206e-06
Batch: 0; loss: 1.89; acc: 0.33
Batch: 20; loss: 2.05; acc: 0.25
Batch: 40; loss: 1.53; acc: 0.58
Batch: 60; loss: 1.86; acc: 0.39
Batch: 80; loss: 1.83; acc: 0.36
Batch: 100; loss: 1.78; acc: 0.41
Batch: 120; loss: 1.92; acc: 0.41
Batch: 140; loss: 1.77; acc: 0.39
Val Epoch over. val_loss: 1.8521405549565697; val_accuracy: 0.3772890127388535 

The current subspace-distance is: 5.0447042667656206e-06 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.88; acc: 0.38
Batch: 20; loss: 1.76; acc: 0.41
Batch: 40; loss: 1.91; acc: 0.39
Batch: 60; loss: 1.84; acc: 0.41
Batch: 80; loss: 1.93; acc: 0.31
Batch: 100; loss: 1.67; acc: 0.45
Batch: 120; loss: 1.9; acc: 0.41
Batch: 140; loss: 2.05; acc: 0.3
Batch: 160; loss: 1.83; acc: 0.45
Batch: 180; loss: 1.89; acc: 0.39
Batch: 200; loss: 1.78; acc: 0.39
Batch: 220; loss: 2.04; acc: 0.28
Batch: 240; loss: 1.92; acc: 0.36
Batch: 260; loss: 1.96; acc: 0.3
Batch: 280; loss: 2.0; acc: 0.3
Batch: 300; loss: 1.79; acc: 0.42
Batch: 320; loss: 1.84; acc: 0.39
Batch: 340; loss: 1.87; acc: 0.39
Batch: 360; loss: 1.94; acc: 0.27
Batch: 380; loss: 1.83; acc: 0.36
Batch: 400; loss: 1.71; acc: 0.39
Batch: 420; loss: 2.05; acc: 0.27
Batch: 440; loss: 1.64; acc: 0.39
Batch: 460; loss: 1.92; acc: 0.36
Batch: 480; loss: 1.93; acc: 0.38
Batch: 500; loss: 1.56; acc: 0.52
Batch: 520; loss: 1.84; acc: 0.41
Batch: 540; loss: 1.99; acc: 0.33
Batch: 560; loss: 1.95; acc: 0.41
Batch: 580; loss: 1.83; acc: 0.36
Batch: 600; loss: 1.79; acc: 0.42
Batch: 620; loss: 1.85; acc: 0.36
Batch: 640; loss: 2.07; acc: 0.31
Batch: 660; loss: 1.9; acc: 0.38
Batch: 680; loss: 1.96; acc: 0.36
Batch: 700; loss: 1.95; acc: 0.36
Batch: 720; loss: 2.07; acc: 0.27
Batch: 740; loss: 1.85; acc: 0.33
Batch: 760; loss: 2.05; acc: 0.31
Batch: 780; loss: 1.74; acc: 0.41
Train Epoch over. train_loss: 1.87; train_accuracy: 0.37 

1.6979924112092704e-05
3.6436990740185138e-06
Batch: 0; loss: 1.89; acc: 0.33
Batch: 20; loss: 2.05; acc: 0.25
Batch: 40; loss: 1.54; acc: 0.56
Batch: 60; loss: 1.86; acc: 0.39
Batch: 80; loss: 1.82; acc: 0.34
Batch: 100; loss: 1.78; acc: 0.41
Batch: 120; loss: 1.92; acc: 0.41
Batch: 140; loss: 1.77; acc: 0.39
Val Epoch over. val_loss: 1.8515665576716138; val_accuracy: 0.37679140127388533 

The current subspace-distance is: 3.6436990740185138e-06 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.83; acc: 0.36
Batch: 20; loss: 1.77; acc: 0.41
Batch: 40; loss: 1.95; acc: 0.33
Batch: 60; loss: 1.63; acc: 0.44
Batch: 80; loss: 1.72; acc: 0.41
Batch: 100; loss: 1.77; acc: 0.39
Batch: 120; loss: 1.88; acc: 0.38
Batch: 140; loss: 2.01; acc: 0.34
Batch: 160; loss: 1.85; acc: 0.39
Batch: 180; loss: 1.73; acc: 0.41
Batch: 200; loss: 1.73; acc: 0.45
Batch: 220; loss: 2.04; acc: 0.34
Batch: 240; loss: 1.72; acc: 0.47
Batch: 260; loss: 1.93; acc: 0.34
Batch: 280; loss: 1.87; acc: 0.47
Batch: 300; loss: 1.91; acc: 0.34
Batch: 320; loss: 1.93; acc: 0.33
Batch: 340; loss: 1.87; acc: 0.38
Batch: 360; loss: 1.91; acc: 0.31
Batch: 380; loss: 1.82; acc: 0.39
Batch: 400; loss: 1.83; acc: 0.45
Batch: 420; loss: 1.9; acc: 0.34
Batch: 440; loss: 2.02; acc: 0.28
Batch: 460; loss: 1.91; acc: 0.33
Batch: 480; loss: 1.94; acc: 0.36
Batch: 500; loss: 2.0; acc: 0.39
Batch: 520; loss: 1.86; acc: 0.36
Batch: 540; loss: 1.78; acc: 0.45
Batch: 560; loss: 1.83; acc: 0.31
Batch: 580; loss: 2.13; acc: 0.23
Batch: 600; loss: 1.76; acc: 0.41
Batch: 620; loss: 1.79; acc: 0.41
Batch: 640; loss: 1.91; acc: 0.38
Batch: 660; loss: 1.76; acc: 0.42
Batch: 680; loss: 1.81; acc: 0.41
Batch: 700; loss: 1.97; acc: 0.39
Batch: 720; loss: 2.02; acc: 0.36
Batch: 740; loss: 1.91; acc: 0.31
Batch: 760; loss: 1.85; acc: 0.39
Batch: 780; loss: 1.9; acc: 0.38
Train Epoch over. train_loss: 1.87; train_accuracy: 0.37 

1.423658432031516e-05
4.386720775073627e-06
Batch: 0; loss: 1.89; acc: 0.33
Batch: 20; loss: 2.05; acc: 0.25
Batch: 40; loss: 1.54; acc: 0.55
Batch: 60; loss: 1.86; acc: 0.39
Batch: 80; loss: 1.82; acc: 0.34
Batch: 100; loss: 1.78; acc: 0.41
Batch: 120; loss: 1.92; acc: 0.39
Batch: 140; loss: 1.77; acc: 0.38
Val Epoch over. val_loss: 1.8507067785141573; val_accuracy: 0.3765923566878981 

The current subspace-distance is: 4.386720775073627e-06 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.87; acc: 0.34
Batch: 20; loss: 2.04; acc: 0.31
Batch: 40; loss: 2.07; acc: 0.28
Batch: 60; loss: 1.8; acc: 0.36
Batch: 80; loss: 2.0; acc: 0.38
Batch: 100; loss: 1.95; acc: 0.39
Batch: 120; loss: 1.92; acc: 0.31
Batch: 140; loss: 1.83; acc: 0.44
Batch: 160; loss: 1.76; acc: 0.5
Batch: 180; loss: 1.94; acc: 0.36
Batch: 200; loss: 1.84; acc: 0.39
Batch: 220; loss: 1.91; acc: 0.39
Batch: 240; loss: 1.76; acc: 0.44
Batch: 260; loss: 1.9; acc: 0.33
Batch: 280; loss: 1.86; acc: 0.36
Batch: 300; loss: 1.96; acc: 0.39
Batch: 320; loss: 1.98; acc: 0.38
Batch: 340; loss: 1.9; acc: 0.31
Batch: 360; loss: 1.86; acc: 0.39
Batch: 380; loss: 1.73; acc: 0.42
Batch: 400; loss: 2.01; acc: 0.33
Batch: 420; loss: 1.8; acc: 0.42
Batch: 440; loss: 1.82; acc: 0.41
Batch: 460; loss: 1.9; acc: 0.33
Batch: 480; loss: 1.89; acc: 0.39
Batch: 500; loss: 1.78; acc: 0.45
Batch: 520; loss: 1.84; acc: 0.34
Batch: 540; loss: 1.87; acc: 0.38
Batch: 560; loss: 1.97; acc: 0.33
Batch: 580; loss: 1.91; acc: 0.41
Batch: 600; loss: 1.82; acc: 0.3
Batch: 620; loss: 1.87; acc: 0.34
Batch: 640; loss: 2.07; acc: 0.31
Batch: 660; loss: 1.76; acc: 0.36
Batch: 680; loss: 1.9; acc: 0.38
Batch: 700; loss: 2.23; acc: 0.27
Batch: 720; loss: 1.9; acc: 0.34
Batch: 740; loss: 1.79; acc: 0.36
Batch: 760; loss: 1.9; acc: 0.34
Batch: 780; loss: 1.81; acc: 0.38
Train Epoch over. train_loss: 1.87; train_accuracy: 0.38 

1.7086425941670313e-05
6.586433300981298e-06
Batch: 0; loss: 1.89; acc: 0.33
Batch: 20; loss: 2.05; acc: 0.27
Batch: 40; loss: 1.54; acc: 0.55
Batch: 60; loss: 1.85; acc: 0.39
Batch: 80; loss: 1.82; acc: 0.34
Batch: 100; loss: 1.77; acc: 0.42
Batch: 120; loss: 1.92; acc: 0.39
Batch: 140; loss: 1.77; acc: 0.38
Val Epoch over. val_loss: 1.8497209822296337; val_accuracy: 0.3770899681528662 

The current subspace-distance is: 6.586433300981298e-06 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.93; acc: 0.33
Batch: 20; loss: 1.89; acc: 0.38
Batch: 40; loss: 1.92; acc: 0.36
Batch: 60; loss: 1.91; acc: 0.42
Batch: 80; loss: 1.99; acc: 0.34
Batch: 100; loss: 1.88; acc: 0.39
Batch: 120; loss: 1.88; acc: 0.41
Batch: 140; loss: 2.07; acc: 0.33
Batch: 160; loss: 1.66; acc: 0.42
Batch: 180; loss: 1.68; acc: 0.48
Batch: 200; loss: 1.94; acc: 0.36
Batch: 220; loss: 2.01; acc: 0.31
Batch: 240; loss: 1.93; acc: 0.34
Batch: 260; loss: 1.81; acc: 0.41
Batch: 280; loss: 1.94; acc: 0.3
Batch: 300; loss: 1.87; acc: 0.36
Batch: 320; loss: 1.59; acc: 0.53
Batch: 340; loss: 1.87; acc: 0.39
Batch: 360; loss: 1.53; acc: 0.59
Batch: 380; loss: 1.97; acc: 0.28
Batch: 400; loss: 1.78; acc: 0.36
Batch: 420; loss: 1.78; acc: 0.39
Batch: 440; loss: 2.01; acc: 0.38
Batch: 460; loss: 1.99; acc: 0.3
Batch: 480; loss: 1.78; acc: 0.45
Batch: 500; loss: 1.67; acc: 0.42
Batch: 520; loss: 1.91; acc: 0.33
Batch: 540; loss: 1.72; acc: 0.38
Batch: 560; loss: 1.83; acc: 0.39
Batch: 580; loss: 1.89; acc: 0.34
Batch: 600; loss: 2.04; acc: 0.27
Batch: 620; loss: 1.76; acc: 0.39
Batch: 640; loss: 1.67; acc: 0.53
Batch: 660; loss: 1.9; acc: 0.36
Batch: 680; loss: 1.76; acc: 0.34
Batch: 700; loss: 1.93; acc: 0.3
Batch: 720; loss: 1.93; acc: 0.3
Batch: 740; loss: 1.98; acc: 0.28
Batch: 760; loss: 1.99; acc: 0.3
Batch: 780; loss: 1.91; acc: 0.33
Train Epoch over. train_loss: 1.87; train_accuracy: 0.38 

2.0661373127950355e-05
5.781339496024884e-06
Batch: 0; loss: 1.88; acc: 0.33
Batch: 20; loss: 2.05; acc: 0.27
Batch: 40; loss: 1.54; acc: 0.53
Batch: 60; loss: 1.85; acc: 0.41
Batch: 80; loss: 1.81; acc: 0.34
Batch: 100; loss: 1.77; acc: 0.42
Batch: 120; loss: 1.92; acc: 0.39
Batch: 140; loss: 1.77; acc: 0.38
Val Epoch over. val_loss: 1.8489048974529194; val_accuracy: 0.3775875796178344 

The current subspace-distance is: 5.781339496024884e-06 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.98; acc: 0.3
Batch: 20; loss: 1.96; acc: 0.38
Batch: 40; loss: 1.75; acc: 0.5
Batch: 60; loss: 1.74; acc: 0.42
Batch: 80; loss: 2.01; acc: 0.34
Batch: 100; loss: 1.72; acc: 0.44
Batch: 120; loss: 2.04; acc: 0.27
Batch: 140; loss: 2.02; acc: 0.33
Batch: 160; loss: 1.71; acc: 0.5
Batch: 180; loss: 1.97; acc: 0.39
Batch: 200; loss: 1.91; acc: 0.38
Batch: 220; loss: 1.83; acc: 0.3
Batch: 240; loss: 1.72; acc: 0.52
Batch: 260; loss: 1.77; acc: 0.38
Batch: 280; loss: 1.9; acc: 0.41
Batch: 300; loss: 1.88; acc: 0.41
Batch: 320; loss: 1.72; acc: 0.47
Batch: 340; loss: 1.87; acc: 0.33
Batch: 360; loss: 1.76; acc: 0.39
Batch: 380; loss: 1.82; acc: 0.39
Batch: 400; loss: 1.58; acc: 0.55
Batch: 420; loss: 1.74; acc: 0.42
Batch: 440; loss: 1.61; acc: 0.47
Batch: 460; loss: 1.7; acc: 0.53
Batch: 480; loss: 1.86; acc: 0.39
Batch: 500; loss: 1.73; acc: 0.44
Batch: 520; loss: 1.72; acc: 0.38
Batch: 540; loss: 1.86; acc: 0.41
Batch: 560; loss: 1.84; acc: 0.39
Batch: 580; loss: 2.05; acc: 0.23
Batch: 600; loss: 1.91; acc: 0.38
Batch: 620; loss: 1.78; acc: 0.38
Batch: 640; loss: 1.83; acc: 0.47
Batch: 660; loss: 1.91; acc: 0.48
Batch: 680; loss: 1.89; acc: 0.38
Batch: 700; loss: 2.02; acc: 0.33
Batch: 720; loss: 1.81; acc: 0.44
Batch: 740; loss: 1.8; acc: 0.44
Batch: 760; loss: 1.86; acc: 0.34
Batch: 780; loss: 1.74; acc: 0.44
Train Epoch over. train_loss: 1.87; train_accuracy: 0.38 

1.4749082765774801e-05
5.216535555518931e-06
Batch: 0; loss: 1.88; acc: 0.33
Batch: 20; loss: 2.05; acc: 0.27
Batch: 40; loss: 1.54; acc: 0.53
Batch: 60; loss: 1.85; acc: 0.41
Batch: 80; loss: 1.81; acc: 0.33
Batch: 100; loss: 1.77; acc: 0.44
Batch: 120; loss: 1.91; acc: 0.39
Batch: 140; loss: 1.77; acc: 0.38
Val Epoch over. val_loss: 1.8475662538200428; val_accuracy: 0.37679140127388533 

The current subspace-distance is: 5.216535555518931e-06 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.78; acc: 0.42
Batch: 20; loss: 1.94; acc: 0.33
Batch: 40; loss: 1.7; acc: 0.48
Batch: 60; loss: 1.91; acc: 0.38
Batch: 80; loss: 1.87; acc: 0.41
Batch: 100; loss: 2.11; acc: 0.23
Batch: 120; loss: 1.87; acc: 0.39
Batch: 140; loss: 1.83; acc: 0.36
Batch: 160; loss: 2.21; acc: 0.27
Batch: 180; loss: 1.88; acc: 0.33
Batch: 200; loss: 1.88; acc: 0.33
Batch: 220; loss: 1.59; acc: 0.55
Batch: 240; loss: 1.62; acc: 0.53
Batch: 260; loss: 1.75; acc: 0.47
Batch: 280; loss: 1.85; acc: 0.39
Batch: 300; loss: 1.88; acc: 0.41
Batch: 320; loss: 1.74; acc: 0.48
Batch: 340; loss: 1.93; acc: 0.34
Batch: 360; loss: 1.83; acc: 0.39
Batch: 380; loss: 1.92; acc: 0.33
Batch: 400; loss: 1.78; acc: 0.34
Batch: 420; loss: 1.92; acc: 0.3
Batch: 440; loss: 1.98; acc: 0.3
Batch: 460; loss: 2.01; acc: 0.44
Batch: 480; loss: 1.66; acc: 0.48
Batch: 500; loss: 1.97; acc: 0.31
Batch: 520; loss: 2.01; acc: 0.34
Batch: 540; loss: 1.77; acc: 0.38
Batch: 560; loss: 1.66; acc: 0.45
Batch: 580; loss: 1.94; acc: 0.33
Batch: 600; loss: 1.76; acc: 0.5
Batch: 620; loss: 1.82; acc: 0.42
Batch: 640; loss: 1.83; acc: 0.36
Batch: 660; loss: 2.0; acc: 0.28
Batch: 680; loss: 2.05; acc: 0.25
Batch: 700; loss: 1.91; acc: 0.31
Batch: 720; loss: 1.96; acc: 0.33
Batch: 740; loss: 1.89; acc: 0.38
Batch: 760; loss: 1.89; acc: 0.28
Batch: 780; loss: 1.83; acc: 0.45
Train Epoch over. train_loss: 1.86; train_accuracy: 0.38 

1.6386820789193735e-05
5.840054654981941e-06
Batch: 0; loss: 1.88; acc: 0.33
Batch: 20; loss: 2.04; acc: 0.27
Batch: 40; loss: 1.54; acc: 0.53
Batch: 60; loss: 1.84; acc: 0.41
Batch: 80; loss: 1.8; acc: 0.33
Batch: 100; loss: 1.77; acc: 0.45
Batch: 120; loss: 1.91; acc: 0.39
Batch: 140; loss: 1.77; acc: 0.38
Val Epoch over. val_loss: 1.8465949357694882; val_accuracy: 0.37738853503184716 

The current subspace-distance is: 5.840054654981941e-06 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.94; acc: 0.44
Batch: 20; loss: 1.82; acc: 0.36
Batch: 40; loss: 1.78; acc: 0.31
Batch: 60; loss: 1.95; acc: 0.34
Batch: 80; loss: 1.67; acc: 0.48
Batch: 100; loss: 1.79; acc: 0.41
Batch: 120; loss: 1.74; acc: 0.47
Batch: 140; loss: 1.98; acc: 0.28
Batch: 160; loss: 1.85; acc: 0.36
Batch: 180; loss: 1.83; acc: 0.41
Batch: 200; loss: 1.81; acc: 0.41
Batch: 220; loss: 1.78; acc: 0.41
Batch: 240; loss: 1.98; acc: 0.36
Batch: 260; loss: 1.73; acc: 0.39
Batch: 280; loss: 2.13; acc: 0.3
Batch: 300; loss: 1.85; acc: 0.41
Batch: 320; loss: 2.04; acc: 0.27
Batch: 340; loss: 1.87; acc: 0.38
Batch: 360; loss: 1.82; acc: 0.42
Batch: 380; loss: 1.95; acc: 0.27
Batch: 400; loss: 2.04; acc: 0.33
Batch: 420; loss: 1.72; acc: 0.39
Batch: 440; loss: 1.83; acc: 0.38
Batch: 460; loss: 1.79; acc: 0.44
Batch: 480; loss: 1.66; acc: 0.47
Batch: 500; loss: 1.77; acc: 0.39
Batch: 520; loss: 1.86; acc: 0.42
Batch: 540; loss: 1.88; acc: 0.34
Batch: 560; loss: 1.67; acc: 0.53
Batch: 580; loss: 1.86; acc: 0.34
Batch: 600; loss: 2.14; acc: 0.28
Batch: 620; loss: 1.96; acc: 0.39
Batch: 640; loss: 1.87; acc: 0.31
Batch: 660; loss: 2.0; acc: 0.36
Batch: 680; loss: 1.99; acc: 0.31
Batch: 700; loss: 1.7; acc: 0.5
Batch: 720; loss: 1.78; acc: 0.45
Batch: 740; loss: 1.79; acc: 0.52
Batch: 760; loss: 1.74; acc: 0.36
Batch: 780; loss: 1.8; acc: 0.41
Train Epoch over. train_loss: 1.86; train_accuracy: 0.38 

1.6138723367475905e-05
5.151121058588615e-06
Batch: 0; loss: 1.87; acc: 0.33
Batch: 20; loss: 2.04; acc: 0.27
Batch: 40; loss: 1.54; acc: 0.53
Batch: 60; loss: 1.84; acc: 0.41
Batch: 80; loss: 1.8; acc: 0.33
Batch: 100; loss: 1.77; acc: 0.45
Batch: 120; loss: 1.91; acc: 0.39
Batch: 140; loss: 1.77; acc: 0.38
Val Epoch over. val_loss: 1.8460710724447942; val_accuracy: 0.37798566878980894 

The current subspace-distance is: 5.151121058588615e-06 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.79; acc: 0.44
Batch: 20; loss: 1.81; acc: 0.39
Batch: 40; loss: 1.69; acc: 0.45
Batch: 60; loss: 1.82; acc: 0.41
Batch: 80; loss: 2.16; acc: 0.25
Batch: 100; loss: 1.86; acc: 0.42
Batch: 120; loss: 1.84; acc: 0.44
Batch: 140; loss: 1.91; acc: 0.39
Batch: 160; loss: 1.94; acc: 0.44
Batch: 180; loss: 1.81; acc: 0.39
Batch: 200; loss: 1.93; acc: 0.44
Batch: 220; loss: 1.85; acc: 0.34
Batch: 240; loss: 1.73; acc: 0.38
Batch: 260; loss: 1.96; acc: 0.36
Batch: 280; loss: 1.76; acc: 0.36
Batch: 300; loss: 1.94; acc: 0.33
Batch: 320; loss: 1.81; acc: 0.38
Batch: 340; loss: 1.8; acc: 0.42
Batch: 360; loss: 1.9; acc: 0.34
Batch: 380; loss: 1.73; acc: 0.41
Batch: 400; loss: 1.88; acc: 0.41
Batch: 420; loss: 1.89; acc: 0.3
Batch: 440; loss: 1.94; acc: 0.34
Batch: 460; loss: 1.86; acc: 0.36
Batch: 480; loss: 1.83; acc: 0.36
Batch: 500; loss: 1.77; acc: 0.45
Batch: 520; loss: 1.92; acc: 0.33
Batch: 540; loss: 1.94; acc: 0.42
Batch: 560; loss: 1.94; acc: 0.34
Batch: 580; loss: 2.01; acc: 0.31
Batch: 600; loss: 1.91; acc: 0.3
Batch: 620; loss: 1.86; acc: 0.34
Batch: 640; loss: 1.84; acc: 0.38
Batch: 660; loss: 1.83; acc: 0.39
Batch: 680; loss: 1.86; acc: 0.36
Batch: 700; loss: 1.76; acc: 0.39
Batch: 720; loss: 1.97; acc: 0.34
Batch: 740; loss: 1.7; acc: 0.52
Batch: 760; loss: 1.76; acc: 0.45
Batch: 780; loss: 1.92; acc: 0.3
Train Epoch over. train_loss: 1.86; train_accuracy: 0.38 

1.116993462346727e-05
3.4826553019229323e-06
Batch: 0; loss: 1.87; acc: 0.33
Batch: 20; loss: 2.04; acc: 0.27
Batch: 40; loss: 1.54; acc: 0.53
Batch: 60; loss: 1.84; acc: 0.41
Batch: 80; loss: 1.79; acc: 0.33
Batch: 100; loss: 1.77; acc: 0.45
Batch: 120; loss: 1.91; acc: 0.39
Batch: 140; loss: 1.77; acc: 0.38
Val Epoch over. val_loss: 1.8455108495274926; val_accuracy: 0.3786823248407643 

The current subspace-distance is: 3.4826553019229323e-06 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.52; acc: 0.52
Batch: 20; loss: 2.17; acc: 0.27
Batch: 40; loss: 1.75; acc: 0.44
Batch: 60; loss: 1.81; acc: 0.42
Batch: 80; loss: 1.83; acc: 0.38
Batch: 100; loss: 1.81; acc: 0.41
Batch: 120; loss: 1.71; acc: 0.41
Batch: 140; loss: 1.88; acc: 0.38
Batch: 160; loss: 1.64; acc: 0.53
Batch: 180; loss: 1.94; acc: 0.31
Batch: 200; loss: 1.94; acc: 0.36
Batch: 220; loss: 1.83; acc: 0.41
Batch: 240; loss: 1.91; acc: 0.36
Batch: 260; loss: 1.81; acc: 0.36
Batch: 280; loss: 1.96; acc: 0.22
Batch: 300; loss: 1.81; acc: 0.38
Batch: 320; loss: 1.83; acc: 0.39
Batch: 340; loss: 2.02; acc: 0.31
Batch: 360; loss: 1.94; acc: 0.38
Batch: 380; loss: 1.82; acc: 0.38
Batch: 400; loss: 1.86; acc: 0.34
Batch: 420; loss: 1.91; acc: 0.38
Batch: 440; loss: 1.86; acc: 0.34
Batch: 460; loss: 2.0; acc: 0.34
Batch: 480; loss: 1.73; acc: 0.44
Batch: 500; loss: 1.63; acc: 0.52
Batch: 520; loss: 2.17; acc: 0.31
Batch: 540; loss: 1.96; acc: 0.3
Batch: 560; loss: 1.69; acc: 0.47
Batch: 580; loss: 1.87; acc: 0.42
Batch: 600; loss: 1.83; acc: 0.34
Batch: 620; loss: 1.98; acc: 0.3
Batch: 640; loss: 1.91; acc: 0.38
Batch: 660; loss: 1.7; acc: 0.45
Batch: 680; loss: 1.88; acc: 0.3
Batch: 700; loss: 1.89; acc: 0.39
Batch: 720; loss: 1.77; acc: 0.42
Batch: 740; loss: 1.86; acc: 0.36
Batch: 760; loss: 1.97; acc: 0.34
Batch: 780; loss: 1.75; acc: 0.31
Train Epoch over. train_loss: 1.86; train_accuracy: 0.38 

1.3693591426999774e-05
6.3493007473880425e-06
Batch: 0; loss: 1.87; acc: 0.33
Batch: 20; loss: 2.04; acc: 0.27
Batch: 40; loss: 1.54; acc: 0.53
Batch: 60; loss: 1.84; acc: 0.41
Batch: 80; loss: 1.79; acc: 0.33
Batch: 100; loss: 1.77; acc: 0.45
Batch: 120; loss: 1.91; acc: 0.39
Batch: 140; loss: 1.78; acc: 0.38
Val Epoch over. val_loss: 1.8450074157897074; val_accuracy: 0.37898089171974525 

The current subspace-distance is: 6.3493007473880425e-06 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 2.11; acc: 0.27
Batch: 20; loss: 1.93; acc: 0.33
Batch: 40; loss: 1.94; acc: 0.36
Batch: 60; loss: 1.79; acc: 0.39
Batch: 80; loss: 1.96; acc: 0.31
Batch: 100; loss: 1.81; acc: 0.47
Batch: 120; loss: 1.62; acc: 0.44
Batch: 140; loss: 1.85; acc: 0.39
Batch: 160; loss: 1.93; acc: 0.39
Batch: 180; loss: 1.88; acc: 0.31
Batch: 200; loss: 1.82; acc: 0.44
Batch: 220; loss: 1.74; acc: 0.44
Batch: 240; loss: 2.1; acc: 0.25
Batch: 260; loss: 1.93; acc: 0.38
Batch: 280; loss: 1.88; acc: 0.31
Batch: 300; loss: 1.84; acc: 0.36
Batch: 320; loss: 1.89; acc: 0.34
Batch: 340; loss: 1.84; acc: 0.39
Batch: 360; loss: 1.96; acc: 0.22
Batch: 380; loss: 1.76; acc: 0.39
Batch: 400; loss: 1.88; acc: 0.31
Batch: 420; loss: 1.9; acc: 0.36
Batch: 440; loss: 2.02; acc: 0.36
Batch: 460; loss: 1.73; acc: 0.42
Batch: 480; loss: 1.83; acc: 0.38
Batch: 500; loss: 2.05; acc: 0.28
Batch: 520; loss: 1.72; acc: 0.39
Batch: 540; loss: 1.8; acc: 0.41
Batch: 560; loss: 1.77; acc: 0.44
Batch: 580; loss: 1.95; acc: 0.34
Batch: 600; loss: 1.83; acc: 0.41
Batch: 620; loss: 1.96; acc: 0.34
Batch: 640; loss: 1.93; acc: 0.41
Batch: 660; loss: 1.85; acc: 0.34
Batch: 680; loss: 1.81; acc: 0.42
Batch: 700; loss: 1.78; acc: 0.33
Batch: 720; loss: 1.94; acc: 0.34
Batch: 740; loss: 1.99; acc: 0.36
Batch: 760; loss: 1.83; acc: 0.34
Batch: 780; loss: 1.96; acc: 0.34
Train Epoch over. train_loss: 1.86; train_accuracy: 0.38 

1.8567807273939252e-05
4.7840985644143075e-06
Batch: 0; loss: 1.87; acc: 0.33
Batch: 20; loss: 2.04; acc: 0.27
Batch: 40; loss: 1.54; acc: 0.53
Batch: 60; loss: 1.84; acc: 0.41
Batch: 80; loss: 1.79; acc: 0.33
Batch: 100; loss: 1.77; acc: 0.45
Batch: 120; loss: 1.91; acc: 0.39
Batch: 140; loss: 1.78; acc: 0.38
Val Epoch over. val_loss: 1.8444398596028613; val_accuracy: 0.37927945859872614 

The current subspace-distance is: 4.7840985644143075e-06 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.85; acc: 0.44
Batch: 20; loss: 1.86; acc: 0.41
Batch: 40; loss: 1.8; acc: 0.39
Batch: 60; loss: 1.7; acc: 0.48
Batch: 80; loss: 1.66; acc: 0.48
Batch: 100; loss: 1.73; acc: 0.44
Batch: 120; loss: 1.84; acc: 0.36
Batch: 140; loss: 1.85; acc: 0.33
Batch: 160; loss: 1.92; acc: 0.38
Batch: 180; loss: 1.9; acc: 0.34
Batch: 200; loss: 1.93; acc: 0.33
Batch: 220; loss: 1.72; acc: 0.38
Batch: 240; loss: 1.82; acc: 0.36
Batch: 260; loss: 1.85; acc: 0.44
Batch: 280; loss: 2.07; acc: 0.27
Batch: 300; loss: 1.82; acc: 0.42
Batch: 320; loss: 1.84; acc: 0.44
Batch: 340; loss: 1.67; acc: 0.52
Batch: 360; loss: 1.92; acc: 0.34
Batch: 380; loss: 1.99; acc: 0.39
Batch: 400; loss: 1.89; acc: 0.39
Batch: 420; loss: 2.16; acc: 0.28
Batch: 440; loss: 1.94; acc: 0.33
Batch: 460; loss: 1.8; acc: 0.39
Batch: 480; loss: 1.93; acc: 0.39
Batch: 500; loss: 1.77; acc: 0.48
Batch: 520; loss: 1.8; acc: 0.45
Batch: 540; loss: 1.95; acc: 0.34
Batch: 560; loss: 1.74; acc: 0.36
Batch: 580; loss: 1.77; acc: 0.52
Batch: 600; loss: 1.95; acc: 0.39
Batch: 620; loss: 1.79; acc: 0.41
Batch: 640; loss: 1.92; acc: 0.28
Batch: 660; loss: 1.74; acc: 0.38
Batch: 680; loss: 1.92; acc: 0.36
Batch: 700; loss: 1.74; acc: 0.42
Batch: 720; loss: 1.9; acc: 0.38
Batch: 740; loss: 1.85; acc: 0.33
Batch: 760; loss: 1.81; acc: 0.39
Batch: 780; loss: 1.9; acc: 0.39
Train Epoch over. train_loss: 1.86; train_accuracy: 0.38 

1.8158621969632804e-05
8.12193684396334e-06
Batch: 0; loss: 1.87; acc: 0.33
Batch: 20; loss: 2.04; acc: 0.27
Batch: 40; loss: 1.55; acc: 0.53
Batch: 60; loss: 1.83; acc: 0.41
Batch: 80; loss: 1.78; acc: 0.33
Batch: 100; loss: 1.77; acc: 0.47
Batch: 120; loss: 1.91; acc: 0.39
Batch: 140; loss: 1.78; acc: 0.38
Val Epoch over. val_loss: 1.843831163303108; val_accuracy: 0.38007563694267515 

The current subspace-distance is: 8.12193684396334e-06 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.82; acc: 0.38
Batch: 20; loss: 1.77; acc: 0.41
Batch: 40; loss: 2.02; acc: 0.31
Batch: 60; loss: 1.99; acc: 0.3
Batch: 80; loss: 2.02; acc: 0.42
Batch: 100; loss: 1.91; acc: 0.38
Batch: 120; loss: 1.74; acc: 0.45
Batch: 140; loss: 1.89; acc: 0.42
Batch: 160; loss: 2.0; acc: 0.3
Batch: 180; loss: 1.61; acc: 0.5
Batch: 200; loss: 1.67; acc: 0.47
Batch: 220; loss: 1.75; acc: 0.42
Batch: 240; loss: 1.86; acc: 0.38
Batch: 260; loss: 1.59; acc: 0.41
Batch: 280; loss: 1.92; acc: 0.41
Batch: 300; loss: 1.83; acc: 0.36
Batch: 320; loss: 1.9; acc: 0.36
Batch: 340; loss: 1.85; acc: 0.3
Batch: 360; loss: 1.77; acc: 0.47
Batch: 380; loss: 1.99; acc: 0.34
Batch: 400; loss: 1.82; acc: 0.42
Batch: 420; loss: 1.93; acc: 0.28
Batch: 440; loss: 1.95; acc: 0.31
Batch: 460; loss: 1.81; acc: 0.48
Batch: 480; loss: 1.77; acc: 0.39
Batch: 500; loss: 2.04; acc: 0.3
Batch: 520; loss: 1.96; acc: 0.33
Batch: 540; loss: 2.07; acc: 0.25
Batch: 560; loss: 1.97; acc: 0.36
Batch: 580; loss: 1.85; acc: 0.36
Batch: 600; loss: 1.93; acc: 0.28
Batch: 620; loss: 1.91; acc: 0.31
Batch: 640; loss: 1.81; acc: 0.38
Batch: 660; loss: 1.92; acc: 0.39
Batch: 680; loss: 1.67; acc: 0.38
Batch: 700; loss: 2.14; acc: 0.28
Batch: 720; loss: 1.91; acc: 0.34
Batch: 740; loss: 1.87; acc: 0.28
Batch: 760; loss: 1.92; acc: 0.31
Batch: 780; loss: 1.91; acc: 0.3
Train Epoch over. train_loss: 1.86; train_accuracy: 0.38 

1.4179985555529129e-05
4.697372332884697e-06
Batch: 0; loss: 1.86; acc: 0.33
Batch: 20; loss: 2.04; acc: 0.27
Batch: 40; loss: 1.55; acc: 0.52
Batch: 60; loss: 1.83; acc: 0.41
Batch: 80; loss: 1.78; acc: 0.33
Batch: 100; loss: 1.77; acc: 0.47
Batch: 120; loss: 1.91; acc: 0.39
Batch: 140; loss: 1.78; acc: 0.38
Val Epoch over. val_loss: 1.843102207609043; val_accuracy: 0.3804737261146497 

The current subspace-distance is: 4.697372332884697e-06 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.84; acc: 0.38
Batch: 20; loss: 1.88; acc: 0.34
Batch: 40; loss: 1.79; acc: 0.39
Batch: 60; loss: 1.93; acc: 0.33
Batch: 80; loss: 2.02; acc: 0.33
Batch: 100; loss: 1.86; acc: 0.45
Batch: 120; loss: 1.93; acc: 0.39
Batch: 140; loss: 2.19; acc: 0.3
Batch: 160; loss: 1.92; acc: 0.38
Batch: 180; loss: 1.84; acc: 0.45
Batch: 200; loss: 2.01; acc: 0.34
Batch: 220; loss: 2.0; acc: 0.27
Batch: 240; loss: 1.95; acc: 0.38
Batch: 260; loss: 1.78; acc: 0.47
Batch: 280; loss: 1.64; acc: 0.45
Batch: 300; loss: 1.64; acc: 0.44
Batch: 320; loss: 1.69; acc: 0.44
Batch: 340; loss: 1.76; acc: 0.38
Batch: 360; loss: 1.95; acc: 0.36
Batch: 380; loss: 1.81; acc: 0.42
Batch: 400; loss: 1.74; acc: 0.52
Batch: 420; loss: 1.71; acc: 0.45
Batch: 440; loss: 1.83; acc: 0.33
Batch: 460; loss: 2.0; acc: 0.39
Batch: 480; loss: 1.93; acc: 0.34
Batch: 500; loss: 1.9; acc: 0.36
Batch: 520; loss: 1.77; acc: 0.39
Batch: 540; loss: 1.92; acc: 0.33
Batch: 560; loss: 1.9; acc: 0.34
Batch: 580; loss: 1.8; acc: 0.47
Batch: 600; loss: 1.73; acc: 0.41
Batch: 620; loss: 1.97; acc: 0.31
Batch: 640; loss: 1.95; acc: 0.36
Batch: 660; loss: 2.0; acc: 0.36
Batch: 680; loss: 1.74; acc: 0.47
Batch: 700; loss: 1.94; acc: 0.34
Batch: 720; loss: 1.75; acc: 0.38
Batch: 740; loss: 1.96; acc: 0.31
Batch: 760; loss: 2.07; acc: 0.2
Batch: 780; loss: 1.84; acc: 0.39
Train Epoch over. train_loss: 1.86; train_accuracy: 0.38 

1.478262129239738e-05
6.96148117640405e-06
Batch: 0; loss: 1.86; acc: 0.33
Batch: 20; loss: 2.04; acc: 0.27
Batch: 40; loss: 1.55; acc: 0.52
Batch: 60; loss: 1.83; acc: 0.42
Batch: 80; loss: 1.78; acc: 0.33
Batch: 100; loss: 1.77; acc: 0.48
Batch: 120; loss: 1.91; acc: 0.39
Batch: 140; loss: 1.79; acc: 0.39
Val Epoch over. val_loss: 1.8424580492031801; val_accuracy: 0.3818670382165605 

The current subspace-distance is: 6.96148117640405e-06 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.77; acc: 0.42
Batch: 20; loss: 1.97; acc: 0.31
Batch: 40; loss: 1.85; acc: 0.33
Batch: 60; loss: 1.82; acc: 0.38
Batch: 80; loss: 1.81; acc: 0.44
Batch: 100; loss: 1.87; acc: 0.41
Batch: 120; loss: 1.95; acc: 0.34
Batch: 140; loss: 1.85; acc: 0.33
Batch: 160; loss: 1.9; acc: 0.36
Batch: 180; loss: 1.87; acc: 0.39
Batch: 200; loss: 1.98; acc: 0.34
Batch: 220; loss: 1.94; acc: 0.34
Batch: 240; loss: 1.83; acc: 0.41
Batch: 260; loss: 1.88; acc: 0.31
Batch: 280; loss: 1.86; acc: 0.44
Batch: 300; loss: 1.85; acc: 0.42
Batch: 320; loss: 2.06; acc: 0.33
Batch: 340; loss: 1.8; acc: 0.44
Batch: 360; loss: 1.89; acc: 0.36
Batch: 380; loss: 1.82; acc: 0.38
Batch: 400; loss: 1.69; acc: 0.45
Batch: 420; loss: 1.64; acc: 0.48
Batch: 440; loss: 2.07; acc: 0.3
Batch: 460; loss: 1.94; acc: 0.33
Batch: 480; loss: 2.03; acc: 0.3
Batch: 500; loss: 1.85; acc: 0.36
Batch: 520; loss: 1.84; acc: 0.42
Batch: 540; loss: 1.96; acc: 0.39
Batch: 560; loss: 1.82; acc: 0.44
Batch: 580; loss: 2.19; acc: 0.34
Batch: 600; loss: 1.9; acc: 0.42
Batch: 620; loss: 1.87; acc: 0.36
Batch: 640; loss: 1.83; acc: 0.34
Batch: 660; loss: 1.82; acc: 0.39
Batch: 680; loss: 1.72; acc: 0.42
Batch: 700; loss: 1.97; acc: 0.33
Batch: 720; loss: 1.87; acc: 0.41
Batch: 740; loss: 1.83; acc: 0.39
Batch: 760; loss: 2.07; acc: 0.28
Batch: 780; loss: 1.64; acc: 0.47
Train Epoch over. train_loss: 1.86; train_accuracy: 0.38 

1.3528495401260443e-05
3.83361111744307e-06
Batch: 0; loss: 1.86; acc: 0.33
Batch: 20; loss: 2.04; acc: 0.27
Batch: 40; loss: 1.55; acc: 0.52
Batch: 60; loss: 1.83; acc: 0.41
Batch: 80; loss: 1.78; acc: 0.33
Batch: 100; loss: 1.77; acc: 0.48
Batch: 120; loss: 1.91; acc: 0.39
Batch: 140; loss: 1.79; acc: 0.39
Val Epoch over. val_loss: 1.841673287616414; val_accuracy: 0.3801751592356688 

The current subspace-distance is: 3.83361111744307e-06 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.83; acc: 0.34
Batch: 20; loss: 1.95; acc: 0.31
Batch: 40; loss: 1.95; acc: 0.33
Batch: 60; loss: 1.78; acc: 0.44
Batch: 80; loss: 1.71; acc: 0.44
Batch: 100; loss: 1.75; acc: 0.47
Batch: 120; loss: 1.91; acc: 0.36
Batch: 140; loss: 1.7; acc: 0.41
Batch: 160; loss: 1.74; acc: 0.44
Batch: 180; loss: 1.95; acc: 0.34
Batch: 200; loss: 1.92; acc: 0.36
Batch: 220; loss: 1.74; acc: 0.39
Batch: 240; loss: 1.81; acc: 0.38
Batch: 260; loss: 1.89; acc: 0.33
Batch: 280; loss: 1.98; acc: 0.33
Batch: 300; loss: 1.68; acc: 0.39
Batch: 320; loss: 1.97; acc: 0.31
Batch: 340; loss: 1.89; acc: 0.42
Batch: 360; loss: 1.99; acc: 0.39
Batch: 380; loss: 1.9; acc: 0.38
Batch: 400; loss: 1.98; acc: 0.34
Batch: 420; loss: 1.9; acc: 0.3
Batch: 440; loss: 1.85; acc: 0.38
Batch: 460; loss: 1.8; acc: 0.38
Batch: 480; loss: 1.86; acc: 0.38
Batch: 500; loss: 1.9; acc: 0.34
Batch: 520; loss: 1.74; acc: 0.39
Batch: 540; loss: 1.76; acc: 0.44
Batch: 560; loss: 1.58; acc: 0.47
Batch: 580; loss: 1.95; acc: 0.34
Batch: 600; loss: 1.86; acc: 0.34
Batch: 620; loss: 1.82; acc: 0.44
Batch: 640; loss: 1.9; acc: 0.44
Batch: 660; loss: 1.68; acc: 0.45
Batch: 680; loss: 1.84; acc: 0.38
Batch: 700; loss: 1.89; acc: 0.31
Batch: 720; loss: 2.05; acc: 0.3
Batch: 740; loss: 1.7; acc: 0.36
Batch: 760; loss: 1.96; acc: 0.39
Batch: 780; loss: 1.76; acc: 0.42
Train Epoch over. train_loss: 1.86; train_accuracy: 0.38 

1.4279827155405656e-05
4.698267730418593e-06
Batch: 0; loss: 1.86; acc: 0.33
Batch: 20; loss: 2.04; acc: 0.27
Batch: 40; loss: 1.55; acc: 0.52
Batch: 60; loss: 1.82; acc: 0.41
Batch: 80; loss: 1.77; acc: 0.33
Batch: 100; loss: 1.77; acc: 0.48
Batch: 120; loss: 1.91; acc: 0.41
Batch: 140; loss: 1.79; acc: 0.39
Val Epoch over. val_loss: 1.8409546051815058; val_accuracy: 0.3802746815286624 

The current subspace-distance is: 4.698267730418593e-06 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 2.0; acc: 0.27
Batch: 20; loss: 2.0; acc: 0.3
Batch: 40; loss: 1.68; acc: 0.44
Batch: 60; loss: 1.85; acc: 0.39
Batch: 80; loss: 1.73; acc: 0.44
Batch: 100; loss: 1.86; acc: 0.36
Batch: 120; loss: 1.96; acc: 0.33
Batch: 140; loss: 1.93; acc: 0.41
Batch: 160; loss: 2.03; acc: 0.33
Batch: 180; loss: 1.82; acc: 0.45
Batch: 200; loss: 2.01; acc: 0.33
Batch: 220; loss: 1.81; acc: 0.36
Batch: 240; loss: 1.77; acc: 0.44
Batch: 260; loss: 1.82; acc: 0.34
Batch: 280; loss: 1.57; acc: 0.55
Batch: 300; loss: 1.82; acc: 0.44
Batch: 320; loss: 1.89; acc: 0.38
Batch: 340; loss: 2.03; acc: 0.27
Batch: 360; loss: 2.12; acc: 0.33
Batch: 380; loss: 1.89; acc: 0.34
Batch: 400; loss: 1.86; acc: 0.38
Batch: 420; loss: 1.95; acc: 0.36
Batch: 440; loss: 1.86; acc: 0.42
Batch: 460; loss: 1.96; acc: 0.34
Batch: 480; loss: 1.95; acc: 0.3
Batch: 500; loss: 1.69; acc: 0.42
Batch: 520; loss: 1.89; acc: 0.33
Batch: 540; loss: 1.59; acc: 0.52
Batch: 560; loss: 1.91; acc: 0.38
Batch: 580; loss: 1.98; acc: 0.33
Batch: 600; loss: 1.83; acc: 0.42
Batch: 620; loss: 2.0; acc: 0.36
Batch: 640; loss: 1.68; acc: 0.42
Batch: 660; loss: 1.94; acc: 0.34
Batch: 680; loss: 1.98; acc: 0.33
Batch: 700; loss: 1.88; acc: 0.38
Batch: 720; loss: 1.85; acc: 0.44
Batch: 740; loss: 1.9; acc: 0.41
Batch: 760; loss: 1.64; acc: 0.44
Batch: 780; loss: 2.2; acc: 0.33
Train Epoch over. train_loss: 1.86; train_accuracy: 0.38 

1.9673065253300592e-05
7.186766652012011e-06
Batch: 0; loss: 1.85; acc: 0.33
Batch: 20; loss: 2.04; acc: 0.27
Batch: 40; loss: 1.56; acc: 0.5
Batch: 60; loss: 1.82; acc: 0.41
Batch: 80; loss: 1.77; acc: 0.34
Batch: 100; loss: 1.77; acc: 0.47
Batch: 120; loss: 1.91; acc: 0.41
Batch: 140; loss: 1.79; acc: 0.39
Val Epoch over. val_loss: 1.840190366574913; val_accuracy: 0.38057324840764334 

The current subspace-distance is: 7.186766652012011e-06 

plots/subspace_training/reg_lenet_3/2020-01-22 20:51:04/d_dim_25_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
nonzero elements in E: 10626
elements in E: 2249500
fraction nonzero: 0.004723716381418093
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.31; acc: 0.08
Batch: 20; loss: 2.29; acc: 0.05
Batch: 40; loss: 2.3; acc: 0.06
Batch: 60; loss: 2.3; acc: 0.02
Batch: 80; loss: 2.3; acc: 0.03
Batch: 100; loss: 2.3; acc: 0.05
Batch: 120; loss: 2.31; acc: 0.08
Batch: 140; loss: 2.32; acc: 0.05
Batch: 160; loss: 2.3; acc: 0.05
Batch: 180; loss: 2.3; acc: 0.08
Batch: 200; loss: 2.3; acc: 0.06
Batch: 220; loss: 2.31; acc: 0.08
Batch: 240; loss: 2.32; acc: 0.05
Batch: 260; loss: 2.3; acc: 0.08
Batch: 280; loss: 2.29; acc: 0.02
Batch: 300; loss: 2.3; acc: 0.05
Batch: 320; loss: 2.31; acc: 0.11
Batch: 340; loss: 2.3; acc: 0.12
Batch: 360; loss: 2.3; acc: 0.05
Batch: 380; loss: 2.3; acc: 0.14
Batch: 400; loss: 2.31; acc: 0.06
Batch: 420; loss: 2.32; acc: 0.03
Batch: 440; loss: 2.3; acc: 0.09
Batch: 460; loss: 2.31; acc: 0.09
Batch: 480; loss: 2.3; acc: 0.12
Batch: 500; loss: 2.3; acc: 0.09
Batch: 520; loss: 2.28; acc: 0.14
Batch: 540; loss: 2.3; acc: 0.09
Batch: 560; loss: 2.3; acc: 0.12
Batch: 580; loss: 2.29; acc: 0.09
Batch: 600; loss: 2.3; acc: 0.14
Batch: 620; loss: 2.29; acc: 0.08
Batch: 640; loss: 2.29; acc: 0.03
Batch: 660; loss: 2.29; acc: 0.16
Batch: 680; loss: 2.3; acc: 0.08
Batch: 700; loss: 2.31; acc: 0.09
Batch: 720; loss: 2.31; acc: 0.05
Batch: 740; loss: 2.29; acc: 0.14
Batch: 760; loss: 2.3; acc: 0.14
Batch: 780; loss: 2.29; acc: 0.16
Train Epoch over. train_loss: 2.3; train_accuracy: 0.09 

3.6347514651424717e-06
7.84145413490478e-07
Batch: 0; loss: 2.29; acc: 0.06
Batch: 20; loss: 2.29; acc: 0.06
Batch: 40; loss: 2.3; acc: 0.06
Batch: 60; loss: 2.29; acc: 0.12
Batch: 80; loss: 2.28; acc: 0.2
Batch: 100; loss: 2.3; acc: 0.03
Batch: 120; loss: 2.31; acc: 0.03
Batch: 140; loss: 2.3; acc: 0.09
Val Epoch over. val_loss: 2.2922581548144105; val_accuracy: 0.10539410828025478 

The current subspace-distance is: 7.84145413490478e-07 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.19
Batch: 20; loss: 2.3; acc: 0.08
Batch: 40; loss: 2.3; acc: 0.06
Batch: 60; loss: 2.27; acc: 0.14
Batch: 80; loss: 2.29; acc: 0.14
Batch: 100; loss: 2.29; acc: 0.12
Batch: 120; loss: 2.28; acc: 0.08
Batch: 140; loss: 2.3; acc: 0.09
Batch: 160; loss: 2.3; acc: 0.09
Batch: 180; loss: 2.29; acc: 0.11
Batch: 200; loss: 2.28; acc: 0.12
Batch: 220; loss: 2.28; acc: 0.09
Batch: 240; loss: 2.27; acc: 0.12
Batch: 260; loss: 2.29; acc: 0.08
Batch: 280; loss: 2.28; acc: 0.12
Batch: 300; loss: 2.3; acc: 0.06
Batch: 320; loss: 2.29; acc: 0.08
Batch: 340; loss: 2.28; acc: 0.12
Batch: 360; loss: 2.28; acc: 0.12
Batch: 380; loss: 2.29; acc: 0.12
Batch: 400; loss: 2.29; acc: 0.02
Batch: 420; loss: 2.27; acc: 0.14
Batch: 440; loss: 2.28; acc: 0.09
Batch: 460; loss: 2.29; acc: 0.17
Batch: 480; loss: 2.29; acc: 0.12
Batch: 500; loss: 2.27; acc: 0.19
Batch: 520; loss: 2.29; acc: 0.06
Batch: 540; loss: 2.28; acc: 0.17
Batch: 560; loss: 2.28; acc: 0.14
Batch: 580; loss: 2.27; acc: 0.17
Batch: 600; loss: 2.28; acc: 0.14
Batch: 620; loss: 2.27; acc: 0.16
Batch: 640; loss: 2.27; acc: 0.2
Batch: 660; loss: 2.29; acc: 0.16
Batch: 680; loss: 2.3; acc: 0.09
Batch: 700; loss: 2.28; acc: 0.12
Batch: 720; loss: 2.27; acc: 0.16
Batch: 740; loss: 2.27; acc: 0.14
Batch: 760; loss: 2.28; acc: 0.17
Batch: 780; loss: 2.26; acc: 0.22
Train Epoch over. train_loss: 2.29; train_accuracy: 0.13 

4.548558081296505e-06
1.6124930652949843e-06
Batch: 0; loss: 2.28; acc: 0.14
Batch: 20; loss: 2.28; acc: 0.14
Batch: 40; loss: 2.27; acc: 0.14
Batch: 60; loss: 2.27; acc: 0.19
Batch: 80; loss: 2.25; acc: 0.25
Batch: 100; loss: 2.28; acc: 0.12
Batch: 120; loss: 2.3; acc: 0.08
Batch: 140; loss: 2.28; acc: 0.16
Val Epoch over. val_loss: 2.2763603842182523; val_accuracy: 0.16779458598726116 

The current subspace-distance is: 1.6124930652949843e-06 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 2.29; acc: 0.12
Batch: 20; loss: 2.29; acc: 0.09
Batch: 40; loss: 2.27; acc: 0.14
Batch: 60; loss: 2.28; acc: 0.14
Batch: 80; loss: 2.29; acc: 0.14
Batch: 100; loss: 2.27; acc: 0.23
Batch: 120; loss: 2.29; acc: 0.09
Batch: 140; loss: 2.28; acc: 0.16
Batch: 160; loss: 2.26; acc: 0.17
Batch: 180; loss: 2.29; acc: 0.14
Batch: 200; loss: 2.29; acc: 0.08
Batch: 220; loss: 2.28; acc: 0.12
Batch: 240; loss: 2.27; acc: 0.17
Batch: 260; loss: 2.28; acc: 0.14
Batch: 280; loss: 2.27; acc: 0.19
Batch: 300; loss: 2.24; acc: 0.22
Batch: 320; loss: 2.25; acc: 0.22
Batch: 340; loss: 2.26; acc: 0.17
Batch: 360; loss: 2.25; acc: 0.2
Batch: 380; loss: 2.24; acc: 0.22
Batch: 400; loss: 2.27; acc: 0.14
Batch: 420; loss: 2.25; acc: 0.19
Batch: 440; loss: 2.23; acc: 0.22
Batch: 460; loss: 2.27; acc: 0.19
Batch: 480; loss: 2.25; acc: 0.19
Batch: 500; loss: 2.25; acc: 0.17
Batch: 520; loss: 2.24; acc: 0.25
Batch: 540; loss: 2.26; acc: 0.09
Batch: 560; loss: 2.26; acc: 0.12
Batch: 580; loss: 2.25; acc: 0.12
Batch: 600; loss: 2.21; acc: 0.2
Batch: 620; loss: 2.25; acc: 0.11
Batch: 640; loss: 2.24; acc: 0.16
Batch: 660; loss: 2.24; acc: 0.17
Batch: 680; loss: 2.2; acc: 0.23
Batch: 700; loss: 2.21; acc: 0.2
Batch: 720; loss: 2.19; acc: 0.22
Batch: 740; loss: 2.22; acc: 0.16
Batch: 760; loss: 2.21; acc: 0.22
Batch: 780; loss: 2.22; acc: 0.14
Train Epoch over. train_loss: 2.25; train_accuracy: 0.17 

6.848526936664712e-06
2.7459836928755976e-06
Batch: 0; loss: 2.22; acc: 0.16
Batch: 20; loss: 2.22; acc: 0.12
Batch: 40; loss: 2.16; acc: 0.19
Batch: 60; loss: 2.17; acc: 0.3
Batch: 80; loss: 2.15; acc: 0.25
Batch: 100; loss: 2.2; acc: 0.2
Batch: 120; loss: 2.23; acc: 0.11
Batch: 140; loss: 2.19; acc: 0.25
Val Epoch over. val_loss: 2.201304593663307; val_accuracy: 0.20113455414012738 

The current subspace-distance is: 2.7459836928755976e-06 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 2.22; acc: 0.19
Batch: 20; loss: 2.21; acc: 0.14
Batch: 40; loss: 2.2; acc: 0.14
Batch: 60; loss: 2.17; acc: 0.19
Batch: 80; loss: 2.17; acc: 0.2
Batch: 100; loss: 2.17; acc: 0.23
Batch: 120; loss: 2.19; acc: 0.16
Batch: 140; loss: 2.17; acc: 0.2
Batch: 160; loss: 2.13; acc: 0.27
Batch: 180; loss: 2.16; acc: 0.16
Batch: 200; loss: 2.19; acc: 0.2
Batch: 220; loss: 2.16; acc: 0.14
Batch: 240; loss: 2.09; acc: 0.22
Batch: 260; loss: 2.16; acc: 0.11
Batch: 280; loss: 2.13; acc: 0.17
Batch: 300; loss: 2.16; acc: 0.17
Batch: 320; loss: 2.09; acc: 0.25
Batch: 340; loss: 2.22; acc: 0.14
Batch: 360; loss: 2.09; acc: 0.16
Batch: 380; loss: 2.09; acc: 0.22
Batch: 400; loss: 2.1; acc: 0.2
Batch: 420; loss: 2.15; acc: 0.19
Batch: 440; loss: 2.08; acc: 0.22
Batch: 460; loss: 2.07; acc: 0.23
Batch: 480; loss: 2.03; acc: 0.25
Batch: 500; loss: 2.01; acc: 0.27
Batch: 520; loss: 1.97; acc: 0.33
Batch: 540; loss: 1.97; acc: 0.34
Batch: 560; loss: 1.95; acc: 0.38
Batch: 580; loss: 2.05; acc: 0.27
Batch: 600; loss: 1.99; acc: 0.27
Batch: 620; loss: 2.13; acc: 0.22
Batch: 640; loss: 1.92; acc: 0.36
Batch: 660; loss: 1.84; acc: 0.52
Batch: 680; loss: 1.81; acc: 0.38
Batch: 700; loss: 1.9; acc: 0.42
Batch: 720; loss: 1.89; acc: 0.33
Batch: 740; loss: 1.92; acc: 0.28
Batch: 760; loss: 1.84; acc: 0.42
Batch: 780; loss: 1.78; acc: 0.34
Train Epoch over. train_loss: 2.06; train_accuracy: 0.25 

1.1768171134463046e-05
5.201402927923482e-06
Batch: 0; loss: 1.89; acc: 0.33
Batch: 20; loss: 1.95; acc: 0.33
Batch: 40; loss: 1.67; acc: 0.45
Batch: 60; loss: 1.65; acc: 0.5
Batch: 80; loss: 1.67; acc: 0.5
Batch: 100; loss: 1.72; acc: 0.45
Batch: 120; loss: 1.87; acc: 0.38
Batch: 140; loss: 1.57; acc: 0.62
Val Epoch over. val_loss: 1.8110888923049733; val_accuracy: 0.4212778662420382 

The current subspace-distance is: 5.201402927923482e-06 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 1.92; acc: 0.28
Batch: 20; loss: 1.8; acc: 0.47
Batch: 40; loss: 1.76; acc: 0.38
Batch: 60; loss: 1.79; acc: 0.34
Batch: 80; loss: 1.77; acc: 0.42
Batch: 100; loss: 1.73; acc: 0.42
Batch: 120; loss: 1.81; acc: 0.38
Batch: 140; loss: 1.62; acc: 0.55
Batch: 160; loss: 1.77; acc: 0.41
Batch: 180; loss: 1.66; acc: 0.42
Batch: 200; loss: 1.45; acc: 0.59
Batch: 220; loss: 1.67; acc: 0.47
Batch: 240; loss: 1.82; acc: 0.36
Batch: 260; loss: 1.56; acc: 0.5
Batch: 280; loss: 1.67; acc: 0.38
Batch: 300; loss: 1.55; acc: 0.56
Batch: 320; loss: 1.51; acc: 0.5
Batch: 340; loss: 1.59; acc: 0.44
Batch: 360; loss: 1.81; acc: 0.41
Batch: 380; loss: 1.64; acc: 0.5
Batch: 400; loss: 1.6; acc: 0.45
Batch: 420; loss: 1.54; acc: 0.48
Batch: 440; loss: 1.62; acc: 0.45
Batch: 460; loss: 1.45; acc: 0.56
Batch: 480; loss: 1.56; acc: 0.45
Batch: 500; loss: 1.42; acc: 0.58
Batch: 520; loss: 1.68; acc: 0.44
Batch: 540; loss: 1.45; acc: 0.52
Batch: 560; loss: 1.51; acc: 0.5
Batch: 580; loss: 1.43; acc: 0.53
Batch: 600; loss: 1.33; acc: 0.56
Batch: 620; loss: 1.4; acc: 0.56
Batch: 640; loss: 1.58; acc: 0.44
Batch: 660; loss: 1.59; acc: 0.52
Batch: 680; loss: 1.72; acc: 0.42
Batch: 700; loss: 1.46; acc: 0.53
Batch: 720; loss: 1.48; acc: 0.48
Batch: 740; loss: 1.55; acc: 0.5
Batch: 760; loss: 1.42; acc: 0.53
Batch: 780; loss: 1.53; acc: 0.52
Train Epoch over. train_loss: 1.61; train_accuracy: 0.48 

1.8848895706469193e-05
6.8873273448843975e-06
Batch: 0; loss: 1.68; acc: 0.47
Batch: 20; loss: 1.48; acc: 0.5
Batch: 40; loss: 1.27; acc: 0.59
Batch: 60; loss: 1.31; acc: 0.64
Batch: 80; loss: 1.19; acc: 0.62
Batch: 100; loss: 1.28; acc: 0.61
Batch: 120; loss: 1.58; acc: 0.44
Batch: 140; loss: 1.07; acc: 0.77
Val Epoch over. val_loss: 1.4496529580681188; val_accuracy: 0.5297571656050956 

The current subspace-distance is: 6.8873273448843975e-06 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 1.7; acc: 0.52
Batch: 20; loss: 1.66; acc: 0.47
Batch: 40; loss: 1.73; acc: 0.55
Batch: 60; loss: 1.62; acc: 0.48
Batch: 80; loss: 1.57; acc: 0.42
Batch: 100; loss: 1.52; acc: 0.44
Batch: 120; loss: 1.51; acc: 0.5
Batch: 140; loss: 1.34; acc: 0.55
Batch: 160; loss: 1.56; acc: 0.45
Batch: 180; loss: 1.35; acc: 0.61
Batch: 200; loss: 1.4; acc: 0.52
Batch: 220; loss: 1.46; acc: 0.45
Batch: 240; loss: 1.27; acc: 0.64
Batch: 260; loss: 1.4; acc: 0.56
Batch: 280; loss: 1.23; acc: 0.61
Batch: 300; loss: 1.41; acc: 0.62
Batch: 320; loss: 1.41; acc: 0.56
Batch: 340; loss: 1.31; acc: 0.66
Batch: 360; loss: 1.61; acc: 0.53
Batch: 380; loss: 1.57; acc: 0.47
Batch: 400; loss: 1.38; acc: 0.5
Batch: 420; loss: 1.55; acc: 0.45
Batch: 440; loss: 1.39; acc: 0.59
Batch: 460; loss: 1.62; acc: 0.5
Batch: 480; loss: 1.74; acc: 0.45
Batch: 500; loss: 1.48; acc: 0.55
Batch: 520; loss: 1.59; acc: 0.5
Batch: 540; loss: 1.32; acc: 0.55
Batch: 560; loss: 1.6; acc: 0.44
Batch: 580; loss: 1.52; acc: 0.55
Batch: 600; loss: 1.38; acc: 0.52
Batch: 620; loss: 1.41; acc: 0.52
Batch: 640; loss: 1.44; acc: 0.52
Batch: 660; loss: 1.33; acc: 0.67
Batch: 680; loss: 1.03; acc: 0.73
Batch: 700; loss: 1.23; acc: 0.56
Batch: 720; loss: 1.54; acc: 0.45
Batch: 740; loss: 1.54; acc: 0.55
Batch: 760; loss: 1.52; acc: 0.47
Batch: 780; loss: 1.69; acc: 0.45
Train Epoch over. train_loss: 1.47; train_accuracy: 0.52 

2.1162451957934536e-05
6.601799668715103e-06
Batch: 0; loss: 1.77; acc: 0.44
Batch: 20; loss: 1.37; acc: 0.5
Batch: 40; loss: 1.19; acc: 0.69
Batch: 60; loss: 1.31; acc: 0.62
Batch: 80; loss: 1.17; acc: 0.61
Batch: 100; loss: 1.24; acc: 0.58
Batch: 120; loss: 1.53; acc: 0.47
Batch: 140; loss: 1.03; acc: 0.73
Val Epoch over. val_loss: 1.4259369373321533; val_accuracy: 0.5368232484076433 

The current subspace-distance is: 6.601799668715103e-06 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 1.57; acc: 0.52
Batch: 20; loss: 1.56; acc: 0.48
Batch: 40; loss: 1.53; acc: 0.56
Batch: 60; loss: 1.35; acc: 0.53
Batch: 80; loss: 1.29; acc: 0.61
Batch: 100; loss: 1.5; acc: 0.56
Batch: 120; loss: 1.36; acc: 0.55
Batch: 140; loss: 1.45; acc: 0.48
Batch: 160; loss: 1.38; acc: 0.61
Batch: 180; loss: 1.45; acc: 0.52
Batch: 200; loss: 1.75; acc: 0.42
Batch: 220; loss: 1.58; acc: 0.53
Batch: 240; loss: 1.32; acc: 0.5
Batch: 260; loss: 1.58; acc: 0.45
Batch: 280; loss: 1.35; acc: 0.5
Batch: 300; loss: 1.46; acc: 0.42
Batch: 320; loss: 1.33; acc: 0.61
Batch: 340; loss: 1.3; acc: 0.61
Batch: 360; loss: 1.64; acc: 0.47
Batch: 380; loss: 1.58; acc: 0.52
Batch: 400; loss: 1.42; acc: 0.55
Batch: 420; loss: 1.51; acc: 0.44
Batch: 440; loss: 1.57; acc: 0.52
Batch: 460; loss: 1.28; acc: 0.53
Batch: 480; loss: 1.47; acc: 0.56
Batch: 500; loss: 1.37; acc: 0.58
Batch: 520; loss: 1.52; acc: 0.53
Batch: 540; loss: 1.5; acc: 0.58
Batch: 560; loss: 1.48; acc: 0.58
Batch: 580; loss: 1.57; acc: 0.52
Batch: 600; loss: 1.29; acc: 0.64
Batch: 620; loss: 1.33; acc: 0.61
Batch: 640; loss: 1.53; acc: 0.47
Batch: 660; loss: 1.44; acc: 0.5
Batch: 680; loss: 1.63; acc: 0.44
Batch: 700; loss: 1.46; acc: 0.48
Batch: 720; loss: 1.45; acc: 0.59
Batch: 740; loss: 1.64; acc: 0.47
Batch: 760; loss: 1.35; acc: 0.58
Batch: 780; loss: 1.28; acc: 0.5
Train Epoch over. train_loss: 1.46; train_accuracy: 0.52 

1.9401735698920675e-05
6.273331109696301e-06
Batch: 0; loss: 1.86; acc: 0.44
Batch: 20; loss: 1.42; acc: 0.47
Batch: 40; loss: 1.18; acc: 0.66
Batch: 60; loss: 1.32; acc: 0.64
Batch: 80; loss: 1.17; acc: 0.59
Batch: 100; loss: 1.24; acc: 0.55
Batch: 120; loss: 1.52; acc: 0.52
Batch: 140; loss: 1.05; acc: 0.78
Val Epoch over. val_loss: 1.4259153786738208; val_accuracy: 0.5344347133757962 

The current subspace-distance is: 6.273331109696301e-06 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 1.48; acc: 0.55
Batch: 20; loss: 1.34; acc: 0.53
Batch: 40; loss: 1.31; acc: 0.52
Batch: 60; loss: 1.44; acc: 0.55
Batch: 80; loss: 1.34; acc: 0.59
Batch: 100; loss: 1.63; acc: 0.47
Batch: 120; loss: 1.45; acc: 0.42
Batch: 140; loss: 1.62; acc: 0.45
Batch: 160; loss: 1.48; acc: 0.5
Batch: 180; loss: 1.32; acc: 0.62
Batch: 200; loss: 1.47; acc: 0.45
Batch: 220; loss: 1.66; acc: 0.38
Batch: 240; loss: 1.44; acc: 0.5
Batch: 260; loss: 1.75; acc: 0.42
Batch: 280; loss: 1.41; acc: 0.48
Batch: 300; loss: 1.6; acc: 0.48
Batch: 320; loss: 1.42; acc: 0.56
Batch: 340; loss: 1.62; acc: 0.52
Batch: 360; loss: 1.35; acc: 0.61
Batch: 380; loss: 1.34; acc: 0.61
Batch: 400; loss: 1.46; acc: 0.55
Batch: 420; loss: 1.32; acc: 0.59
Batch: 440; loss: 1.63; acc: 0.45
Batch: 460; loss: 1.57; acc: 0.5
Batch: 480; loss: 1.55; acc: 0.48
Batch: 500; loss: 1.6; acc: 0.41
Batch: 520; loss: 1.48; acc: 0.55
Batch: 540; loss: 1.46; acc: 0.55
Batch: 560; loss: 1.35; acc: 0.55
Batch: 580; loss: 1.42; acc: 0.47
Batch: 600; loss: 1.63; acc: 0.45
Batch: 620; loss: 1.45; acc: 0.5
Batch: 640; loss: 1.35; acc: 0.59
Batch: 660; loss: 1.36; acc: 0.58
Batch: 680; loss: 1.51; acc: 0.45
Batch: 700; loss: 1.83; acc: 0.39
Batch: 720; loss: 1.25; acc: 0.67
Batch: 740; loss: 1.57; acc: 0.47
Batch: 760; loss: 1.3; acc: 0.64
Batch: 780; loss: 1.53; acc: 0.47
Train Epoch over. train_loss: 1.45; train_accuracy: 0.53 

2.0092840713914484e-05
7.241800631163642e-06
Batch: 0; loss: 1.82; acc: 0.42
Batch: 20; loss: 1.47; acc: 0.48
Batch: 40; loss: 1.06; acc: 0.7
Batch: 60; loss: 1.21; acc: 0.64
Batch: 80; loss: 1.24; acc: 0.61
Batch: 100; loss: 1.18; acc: 0.61
Batch: 120; loss: 1.47; acc: 0.55
Batch: 140; loss: 1.07; acc: 0.73
Val Epoch over. val_loss: 1.4013769763290502; val_accuracy: 0.5512539808917197 

The current subspace-distance is: 7.241800631163642e-06 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 1.51; acc: 0.61
Batch: 20; loss: 1.43; acc: 0.52
Batch: 40; loss: 1.34; acc: 0.59
Batch: 60; loss: 1.47; acc: 0.52
Batch: 80; loss: 1.7; acc: 0.45
Batch: 100; loss: 1.23; acc: 0.56
Batch: 120; loss: 1.17; acc: 0.62
Batch: 140; loss: 1.48; acc: 0.5
Batch: 160; loss: 1.44; acc: 0.59
Batch: 180; loss: 1.44; acc: 0.53
Batch: 200; loss: 1.16; acc: 0.64
Batch: 220; loss: 1.28; acc: 0.56
Batch: 240; loss: 1.42; acc: 0.55
Batch: 260; loss: 1.66; acc: 0.42
Batch: 280; loss: 1.42; acc: 0.55
Batch: 300; loss: 1.37; acc: 0.56
Batch: 320; loss: 1.42; acc: 0.48
Batch: 340; loss: 1.5; acc: 0.48
Batch: 360; loss: 1.57; acc: 0.44
Batch: 380; loss: 1.39; acc: 0.58
Batch: 400; loss: 1.39; acc: 0.52
Batch: 420; loss: 1.33; acc: 0.61
Batch: 440; loss: 1.49; acc: 0.5
Batch: 460; loss: 1.47; acc: 0.48
Batch: 480; loss: 1.4; acc: 0.55
Batch: 500; loss: 1.63; acc: 0.47
Batch: 520; loss: 1.37; acc: 0.52
Batch: 540; loss: 1.38; acc: 0.62
Batch: 560; loss: 1.52; acc: 0.45
Batch: 580; loss: 1.57; acc: 0.45
Batch: 600; loss: 1.54; acc: 0.5
Batch: 620; loss: 1.83; acc: 0.44
Batch: 640; loss: 1.56; acc: 0.45
Batch: 660; loss: 1.51; acc: 0.44
Batch: 680; loss: 1.46; acc: 0.5
Batch: 700; loss: 1.38; acc: 0.47
Batch: 720; loss: 1.08; acc: 0.66
Batch: 740; loss: 1.28; acc: 0.64
Batch: 760; loss: 1.37; acc: 0.53
Batch: 780; loss: 1.37; acc: 0.58
Train Epoch over. train_loss: 1.42; train_accuracy: 0.54 

2.0602303266059607e-05
8.805623110674787e-06
Batch: 0; loss: 1.77; acc: 0.47
Batch: 20; loss: 1.41; acc: 0.47
Batch: 40; loss: 1.02; acc: 0.69
Batch: 60; loss: 1.18; acc: 0.64
Batch: 80; loss: 1.22; acc: 0.66
Batch: 100; loss: 1.18; acc: 0.66
Batch: 120; loss: 1.4; acc: 0.58
Batch: 140; loss: 1.06; acc: 0.77
Val Epoch over. val_loss: 1.3862772306818871; val_accuracy: 0.559812898089172 

The current subspace-distance is: 8.805623110674787e-06 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 1.6; acc: 0.55
Batch: 20; loss: 1.31; acc: 0.55
Batch: 40; loss: 1.67; acc: 0.52
Batch: 60; loss: 1.59; acc: 0.42
Batch: 80; loss: 1.29; acc: 0.64
Batch: 100; loss: 1.36; acc: 0.59
Batch: 120; loss: 1.16; acc: 0.64
Batch: 140; loss: 1.56; acc: 0.45
Batch: 160; loss: 1.34; acc: 0.58
Batch: 180; loss: 1.39; acc: 0.58
Batch: 200; loss: 1.57; acc: 0.44
Batch: 220; loss: 1.68; acc: 0.44
Batch: 240; loss: 1.49; acc: 0.47
Batch: 260; loss: 1.5; acc: 0.52
Batch: 280; loss: 1.23; acc: 0.64
Batch: 300; loss: 1.35; acc: 0.53
Batch: 320; loss: 1.56; acc: 0.5
Batch: 340; loss: 1.37; acc: 0.53
Batch: 360; loss: 1.33; acc: 0.56
Batch: 380; loss: 1.55; acc: 0.44
Batch: 400; loss: 1.46; acc: 0.47
Batch: 420; loss: 1.39; acc: 0.48
Batch: 440; loss: 1.25; acc: 0.58
Batch: 460; loss: 1.33; acc: 0.53
Batch: 480; loss: 1.3; acc: 0.56
Batch: 500; loss: 1.55; acc: 0.5
Batch: 520; loss: 1.42; acc: 0.56
Batch: 540; loss: 1.43; acc: 0.55
Batch: 560; loss: 1.4; acc: 0.52
Batch: 580; loss: 1.54; acc: 0.48
Batch: 600; loss: 1.15; acc: 0.69
Batch: 620; loss: 1.68; acc: 0.52
Batch: 640; loss: 1.34; acc: 0.61
Batch: 660; loss: 1.26; acc: 0.59
Batch: 680; loss: 1.36; acc: 0.61
Batch: 700; loss: 1.59; acc: 0.47
Batch: 720; loss: 1.39; acc: 0.52
Batch: 740; loss: 1.41; acc: 0.53
Batch: 760; loss: 1.44; acc: 0.55
Batch: 780; loss: 1.45; acc: 0.47
Train Epoch over. train_loss: 1.42; train_accuracy: 0.54 

1.9388151486054994e-05
8.475773938698694e-06
Batch: 0; loss: 1.74; acc: 0.48
Batch: 20; loss: 1.42; acc: 0.52
Batch: 40; loss: 0.99; acc: 0.75
Batch: 60; loss: 1.16; acc: 0.66
Batch: 80; loss: 1.26; acc: 0.61
Batch: 100; loss: 1.18; acc: 0.66
Batch: 120; loss: 1.41; acc: 0.56
Batch: 140; loss: 1.05; acc: 0.66
Val Epoch over. val_loss: 1.394705199511947; val_accuracy: 0.5496616242038217 

The current subspace-distance is: 8.475773938698694e-06 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 1.2; acc: 0.66
Batch: 20; loss: 1.48; acc: 0.47
Batch: 40; loss: 1.39; acc: 0.61
Batch: 60; loss: 1.35; acc: 0.58
Batch: 80; loss: 1.28; acc: 0.58
Batch: 100; loss: 1.37; acc: 0.53
Batch: 120; loss: 1.42; acc: 0.56
Batch: 140; loss: 1.4; acc: 0.44
Batch: 160; loss: 1.22; acc: 0.61
Batch: 180; loss: 1.27; acc: 0.53
Batch: 200; loss: 1.56; acc: 0.59
Batch: 220; loss: 1.48; acc: 0.55
Batch: 240; loss: 1.64; acc: 0.45
Batch: 260; loss: 1.36; acc: 0.55
Batch: 280; loss: 1.43; acc: 0.55
Batch: 300; loss: 1.37; acc: 0.53
Batch: 320; loss: 1.3; acc: 0.58
Batch: 340; loss: 1.4; acc: 0.61
Batch: 360; loss: 1.46; acc: 0.58
Batch: 380; loss: 1.57; acc: 0.38
Batch: 400; loss: 1.44; acc: 0.48
Batch: 420; loss: 1.14; acc: 0.66
Batch: 440; loss: 1.44; acc: 0.52
Batch: 460; loss: 1.21; acc: 0.52
Batch: 480; loss: 1.39; acc: 0.53
Batch: 500; loss: 1.47; acc: 0.58
Batch: 520; loss: 1.43; acc: 0.55
Batch: 540; loss: 1.44; acc: 0.5
Batch: 560; loss: 1.38; acc: 0.58
Batch: 580; loss: 1.55; acc: 0.52
Batch: 600; loss: 1.49; acc: 0.52
Batch: 620; loss: 1.31; acc: 0.53
Batch: 640; loss: 1.41; acc: 0.55
Batch: 660; loss: 1.31; acc: 0.52
Batch: 680; loss: 1.4; acc: 0.55
Batch: 700; loss: 1.4; acc: 0.58
Batch: 720; loss: 1.46; acc: 0.45
Batch: 740; loss: 1.48; acc: 0.48
Batch: 760; loss: 1.43; acc: 0.52
Batch: 780; loss: 1.26; acc: 0.58
Train Epoch over. train_loss: 1.41; train_accuracy: 0.54 

1.880753188743256e-05
5.641450570692541e-06
Batch: 0; loss: 1.79; acc: 0.47
Batch: 20; loss: 1.44; acc: 0.5
Batch: 40; loss: 1.01; acc: 0.77
Batch: 60; loss: 1.16; acc: 0.62
Batch: 80; loss: 1.19; acc: 0.64
Batch: 100; loss: 1.18; acc: 0.66
Batch: 120; loss: 1.44; acc: 0.55
Batch: 140; loss: 1.03; acc: 0.77
Val Epoch over. val_loss: 1.3797022430760086; val_accuracy: 0.5581210191082803 

The current subspace-distance is: 5.641450570692541e-06 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 1.8; acc: 0.38
Batch: 20; loss: 1.42; acc: 0.5
Batch: 40; loss: 1.32; acc: 0.53
Batch: 60; loss: 1.45; acc: 0.58
Batch: 80; loss: 1.39; acc: 0.59
Batch: 100; loss: 1.34; acc: 0.59
Batch: 120; loss: 1.29; acc: 0.58
Batch: 140; loss: 1.23; acc: 0.59
Batch: 160; loss: 1.41; acc: 0.48
Batch: 180; loss: 1.16; acc: 0.56
Batch: 200; loss: 1.42; acc: 0.48
Batch: 220; loss: 1.45; acc: 0.48
Batch: 240; loss: 1.53; acc: 0.48
Batch: 260; loss: 1.46; acc: 0.56
Batch: 280; loss: 1.5; acc: 0.55
Batch: 300; loss: 1.26; acc: 0.61
Batch: 320; loss: 1.19; acc: 0.62
Batch: 340; loss: 1.22; acc: 0.62
Batch: 360; loss: 1.31; acc: 0.64
Batch: 380; loss: 1.46; acc: 0.41
Batch: 400; loss: 1.27; acc: 0.56
Batch: 420; loss: 1.4; acc: 0.48
Batch: 440; loss: 1.41; acc: 0.5
Batch: 460; loss: 1.52; acc: 0.5
Batch: 480; loss: 1.56; acc: 0.47
Batch: 500; loss: 1.4; acc: 0.39
Batch: 520; loss: 1.23; acc: 0.61
Batch: 540; loss: 1.65; acc: 0.42
Batch: 560; loss: 1.18; acc: 0.62
Batch: 580; loss: 1.21; acc: 0.62
Batch: 600; loss: 1.45; acc: 0.48
Batch: 620; loss: 1.5; acc: 0.47
Batch: 640; loss: 1.23; acc: 0.56
Batch: 660; loss: 1.58; acc: 0.52
Batch: 680; loss: 1.53; acc: 0.5
Batch: 700; loss: 1.36; acc: 0.61
Batch: 720; loss: 1.36; acc: 0.48
Batch: 740; loss: 1.62; acc: 0.56
Batch: 760; loss: 1.52; acc: 0.52
Batch: 780; loss: 1.28; acc: 0.62
Train Epoch over. train_loss: 1.41; train_accuracy: 0.54 

1.8873181033995934e-05
8.870721103448886e-06
Batch: 0; loss: 1.75; acc: 0.48
Batch: 20; loss: 1.43; acc: 0.48
Batch: 40; loss: 0.99; acc: 0.78
Batch: 60; loss: 1.13; acc: 0.66
Batch: 80; loss: 1.2; acc: 0.64
Batch: 100; loss: 1.17; acc: 0.67
Batch: 120; loss: 1.41; acc: 0.56
Batch: 140; loss: 1.04; acc: 0.73
Val Epoch over. val_loss: 1.3786333681671483; val_accuracy: 0.5534434713375797 

The current subspace-distance is: 8.870721103448886e-06 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 1.71; acc: 0.42
Batch: 20; loss: 1.57; acc: 0.48
Batch: 40; loss: 1.35; acc: 0.55
Batch: 60; loss: 1.44; acc: 0.48
Batch: 80; loss: 1.43; acc: 0.55
Batch: 100; loss: 1.28; acc: 0.56
Batch: 120; loss: 1.22; acc: 0.59
Batch: 140; loss: 1.51; acc: 0.48
Batch: 160; loss: 1.76; acc: 0.42
Batch: 180; loss: 1.28; acc: 0.64
Batch: 200; loss: 1.04; acc: 0.7
Batch: 220; loss: 1.28; acc: 0.55
Batch: 240; loss: 1.22; acc: 0.66
Batch: 260; loss: 1.19; acc: 0.66
Batch: 280; loss: 1.48; acc: 0.53
Batch: 300; loss: 1.13; acc: 0.66
Batch: 320; loss: 1.34; acc: 0.61
Batch: 340; loss: 1.21; acc: 0.58
Batch: 360; loss: 1.35; acc: 0.5
Batch: 380; loss: 1.75; acc: 0.34
Batch: 400; loss: 1.19; acc: 0.59
Batch: 420; loss: 1.31; acc: 0.55
Batch: 440; loss: 1.55; acc: 0.44
Batch: 460; loss: 1.34; acc: 0.53
Batch: 480; loss: 1.2; acc: 0.59
Batch: 500; loss: 1.33; acc: 0.58
Batch: 520; loss: 1.41; acc: 0.52
Batch: 540; loss: 1.28; acc: 0.58
Batch: 560; loss: 1.27; acc: 0.64
Batch: 580; loss: 1.55; acc: 0.48
Batch: 600; loss: 1.46; acc: 0.52
Batch: 620; loss: 1.39; acc: 0.56
Batch: 640; loss: 1.4; acc: 0.56
Batch: 660; loss: 1.3; acc: 0.58
Batch: 680; loss: 1.36; acc: 0.56
Batch: 700; loss: 1.56; acc: 0.48
Batch: 720; loss: 1.37; acc: 0.56
Batch: 740; loss: 1.5; acc: 0.56
Batch: 760; loss: 1.1; acc: 0.69
Batch: 780; loss: 1.26; acc: 0.62
Train Epoch over. train_loss: 1.41; train_accuracy: 0.54 

1.9818910004687496e-05
6.676272732875077e-06
Batch: 0; loss: 1.75; acc: 0.5
Batch: 20; loss: 1.42; acc: 0.53
Batch: 40; loss: 1.0; acc: 0.73
Batch: 60; loss: 1.14; acc: 0.66
Batch: 80; loss: 1.2; acc: 0.66
Batch: 100; loss: 1.18; acc: 0.67
Batch: 120; loss: 1.4; acc: 0.58
Batch: 140; loss: 1.05; acc: 0.73
Val Epoch over. val_loss: 1.3800329805179765; val_accuracy: 0.5570262738853503 

The current subspace-distance is: 6.676272732875077e-06 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 1.36; acc: 0.5
Batch: 20; loss: 1.47; acc: 0.55
Batch: 40; loss: 1.44; acc: 0.56
Batch: 60; loss: 1.37; acc: 0.55
Batch: 80; loss: 1.33; acc: 0.58
Batch: 100; loss: 1.15; acc: 0.61
Batch: 120; loss: 1.21; acc: 0.58
Batch: 140; loss: 1.61; acc: 0.38
Batch: 160; loss: 1.28; acc: 0.58
Batch: 180; loss: 1.23; acc: 0.62
Batch: 200; loss: 1.04; acc: 0.7
Batch: 220; loss: 1.7; acc: 0.39
Batch: 240; loss: 1.45; acc: 0.56
Batch: 260; loss: 1.45; acc: 0.47
Batch: 280; loss: 1.56; acc: 0.5
Batch: 300; loss: 1.36; acc: 0.59
Batch: 320; loss: 1.23; acc: 0.56
Batch: 340; loss: 1.29; acc: 0.56
Batch: 360; loss: 1.49; acc: 0.55
Batch: 380; loss: 1.25; acc: 0.56
Batch: 400; loss: 1.53; acc: 0.5
Batch: 420; loss: 1.36; acc: 0.58
Batch: 440; loss: 1.25; acc: 0.58
Batch: 460; loss: 1.41; acc: 0.56
Batch: 480; loss: 1.35; acc: 0.55
Batch: 500; loss: 1.27; acc: 0.61
Batch: 520; loss: 1.51; acc: 0.5
Batch: 540; loss: 1.16; acc: 0.67
Batch: 560; loss: 1.38; acc: 0.48
Batch: 580; loss: 1.23; acc: 0.69
Batch: 600; loss: 1.68; acc: 0.48
Batch: 620; loss: 1.53; acc: 0.55
Batch: 640; loss: 1.45; acc: 0.55
Batch: 660; loss: 1.57; acc: 0.5
Batch: 680; loss: 1.71; acc: 0.44
Batch: 700; loss: 1.4; acc: 0.55
Batch: 720; loss: 1.31; acc: 0.55
Batch: 740; loss: 1.31; acc: 0.56
Batch: 760; loss: 1.47; acc: 0.48
Batch: 780; loss: 1.25; acc: 0.59
Train Epoch over. train_loss: 1.41; train_accuracy: 0.54 

2.1004992959205993e-05
8.395790246140677e-06
Batch: 0; loss: 1.78; acc: 0.5
Batch: 20; loss: 1.43; acc: 0.5
Batch: 40; loss: 0.99; acc: 0.78
Batch: 60; loss: 1.15; acc: 0.61
Batch: 80; loss: 1.21; acc: 0.62
Batch: 100; loss: 1.18; acc: 0.67
Batch: 120; loss: 1.42; acc: 0.56
Batch: 140; loss: 1.02; acc: 0.73
Val Epoch over. val_loss: 1.3785708945268278; val_accuracy: 0.5528463375796179 

The current subspace-distance is: 8.395790246140677e-06 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 1.61; acc: 0.41
Batch: 20; loss: 1.23; acc: 0.62
Batch: 40; loss: 1.59; acc: 0.48
Batch: 60; loss: 1.23; acc: 0.7
Batch: 80; loss: 1.32; acc: 0.61
Batch: 100; loss: 1.36; acc: 0.59
Batch: 120; loss: 1.56; acc: 0.47
Batch: 140; loss: 1.31; acc: 0.61
Batch: 160; loss: 1.43; acc: 0.52
Batch: 180; loss: 1.29; acc: 0.59
Batch: 200; loss: 1.5; acc: 0.53
Batch: 220; loss: 1.22; acc: 0.61
Batch: 240; loss: 1.6; acc: 0.47
Batch: 260; loss: 1.31; acc: 0.56
Batch: 280; loss: 1.48; acc: 0.53
Batch: 300; loss: 1.4; acc: 0.55
Batch: 320; loss: 1.25; acc: 0.61
Batch: 340; loss: 1.39; acc: 0.55
Batch: 360; loss: 1.33; acc: 0.58
Batch: 380; loss: 1.47; acc: 0.52
Batch: 400; loss: 1.65; acc: 0.47
Batch: 420; loss: 1.24; acc: 0.61
Batch: 440; loss: 1.32; acc: 0.52
Batch: 460; loss: 1.51; acc: 0.53
Batch: 480; loss: 1.31; acc: 0.53
Batch: 500; loss: 1.11; acc: 0.62
Batch: 520; loss: 1.49; acc: 0.47
Batch: 540; loss: 1.24; acc: 0.62
Batch: 560; loss: 1.47; acc: 0.59
Batch: 580; loss: 1.5; acc: 0.56
Batch: 600; loss: 1.46; acc: 0.47
Batch: 620; loss: 1.6; acc: 0.48
Batch: 640; loss: 1.44; acc: 0.56
Batch: 660; loss: 1.4; acc: 0.58
Batch: 680; loss: 1.51; acc: 0.5
Batch: 700; loss: 1.21; acc: 0.61
Batch: 720; loss: 1.47; acc: 0.5
Batch: 740; loss: 1.24; acc: 0.59
Batch: 760; loss: 1.36; acc: 0.53
Batch: 780; loss: 1.22; acc: 0.66
Train Epoch over. train_loss: 1.41; train_accuracy: 0.54 

2.088791188725736e-05
8.691957191331312e-06
Batch: 0; loss: 1.78; acc: 0.5
Batch: 20; loss: 1.45; acc: 0.52
Batch: 40; loss: 1.01; acc: 0.78
Batch: 60; loss: 1.15; acc: 0.64
Batch: 80; loss: 1.18; acc: 0.62
Batch: 100; loss: 1.18; acc: 0.67
Batch: 120; loss: 1.42; acc: 0.56
Batch: 140; loss: 1.04; acc: 0.73
Val Epoch over. val_loss: 1.3784136058418615; val_accuracy: 0.5572253184713376 

The current subspace-distance is: 8.691957191331312e-06 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 1.4; acc: 0.5
Batch: 20; loss: 1.64; acc: 0.48
Batch: 40; loss: 1.25; acc: 0.62
Batch: 60; loss: 1.19; acc: 0.66
Batch: 80; loss: 1.18; acc: 0.64
Batch: 100; loss: 1.39; acc: 0.55
Batch: 120; loss: 1.6; acc: 0.45
Batch: 140; loss: 1.37; acc: 0.47
Batch: 160; loss: 1.46; acc: 0.42
Batch: 180; loss: 1.48; acc: 0.53
Batch: 200; loss: 1.53; acc: 0.47
Batch: 220; loss: 1.32; acc: 0.58
Batch: 240; loss: 1.75; acc: 0.45
Batch: 260; loss: 1.61; acc: 0.44
Batch: 280; loss: 1.59; acc: 0.42
Batch: 300; loss: 1.41; acc: 0.53
Batch: 320; loss: 1.39; acc: 0.56
Batch: 340; loss: 1.52; acc: 0.56
Batch: 360; loss: 1.66; acc: 0.44
Batch: 380; loss: 1.76; acc: 0.47
Batch: 400; loss: 1.49; acc: 0.52
Batch: 420; loss: 1.38; acc: 0.52
Batch: 440; loss: 1.4; acc: 0.53
Batch: 460; loss: 1.18; acc: 0.58
Batch: 480; loss: 1.2; acc: 0.56
Batch: 500; loss: 1.68; acc: 0.44
Batch: 520; loss: 1.17; acc: 0.64
Batch: 540; loss: 1.52; acc: 0.55
Batch: 560; loss: 1.61; acc: 0.56
Batch: 580; loss: 1.42; acc: 0.58
Batch: 600; loss: 1.55; acc: 0.5
Batch: 620; loss: 1.27; acc: 0.56
Batch: 640; loss: 1.63; acc: 0.39
Batch: 660; loss: 1.33; acc: 0.58
Batch: 680; loss: 1.55; acc: 0.47
Batch: 700; loss: 1.36; acc: 0.55
Batch: 720; loss: 1.33; acc: 0.59
Batch: 740; loss: 1.6; acc: 0.52
Batch: 760; loss: 1.39; acc: 0.58
Batch: 780; loss: 1.33; acc: 0.56
Train Epoch over. train_loss: 1.41; train_accuracy: 0.54 

1.806958061933983e-05
7.0275050347845536e-06
Batch: 0; loss: 1.76; acc: 0.52
Batch: 20; loss: 1.42; acc: 0.52
Batch: 40; loss: 1.0; acc: 0.81
Batch: 60; loss: 1.14; acc: 0.64
Batch: 80; loss: 1.19; acc: 0.66
Batch: 100; loss: 1.17; acc: 0.67
Batch: 120; loss: 1.41; acc: 0.58
Batch: 140; loss: 1.03; acc: 0.75
Val Epoch over. val_loss: 1.377702883094739; val_accuracy: 0.5559315286624203 

The current subspace-distance is: 7.0275050347845536e-06 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 1.19; acc: 0.66
Batch: 20; loss: 1.48; acc: 0.5
Batch: 40; loss: 1.46; acc: 0.52
Batch: 60; loss: 1.58; acc: 0.5
Batch: 80; loss: 1.27; acc: 0.66
Batch: 100; loss: 1.41; acc: 0.62
Batch: 120; loss: 1.59; acc: 0.55
Batch: 140; loss: 1.55; acc: 0.55
Batch: 160; loss: 1.39; acc: 0.55
Batch: 180; loss: 1.43; acc: 0.5
Batch: 200; loss: 1.38; acc: 0.55
Batch: 220; loss: 1.33; acc: 0.55
Batch: 240; loss: 1.55; acc: 0.45
Batch: 260; loss: 1.31; acc: 0.53
Batch: 280; loss: 1.36; acc: 0.58
Batch: 300; loss: 1.39; acc: 0.44
Batch: 320; loss: 1.38; acc: 0.56
Batch: 340; loss: 1.46; acc: 0.48
Batch: 360; loss: 1.28; acc: 0.62
Batch: 380; loss: 1.68; acc: 0.48
Batch: 400; loss: 1.32; acc: 0.55
Batch: 420; loss: 1.29; acc: 0.47
Batch: 440; loss: 1.41; acc: 0.53
Batch: 460; loss: 1.17; acc: 0.62
Batch: 480; loss: 1.29; acc: 0.55
Batch: 500; loss: 1.5; acc: 0.45
Batch: 520; loss: 1.35; acc: 0.52
Batch: 540; loss: 1.46; acc: 0.56
Batch: 560; loss: 1.57; acc: 0.47
Batch: 580; loss: 1.26; acc: 0.58
Batch: 600; loss: 1.5; acc: 0.52
Batch: 620; loss: 1.65; acc: 0.52
Batch: 640; loss: 1.38; acc: 0.58
Batch: 660; loss: 1.5; acc: 0.52
Batch: 680; loss: 1.57; acc: 0.39
Batch: 700; loss: 1.33; acc: 0.59
Batch: 720; loss: 1.06; acc: 0.7
Batch: 740; loss: 1.53; acc: 0.56
Batch: 760; loss: 1.37; acc: 0.53
Batch: 780; loss: 1.41; acc: 0.55
Train Epoch over. train_loss: 1.41; train_accuracy: 0.53 

2.0574532754835673e-05
9.02650299394736e-06
Batch: 0; loss: 1.76; acc: 0.53
Batch: 20; loss: 1.42; acc: 0.53
Batch: 40; loss: 0.99; acc: 0.75
Batch: 60; loss: 1.15; acc: 0.67
Batch: 80; loss: 1.19; acc: 0.62
Batch: 100; loss: 1.18; acc: 0.67
Batch: 120; loss: 1.4; acc: 0.58
Batch: 140; loss: 1.03; acc: 0.73
Val Epoch over. val_loss: 1.3774050998080307; val_accuracy: 0.5529458598726115 

The current subspace-distance is: 9.02650299394736e-06 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 1.37; acc: 0.58
Batch: 20; loss: 1.57; acc: 0.44
Batch: 40; loss: 1.48; acc: 0.52
Batch: 60; loss: 1.62; acc: 0.44
Batch: 80; loss: 1.46; acc: 0.56
Batch: 100; loss: 1.23; acc: 0.61
Batch: 120; loss: 1.32; acc: 0.55
Batch: 140; loss: 1.45; acc: 0.47
Batch: 160; loss: 1.27; acc: 0.58
Batch: 180; loss: 1.64; acc: 0.42
Batch: 200; loss: 1.24; acc: 0.62
Batch: 220; loss: 1.32; acc: 0.62
Batch: 240; loss: 1.43; acc: 0.58
Batch: 260; loss: 1.55; acc: 0.52
Batch: 280; loss: 1.52; acc: 0.52
Batch: 300; loss: 1.37; acc: 0.48
Batch: 320; loss: 1.58; acc: 0.5
Batch: 340; loss: 1.4; acc: 0.5
Batch: 360; loss: 1.33; acc: 0.55
Batch: 380; loss: 1.31; acc: 0.64
Batch: 400; loss: 1.47; acc: 0.56
Batch: 420; loss: 1.46; acc: 0.56
Batch: 440; loss: 1.66; acc: 0.42
Batch: 460; loss: 1.43; acc: 0.53
Batch: 480; loss: 1.17; acc: 0.62
Batch: 500; loss: 1.39; acc: 0.52
Batch: 520; loss: 1.48; acc: 0.53
Batch: 540; loss: 1.64; acc: 0.42
Batch: 560; loss: 1.29; acc: 0.64
Batch: 580; loss: 1.5; acc: 0.53
Batch: 600; loss: 1.46; acc: 0.48
Batch: 620; loss: 1.56; acc: 0.55
Batch: 640; loss: 1.31; acc: 0.55
Batch: 660; loss: 1.35; acc: 0.59
Batch: 680; loss: 1.08; acc: 0.64
Batch: 700; loss: 1.55; acc: 0.5
Batch: 720; loss: 1.22; acc: 0.59
Batch: 740; loss: 1.21; acc: 0.58
Batch: 760; loss: 1.56; acc: 0.47
Batch: 780; loss: 1.29; acc: 0.52
Train Epoch over. train_loss: 1.41; train_accuracy: 0.53 

2.1627132809953764e-05
9.04289754544152e-06
Batch: 0; loss: 1.78; acc: 0.5
Batch: 20; loss: 1.43; acc: 0.5
Batch: 40; loss: 1.0; acc: 0.77
Batch: 60; loss: 1.14; acc: 0.64
Batch: 80; loss: 1.18; acc: 0.66
Batch: 100; loss: 1.17; acc: 0.67
Batch: 120; loss: 1.4; acc: 0.55
Batch: 140; loss: 1.04; acc: 0.77
Val Epoch over. val_loss: 1.3778365250605686; val_accuracy: 0.5564291401273885 

The current subspace-distance is: 9.04289754544152e-06 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 1.33; acc: 0.53
Batch: 20; loss: 1.39; acc: 0.55
Batch: 40; loss: 1.36; acc: 0.55
Batch: 60; loss: 1.22; acc: 0.64
Batch: 80; loss: 1.49; acc: 0.45
Batch: 100; loss: 1.48; acc: 0.48
Batch: 120; loss: 1.38; acc: 0.5
Batch: 140; loss: 1.33; acc: 0.59
Batch: 160; loss: 1.45; acc: 0.53
Batch: 180; loss: 1.28; acc: 0.56
Batch: 200; loss: 1.66; acc: 0.44
Batch: 220; loss: 1.19; acc: 0.56
Batch: 240; loss: 1.49; acc: 0.48
Batch: 260; loss: 1.52; acc: 0.47
Batch: 280; loss: 1.48; acc: 0.5
Batch: 300; loss: 1.64; acc: 0.41
Batch: 320; loss: 1.63; acc: 0.44
Batch: 340; loss: 1.35; acc: 0.55
Batch: 360; loss: 1.43; acc: 0.53
Batch: 380; loss: 1.44; acc: 0.53
Batch: 400; loss: 1.6; acc: 0.44
Batch: 420; loss: 1.37; acc: 0.52
Batch: 440; loss: 1.19; acc: 0.61
Batch: 460; loss: 1.39; acc: 0.61
Batch: 480; loss: 1.28; acc: 0.61
Batch: 500; loss: 1.29; acc: 0.56
Batch: 520; loss: 1.34; acc: 0.5
Batch: 540; loss: 1.48; acc: 0.45
Batch: 560; loss: 1.47; acc: 0.61
Batch: 580; loss: 1.27; acc: 0.66
Batch: 600; loss: 1.29; acc: 0.58
Batch: 620; loss: 1.49; acc: 0.52
Batch: 640; loss: 1.63; acc: 0.47
Batch: 660; loss: 1.15; acc: 0.64
Batch: 680; loss: 1.29; acc: 0.55
Batch: 700; loss: 1.43; acc: 0.55
Batch: 720; loss: 1.55; acc: 0.44
Batch: 740; loss: 1.15; acc: 0.62
Batch: 760; loss: 1.38; acc: 0.53
Batch: 780; loss: 1.21; acc: 0.62
Train Epoch over. train_loss: 1.41; train_accuracy: 0.54 

1.9002209228347056e-05
6.987054803175852e-06
Batch: 0; loss: 1.74; acc: 0.5
Batch: 20; loss: 1.42; acc: 0.52
Batch: 40; loss: 1.0; acc: 0.77
Batch: 60; loss: 1.13; acc: 0.66
Batch: 80; loss: 1.19; acc: 0.66
Batch: 100; loss: 1.17; acc: 0.66
Batch: 120; loss: 1.4; acc: 0.58
Batch: 140; loss: 1.04; acc: 0.72
Val Epoch over. val_loss: 1.378893441075732; val_accuracy: 0.5565286624203821 

The current subspace-distance is: 6.987054803175852e-06 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 1.41; acc: 0.48
Batch: 20; loss: 1.49; acc: 0.53
Batch: 40; loss: 1.36; acc: 0.59
Batch: 60; loss: 1.35; acc: 0.58
Batch: 80; loss: 1.62; acc: 0.41
Batch: 100; loss: 1.47; acc: 0.48
Batch: 120; loss: 1.42; acc: 0.58
Batch: 140; loss: 1.39; acc: 0.58
Batch: 160; loss: 1.67; acc: 0.41
Batch: 180; loss: 1.4; acc: 0.53
Batch: 200; loss: 1.45; acc: 0.48
Batch: 220; loss: 1.69; acc: 0.45
Batch: 240; loss: 1.5; acc: 0.5
Batch: 260; loss: 1.46; acc: 0.52
Batch: 280; loss: 1.3; acc: 0.53
Batch: 300; loss: 1.47; acc: 0.56
Batch: 320; loss: 1.62; acc: 0.47
Batch: 340; loss: 1.36; acc: 0.55
Batch: 360; loss: 1.17; acc: 0.62
Batch: 380; loss: 1.48; acc: 0.52
Batch: 400; loss: 1.42; acc: 0.53
Batch: 420; loss: 1.21; acc: 0.66
Batch: 440; loss: 1.55; acc: 0.41
Batch: 460; loss: 1.44; acc: 0.56
Batch: 480; loss: 1.52; acc: 0.44
Batch: 500; loss: 1.36; acc: 0.58
Batch: 520; loss: 1.34; acc: 0.56
Batch: 540; loss: 1.22; acc: 0.69
Batch: 560; loss: 1.43; acc: 0.53
Batch: 580; loss: 1.34; acc: 0.56
Batch: 600; loss: 1.63; acc: 0.44
Batch: 620; loss: 1.26; acc: 0.56
Batch: 640; loss: 1.5; acc: 0.55
Batch: 660; loss: 1.38; acc: 0.56
Batch: 680; loss: 1.34; acc: 0.52
Batch: 700; loss: 1.58; acc: 0.48
Batch: 720; loss: 1.5; acc: 0.45
Batch: 740; loss: 1.4; acc: 0.53
Batch: 760; loss: 1.48; acc: 0.48
Batch: 780; loss: 1.27; acc: 0.52
Train Epoch over. train_loss: 1.41; train_accuracy: 0.54 

2.18089044210501e-05
1.0464430488354992e-05
Batch: 0; loss: 1.75; acc: 0.52
Batch: 20; loss: 1.41; acc: 0.53
Batch: 40; loss: 0.99; acc: 0.8
Batch: 60; loss: 1.13; acc: 0.67
Batch: 80; loss: 1.19; acc: 0.66
Batch: 100; loss: 1.17; acc: 0.67
Batch: 120; loss: 1.4; acc: 0.58
Batch: 140; loss: 1.02; acc: 0.75
Val Epoch over. val_loss: 1.377705969628255; val_accuracy: 0.555234872611465 

The current subspace-distance is: 1.0464430488354992e-05 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.24; acc: 0.58
Batch: 20; loss: 1.28; acc: 0.62
Batch: 40; loss: 1.65; acc: 0.48
Batch: 60; loss: 1.28; acc: 0.62
Batch: 80; loss: 1.57; acc: 0.53
Batch: 100; loss: 1.42; acc: 0.53
Batch: 120; loss: 1.42; acc: 0.5
Batch: 140; loss: 1.59; acc: 0.5
Batch: 160; loss: 1.64; acc: 0.44
Batch: 180; loss: 1.56; acc: 0.58
Batch: 200; loss: 1.32; acc: 0.55
Batch: 220; loss: 1.24; acc: 0.62
Batch: 240; loss: 1.29; acc: 0.48
Batch: 260; loss: 1.36; acc: 0.58
Batch: 280; loss: 1.38; acc: 0.52
Batch: 300; loss: 1.49; acc: 0.52
Batch: 320; loss: 1.49; acc: 0.53
Batch: 340; loss: 1.34; acc: 0.62
Batch: 360; loss: 1.19; acc: 0.59
Batch: 380; loss: 1.28; acc: 0.56
Batch: 400; loss: 1.16; acc: 0.62
Batch: 420; loss: 1.59; acc: 0.55
Batch: 440; loss: 1.26; acc: 0.55
Batch: 460; loss: 1.52; acc: 0.5
Batch: 480; loss: 1.66; acc: 0.47
Batch: 500; loss: 1.36; acc: 0.52
Batch: 520; loss: 1.59; acc: 0.47
Batch: 540; loss: 1.31; acc: 0.59
Batch: 560; loss: 1.31; acc: 0.53
Batch: 580; loss: 1.46; acc: 0.59
Batch: 600; loss: 1.36; acc: 0.64
Batch: 620; loss: 1.54; acc: 0.42
Batch: 640; loss: 1.62; acc: 0.53
Batch: 660; loss: 1.35; acc: 0.62
Batch: 680; loss: 1.46; acc: 0.5
Batch: 700; loss: 1.4; acc: 0.55
Batch: 720; loss: 1.47; acc: 0.55
Batch: 740; loss: 1.66; acc: 0.48
Batch: 760; loss: 1.38; acc: 0.52
Batch: 780; loss: 1.32; acc: 0.58
Train Epoch over. train_loss: 1.41; train_accuracy: 0.54 

2.139954813173972e-05
8.762346624280326e-06
Batch: 0; loss: 1.76; acc: 0.5
Batch: 20; loss: 1.43; acc: 0.53
Batch: 40; loss: 1.0; acc: 0.8
Batch: 60; loss: 1.14; acc: 0.66
Batch: 80; loss: 1.19; acc: 0.66
Batch: 100; loss: 1.17; acc: 0.66
Batch: 120; loss: 1.4; acc: 0.59
Batch: 140; loss: 1.03; acc: 0.73
Val Epoch over. val_loss: 1.3771988202811807; val_accuracy: 0.5550358280254777 

The current subspace-distance is: 8.762346624280326e-06 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.65; acc: 0.47
Batch: 20; loss: 1.39; acc: 0.53
Batch: 40; loss: 1.28; acc: 0.66
Batch: 60; loss: 1.42; acc: 0.52
Batch: 80; loss: 1.1; acc: 0.66
Batch: 100; loss: 1.13; acc: 0.72
Batch: 120; loss: 1.5; acc: 0.5
Batch: 140; loss: 1.42; acc: 0.55
Batch: 160; loss: 1.48; acc: 0.56
Batch: 180; loss: 1.45; acc: 0.56
Batch: 200; loss: 1.47; acc: 0.58
Batch: 220; loss: 1.19; acc: 0.58
Batch: 240; loss: 1.54; acc: 0.5
Batch: 260; loss: 1.6; acc: 0.48
Batch: 280; loss: 1.37; acc: 0.61
Batch: 300; loss: 1.34; acc: 0.58
Batch: 320; loss: 1.41; acc: 0.48
Batch: 340; loss: 1.41; acc: 0.58
Batch: 360; loss: 1.3; acc: 0.55
Batch: 380; loss: 1.5; acc: 0.55
Batch: 400; loss: 1.25; acc: 0.61
Batch: 420; loss: 1.4; acc: 0.55
Batch: 440; loss: 1.31; acc: 0.58
Batch: 460; loss: 1.58; acc: 0.47
Batch: 480; loss: 1.5; acc: 0.48
Batch: 500; loss: 1.65; acc: 0.42
Batch: 520; loss: 1.35; acc: 0.61
Batch: 540; loss: 1.51; acc: 0.5
Batch: 560; loss: 1.2; acc: 0.62
Batch: 580; loss: 1.4; acc: 0.53
Batch: 600; loss: 1.64; acc: 0.52
Batch: 620; loss: 1.26; acc: 0.61
Batch: 640; loss: 1.32; acc: 0.58
Batch: 660; loss: 1.3; acc: 0.59
Batch: 680; loss: 1.38; acc: 0.52
Batch: 700; loss: 1.25; acc: 0.5
Batch: 720; loss: 1.56; acc: 0.55
Batch: 740; loss: 1.24; acc: 0.58
Batch: 760; loss: 1.17; acc: 0.64
Batch: 780; loss: 1.61; acc: 0.45
Train Epoch over. train_loss: 1.41; train_accuracy: 0.54 

1.8209737390861847e-05
8.393085408897605e-06
Batch: 0; loss: 1.76; acc: 0.52
Batch: 20; loss: 1.43; acc: 0.53
Batch: 40; loss: 1.0; acc: 0.75
Batch: 60; loss: 1.14; acc: 0.66
Batch: 80; loss: 1.19; acc: 0.66
Batch: 100; loss: 1.18; acc: 0.66
Batch: 120; loss: 1.41; acc: 0.59
Batch: 140; loss: 1.03; acc: 0.72
Val Epoch over. val_loss: 1.3770419761633417; val_accuracy: 0.5531449044585988 

The current subspace-distance is: 8.393085408897605e-06 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.47; acc: 0.55
Batch: 20; loss: 1.44; acc: 0.5
Batch: 40; loss: 1.31; acc: 0.64
Batch: 60; loss: 1.47; acc: 0.52
Batch: 80; loss: 1.3; acc: 0.59
Batch: 100; loss: 1.27; acc: 0.59
Batch: 120; loss: 1.52; acc: 0.5
Batch: 140; loss: 1.36; acc: 0.55
Batch: 160; loss: 1.48; acc: 0.52
Batch: 180; loss: 1.52; acc: 0.53
Batch: 200; loss: 1.71; acc: 0.47
Batch: 220; loss: 1.56; acc: 0.5
Batch: 240; loss: 1.35; acc: 0.55
Batch: 260; loss: 1.63; acc: 0.47
Batch: 280; loss: 1.36; acc: 0.59
Batch: 300; loss: 1.21; acc: 0.66
Batch: 320; loss: 1.38; acc: 0.55
Batch: 340; loss: 1.4; acc: 0.55
Batch: 360; loss: 1.57; acc: 0.55
Batch: 380; loss: 1.43; acc: 0.52
Batch: 400; loss: 1.28; acc: 0.55
Batch: 420; loss: 1.54; acc: 0.45
Batch: 440; loss: 1.64; acc: 0.45
Batch: 460; loss: 1.39; acc: 0.58
Batch: 480; loss: 1.36; acc: 0.5
Batch: 500; loss: 1.56; acc: 0.42
Batch: 520; loss: 1.53; acc: 0.48
Batch: 540; loss: 1.45; acc: 0.52
Batch: 560; loss: 1.33; acc: 0.55
Batch: 580; loss: 1.47; acc: 0.47
Batch: 600; loss: 1.39; acc: 0.5
Batch: 620; loss: 1.54; acc: 0.45
Batch: 640; loss: 1.47; acc: 0.5
Batch: 660; loss: 1.27; acc: 0.58
Batch: 680; loss: 1.44; acc: 0.52
Batch: 700; loss: 1.21; acc: 0.62
Batch: 720; loss: 1.29; acc: 0.58
Batch: 740; loss: 1.28; acc: 0.62
Batch: 760; loss: 1.49; acc: 0.47
Batch: 780; loss: 1.32; acc: 0.55
Train Epoch over. train_loss: 1.41; train_accuracy: 0.54 

2.5800509320106357e-05
8.862076356308535e-06
Batch: 0; loss: 1.76; acc: 0.52
Batch: 20; loss: 1.42; acc: 0.53
Batch: 40; loss: 1.0; acc: 0.75
Batch: 60; loss: 1.14; acc: 0.67
Batch: 80; loss: 1.19; acc: 0.66
Batch: 100; loss: 1.18; acc: 0.67
Batch: 120; loss: 1.4; acc: 0.61
Batch: 140; loss: 1.03; acc: 0.77
Val Epoch over. val_loss: 1.3774390140916133; val_accuracy: 0.556827229299363 

The current subspace-distance is: 8.862076356308535e-06 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.32; acc: 0.59
Batch: 20; loss: 1.48; acc: 0.52
Batch: 40; loss: 1.48; acc: 0.47
Batch: 60; loss: 1.63; acc: 0.44
Batch: 80; loss: 1.36; acc: 0.59
Batch: 100; loss: 1.62; acc: 0.42
Batch: 120; loss: 1.5; acc: 0.45
Batch: 140; loss: 1.39; acc: 0.52
Batch: 160; loss: 1.5; acc: 0.52
Batch: 180; loss: 1.38; acc: 0.55
Batch: 200; loss: 1.25; acc: 0.61
Batch: 220; loss: 1.58; acc: 0.48
Batch: 240; loss: 1.36; acc: 0.55
Batch: 260; loss: 1.25; acc: 0.72
Batch: 280; loss: 1.38; acc: 0.58
Batch: 300; loss: 1.5; acc: 0.56
Batch: 320; loss: 1.15; acc: 0.61
Batch: 340; loss: 1.62; acc: 0.5
Batch: 360; loss: 1.33; acc: 0.62
Batch: 380; loss: 1.22; acc: 0.62
Batch: 400; loss: 1.37; acc: 0.56
Batch: 420; loss: 1.58; acc: 0.47
Batch: 440; loss: 1.42; acc: 0.53
Batch: 460; loss: 1.34; acc: 0.56
Batch: 480; loss: 1.41; acc: 0.44
Batch: 500; loss: 1.43; acc: 0.56
Batch: 520; loss: 1.31; acc: 0.53
Batch: 540; loss: 1.33; acc: 0.55
Batch: 560; loss: 1.24; acc: 0.56
Batch: 580; loss: 1.37; acc: 0.55
Batch: 600; loss: 1.5; acc: 0.45
Batch: 620; loss: 1.59; acc: 0.52
Batch: 640; loss: 1.36; acc: 0.59
Batch: 660; loss: 1.36; acc: 0.56
Batch: 680; loss: 1.59; acc: 0.58
Batch: 700; loss: 1.13; acc: 0.61
Batch: 720; loss: 1.25; acc: 0.58
Batch: 740; loss: 1.28; acc: 0.61
Batch: 760; loss: 1.25; acc: 0.58
Batch: 780; loss: 1.52; acc: 0.45
Train Epoch over. train_loss: 1.41; train_accuracy: 0.54 

1.8718197679845616e-05
9.065781341632828e-06
Batch: 0; loss: 1.75; acc: 0.52
Batch: 20; loss: 1.41; acc: 0.56
Batch: 40; loss: 0.99; acc: 0.77
Batch: 60; loss: 1.13; acc: 0.67
Batch: 80; loss: 1.19; acc: 0.66
Batch: 100; loss: 1.17; acc: 0.69
Batch: 120; loss: 1.39; acc: 0.59
Batch: 140; loss: 1.03; acc: 0.72
Val Epoch over. val_loss: 1.3769069773376368; val_accuracy: 0.5561305732484076 

The current subspace-distance is: 9.065781341632828e-06 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.4; acc: 0.45
Batch: 20; loss: 1.59; acc: 0.58
Batch: 40; loss: 1.49; acc: 0.52
Batch: 60; loss: 1.61; acc: 0.56
Batch: 80; loss: 1.39; acc: 0.59
Batch: 100; loss: 1.57; acc: 0.47
Batch: 120; loss: 1.47; acc: 0.53
Batch: 140; loss: 1.28; acc: 0.56
Batch: 160; loss: 1.44; acc: 0.55
Batch: 180; loss: 1.44; acc: 0.53
Batch: 200; loss: 1.58; acc: 0.53
Batch: 220; loss: 1.03; acc: 0.69
Batch: 240; loss: 1.46; acc: 0.53
Batch: 260; loss: 1.22; acc: 0.59
Batch: 280; loss: 1.38; acc: 0.53
Batch: 300; loss: 1.25; acc: 0.62
Batch: 320; loss: 1.41; acc: 0.53
Batch: 340; loss: 1.34; acc: 0.56
Batch: 360; loss: 1.39; acc: 0.55
Batch: 380; loss: 1.27; acc: 0.59
Batch: 400; loss: 1.47; acc: 0.48
Batch: 420; loss: 1.5; acc: 0.5
Batch: 440; loss: 1.45; acc: 0.59
Batch: 460; loss: 1.65; acc: 0.45
Batch: 480; loss: 1.22; acc: 0.56
Batch: 500; loss: 1.41; acc: 0.47
Batch: 520; loss: 1.29; acc: 0.58
Batch: 540; loss: 1.48; acc: 0.45
Batch: 560; loss: 1.32; acc: 0.56
Batch: 580; loss: 1.26; acc: 0.58
Batch: 600; loss: 1.39; acc: 0.56
Batch: 620; loss: 1.39; acc: 0.53
Batch: 640; loss: 1.52; acc: 0.5
Batch: 660; loss: 1.4; acc: 0.59
Batch: 680; loss: 1.31; acc: 0.48
Batch: 700; loss: 1.18; acc: 0.61
Batch: 720; loss: 1.5; acc: 0.53
Batch: 740; loss: 1.29; acc: 0.62
Batch: 760; loss: 1.57; acc: 0.42
Batch: 780; loss: 1.41; acc: 0.5
Train Epoch over. train_loss: 1.41; train_accuracy: 0.53 

1.7521741028758697e-05
8.31915076560108e-06
Batch: 0; loss: 1.75; acc: 0.52
Batch: 20; loss: 1.41; acc: 0.53
Batch: 40; loss: 0.99; acc: 0.77
Batch: 60; loss: 1.13; acc: 0.66
Batch: 80; loss: 1.19; acc: 0.67
Batch: 100; loss: 1.17; acc: 0.64
Batch: 120; loss: 1.39; acc: 0.59
Batch: 140; loss: 1.03; acc: 0.73
Val Epoch over. val_loss: 1.3772965589906; val_accuracy: 0.5569267515923567 

The current subspace-distance is: 8.31915076560108e-06 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.35; acc: 0.5
Batch: 20; loss: 1.5; acc: 0.56
Batch: 40; loss: 1.56; acc: 0.44
Batch: 60; loss: 1.33; acc: 0.59
Batch: 80; loss: 1.46; acc: 0.5
Batch: 100; loss: 1.52; acc: 0.55
Batch: 120; loss: 1.41; acc: 0.5
Batch: 140; loss: 1.4; acc: 0.53
Batch: 160; loss: 1.44; acc: 0.48
Batch: 180; loss: 1.17; acc: 0.67
Batch: 200; loss: 1.49; acc: 0.41
Batch: 220; loss: 1.63; acc: 0.44
Batch: 240; loss: 1.42; acc: 0.5
Batch: 260; loss: 1.51; acc: 0.47
Batch: 280; loss: 1.29; acc: 0.64
Batch: 300; loss: 1.43; acc: 0.48
Batch: 320; loss: 1.41; acc: 0.48
Batch: 340; loss: 1.28; acc: 0.61
Batch: 360; loss: 1.5; acc: 0.48
Batch: 380; loss: 1.21; acc: 0.62
Batch: 400; loss: 1.47; acc: 0.48
Batch: 420; loss: 1.42; acc: 0.59
Batch: 440; loss: 1.43; acc: 0.56
Batch: 460; loss: 1.48; acc: 0.55
Batch: 480; loss: 1.39; acc: 0.45
Batch: 500; loss: 1.47; acc: 0.48
Batch: 520; loss: 1.17; acc: 0.64
Batch: 540; loss: 1.59; acc: 0.53
Batch: 560; loss: 1.23; acc: 0.55
Batch: 580; loss: 1.26; acc: 0.61
Batch: 600; loss: 1.61; acc: 0.47
Batch: 620; loss: 1.74; acc: 0.39
Batch: 640; loss: 1.42; acc: 0.58
Batch: 660; loss: 1.44; acc: 0.53
Batch: 680; loss: 1.38; acc: 0.44
Batch: 700; loss: 1.45; acc: 0.59
Batch: 720; loss: 1.52; acc: 0.38
Batch: 740; loss: 1.36; acc: 0.59
Batch: 760; loss: 1.31; acc: 0.66
Batch: 780; loss: 1.34; acc: 0.56
Train Epoch over. train_loss: 1.41; train_accuracy: 0.53 

1.893608168757055e-05
6.68774964651675e-06
Batch: 0; loss: 1.74; acc: 0.52
Batch: 20; loss: 1.41; acc: 0.52
Batch: 40; loss: 0.99; acc: 0.73
Batch: 60; loss: 1.13; acc: 0.66
Batch: 80; loss: 1.2; acc: 0.64
Batch: 100; loss: 1.17; acc: 0.67
Batch: 120; loss: 1.39; acc: 0.59
Batch: 140; loss: 1.03; acc: 0.72
Val Epoch over. val_loss: 1.3781405721500422; val_accuracy: 0.5531449044585988 

The current subspace-distance is: 6.68774964651675e-06 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.74; acc: 0.36
Batch: 20; loss: 1.44; acc: 0.55
Batch: 40; loss: 1.47; acc: 0.59
Batch: 60; loss: 1.55; acc: 0.47
Batch: 80; loss: 1.54; acc: 0.58
Batch: 100; loss: 1.48; acc: 0.56
Batch: 120; loss: 1.44; acc: 0.58
Batch: 140; loss: 1.35; acc: 0.52
Batch: 160; loss: 1.49; acc: 0.44
Batch: 180; loss: 1.44; acc: 0.5
Batch: 200; loss: 1.44; acc: 0.5
Batch: 220; loss: 1.58; acc: 0.39
Batch: 240; loss: 1.22; acc: 0.55
Batch: 260; loss: 1.35; acc: 0.58
Batch: 280; loss: 1.53; acc: 0.5
Batch: 300; loss: 1.68; acc: 0.41
Batch: 320; loss: 1.37; acc: 0.56
Batch: 340; loss: 1.49; acc: 0.48
Batch: 360; loss: 1.07; acc: 0.7
Batch: 380; loss: 1.47; acc: 0.58
Batch: 400; loss: 1.34; acc: 0.56
Batch: 420; loss: 1.46; acc: 0.58
Batch: 440; loss: 1.32; acc: 0.58
Batch: 460; loss: 1.42; acc: 0.53
Batch: 480; loss: 1.16; acc: 0.64
Batch: 500; loss: 1.35; acc: 0.56
Batch: 520; loss: 1.31; acc: 0.61
Batch: 540; loss: 1.23; acc: 0.52
Batch: 560; loss: 1.27; acc: 0.66
Batch: 580; loss: 1.41; acc: 0.53
Batch: 600; loss: 1.26; acc: 0.58
Batch: 620; loss: 1.44; acc: 0.56
Batch: 640; loss: 1.52; acc: 0.53
Batch: 660; loss: 1.38; acc: 0.53
Batch: 680; loss: 1.62; acc: 0.5
Batch: 700; loss: 1.34; acc: 0.53
Batch: 720; loss: 1.19; acc: 0.66
Batch: 740; loss: 1.53; acc: 0.53
Batch: 760; loss: 1.45; acc: 0.58
Batch: 780; loss: 1.25; acc: 0.58
Train Epoch over. train_loss: 1.41; train_accuracy: 0.54 

2.0724610294564627e-05
9.017880984174553e-06
Batch: 0; loss: 1.75; acc: 0.52
Batch: 20; loss: 1.42; acc: 0.53
Batch: 40; loss: 0.99; acc: 0.78
Batch: 60; loss: 1.14; acc: 0.66
Batch: 80; loss: 1.19; acc: 0.64
Batch: 100; loss: 1.17; acc: 0.67
Batch: 120; loss: 1.4; acc: 0.58
Batch: 140; loss: 1.03; acc: 0.73
Val Epoch over. val_loss: 1.3769626492147993; val_accuracy: 0.5539410828025477 

The current subspace-distance is: 9.017880984174553e-06 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.48; acc: 0.48
Batch: 20; loss: 1.55; acc: 0.44
Batch: 40; loss: 1.23; acc: 0.58
Batch: 60; loss: 1.47; acc: 0.52
Batch: 80; loss: 1.35; acc: 0.52
Batch: 100; loss: 1.36; acc: 0.53
Batch: 120; loss: 1.17; acc: 0.62
Batch: 140; loss: 1.22; acc: 0.58
Batch: 160; loss: 1.48; acc: 0.53
Batch: 180; loss: 1.76; acc: 0.45
Batch: 200; loss: 1.46; acc: 0.53
Batch: 220; loss: 1.4; acc: 0.48
Batch: 240; loss: 1.39; acc: 0.53
Batch: 260; loss: 1.4; acc: 0.53
Batch: 280; loss: 1.34; acc: 0.55
Batch: 300; loss: 1.34; acc: 0.55
Batch: 320; loss: 1.53; acc: 0.52
Batch: 340; loss: 1.41; acc: 0.48
Batch: 360; loss: 1.45; acc: 0.52
Batch: 380; loss: 1.27; acc: 0.59
Batch: 400; loss: 1.38; acc: 0.59
Batch: 420; loss: 1.44; acc: 0.45
Batch: 440; loss: 1.52; acc: 0.45
Batch: 460; loss: 1.19; acc: 0.64
Batch: 480; loss: 1.31; acc: 0.59
Batch: 500; loss: 1.41; acc: 0.48
Batch: 520; loss: 1.45; acc: 0.55
Batch: 540; loss: 1.31; acc: 0.66
Batch: 560; loss: 1.34; acc: 0.55
Batch: 580; loss: 1.31; acc: 0.52
Batch: 600; loss: 1.65; acc: 0.41
Batch: 620; loss: 1.11; acc: 0.69
Batch: 640; loss: 1.34; acc: 0.55
Batch: 660; loss: 1.5; acc: 0.5
Batch: 680; loss: 1.33; acc: 0.52
Batch: 700; loss: 1.53; acc: 0.47
Batch: 720; loss: 1.55; acc: 0.44
Batch: 740; loss: 1.81; acc: 0.45
Batch: 760; loss: 1.28; acc: 0.67
Batch: 780; loss: 1.5; acc: 0.56
Train Epoch over. train_loss: 1.41; train_accuracy: 0.53 

2.0834429960814305e-05
7.702850780333392e-06
Batch: 0; loss: 1.75; acc: 0.52
Batch: 20; loss: 1.43; acc: 0.52
Batch: 40; loss: 0.99; acc: 0.78
Batch: 60; loss: 1.13; acc: 0.66
Batch: 80; loss: 1.19; acc: 0.66
Batch: 100; loss: 1.17; acc: 0.66
Batch: 120; loss: 1.4; acc: 0.59
Batch: 140; loss: 1.03; acc: 0.73
Val Epoch over. val_loss: 1.377400468489167; val_accuracy: 0.5538415605095541 

The current subspace-distance is: 7.702850780333392e-06 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.61; acc: 0.53
Batch: 20; loss: 1.38; acc: 0.58
Batch: 40; loss: 1.23; acc: 0.59
Batch: 60; loss: 1.4; acc: 0.59
Batch: 80; loss: 1.46; acc: 0.5
Batch: 100; loss: 1.22; acc: 0.61
Batch: 120; loss: 1.44; acc: 0.48
Batch: 140; loss: 1.24; acc: 0.62
Batch: 160; loss: 1.65; acc: 0.48
Batch: 180; loss: 1.46; acc: 0.5
Batch: 200; loss: 1.25; acc: 0.58
Batch: 220; loss: 1.41; acc: 0.53
Batch: 240; loss: 1.3; acc: 0.56
Batch: 260; loss: 1.55; acc: 0.48
Batch: 280; loss: 1.54; acc: 0.53
Batch: 300; loss: 1.25; acc: 0.56
Batch: 320; loss: 1.22; acc: 0.55
Batch: 340; loss: 1.31; acc: 0.58
Batch: 360; loss: 1.44; acc: 0.53
Batch: 380; loss: 1.55; acc: 0.44
Batch: 400; loss: 1.41; acc: 0.58
Batch: 420; loss: 1.59; acc: 0.52
Batch: 440; loss: 1.44; acc: 0.5
Batch: 460; loss: 1.45; acc: 0.5
Batch: 480; loss: 1.61; acc: 0.5
Batch: 500; loss: 1.15; acc: 0.64
Batch: 520; loss: 1.48; acc: 0.48
Batch: 540; loss: 1.2; acc: 0.59
Batch: 560; loss: 1.75; acc: 0.39
Batch: 580; loss: 1.47; acc: 0.48
Batch: 600; loss: 1.41; acc: 0.48
Batch: 620; loss: 1.37; acc: 0.5
Batch: 640; loss: 1.45; acc: 0.48
Batch: 660; loss: 1.22; acc: 0.59
Batch: 680; loss: 1.39; acc: 0.5
Batch: 700; loss: 1.45; acc: 0.5
Batch: 720; loss: 1.46; acc: 0.48
Batch: 740; loss: 1.48; acc: 0.5
Batch: 760; loss: 1.54; acc: 0.53
Batch: 780; loss: 1.64; acc: 0.42
Train Epoch over. train_loss: 1.41; train_accuracy: 0.53 

1.91570525203133e-05
6.563682745763799e-06
Batch: 0; loss: 1.73; acc: 0.52
Batch: 20; loss: 1.41; acc: 0.56
Batch: 40; loss: 0.99; acc: 0.73
Batch: 60; loss: 1.13; acc: 0.67
Batch: 80; loss: 1.2; acc: 0.64
Batch: 100; loss: 1.17; acc: 0.67
Batch: 120; loss: 1.39; acc: 0.59
Batch: 140; loss: 1.04; acc: 0.72
Val Epoch over. val_loss: 1.3781607785042684; val_accuracy: 0.5563296178343949 

The current subspace-distance is: 6.563682745763799e-06 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.4; acc: 0.55
Batch: 20; loss: 1.6; acc: 0.44
Batch: 40; loss: 1.26; acc: 0.64
Batch: 60; loss: 1.64; acc: 0.44
Batch: 80; loss: 1.22; acc: 0.7
Batch: 100; loss: 1.56; acc: 0.47
Batch: 120; loss: 1.21; acc: 0.62
Batch: 140; loss: 1.14; acc: 0.61
Batch: 160; loss: 1.65; acc: 0.41
Batch: 180; loss: 1.41; acc: 0.56
Batch: 200; loss: 1.22; acc: 0.67
Batch: 220; loss: 1.5; acc: 0.5
Batch: 240; loss: 1.31; acc: 0.53
Batch: 260; loss: 1.4; acc: 0.52
Batch: 280; loss: 1.33; acc: 0.55
Batch: 300; loss: 1.51; acc: 0.53
Batch: 320; loss: 1.34; acc: 0.56
Batch: 340; loss: 1.51; acc: 0.5
Batch: 360; loss: 1.39; acc: 0.52
Batch: 380; loss: 1.47; acc: 0.47
Batch: 400; loss: 1.49; acc: 0.45
Batch: 420; loss: 1.5; acc: 0.56
Batch: 440; loss: 1.65; acc: 0.39
Batch: 460; loss: 1.68; acc: 0.47
Batch: 480; loss: 1.31; acc: 0.61
Batch: 500; loss: 1.22; acc: 0.62
Batch: 520; loss: 1.3; acc: 0.58
Batch: 540; loss: 1.42; acc: 0.56
Batch: 560; loss: 1.4; acc: 0.58
Batch: 580; loss: 1.37; acc: 0.55
Batch: 600; loss: 1.46; acc: 0.52
Batch: 620; loss: 1.42; acc: 0.59
Batch: 640; loss: 1.3; acc: 0.53
Batch: 660; loss: 1.3; acc: 0.61
Batch: 680; loss: 1.47; acc: 0.56
Batch: 700; loss: 1.57; acc: 0.47
Batch: 720; loss: 1.33; acc: 0.5
Batch: 740; loss: 1.31; acc: 0.5
Batch: 760; loss: 1.21; acc: 0.56
Batch: 780; loss: 1.35; acc: 0.53
Train Epoch over. train_loss: 1.41; train_accuracy: 0.54 

2.0342315110610798e-05
9.295049494539853e-06
Batch: 0; loss: 1.74; acc: 0.52
Batch: 20; loss: 1.41; acc: 0.55
Batch: 40; loss: 0.99; acc: 0.75
Batch: 60; loss: 1.13; acc: 0.67
Batch: 80; loss: 1.2; acc: 0.64
Batch: 100; loss: 1.17; acc: 0.67
Batch: 120; loss: 1.39; acc: 0.59
Batch: 140; loss: 1.04; acc: 0.73
Val Epoch over. val_loss: 1.3772496759511863; val_accuracy: 0.5554339171974523 

The current subspace-distance is: 9.295049494539853e-06 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.28; acc: 0.59
Batch: 20; loss: 1.24; acc: 0.59
Batch: 40; loss: 1.45; acc: 0.5
Batch: 60; loss: 1.42; acc: 0.56
Batch: 80; loss: 1.52; acc: 0.47
Batch: 100; loss: 1.29; acc: 0.59
Batch: 120; loss: 1.47; acc: 0.56
Batch: 140; loss: 1.46; acc: 0.55
Batch: 160; loss: 1.38; acc: 0.58
Batch: 180; loss: 1.31; acc: 0.53
Batch: 200; loss: 1.48; acc: 0.53
Batch: 220; loss: 1.44; acc: 0.53
Batch: 240; loss: 1.25; acc: 0.58
Batch: 260; loss: 1.37; acc: 0.56
Batch: 280; loss: 1.53; acc: 0.48
Batch: 300; loss: 1.46; acc: 0.45
Batch: 320; loss: 1.54; acc: 0.5
Batch: 340; loss: 1.33; acc: 0.52
Batch: 360; loss: 1.39; acc: 0.53
Batch: 380; loss: 1.41; acc: 0.5
Batch: 400; loss: 1.4; acc: 0.59
Batch: 420; loss: 1.24; acc: 0.61
Batch: 440; loss: 1.31; acc: 0.53
Batch: 460; loss: 1.31; acc: 0.52
Batch: 480; loss: 1.26; acc: 0.59
Batch: 500; loss: 1.49; acc: 0.52
Batch: 520; loss: 1.28; acc: 0.61
Batch: 540; loss: 1.26; acc: 0.61
Batch: 560; loss: 1.47; acc: 0.48
Batch: 580; loss: 1.33; acc: 0.59
Batch: 600; loss: 1.55; acc: 0.5
Batch: 620; loss: 1.28; acc: 0.64
Batch: 640; loss: 1.59; acc: 0.56
Batch: 660; loss: 1.22; acc: 0.66
Batch: 680; loss: 1.39; acc: 0.56
Batch: 700; loss: 1.56; acc: 0.53
Batch: 720; loss: 1.43; acc: 0.52
Batch: 740; loss: 1.57; acc: 0.53
Batch: 760; loss: 1.7; acc: 0.45
Batch: 780; loss: 1.35; acc: 0.58
Train Epoch over. train_loss: 1.41; train_accuracy: 0.53 

2.0401306755957194e-05
8.569598321628291e-06
Batch: 0; loss: 1.75; acc: 0.52
Batch: 20; loss: 1.42; acc: 0.55
Batch: 40; loss: 1.0; acc: 0.78
Batch: 60; loss: 1.13; acc: 0.66
Batch: 80; loss: 1.19; acc: 0.64
Batch: 100; loss: 1.17; acc: 0.69
Batch: 120; loss: 1.4; acc: 0.59
Batch: 140; loss: 1.03; acc: 0.72
Val Epoch over. val_loss: 1.3769309630819186; val_accuracy: 0.5544386942675159 

The current subspace-distance is: 8.569598321628291e-06 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.58; acc: 0.52
Batch: 20; loss: 1.45; acc: 0.55
Batch: 40; loss: 1.37; acc: 0.58
Batch: 60; loss: 1.38; acc: 0.5
Batch: 80; loss: 1.56; acc: 0.48
Batch: 100; loss: 1.56; acc: 0.45
Batch: 120; loss: 1.39; acc: 0.53
Batch: 140; loss: 1.53; acc: 0.45
Batch: 160; loss: 1.15; acc: 0.61
Batch: 180; loss: 1.46; acc: 0.48
Batch: 200; loss: 1.5; acc: 0.44
Batch: 220; loss: 1.57; acc: 0.52
Batch: 240; loss: 1.31; acc: 0.53
Batch: 260; loss: 1.29; acc: 0.58
Batch: 280; loss: 1.38; acc: 0.55
Batch: 300; loss: 1.64; acc: 0.39
Batch: 320; loss: 1.19; acc: 0.61
Batch: 340; loss: 1.66; acc: 0.44
Batch: 360; loss: 1.49; acc: 0.53
Batch: 380; loss: 1.22; acc: 0.62
Batch: 400; loss: 1.44; acc: 0.52
Batch: 420; loss: 1.15; acc: 0.64
Batch: 440; loss: 1.41; acc: 0.5
Batch: 460; loss: 1.44; acc: 0.52
Batch: 480; loss: 1.33; acc: 0.59
Batch: 500; loss: 1.35; acc: 0.55
Batch: 520; loss: 1.33; acc: 0.58
Batch: 540; loss: 1.21; acc: 0.56
Batch: 560; loss: 1.35; acc: 0.55
Batch: 580; loss: 1.29; acc: 0.61
Batch: 600; loss: 1.42; acc: 0.53
Batch: 620; loss: 1.48; acc: 0.47
Batch: 640; loss: 1.26; acc: 0.56
Batch: 660; loss: 1.41; acc: 0.45
Batch: 680; loss: 1.51; acc: 0.53
Batch: 700; loss: 1.49; acc: 0.55
Batch: 720; loss: 1.48; acc: 0.53
Batch: 740; loss: 1.52; acc: 0.53
Batch: 760; loss: 1.47; acc: 0.48
Batch: 780; loss: 1.42; acc: 0.53
Train Epoch over. train_loss: 1.41; train_accuracy: 0.53 

2.1914311219006777e-05
7.532512427133042e-06
Batch: 0; loss: 1.75; acc: 0.52
Batch: 20; loss: 1.42; acc: 0.55
Batch: 40; loss: 0.99; acc: 0.75
Batch: 60; loss: 1.13; acc: 0.67
Batch: 80; loss: 1.2; acc: 0.66
Batch: 100; loss: 1.17; acc: 0.67
Batch: 120; loss: 1.39; acc: 0.59
Batch: 140; loss: 1.03; acc: 0.72
Val Epoch over. val_loss: 1.3768883119722841; val_accuracy: 0.5540406050955414 

The current subspace-distance is: 7.532512427133042e-06 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.54; acc: 0.48
Batch: 20; loss: 1.31; acc: 0.62
Batch: 40; loss: 1.44; acc: 0.55
Batch: 60; loss: 1.11; acc: 0.64
Batch: 80; loss: 1.23; acc: 0.59
Batch: 100; loss: 1.31; acc: 0.59
Batch: 120; loss: 1.4; acc: 0.58
Batch: 140; loss: 1.27; acc: 0.58
Batch: 160; loss: 1.27; acc: 0.59
Batch: 180; loss: 1.26; acc: 0.58
Batch: 200; loss: 1.5; acc: 0.45
Batch: 220; loss: 1.27; acc: 0.5
Batch: 240; loss: 1.5; acc: 0.47
Batch: 260; loss: 1.33; acc: 0.59
Batch: 280; loss: 1.21; acc: 0.56
Batch: 300; loss: 1.52; acc: 0.58
Batch: 320; loss: 1.33; acc: 0.56
Batch: 340; loss: 1.56; acc: 0.53
Batch: 360; loss: 1.31; acc: 0.56
Batch: 380; loss: 1.41; acc: 0.55
Batch: 400; loss: 1.47; acc: 0.5
Batch: 420; loss: 1.52; acc: 0.45
Batch: 440; loss: 1.38; acc: 0.52
Batch: 460; loss: 1.55; acc: 0.47
Batch: 480; loss: 1.24; acc: 0.58
Batch: 500; loss: 1.55; acc: 0.55
Batch: 520; loss: 1.39; acc: 0.55
Batch: 540; loss: 1.23; acc: 0.58
Batch: 560; loss: 1.42; acc: 0.59
Batch: 580; loss: 1.26; acc: 0.64
Batch: 600; loss: 1.3; acc: 0.62
Batch: 620; loss: 1.34; acc: 0.62
Batch: 640; loss: 1.32; acc: 0.58
Batch: 660; loss: 1.61; acc: 0.45
Batch: 680; loss: 1.21; acc: 0.61
Batch: 700; loss: 1.24; acc: 0.66
Batch: 720; loss: 1.67; acc: 0.45
Batch: 740; loss: 1.47; acc: 0.47
Batch: 760; loss: 1.51; acc: 0.44
Batch: 780; loss: 1.63; acc: 0.42
Train Epoch over. train_loss: 1.41; train_accuracy: 0.54 

1.932846862473525e-05
7.049754003674025e-06
Batch: 0; loss: 1.75; acc: 0.5
Batch: 20; loss: 1.41; acc: 0.55
Batch: 40; loss: 0.99; acc: 0.78
Batch: 60; loss: 1.13; acc: 0.67
Batch: 80; loss: 1.19; acc: 0.67
Batch: 100; loss: 1.17; acc: 0.69
Batch: 120; loss: 1.39; acc: 0.58
Batch: 140; loss: 1.03; acc: 0.72
Val Epoch over. val_loss: 1.3766881227493286; val_accuracy: 0.5555334394904459 

The current subspace-distance is: 7.049754003674025e-06 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.23; acc: 0.58
Batch: 20; loss: 1.27; acc: 0.59
Batch: 40; loss: 1.32; acc: 0.59
Batch: 60; loss: 1.35; acc: 0.52
Batch: 80; loss: 1.44; acc: 0.41
Batch: 100; loss: 1.54; acc: 0.45
Batch: 120; loss: 1.42; acc: 0.53
Batch: 140; loss: 1.3; acc: 0.58
Batch: 160; loss: 1.79; acc: 0.39
Batch: 180; loss: 1.48; acc: 0.58
Batch: 200; loss: 1.35; acc: 0.58
Batch: 220; loss: 1.48; acc: 0.55
Batch: 240; loss: 1.27; acc: 0.53
Batch: 260; loss: 1.51; acc: 0.56
Batch: 280; loss: 1.51; acc: 0.45
Batch: 300; loss: 1.26; acc: 0.58
Batch: 320; loss: 1.41; acc: 0.59
Batch: 340; loss: 1.52; acc: 0.42
Batch: 360; loss: 1.48; acc: 0.48
Batch: 380; loss: 1.38; acc: 0.61
Batch: 400; loss: 1.79; acc: 0.38
Batch: 420; loss: 1.42; acc: 0.53
Batch: 440; loss: 1.5; acc: 0.53
Batch: 460; loss: 1.63; acc: 0.5
Batch: 480; loss: 1.18; acc: 0.61
Batch: 500; loss: 1.38; acc: 0.44
Batch: 520; loss: 1.24; acc: 0.58
Batch: 540; loss: 1.37; acc: 0.55
Batch: 560; loss: 1.45; acc: 0.45
Batch: 580; loss: 1.38; acc: 0.55
Batch: 600; loss: 1.5; acc: 0.53
Batch: 620; loss: 1.23; acc: 0.55
Batch: 640; loss: 1.27; acc: 0.61
Batch: 660; loss: 1.43; acc: 0.53
Batch: 680; loss: 1.81; acc: 0.48
Batch: 700; loss: 1.46; acc: 0.56
Batch: 720; loss: 1.33; acc: 0.52
Batch: 740; loss: 1.56; acc: 0.48
Batch: 760; loss: 1.52; acc: 0.5
Batch: 780; loss: 1.17; acc: 0.61
Train Epoch over. train_loss: 1.41; train_accuracy: 0.54 

2.0241381207597442e-05
9.550361937726848e-06
Batch: 0; loss: 1.75; acc: 0.52
Batch: 20; loss: 1.42; acc: 0.56
Batch: 40; loss: 0.99; acc: 0.78
Batch: 60; loss: 1.13; acc: 0.67
Batch: 80; loss: 1.19; acc: 0.66
Batch: 100; loss: 1.17; acc: 0.67
Batch: 120; loss: 1.4; acc: 0.59
Batch: 140; loss: 1.03; acc: 0.72
Val Epoch over. val_loss: 1.3770293866752819; val_accuracy: 0.5550358280254777 

The current subspace-distance is: 9.550361937726848e-06 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.5; acc: 0.47
Batch: 20; loss: 1.29; acc: 0.56
Batch: 40; loss: 1.33; acc: 0.58
Batch: 60; loss: 1.58; acc: 0.42
Batch: 80; loss: 1.49; acc: 0.52
Batch: 100; loss: 1.22; acc: 0.67
Batch: 120; loss: 1.53; acc: 0.52
Batch: 140; loss: 1.39; acc: 0.5
Batch: 160; loss: 1.2; acc: 0.64
Batch: 180; loss: 1.22; acc: 0.62
Batch: 200; loss: 1.3; acc: 0.56
Batch: 220; loss: 1.49; acc: 0.55
Batch: 240; loss: 1.41; acc: 0.59
Batch: 260; loss: 1.46; acc: 0.52
Batch: 280; loss: 1.46; acc: 0.52
Batch: 300; loss: 1.35; acc: 0.61
Batch: 320; loss: 1.46; acc: 0.56
Batch: 340; loss: 1.35; acc: 0.58
Batch: 360; loss: 1.71; acc: 0.42
Batch: 380; loss: 1.32; acc: 0.52
Batch: 400; loss: 1.26; acc: 0.61
Batch: 420; loss: 1.58; acc: 0.48
Batch: 440; loss: 1.19; acc: 0.67
Batch: 460; loss: 1.51; acc: 0.48
Batch: 480; loss: 1.2; acc: 0.61
Batch: 500; loss: 1.31; acc: 0.61
Batch: 520; loss: 1.36; acc: 0.61
Batch: 540; loss: 1.34; acc: 0.53
Batch: 560; loss: 1.49; acc: 0.55
Batch: 580; loss: 1.47; acc: 0.47
Batch: 600; loss: 1.63; acc: 0.42
Batch: 620; loss: 1.56; acc: 0.47
Batch: 640; loss: 1.43; acc: 0.47
Batch: 660; loss: 1.49; acc: 0.59
Batch: 680; loss: 1.33; acc: 0.52
Batch: 700; loss: 1.66; acc: 0.48
Batch: 720; loss: 1.56; acc: 0.48
Batch: 740; loss: 1.34; acc: 0.55
Batch: 760; loss: 1.28; acc: 0.62
Batch: 780; loss: 1.39; acc: 0.55
Train Epoch over. train_loss: 1.41; train_accuracy: 0.54 

1.930841608555056e-05
7.713609193160664e-06
Batch: 0; loss: 1.76; acc: 0.52
Batch: 20; loss: 1.42; acc: 0.53
Batch: 40; loss: 1.0; acc: 0.78
Batch: 60; loss: 1.14; acc: 0.66
Batch: 80; loss: 1.19; acc: 0.67
Batch: 100; loss: 1.17; acc: 0.7
Batch: 120; loss: 1.4; acc: 0.59
Batch: 140; loss: 1.03; acc: 0.73
Val Epoch over. val_loss: 1.3773321843450996; val_accuracy: 0.555234872611465 

The current subspace-distance is: 7.713609193160664e-06 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.19; acc: 0.62
Batch: 20; loss: 1.59; acc: 0.52
Batch: 40; loss: 1.34; acc: 0.59
Batch: 60; loss: 1.3; acc: 0.61
Batch: 80; loss: 1.19; acc: 0.64
Batch: 100; loss: 1.21; acc: 0.58
Batch: 120; loss: 1.49; acc: 0.42
Batch: 140; loss: 1.4; acc: 0.66
Batch: 160; loss: 1.28; acc: 0.62
Batch: 180; loss: 1.39; acc: 0.58
Batch: 200; loss: 1.37; acc: 0.58
Batch: 220; loss: 1.26; acc: 0.58
Batch: 240; loss: 1.35; acc: 0.59
Batch: 260; loss: 1.66; acc: 0.39
Batch: 280; loss: 1.76; acc: 0.41
Batch: 300; loss: 1.52; acc: 0.52
Batch: 320; loss: 1.37; acc: 0.58
Batch: 340; loss: 1.43; acc: 0.47
Batch: 360; loss: 1.4; acc: 0.52
Batch: 380; loss: 1.42; acc: 0.47
Batch: 400; loss: 1.35; acc: 0.56
Batch: 420; loss: 1.48; acc: 0.5
Batch: 440; loss: 1.4; acc: 0.58
Batch: 460; loss: 1.54; acc: 0.47
Batch: 480; loss: 1.48; acc: 0.53
Batch: 500; loss: 1.22; acc: 0.55
Batch: 520; loss: 1.24; acc: 0.64
Batch: 540; loss: 1.54; acc: 0.56
Batch: 560; loss: 1.47; acc: 0.48
Batch: 580; loss: 1.4; acc: 0.47
Batch: 600; loss: 1.32; acc: 0.55
Batch: 620; loss: 1.26; acc: 0.62
Batch: 640; loss: 1.29; acc: 0.58
Batch: 660; loss: 1.5; acc: 0.52
Batch: 680; loss: 1.9; acc: 0.41
Batch: 700; loss: 1.29; acc: 0.58
Batch: 720; loss: 1.24; acc: 0.62
Batch: 740; loss: 1.36; acc: 0.5
Batch: 760; loss: 1.48; acc: 0.52
Batch: 780; loss: 1.37; acc: 0.52
Train Epoch over. train_loss: 1.41; train_accuracy: 0.53 

1.9363533283467405e-05
7.691313840041403e-06
Batch: 0; loss: 1.75; acc: 0.52
Batch: 20; loss: 1.42; acc: 0.55
Batch: 40; loss: 0.99; acc: 0.73
Batch: 60; loss: 1.13; acc: 0.67
Batch: 80; loss: 1.2; acc: 0.66
Batch: 100; loss: 1.17; acc: 0.66
Batch: 120; loss: 1.39; acc: 0.59
Batch: 140; loss: 1.03; acc: 0.72
Val Epoch over. val_loss: 1.3770444324821423; val_accuracy: 0.5566281847133758 

The current subspace-distance is: 7.691313840041403e-06 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.4; acc: 0.55
Batch: 20; loss: 1.53; acc: 0.45
Batch: 40; loss: 1.58; acc: 0.45
Batch: 60; loss: 1.48; acc: 0.53
Batch: 80; loss: 1.44; acc: 0.5
Batch: 100; loss: 1.43; acc: 0.5
Batch: 120; loss: 1.26; acc: 0.59
Batch: 140; loss: 1.22; acc: 0.58
Batch: 160; loss: 1.3; acc: 0.52
Batch: 180; loss: 1.45; acc: 0.42
Batch: 200; loss: 1.49; acc: 0.53
Batch: 220; loss: 1.56; acc: 0.42
Batch: 240; loss: 1.38; acc: 0.47
Batch: 260; loss: 1.41; acc: 0.55
Batch: 280; loss: 1.51; acc: 0.47
Batch: 300; loss: 1.3; acc: 0.56
Batch: 320; loss: 1.15; acc: 0.61
Batch: 340; loss: 1.55; acc: 0.48
Batch: 360; loss: 1.52; acc: 0.55
Batch: 380; loss: 1.46; acc: 0.48
Batch: 400; loss: 1.34; acc: 0.48
Batch: 420; loss: 1.36; acc: 0.53
Batch: 440; loss: 1.39; acc: 0.5
Batch: 460; loss: 1.62; acc: 0.42
Batch: 480; loss: 1.56; acc: 0.53
Batch: 500; loss: 1.4; acc: 0.53
Batch: 520; loss: 1.08; acc: 0.62
Batch: 540; loss: 1.3; acc: 0.53
Batch: 560; loss: 1.41; acc: 0.55
Batch: 580; loss: 1.33; acc: 0.55
Batch: 600; loss: 1.35; acc: 0.56
Batch: 620; loss: 1.25; acc: 0.59
Batch: 640; loss: 1.48; acc: 0.52
Batch: 660; loss: 1.57; acc: 0.48
Batch: 680; loss: 1.39; acc: 0.53
Batch: 700; loss: 1.62; acc: 0.5
Batch: 720; loss: 1.53; acc: 0.55
Batch: 740; loss: 1.18; acc: 0.66
Batch: 760; loss: 1.56; acc: 0.5
Batch: 780; loss: 1.47; acc: 0.5
Train Epoch over. train_loss: 1.41; train_accuracy: 0.53 

2.166733429476153e-05
9.387738828081638e-06
Batch: 0; loss: 1.75; acc: 0.52
Batch: 20; loss: 1.42; acc: 0.56
Batch: 40; loss: 0.99; acc: 0.75
Batch: 60; loss: 1.13; acc: 0.67
Batch: 80; loss: 1.19; acc: 0.66
Batch: 100; loss: 1.17; acc: 0.69
Batch: 120; loss: 1.4; acc: 0.59
Batch: 140; loss: 1.03; acc: 0.72
Val Epoch over. val_loss: 1.3770284295841386; val_accuracy: 0.5544386942675159 

The current subspace-distance is: 9.387738828081638e-06 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.31; acc: 0.53
Batch: 20; loss: 1.54; acc: 0.48
Batch: 40; loss: 1.48; acc: 0.52
Batch: 60; loss: 1.29; acc: 0.66
Batch: 80; loss: 1.3; acc: 0.64
Batch: 100; loss: 1.4; acc: 0.5
Batch: 120; loss: 1.3; acc: 0.55
Batch: 140; loss: 1.59; acc: 0.48
Batch: 160; loss: 1.28; acc: 0.5
Batch: 180; loss: 1.17; acc: 0.59
Batch: 200; loss: 1.3; acc: 0.5
Batch: 220; loss: 1.27; acc: 0.58
Batch: 240; loss: 1.37; acc: 0.53
Batch: 260; loss: 1.49; acc: 0.55
Batch: 280; loss: 1.43; acc: 0.44
Batch: 300; loss: 1.31; acc: 0.55
Batch: 320; loss: 1.53; acc: 0.48
Batch: 340; loss: 1.36; acc: 0.55
Batch: 360; loss: 1.21; acc: 0.52
Batch: 380; loss: 1.53; acc: 0.55
Batch: 400; loss: 1.24; acc: 0.66
Batch: 420; loss: 1.44; acc: 0.52
Batch: 440; loss: 1.45; acc: 0.5
Batch: 460; loss: 1.3; acc: 0.52
Batch: 480; loss: 1.11; acc: 0.62
Batch: 500; loss: 1.27; acc: 0.61
Batch: 520; loss: 1.43; acc: 0.47
Batch: 540; loss: 1.44; acc: 0.55
Batch: 560; loss: 1.44; acc: 0.52
Batch: 580; loss: 1.74; acc: 0.39
Batch: 600; loss: 1.61; acc: 0.52
Batch: 620; loss: 1.44; acc: 0.5
Batch: 640; loss: 1.33; acc: 0.59
Batch: 660; loss: 1.33; acc: 0.58
Batch: 680; loss: 1.28; acc: 0.55
Batch: 700; loss: 1.44; acc: 0.5
Batch: 720; loss: 1.27; acc: 0.62
Batch: 740; loss: 1.66; acc: 0.47
Batch: 760; loss: 1.34; acc: 0.58
Batch: 780; loss: 1.43; acc: 0.56
Train Epoch over. train_loss: 1.41; train_accuracy: 0.54 

2.0927354853483848e-05
8.140492354868911e-06
Batch: 0; loss: 1.75; acc: 0.52
Batch: 20; loss: 1.42; acc: 0.56
Batch: 40; loss: 0.99; acc: 0.78
Batch: 60; loss: 1.13; acc: 0.67
Batch: 80; loss: 1.19; acc: 0.67
Batch: 100; loss: 1.17; acc: 0.67
Batch: 120; loss: 1.4; acc: 0.59
Batch: 140; loss: 1.03; acc: 0.72
Val Epoch over. val_loss: 1.3769866607751056; val_accuracy: 0.5546377388535032 

The current subspace-distance is: 8.140492354868911e-06 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.6; acc: 0.44
Batch: 20; loss: 1.11; acc: 0.61
Batch: 40; loss: 1.41; acc: 0.52
Batch: 60; loss: 1.32; acc: 0.53
Batch: 80; loss: 1.57; acc: 0.52
Batch: 100; loss: 1.53; acc: 0.52
Batch: 120; loss: 1.48; acc: 0.5
Batch: 140; loss: 1.21; acc: 0.66
Batch: 160; loss: 1.34; acc: 0.61
Batch: 180; loss: 1.2; acc: 0.7
Batch: 200; loss: 1.47; acc: 0.44
Batch: 220; loss: 1.48; acc: 0.56
Batch: 240; loss: 1.23; acc: 0.62
Batch: 260; loss: 1.52; acc: 0.48
Batch: 280; loss: 1.37; acc: 0.56
Batch: 300; loss: 1.43; acc: 0.56
Batch: 320; loss: 1.49; acc: 0.45
Batch: 340; loss: 1.46; acc: 0.61
Batch: 360; loss: 0.98; acc: 0.73
Batch: 380; loss: 1.47; acc: 0.53
Batch: 400; loss: 1.17; acc: 0.58
Batch: 420; loss: 1.35; acc: 0.58
Batch: 440; loss: 1.17; acc: 0.61
Batch: 460; loss: 1.33; acc: 0.55
Batch: 480; loss: 1.57; acc: 0.42
Batch: 500; loss: 1.27; acc: 0.59
Batch: 520; loss: 1.46; acc: 0.5
Batch: 540; loss: 1.41; acc: 0.53
Batch: 560; loss: 1.48; acc: 0.55
Batch: 580; loss: 1.53; acc: 0.48
Batch: 600; loss: 1.4; acc: 0.55
Batch: 620; loss: 1.33; acc: 0.61
Batch: 640; loss: 1.21; acc: 0.66
Batch: 660; loss: 1.35; acc: 0.56
Batch: 680; loss: 1.42; acc: 0.56
Batch: 700; loss: 1.47; acc: 0.52
Batch: 720; loss: 1.38; acc: 0.59
Batch: 740; loss: 1.5; acc: 0.5
Batch: 760; loss: 1.27; acc: 0.59
Batch: 780; loss: 1.44; acc: 0.56
Train Epoch over. train_loss: 1.41; train_accuracy: 0.54 

1.997604704229161e-05
8.983532097772695e-06
Batch: 0; loss: 1.75; acc: 0.52
Batch: 20; loss: 1.42; acc: 0.56
Batch: 40; loss: 0.99; acc: 0.75
Batch: 60; loss: 1.14; acc: 0.67
Batch: 80; loss: 1.19; acc: 0.66
Batch: 100; loss: 1.17; acc: 0.69
Batch: 120; loss: 1.4; acc: 0.59
Batch: 140; loss: 1.03; acc: 0.75
Val Epoch over. val_loss: 1.3771697673827978; val_accuracy: 0.554140127388535 

The current subspace-distance is: 8.983532097772695e-06 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.29; acc: 0.61
Batch: 20; loss: 1.29; acc: 0.59
Batch: 40; loss: 1.39; acc: 0.58
Batch: 60; loss: 1.27; acc: 0.62
Batch: 80; loss: 1.28; acc: 0.52
Batch: 100; loss: 1.67; acc: 0.5
Batch: 120; loss: 1.43; acc: 0.55
Batch: 140; loss: 1.63; acc: 0.5
Batch: 160; loss: 1.44; acc: 0.48
Batch: 180; loss: 1.49; acc: 0.56
Batch: 200; loss: 1.32; acc: 0.59
Batch: 220; loss: 1.37; acc: 0.55
Batch: 240; loss: 1.57; acc: 0.5
Batch: 260; loss: 1.4; acc: 0.52
Batch: 280; loss: 1.48; acc: 0.45
Batch: 300; loss: 1.37; acc: 0.55
Batch: 320; loss: 1.34; acc: 0.62
Batch: 340; loss: 1.39; acc: 0.59
Batch: 360; loss: 1.36; acc: 0.47
Batch: 380; loss: 1.18; acc: 0.69
Batch: 400; loss: 1.36; acc: 0.62
Batch: 420; loss: 1.3; acc: 0.58
Batch: 440; loss: 1.42; acc: 0.5
Batch: 460; loss: 1.46; acc: 0.47
Batch: 480; loss: 1.26; acc: 0.55
Batch: 500; loss: 1.49; acc: 0.55
Batch: 520; loss: 1.25; acc: 0.56
Batch: 540; loss: 1.36; acc: 0.52
Batch: 560; loss: 1.59; acc: 0.48
Batch: 580; loss: 1.49; acc: 0.55
Batch: 600; loss: 1.59; acc: 0.5
Batch: 620; loss: 1.34; acc: 0.61
Batch: 640; loss: 1.5; acc: 0.52
Batch: 660; loss: 1.44; acc: 0.56
Batch: 680; loss: 1.71; acc: 0.52
Batch: 700; loss: 1.39; acc: 0.53
Batch: 720; loss: 1.24; acc: 0.62
Batch: 740; loss: 1.5; acc: 0.52
Batch: 760; loss: 1.39; acc: 0.55
Batch: 780; loss: 1.43; acc: 0.61
Train Epoch over. train_loss: 1.41; train_accuracy: 0.53 

2.0063864212715998e-05
9.810487426875625e-06
Batch: 0; loss: 1.76; acc: 0.52
Batch: 20; loss: 1.42; acc: 0.55
Batch: 40; loss: 1.0; acc: 0.75
Batch: 60; loss: 1.13; acc: 0.67
Batch: 80; loss: 1.19; acc: 0.66
Batch: 100; loss: 1.17; acc: 0.69
Batch: 120; loss: 1.4; acc: 0.58
Batch: 140; loss: 1.03; acc: 0.73
Val Epoch over. val_loss: 1.3770826052708232; val_accuracy: 0.5547372611464968 

The current subspace-distance is: 9.810487426875625e-06 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.38; acc: 0.53
Batch: 20; loss: 1.28; acc: 0.56
Batch: 40; loss: 1.26; acc: 0.56
Batch: 60; loss: 1.36; acc: 0.52
Batch: 80; loss: 1.51; acc: 0.47
Batch: 100; loss: 1.39; acc: 0.5
Batch: 120; loss: 1.49; acc: 0.5
Batch: 140; loss: 1.6; acc: 0.42
Batch: 160; loss: 1.44; acc: 0.48
Batch: 180; loss: 1.25; acc: 0.62
Batch: 200; loss: 1.29; acc: 0.56
Batch: 220; loss: 1.49; acc: 0.47
Batch: 240; loss: 1.69; acc: 0.5
Batch: 260; loss: 1.33; acc: 0.58
Batch: 280; loss: 1.41; acc: 0.55
Batch: 300; loss: 1.61; acc: 0.42
Batch: 320; loss: 1.56; acc: 0.38
Batch: 340; loss: 1.39; acc: 0.59
Batch: 360; loss: 1.53; acc: 0.5
Batch: 380; loss: 1.4; acc: 0.56
Batch: 400; loss: 1.39; acc: 0.53
Batch: 420; loss: 1.43; acc: 0.58
Batch: 440; loss: 1.49; acc: 0.52
Batch: 460; loss: 1.39; acc: 0.55
Batch: 480; loss: 1.12; acc: 0.66
Batch: 500; loss: 1.14; acc: 0.67
Batch: 520; loss: 1.57; acc: 0.52
Batch: 540; loss: 1.14; acc: 0.69
Batch: 560; loss: 1.48; acc: 0.5
Batch: 580; loss: 1.49; acc: 0.48
Batch: 600; loss: 1.53; acc: 0.45
Batch: 620; loss: 1.35; acc: 0.48
Batch: 640; loss: 1.36; acc: 0.59
Batch: 660; loss: 1.31; acc: 0.59
Batch: 680; loss: 1.27; acc: 0.59
Batch: 700; loss: 1.25; acc: 0.59
Batch: 720; loss: 1.15; acc: 0.61
Batch: 740; loss: 1.23; acc: 0.61
Batch: 760; loss: 1.27; acc: 0.62
Batch: 780; loss: 1.35; acc: 0.53
Train Epoch over. train_loss: 1.41; train_accuracy: 0.54 

1.9176261048414744e-05
7.181647561083082e-06
Batch: 0; loss: 1.75; acc: 0.52
Batch: 20; loss: 1.42; acc: 0.53
Batch: 40; loss: 0.99; acc: 0.75
Batch: 60; loss: 1.13; acc: 0.67
Batch: 80; loss: 1.19; acc: 0.66
Batch: 100; loss: 1.17; acc: 0.67
Batch: 120; loss: 1.4; acc: 0.59
Batch: 140; loss: 1.03; acc: 0.72
Val Epoch over. val_loss: 1.376931230733349; val_accuracy: 0.5540406050955414 

The current subspace-distance is: 7.181647561083082e-06 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.34; acc: 0.56
Batch: 20; loss: 1.68; acc: 0.52
Batch: 40; loss: 1.48; acc: 0.52
Batch: 60; loss: 1.45; acc: 0.47
Batch: 80; loss: 1.42; acc: 0.52
Batch: 100; loss: 1.36; acc: 0.52
Batch: 120; loss: 1.33; acc: 0.5
Batch: 140; loss: 1.35; acc: 0.5
Batch: 160; loss: 1.49; acc: 0.48
Batch: 180; loss: 1.14; acc: 0.69
Batch: 200; loss: 1.19; acc: 0.7
Batch: 220; loss: 1.34; acc: 0.58
Batch: 240; loss: 1.2; acc: 0.55
Batch: 260; loss: 1.24; acc: 0.59
Batch: 280; loss: 1.32; acc: 0.58
Batch: 300; loss: 1.6; acc: 0.52
Batch: 320; loss: 1.19; acc: 0.61
Batch: 340; loss: 1.33; acc: 0.55
Batch: 360; loss: 1.19; acc: 0.66
Batch: 380; loss: 1.33; acc: 0.53
Batch: 400; loss: 1.29; acc: 0.59
Batch: 420; loss: 1.42; acc: 0.55
Batch: 440; loss: 1.46; acc: 0.45
Batch: 460; loss: 1.39; acc: 0.56
Batch: 480; loss: 1.47; acc: 0.53
Batch: 500; loss: 1.13; acc: 0.67
Batch: 520; loss: 1.4; acc: 0.53
Batch: 540; loss: 1.42; acc: 0.56
Batch: 560; loss: 1.27; acc: 0.58
Batch: 580; loss: 1.59; acc: 0.45
Batch: 600; loss: 1.55; acc: 0.45
Batch: 620; loss: 1.47; acc: 0.5
Batch: 640; loss: 1.61; acc: 0.48
Batch: 660; loss: 1.57; acc: 0.59
Batch: 680; loss: 1.49; acc: 0.48
Batch: 700; loss: 1.48; acc: 0.53
Batch: 720; loss: 1.3; acc: 0.58
Batch: 740; loss: 1.49; acc: 0.45
Batch: 760; loss: 1.29; acc: 0.59
Batch: 780; loss: 1.57; acc: 0.45
Train Epoch over. train_loss: 1.41; train_accuracy: 0.54 

1.850635999289807e-05
7.252833711390849e-06
Batch: 0; loss: 1.75; acc: 0.52
Batch: 20; loss: 1.42; acc: 0.56
Batch: 40; loss: 0.99; acc: 0.73
Batch: 60; loss: 1.14; acc: 0.67
Batch: 80; loss: 1.19; acc: 0.66
Batch: 100; loss: 1.17; acc: 0.67
Batch: 120; loss: 1.39; acc: 0.59
Batch: 140; loss: 1.03; acc: 0.72
Val Epoch over. val_loss: 1.3768772627138028; val_accuracy: 0.5546377388535032 

The current subspace-distance is: 7.252833711390849e-06 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.25; acc: 0.56
Batch: 20; loss: 1.34; acc: 0.58
Batch: 40; loss: 1.56; acc: 0.56
Batch: 60; loss: 1.34; acc: 0.48
Batch: 80; loss: 1.36; acc: 0.52
Batch: 100; loss: 1.44; acc: 0.52
Batch: 120; loss: 1.39; acc: 0.59
Batch: 140; loss: 1.45; acc: 0.55
Batch: 160; loss: 1.22; acc: 0.58
Batch: 180; loss: 1.46; acc: 0.45
Batch: 200; loss: 1.24; acc: 0.59
Batch: 220; loss: 1.46; acc: 0.58
Batch: 240; loss: 1.29; acc: 0.58
Batch: 260; loss: 1.31; acc: 0.59
Batch: 280; loss: 1.79; acc: 0.33
Batch: 300; loss: 1.44; acc: 0.52
Batch: 320; loss: 1.57; acc: 0.48
Batch: 340; loss: 1.44; acc: 0.52
Batch: 360; loss: 1.44; acc: 0.56
Batch: 380; loss: 1.35; acc: 0.59
Batch: 400; loss: 1.3; acc: 0.53
Batch: 420; loss: 1.63; acc: 0.52
Batch: 440; loss: 1.33; acc: 0.52
Batch: 460; loss: 1.38; acc: 0.59
Batch: 480; loss: 1.33; acc: 0.55
Batch: 500; loss: 1.32; acc: 0.48
Batch: 520; loss: 1.45; acc: 0.42
Batch: 540; loss: 1.23; acc: 0.66
Batch: 560; loss: 1.23; acc: 0.66
Batch: 580; loss: 1.02; acc: 0.64
Batch: 600; loss: 1.61; acc: 0.58
Batch: 620; loss: 1.5; acc: 0.55
Batch: 640; loss: 1.43; acc: 0.41
Batch: 660; loss: 1.46; acc: 0.5
Batch: 680; loss: 1.49; acc: 0.56
Batch: 700; loss: 1.54; acc: 0.42
Batch: 720; loss: 1.55; acc: 0.52
Batch: 740; loss: 1.6; acc: 0.48
Batch: 760; loss: 1.73; acc: 0.42
Batch: 780; loss: 1.53; acc: 0.48
Train Epoch over. train_loss: 1.41; train_accuracy: 0.53 

1.8032846128335223e-05
9.218021659762599e-06
Batch: 0; loss: 1.75; acc: 0.52
Batch: 20; loss: 1.42; acc: 0.56
Batch: 40; loss: 0.99; acc: 0.78
Batch: 60; loss: 1.13; acc: 0.67
Batch: 80; loss: 1.19; acc: 0.66
Batch: 100; loss: 1.17; acc: 0.67
Batch: 120; loss: 1.39; acc: 0.58
Batch: 140; loss: 1.03; acc: 0.72
Val Epoch over. val_loss: 1.3767541130636907; val_accuracy: 0.5549363057324841 

The current subspace-distance is: 9.218021659762599e-06 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.31; acc: 0.62
Batch: 20; loss: 1.3; acc: 0.56
Batch: 40; loss: 1.5; acc: 0.47
Batch: 60; loss: 1.43; acc: 0.58
Batch: 80; loss: 1.41; acc: 0.5
Batch: 100; loss: 1.5; acc: 0.55
Batch: 120; loss: 1.23; acc: 0.58
Batch: 140; loss: 1.42; acc: 0.48
Batch: 160; loss: 1.4; acc: 0.48
Batch: 180; loss: 1.28; acc: 0.58
Batch: 200; loss: 1.53; acc: 0.47
Batch: 220; loss: 1.45; acc: 0.52
Batch: 240; loss: 1.61; acc: 0.48
Batch: 260; loss: 1.41; acc: 0.47
Batch: 280; loss: 1.5; acc: 0.44
Batch: 300; loss: 1.3; acc: 0.61
Batch: 320; loss: 1.32; acc: 0.58
Batch: 340; loss: 1.38; acc: 0.56
Batch: 360; loss: 1.5; acc: 0.48
Batch: 380; loss: 1.4; acc: 0.5
Batch: 400; loss: 1.65; acc: 0.47
Batch: 420; loss: 1.52; acc: 0.52
Batch: 440; loss: 1.53; acc: 0.47
Batch: 460; loss: 1.15; acc: 0.64
Batch: 480; loss: 1.39; acc: 0.52
Batch: 500; loss: 1.71; acc: 0.38
Batch: 520; loss: 1.48; acc: 0.52
Batch: 540; loss: 1.75; acc: 0.45
Batch: 560; loss: 1.37; acc: 0.48
Batch: 580; loss: 1.59; acc: 0.41
Batch: 600; loss: 1.31; acc: 0.59
Batch: 620; loss: 1.44; acc: 0.52
Batch: 640; loss: 1.57; acc: 0.45
Batch: 660; loss: 1.57; acc: 0.45
Batch: 680; loss: 1.43; acc: 0.53
Batch: 700; loss: 1.5; acc: 0.59
Batch: 720; loss: 1.6; acc: 0.41
Batch: 740; loss: 1.51; acc: 0.42
Batch: 760; loss: 1.54; acc: 0.55
Batch: 780; loss: 1.4; acc: 0.58
Train Epoch over. train_loss: 1.41; train_accuracy: 0.53 

1.958048960659653e-05
8.236364010372199e-06
Batch: 0; loss: 1.75; acc: 0.52
Batch: 20; loss: 1.41; acc: 0.56
Batch: 40; loss: 0.99; acc: 0.75
Batch: 60; loss: 1.13; acc: 0.67
Batch: 80; loss: 1.19; acc: 0.67
Batch: 100; loss: 1.17; acc: 0.69
Batch: 120; loss: 1.39; acc: 0.59
Batch: 140; loss: 1.03; acc: 0.72
Val Epoch over. val_loss: 1.376884203427916; val_accuracy: 0.5556329617834395 

The current subspace-distance is: 8.236364010372199e-06 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.59; acc: 0.44
Batch: 20; loss: 1.4; acc: 0.53
Batch: 40; loss: 1.41; acc: 0.45
Batch: 60; loss: 1.15; acc: 0.61
Batch: 80; loss: 1.37; acc: 0.55
Batch: 100; loss: 1.2; acc: 0.61
Batch: 120; loss: 1.48; acc: 0.56
Batch: 140; loss: 1.49; acc: 0.55
Batch: 160; loss: 1.33; acc: 0.56
Batch: 180; loss: 1.5; acc: 0.52
Batch: 200; loss: 1.48; acc: 0.47
Batch: 220; loss: 1.52; acc: 0.5
Batch: 240; loss: 1.47; acc: 0.53
Batch: 260; loss: 1.43; acc: 0.58
Batch: 280; loss: 1.55; acc: 0.44
Batch: 300; loss: 1.34; acc: 0.56
Batch: 320; loss: 1.44; acc: 0.5
Batch: 340; loss: 1.25; acc: 0.58
Batch: 360; loss: 1.55; acc: 0.58
Batch: 380; loss: 1.32; acc: 0.53
Batch: 400; loss: 1.4; acc: 0.45
Batch: 420; loss: 1.55; acc: 0.44
Batch: 440; loss: 1.59; acc: 0.44
Batch: 460; loss: 1.42; acc: 0.52
Batch: 480; loss: 1.58; acc: 0.55
Batch: 500; loss: 1.4; acc: 0.55
Batch: 520; loss: 1.2; acc: 0.59
Batch: 540; loss: 1.48; acc: 0.48
Batch: 560; loss: 1.16; acc: 0.58
Batch: 580; loss: 1.25; acc: 0.59
Batch: 600; loss: 1.43; acc: 0.58
Batch: 620; loss: 1.49; acc: 0.55
Batch: 640; loss: 1.49; acc: 0.56
Batch: 660; loss: 1.36; acc: 0.59
Batch: 680; loss: 1.38; acc: 0.55
Batch: 700; loss: 1.69; acc: 0.48
Batch: 720; loss: 1.56; acc: 0.45
Batch: 740; loss: 1.36; acc: 0.53
Batch: 760; loss: 1.38; acc: 0.59
Batch: 780; loss: 1.29; acc: 0.59
Train Epoch over. train_loss: 1.41; train_accuracy: 0.53 

2.239517925772816e-05
8.286701813631225e-06
Batch: 0; loss: 1.75; acc: 0.52
Batch: 20; loss: 1.42; acc: 0.56
Batch: 40; loss: 0.99; acc: 0.78
Batch: 60; loss: 1.13; acc: 0.67
Batch: 80; loss: 1.19; acc: 0.66
Batch: 100; loss: 1.17; acc: 0.67
Batch: 120; loss: 1.39; acc: 0.59
Batch: 140; loss: 1.03; acc: 0.72
Val Epoch over. val_loss: 1.3767240875086206; val_accuracy: 0.5547372611464968 

The current subspace-distance is: 8.286701813631225e-06 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.55; acc: 0.61
Batch: 20; loss: 1.46; acc: 0.52
Batch: 40; loss: 1.41; acc: 0.48
Batch: 60; loss: 1.59; acc: 0.48
Batch: 80; loss: 1.4; acc: 0.59
Batch: 100; loss: 1.65; acc: 0.44
Batch: 120; loss: 1.42; acc: 0.52
Batch: 140; loss: 1.32; acc: 0.58
Batch: 160; loss: 1.49; acc: 0.48
Batch: 180; loss: 1.48; acc: 0.48
Batch: 200; loss: 1.38; acc: 0.5
Batch: 220; loss: 1.26; acc: 0.53
Batch: 240; loss: 1.36; acc: 0.62
Batch: 260; loss: 1.28; acc: 0.62
Batch: 280; loss: 1.46; acc: 0.48
Batch: 300; loss: 1.31; acc: 0.59
Batch: 320; loss: 1.67; acc: 0.44
Batch: 340; loss: 1.42; acc: 0.5
Batch: 360; loss: 1.51; acc: 0.55
Batch: 380; loss: 1.44; acc: 0.44
Batch: 400; loss: 1.14; acc: 0.59
Batch: 420; loss: 1.45; acc: 0.53
Batch: 440; loss: 1.67; acc: 0.47
Batch: 460; loss: 1.22; acc: 0.62
Batch: 480; loss: 1.38; acc: 0.56
Batch: 500; loss: 1.29; acc: 0.55
Batch: 520; loss: 1.28; acc: 0.56
Batch: 540; loss: 1.36; acc: 0.58
Batch: 560; loss: 1.58; acc: 0.5
Batch: 580; loss: 1.37; acc: 0.53
Batch: 600; loss: 1.39; acc: 0.52
Batch: 620; loss: 1.39; acc: 0.53
Batch: 640; loss: 1.5; acc: 0.58
Batch: 660; loss: 1.31; acc: 0.53
Batch: 680; loss: 1.39; acc: 0.52
Batch: 700; loss: 1.51; acc: 0.48
Batch: 720; loss: 1.66; acc: 0.42
Batch: 740; loss: 1.28; acc: 0.62
Batch: 760; loss: 1.45; acc: 0.47
Batch: 780; loss: 1.5; acc: 0.52
Train Epoch over. train_loss: 1.41; train_accuracy: 0.53 

2.0653245883295313e-05
6.9841235017520376e-06
Batch: 0; loss: 1.75; acc: 0.52
Batch: 20; loss: 1.41; acc: 0.56
Batch: 40; loss: 0.99; acc: 0.77
Batch: 60; loss: 1.13; acc: 0.67
Batch: 80; loss: 1.19; acc: 0.66
Batch: 100; loss: 1.17; acc: 0.67
Batch: 120; loss: 1.39; acc: 0.59
Batch: 140; loss: 1.03; acc: 0.72
Val Epoch over. val_loss: 1.3769126097867443; val_accuracy: 0.5549363057324841 

The current subspace-distance is: 6.9841235017520376e-06 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.38; acc: 0.53
Batch: 20; loss: 1.59; acc: 0.53
Batch: 40; loss: 1.48; acc: 0.47
Batch: 60; loss: 1.68; acc: 0.42
Batch: 80; loss: 1.36; acc: 0.58
Batch: 100; loss: 1.48; acc: 0.45
Batch: 120; loss: 1.45; acc: 0.48
Batch: 140; loss: 1.49; acc: 0.53
Batch: 160; loss: 1.29; acc: 0.55
Batch: 180; loss: 1.41; acc: 0.53
Batch: 200; loss: 1.43; acc: 0.52
Batch: 220; loss: 1.61; acc: 0.52
Batch: 240; loss: 1.47; acc: 0.55
Batch: 260; loss: 1.55; acc: 0.38
Batch: 280; loss: 1.09; acc: 0.64
Batch: 300; loss: 1.16; acc: 0.67
Batch: 320; loss: 1.48; acc: 0.47
Batch: 340; loss: 1.5; acc: 0.53
Batch: 360; loss: 1.51; acc: 0.45
Batch: 380; loss: 1.33; acc: 0.58
Batch: 400; loss: 1.3; acc: 0.47
Batch: 420; loss: 1.62; acc: 0.45
Batch: 440; loss: 1.28; acc: 0.61
Batch: 460; loss: 1.32; acc: 0.55
Batch: 480; loss: 1.35; acc: 0.5
Batch: 500; loss: 1.44; acc: 0.52
Batch: 520; loss: 1.51; acc: 0.61
Batch: 540; loss: 1.25; acc: 0.62
Batch: 560; loss: 1.27; acc: 0.56
Batch: 580; loss: 1.34; acc: 0.55
Batch: 600; loss: 1.2; acc: 0.59
Batch: 620; loss: 1.5; acc: 0.45
Batch: 640; loss: 1.4; acc: 0.52
Batch: 660; loss: 1.5; acc: 0.47
Batch: 680; loss: 1.59; acc: 0.47
Batch: 700; loss: 1.53; acc: 0.45
Batch: 720; loss: 1.32; acc: 0.59
Batch: 740; loss: 1.46; acc: 0.47
Batch: 760; loss: 1.46; acc: 0.52
Batch: 780; loss: 1.43; acc: 0.53
Train Epoch over. train_loss: 1.41; train_accuracy: 0.53 

1.7365222447551787e-05
7.3272635745524894e-06
Batch: 0; loss: 1.75; acc: 0.52
Batch: 20; loss: 1.42; acc: 0.53
Batch: 40; loss: 0.99; acc: 0.77
Batch: 60; loss: 1.14; acc: 0.67
Batch: 80; loss: 1.19; acc: 0.66
Batch: 100; loss: 1.17; acc: 0.67
Batch: 120; loss: 1.4; acc: 0.58
Batch: 140; loss: 1.03; acc: 0.73
Val Epoch over. val_loss: 1.3768137682015729; val_accuracy: 0.554140127388535 

The current subspace-distance is: 7.3272635745524894e-06 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.39; acc: 0.53
Batch: 20; loss: 1.48; acc: 0.44
Batch: 40; loss: 1.29; acc: 0.58
Batch: 60; loss: 1.37; acc: 0.55
Batch: 80; loss: 1.63; acc: 0.5
Batch: 100; loss: 1.26; acc: 0.59
Batch: 120; loss: 1.3; acc: 0.58
Batch: 140; loss: 1.67; acc: 0.42
Batch: 160; loss: 1.27; acc: 0.61
Batch: 180; loss: 1.65; acc: 0.36
Batch: 200; loss: 1.35; acc: 0.58
Batch: 220; loss: 1.28; acc: 0.56
Batch: 240; loss: 1.21; acc: 0.61
Batch: 260; loss: 1.7; acc: 0.42
Batch: 280; loss: 1.36; acc: 0.58
Batch: 300; loss: 1.39; acc: 0.55
Batch: 320; loss: 1.35; acc: 0.58
Batch: 340; loss: 1.53; acc: 0.45
Batch: 360; loss: 1.44; acc: 0.55
Batch: 380; loss: 1.41; acc: 0.58
Batch: 400; loss: 1.51; acc: 0.48
Batch: 420; loss: 1.33; acc: 0.56
Batch: 440; loss: 1.42; acc: 0.5
Batch: 460; loss: 1.29; acc: 0.53
Batch: 480; loss: 1.58; acc: 0.44
Batch: 500; loss: 1.37; acc: 0.55
Batch: 520; loss: 1.47; acc: 0.45
Batch: 540; loss: 1.55; acc: 0.53
Batch: 560; loss: 1.46; acc: 0.48
Batch: 580; loss: 1.41; acc: 0.52
Batch: 600; loss: 1.29; acc: 0.55
Batch: 620; loss: 1.62; acc: 0.5
Batch: 640; loss: 1.33; acc: 0.56
Batch: 660; loss: 1.33; acc: 0.53
Batch: 680; loss: 1.57; acc: 0.52
Batch: 700; loss: 1.44; acc: 0.47
Batch: 720; loss: 1.39; acc: 0.55
Batch: 740; loss: 1.3; acc: 0.56
Batch: 760; loss: 1.64; acc: 0.45
Batch: 780; loss: 1.39; acc: 0.53
Train Epoch over. train_loss: 1.41; train_accuracy: 0.53 

2.0513401977950707e-05
9.267801033274736e-06
Batch: 0; loss: 1.75; acc: 0.52
Batch: 20; loss: 1.42; acc: 0.56
Batch: 40; loss: 0.99; acc: 0.75
Batch: 60; loss: 1.13; acc: 0.67
Batch: 80; loss: 1.19; acc: 0.66
Batch: 100; loss: 1.17; acc: 0.69
Batch: 120; loss: 1.39; acc: 0.59
Batch: 140; loss: 1.03; acc: 0.72
Val Epoch over. val_loss: 1.376898982342641; val_accuracy: 0.5550358280254777 

The current subspace-distance is: 9.267801033274736e-06 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.56; acc: 0.47
Batch: 20; loss: 1.49; acc: 0.52
Batch: 40; loss: 1.73; acc: 0.42
Batch: 60; loss: 1.33; acc: 0.56
Batch: 80; loss: 1.29; acc: 0.58
Batch: 100; loss: 1.14; acc: 0.56
Batch: 120; loss: 1.33; acc: 0.55
Batch: 140; loss: 1.45; acc: 0.47
Batch: 160; loss: 1.36; acc: 0.56
Batch: 180; loss: 1.3; acc: 0.55
Batch: 200; loss: 1.47; acc: 0.52
Batch: 220; loss: 1.34; acc: 0.47
Batch: 240; loss: 1.4; acc: 0.53
Batch: 260; loss: 1.39; acc: 0.53
Batch: 280; loss: 1.54; acc: 0.44
Batch: 300; loss: 1.29; acc: 0.62
Batch: 320; loss: 1.23; acc: 0.53
Batch: 340; loss: 1.32; acc: 0.56
Batch: 360; loss: 1.37; acc: 0.52
Batch: 380; loss: 1.48; acc: 0.52
Batch: 400; loss: 1.46; acc: 0.52
Batch: 420; loss: 1.38; acc: 0.58
Batch: 440; loss: 1.18; acc: 0.59
Batch: 460; loss: 1.33; acc: 0.52
Batch: 480; loss: 1.48; acc: 0.52
Batch: 500; loss: 1.38; acc: 0.52
Batch: 520; loss: 1.46; acc: 0.55
Batch: 540; loss: 1.28; acc: 0.56
Batch: 560; loss: 1.47; acc: 0.64
Batch: 580; loss: 1.11; acc: 0.67
Batch: 600; loss: 1.3; acc: 0.56
Batch: 620; loss: 1.36; acc: 0.58
Batch: 640; loss: 1.26; acc: 0.55
Batch: 660; loss: 1.37; acc: 0.58
Batch: 680; loss: 1.33; acc: 0.59
Batch: 700; loss: 1.47; acc: 0.48
Batch: 720; loss: 1.28; acc: 0.56
Batch: 740; loss: 1.64; acc: 0.45
Batch: 760; loss: 1.48; acc: 0.48
Batch: 780; loss: 1.44; acc: 0.58
Train Epoch over. train_loss: 1.41; train_accuracy: 0.54 

1.755199809849728e-05
6.360696716001257e-06
Batch: 0; loss: 1.76; acc: 0.52
Batch: 20; loss: 1.42; acc: 0.55
Batch: 40; loss: 0.99; acc: 0.77
Batch: 60; loss: 1.13; acc: 0.67
Batch: 80; loss: 1.19; acc: 0.66
Batch: 100; loss: 1.17; acc: 0.67
Batch: 120; loss: 1.4; acc: 0.58
Batch: 140; loss: 1.03; acc: 0.73
Val Epoch over. val_loss: 1.3768430147201391; val_accuracy: 0.5542396496815286 

The current subspace-distance is: 6.360696716001257e-06 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.38; acc: 0.61
Batch: 20; loss: 1.67; acc: 0.53
Batch: 40; loss: 1.44; acc: 0.5
Batch: 60; loss: 1.43; acc: 0.5
Batch: 80; loss: 1.11; acc: 0.73
Batch: 100; loss: 1.42; acc: 0.56
Batch: 120; loss: 1.38; acc: 0.48
Batch: 140; loss: 1.74; acc: 0.53
Batch: 160; loss: 1.32; acc: 0.56
Batch: 180; loss: 1.38; acc: 0.56
Batch: 200; loss: 1.46; acc: 0.59
Batch: 220; loss: 1.39; acc: 0.53
Batch: 240; loss: 1.35; acc: 0.55
Batch: 260; loss: 1.41; acc: 0.59
Batch: 280; loss: 1.38; acc: 0.55
Batch: 300; loss: 1.47; acc: 0.47
Batch: 320; loss: 1.13; acc: 0.64
Batch: 340; loss: 1.43; acc: 0.53
Batch: 360; loss: 1.39; acc: 0.55
Batch: 380; loss: 1.56; acc: 0.47
Batch: 400; loss: 1.31; acc: 0.56
Batch: 420; loss: 1.57; acc: 0.5
Batch: 440; loss: 1.11; acc: 0.64
Batch: 460; loss: 1.64; acc: 0.42
Batch: 480; loss: 1.44; acc: 0.55
Batch: 500; loss: 1.27; acc: 0.61
Batch: 520; loss: 1.69; acc: 0.53
Batch: 540; loss: 1.65; acc: 0.48
Batch: 560; loss: 1.46; acc: 0.56
Batch: 580; loss: 1.55; acc: 0.5
Batch: 600; loss: 1.24; acc: 0.66
Batch: 620; loss: 1.41; acc: 0.55
Batch: 640; loss: 1.3; acc: 0.52
Batch: 660; loss: 1.26; acc: 0.62
Batch: 680; loss: 1.48; acc: 0.45
Batch: 700; loss: 1.22; acc: 0.62
Batch: 720; loss: 1.31; acc: 0.58
Batch: 740; loss: 1.47; acc: 0.55
Batch: 760; loss: 1.24; acc: 0.61
Batch: 780; loss: 1.44; acc: 0.44
Train Epoch over. train_loss: 1.41; train_accuracy: 0.54 

1.9594424884417094e-05
8.806222467683256e-06
Batch: 0; loss: 1.75; acc: 0.52
Batch: 20; loss: 1.42; acc: 0.56
Batch: 40; loss: 0.99; acc: 0.75
Batch: 60; loss: 1.13; acc: 0.67
Batch: 80; loss: 1.19; acc: 0.67
Batch: 100; loss: 1.17; acc: 0.69
Batch: 120; loss: 1.39; acc: 0.59
Batch: 140; loss: 1.03; acc: 0.72
Val Epoch over. val_loss: 1.3768657491465284; val_accuracy: 0.5548367834394905 

The current subspace-distance is: 8.806222467683256e-06 

plots/subspace_training/reg_lenet_3/2020-01-22 20:51:04/d_dim_50_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
nonzero elements in E: 15890
elements in E: 3374250
fraction nonzero: 0.004709194635845002
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.31; acc: 0.08
Batch: 20; loss: 2.29; acc: 0.06
Batch: 40; loss: 2.3; acc: 0.06
Batch: 60; loss: 2.3; acc: 0.05
Batch: 80; loss: 2.3; acc: 0.06
Batch: 100; loss: 2.3; acc: 0.14
Batch: 120; loss: 2.31; acc: 0.09
Batch: 140; loss: 2.32; acc: 0.11
Batch: 160; loss: 2.3; acc: 0.08
Batch: 180; loss: 2.3; acc: 0.16
Batch: 200; loss: 2.3; acc: 0.09
Batch: 220; loss: 2.31; acc: 0.09
Batch: 240; loss: 2.31; acc: 0.05
Batch: 260; loss: 2.31; acc: 0.09
Batch: 280; loss: 2.29; acc: 0.16
Batch: 300; loss: 2.3; acc: 0.09
Batch: 320; loss: 2.31; acc: 0.08
Batch: 340; loss: 2.3; acc: 0.11
Batch: 360; loss: 2.3; acc: 0.17
Batch: 380; loss: 2.3; acc: 0.12
Batch: 400; loss: 2.3; acc: 0.14
Batch: 420; loss: 2.32; acc: 0.08
Batch: 440; loss: 2.29; acc: 0.2
Batch: 460; loss: 2.31; acc: 0.11
Batch: 480; loss: 2.3; acc: 0.06
Batch: 500; loss: 2.3; acc: 0.11
Batch: 520; loss: 2.27; acc: 0.23
Batch: 540; loss: 2.3; acc: 0.12
Batch: 560; loss: 2.29; acc: 0.22
Batch: 580; loss: 2.28; acc: 0.17
Batch: 600; loss: 2.3; acc: 0.17
Batch: 620; loss: 2.28; acc: 0.17
Batch: 640; loss: 2.28; acc: 0.14
Batch: 660; loss: 2.29; acc: 0.14
Batch: 680; loss: 2.3; acc: 0.08
Batch: 700; loss: 2.3; acc: 0.11
Batch: 720; loss: 2.3; acc: 0.05
Batch: 740; loss: 2.28; acc: 0.11
Batch: 760; loss: 2.29; acc: 0.09
Batch: 780; loss: 2.29; acc: 0.16
Train Epoch over. train_loss: 2.3; train_accuracy: 0.12 

4.191550488030771e-06
7.055261903587962e-07
Batch: 0; loss: 2.29; acc: 0.2
Batch: 20; loss: 2.28; acc: 0.19
Batch: 40; loss: 2.29; acc: 0.16
Batch: 60; loss: 2.28; acc: 0.22
Batch: 80; loss: 2.28; acc: 0.16
Batch: 100; loss: 2.28; acc: 0.16
Batch: 120; loss: 2.29; acc: 0.14
Batch: 140; loss: 2.29; acc: 0.08
Val Epoch over. val_loss: 2.2867305187662694; val_accuracy: 0.1389331210191083 

The current subspace-distance is: 7.055261903587962e-07 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 2.29; acc: 0.11
Batch: 20; loss: 2.3; acc: 0.14
Batch: 40; loss: 2.29; acc: 0.11
Batch: 60; loss: 2.27; acc: 0.2
Batch: 80; loss: 2.28; acc: 0.11
Batch: 100; loss: 2.29; acc: 0.11
Batch: 120; loss: 2.27; acc: 0.2
Batch: 140; loss: 2.29; acc: 0.12
Batch: 160; loss: 2.29; acc: 0.17
Batch: 180; loss: 2.28; acc: 0.11
Batch: 200; loss: 2.28; acc: 0.12
Batch: 220; loss: 2.28; acc: 0.12
Batch: 240; loss: 2.27; acc: 0.17
Batch: 260; loss: 2.28; acc: 0.16
Batch: 280; loss: 2.28; acc: 0.14
Batch: 300; loss: 2.29; acc: 0.09
Batch: 320; loss: 2.28; acc: 0.14
Batch: 340; loss: 2.27; acc: 0.08
Batch: 360; loss: 2.27; acc: 0.11
Batch: 380; loss: 2.27; acc: 0.12
Batch: 400; loss: 2.27; acc: 0.22
Batch: 420; loss: 2.25; acc: 0.16
Batch: 440; loss: 2.28; acc: 0.08
Batch: 460; loss: 2.28; acc: 0.09
Batch: 480; loss: 2.27; acc: 0.09
Batch: 500; loss: 2.25; acc: 0.2
Batch: 520; loss: 2.28; acc: 0.09
Batch: 540; loss: 2.26; acc: 0.11
Batch: 560; loss: 2.26; acc: 0.17
Batch: 580; loss: 2.25; acc: 0.12
Batch: 600; loss: 2.26; acc: 0.12
Batch: 620; loss: 2.25; acc: 0.14
Batch: 640; loss: 2.25; acc: 0.17
Batch: 660; loss: 2.25; acc: 0.16
Batch: 680; loss: 2.27; acc: 0.08
Batch: 700; loss: 2.26; acc: 0.12
Batch: 720; loss: 2.21; acc: 0.27
Batch: 740; loss: 2.24; acc: 0.23
Batch: 760; loss: 2.25; acc: 0.11
Batch: 780; loss: 2.22; acc: 0.17
Train Epoch over. train_loss: 2.27; train_accuracy: 0.14 

5.796640380140161e-06
1.9476806301099714e-06
Batch: 0; loss: 2.22; acc: 0.2
Batch: 20; loss: 2.22; acc: 0.2
Batch: 40; loss: 2.22; acc: 0.16
Batch: 60; loss: 2.21; acc: 0.19
Batch: 80; loss: 2.2; acc: 0.25
Batch: 100; loss: 2.2; acc: 0.19
Batch: 120; loss: 2.24; acc: 0.14
Batch: 140; loss: 2.22; acc: 0.19
Val Epoch over. val_loss: 2.2282342090728178; val_accuracy: 0.17854299363057324 

The current subspace-distance is: 1.9476806301099714e-06 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 2.26; acc: 0.16
Batch: 20; loss: 2.24; acc: 0.11
Batch: 40; loss: 2.23; acc: 0.17
Batch: 60; loss: 2.23; acc: 0.11
Batch: 80; loss: 2.22; acc: 0.2
Batch: 100; loss: 2.2; acc: 0.2
Batch: 120; loss: 2.25; acc: 0.16
Batch: 140; loss: 2.22; acc: 0.2
Batch: 160; loss: 2.2; acc: 0.17
Batch: 180; loss: 2.2; acc: 0.25
Batch: 200; loss: 2.15; acc: 0.23
Batch: 220; loss: 2.16; acc: 0.28
Batch: 240; loss: 2.11; acc: 0.39
Batch: 260; loss: 2.11; acc: 0.3
Batch: 280; loss: 2.01; acc: 0.42
Batch: 300; loss: 1.92; acc: 0.45
Batch: 320; loss: 1.99; acc: 0.38
Batch: 340; loss: 1.86; acc: 0.41
Batch: 360; loss: 1.76; acc: 0.56
Batch: 380; loss: 1.56; acc: 0.62
Batch: 400; loss: 1.54; acc: 0.56
Batch: 420; loss: 1.5; acc: 0.52
Batch: 440; loss: 1.35; acc: 0.62
Batch: 460; loss: 1.46; acc: 0.58
Batch: 480; loss: 1.06; acc: 0.7
Batch: 500; loss: 1.27; acc: 0.53
Batch: 520; loss: 1.06; acc: 0.72
Batch: 540; loss: 1.21; acc: 0.64
Batch: 560; loss: 1.25; acc: 0.55
Batch: 580; loss: 1.06; acc: 0.7
Batch: 600; loss: 1.02; acc: 0.66
Batch: 620; loss: 1.29; acc: 0.62
Batch: 640; loss: 1.21; acc: 0.62
Batch: 660; loss: 1.04; acc: 0.72
Batch: 680; loss: 0.95; acc: 0.66
Batch: 700; loss: 0.93; acc: 0.7
Batch: 720; loss: 0.77; acc: 0.78
Batch: 740; loss: 0.97; acc: 0.69
Batch: 760; loss: 1.02; acc: 0.62
Batch: 780; loss: 1.1; acc: 0.61
Train Epoch over. train_loss: 1.64; train_accuracy: 0.46 

1.3434567335934844e-05
6.204849341884255e-06
Batch: 0; loss: 0.93; acc: 0.73
Batch: 20; loss: 1.37; acc: 0.56
Batch: 40; loss: 0.67; acc: 0.81
Batch: 60; loss: 1.06; acc: 0.66
Batch: 80; loss: 0.92; acc: 0.67
Batch: 100; loss: 0.92; acc: 0.66
Batch: 120; loss: 1.05; acc: 0.69
Batch: 140; loss: 0.87; acc: 0.73
Val Epoch over. val_loss: 1.046304646570971; val_accuracy: 0.6572452229299363 

The current subspace-distance is: 6.204849341884255e-06 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 1.12; acc: 0.66
Batch: 20; loss: 1.06; acc: 0.67
Batch: 40; loss: 1.21; acc: 0.64
Batch: 60; loss: 1.11; acc: 0.64
Batch: 80; loss: 0.88; acc: 0.72
Batch: 100; loss: 0.77; acc: 0.81
Batch: 120; loss: 1.18; acc: 0.67
Batch: 140; loss: 0.98; acc: 0.67
Batch: 160; loss: 1.11; acc: 0.67
Batch: 180; loss: 1.03; acc: 0.59
Batch: 200; loss: 1.14; acc: 0.66
Batch: 220; loss: 1.15; acc: 0.69
Batch: 240; loss: 1.53; acc: 0.53
Batch: 260; loss: 1.07; acc: 0.69
Batch: 280; loss: 1.12; acc: 0.66
Batch: 300; loss: 1.17; acc: 0.64
Batch: 320; loss: 1.13; acc: 0.75
Batch: 340; loss: 1.06; acc: 0.61
Batch: 360; loss: 1.16; acc: 0.66
Batch: 380; loss: 0.88; acc: 0.7
Batch: 400; loss: 1.11; acc: 0.62
Batch: 420; loss: 0.91; acc: 0.73
Batch: 440; loss: 0.67; acc: 0.8
Batch: 460; loss: 1.04; acc: 0.64
Batch: 480; loss: 1.14; acc: 0.66
Batch: 500; loss: 0.79; acc: 0.75
Batch: 520; loss: 0.98; acc: 0.72
Batch: 540; loss: 0.89; acc: 0.72
Batch: 560; loss: 1.19; acc: 0.61
Batch: 580; loss: 1.03; acc: 0.58
Batch: 600; loss: 1.28; acc: 0.58
Batch: 620; loss: 1.13; acc: 0.64
Batch: 640; loss: 0.95; acc: 0.66
Batch: 660; loss: 0.85; acc: 0.73
Batch: 680; loss: 1.01; acc: 0.64
Batch: 700; loss: 0.8; acc: 0.72
Batch: 720; loss: 1.15; acc: 0.66
Batch: 740; loss: 0.94; acc: 0.67
Batch: 760; loss: 0.96; acc: 0.72
Batch: 780; loss: 0.73; acc: 0.73
Train Epoch over. train_loss: 1.0; train_accuracy: 0.68 

1.844596590672154e-05
5.880425760551589e-06
Batch: 0; loss: 1.26; acc: 0.61
Batch: 20; loss: 2.36; acc: 0.44
Batch: 40; loss: 1.25; acc: 0.56
Batch: 60; loss: 1.49; acc: 0.55
Batch: 80; loss: 1.31; acc: 0.59
Batch: 100; loss: 1.47; acc: 0.53
Batch: 120; loss: 1.51; acc: 0.64
Batch: 140; loss: 1.5; acc: 0.58
Val Epoch over. val_loss: 1.6592747948731585; val_accuracy: 0.5085589171974523 

The current subspace-distance is: 5.880425760551589e-06 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 1.66; acc: 0.5
Batch: 20; loss: 1.12; acc: 0.67
Batch: 40; loss: 1.25; acc: 0.67
Batch: 60; loss: 1.05; acc: 0.7
Batch: 80; loss: 0.88; acc: 0.77
Batch: 100; loss: 1.02; acc: 0.72
Batch: 120; loss: 1.0; acc: 0.7
Batch: 140; loss: 1.1; acc: 0.67
Batch: 160; loss: 0.9; acc: 0.73
Batch: 180; loss: 0.78; acc: 0.73
Batch: 200; loss: 0.73; acc: 0.75
Batch: 220; loss: 1.13; acc: 0.62
Batch: 240; loss: 0.95; acc: 0.7
Batch: 260; loss: 1.17; acc: 0.59
Batch: 280; loss: 0.6; acc: 0.86
Batch: 300; loss: 0.76; acc: 0.75
Batch: 320; loss: 0.86; acc: 0.73
Batch: 340; loss: 0.92; acc: 0.7
Batch: 360; loss: 1.0; acc: 0.72
Batch: 380; loss: 0.71; acc: 0.75
Batch: 400; loss: 1.01; acc: 0.77
Batch: 420; loss: 0.93; acc: 0.67
Batch: 440; loss: 0.57; acc: 0.84
Batch: 460; loss: 0.74; acc: 0.72
Batch: 480; loss: 0.8; acc: 0.73
Batch: 500; loss: 0.88; acc: 0.77
Batch: 520; loss: 1.09; acc: 0.59
Batch: 540; loss: 0.86; acc: 0.77
Batch: 560; loss: 1.13; acc: 0.61
Batch: 580; loss: 0.81; acc: 0.77
Batch: 600; loss: 0.67; acc: 0.83
Batch: 620; loss: 0.96; acc: 0.66
Batch: 640; loss: 0.86; acc: 0.7
Batch: 660; loss: 1.25; acc: 0.62
Batch: 680; loss: 0.68; acc: 0.81
Batch: 700; loss: 0.58; acc: 0.8
Batch: 720; loss: 0.69; acc: 0.75
Batch: 740; loss: 0.78; acc: 0.78
Batch: 760; loss: 0.79; acc: 0.78
Batch: 780; loss: 0.75; acc: 0.8
Train Epoch over. train_loss: 0.91; train_accuracy: 0.71 

2.1581856344710104e-05
8.043922207434662e-06
Batch: 0; loss: 0.94; acc: 0.7
Batch: 20; loss: 1.0; acc: 0.67
Batch: 40; loss: 0.52; acc: 0.84
Batch: 60; loss: 0.9; acc: 0.77
Batch: 80; loss: 0.59; acc: 0.8
Batch: 100; loss: 0.62; acc: 0.83
Batch: 120; loss: 1.18; acc: 0.67
Batch: 140; loss: 0.71; acc: 0.73
Val Epoch over. val_loss: 0.821781149715375; val_accuracy: 0.7458200636942676 

The current subspace-distance is: 8.043922207434662e-06 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.72; acc: 0.75
Batch: 20; loss: 0.93; acc: 0.72
Batch: 40; loss: 1.22; acc: 0.66
Batch: 60; loss: 0.81; acc: 0.72
Batch: 80; loss: 0.78; acc: 0.67
Batch: 100; loss: 0.85; acc: 0.69
Batch: 120; loss: 0.82; acc: 0.77
Batch: 140; loss: 0.74; acc: 0.77
Batch: 160; loss: 0.88; acc: 0.73
Batch: 180; loss: 0.93; acc: 0.62
Batch: 200; loss: 0.72; acc: 0.75
Batch: 220; loss: 0.72; acc: 0.81
Batch: 240; loss: 1.04; acc: 0.67
Batch: 260; loss: 0.75; acc: 0.8
Batch: 280; loss: 0.87; acc: 0.66
Batch: 300; loss: 0.91; acc: 0.66
Batch: 320; loss: 0.95; acc: 0.7
Batch: 340; loss: 0.75; acc: 0.78
Batch: 360; loss: 0.99; acc: 0.72
Batch: 380; loss: 1.35; acc: 0.66
Batch: 400; loss: 0.76; acc: 0.8
Batch: 420; loss: 0.84; acc: 0.77
Batch: 440; loss: 0.93; acc: 0.75
Batch: 460; loss: 0.85; acc: 0.72
Batch: 480; loss: 0.95; acc: 0.66
Batch: 500; loss: 0.92; acc: 0.7
Batch: 520; loss: 0.91; acc: 0.69
Batch: 540; loss: 0.78; acc: 0.7
Batch: 560; loss: 0.83; acc: 0.78
Batch: 580; loss: 0.84; acc: 0.72
Batch: 600; loss: 0.83; acc: 0.7
Batch: 620; loss: 0.89; acc: 0.7
Batch: 640; loss: 0.85; acc: 0.72
Batch: 660; loss: 1.18; acc: 0.62
Batch: 680; loss: 0.61; acc: 0.83
Batch: 700; loss: 0.68; acc: 0.81
Batch: 720; loss: 1.28; acc: 0.66
Batch: 740; loss: 0.71; acc: 0.78
Batch: 760; loss: 0.88; acc: 0.7
Batch: 780; loss: 0.91; acc: 0.77
Train Epoch over. train_loss: 0.86; train_accuracy: 0.73 

2.056584708043374e-05
7.5220100370643195e-06
Batch: 0; loss: 1.06; acc: 0.61
Batch: 20; loss: 1.05; acc: 0.59
Batch: 40; loss: 0.78; acc: 0.77
Batch: 60; loss: 1.03; acc: 0.69
Batch: 80; loss: 0.67; acc: 0.72
Batch: 100; loss: 0.77; acc: 0.73
Batch: 120; loss: 0.97; acc: 0.67
Batch: 140; loss: 0.81; acc: 0.73
Val Epoch over. val_loss: 1.0371729993516472; val_accuracy: 0.6602308917197452 

The current subspace-distance is: 7.5220100370643195e-06 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 1.41; acc: 0.53
Batch: 20; loss: 0.87; acc: 0.77
Batch: 40; loss: 0.84; acc: 0.78
Batch: 60; loss: 0.64; acc: 0.81
Batch: 80; loss: 0.87; acc: 0.72
Batch: 100; loss: 0.87; acc: 0.69
Batch: 120; loss: 0.76; acc: 0.77
Batch: 140; loss: 0.77; acc: 0.72
Batch: 160; loss: 1.13; acc: 0.67
Batch: 180; loss: 0.85; acc: 0.73
Batch: 200; loss: 0.83; acc: 0.72
Batch: 220; loss: 0.91; acc: 0.77
Batch: 240; loss: 0.77; acc: 0.7
Batch: 260; loss: 0.71; acc: 0.8
Batch: 280; loss: 0.65; acc: 0.81
Batch: 300; loss: 0.78; acc: 0.73
Batch: 320; loss: 1.01; acc: 0.69
Batch: 340; loss: 0.83; acc: 0.75
Batch: 360; loss: 0.77; acc: 0.78
Batch: 380; loss: 0.91; acc: 0.69
Batch: 400; loss: 0.94; acc: 0.69
Batch: 420; loss: 1.1; acc: 0.64
Batch: 440; loss: 1.07; acc: 0.64
Batch: 460; loss: 0.52; acc: 0.86
Batch: 480; loss: 0.87; acc: 0.72
Batch: 500; loss: 0.57; acc: 0.83
Batch: 520; loss: 0.52; acc: 0.81
Batch: 540; loss: 0.87; acc: 0.7
Batch: 560; loss: 0.84; acc: 0.77
Batch: 580; loss: 0.76; acc: 0.84
Batch: 600; loss: 0.61; acc: 0.75
Batch: 620; loss: 0.9; acc: 0.7
Batch: 640; loss: 0.97; acc: 0.7
Batch: 660; loss: 0.83; acc: 0.72
Batch: 680; loss: 0.74; acc: 0.78
Batch: 700; loss: 0.78; acc: 0.75
Batch: 720; loss: 0.93; acc: 0.66
Batch: 740; loss: 0.74; acc: 0.8
Batch: 760; loss: 0.76; acc: 0.77
Batch: 780; loss: 0.55; acc: 0.83
Train Epoch over. train_loss: 0.84; train_accuracy: 0.73 

2.233144005003851e-05
8.289975085062906e-06
Batch: 0; loss: 0.92; acc: 0.66
Batch: 20; loss: 0.9; acc: 0.62
Batch: 40; loss: 0.55; acc: 0.81
Batch: 60; loss: 0.96; acc: 0.75
Batch: 80; loss: 0.56; acc: 0.8
Batch: 100; loss: 0.55; acc: 0.84
Batch: 120; loss: 1.04; acc: 0.67
Batch: 140; loss: 0.74; acc: 0.73
Val Epoch over. val_loss: 0.8332394562709103; val_accuracy: 0.7272093949044586 

The current subspace-distance is: 8.289975085062906e-06 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.92; acc: 0.77
Batch: 20; loss: 0.74; acc: 0.75
Batch: 40; loss: 0.84; acc: 0.72
Batch: 60; loss: 0.81; acc: 0.78
Batch: 80; loss: 1.1; acc: 0.67
Batch: 100; loss: 0.66; acc: 0.72
Batch: 120; loss: 0.65; acc: 0.78
Batch: 140; loss: 0.82; acc: 0.72
Batch: 160; loss: 1.04; acc: 0.66
Batch: 180; loss: 0.64; acc: 0.77
Batch: 200; loss: 0.79; acc: 0.73
Batch: 220; loss: 1.01; acc: 0.72
Batch: 240; loss: 0.92; acc: 0.75
Batch: 260; loss: 0.77; acc: 0.77
Batch: 280; loss: 0.99; acc: 0.73
Batch: 300; loss: 1.1; acc: 0.66
Batch: 320; loss: 1.04; acc: 0.64
Batch: 340; loss: 0.85; acc: 0.72
Batch: 360; loss: 0.62; acc: 0.8
Batch: 380; loss: 0.8; acc: 0.73
Batch: 400; loss: 1.0; acc: 0.64
Batch: 420; loss: 0.66; acc: 0.77
Batch: 440; loss: 1.25; acc: 0.59
Batch: 460; loss: 0.76; acc: 0.77
Batch: 480; loss: 0.88; acc: 0.7
Batch: 500; loss: 0.73; acc: 0.73
Batch: 520; loss: 0.96; acc: 0.72
Batch: 540; loss: 0.94; acc: 0.77
Batch: 560; loss: 0.65; acc: 0.83
Batch: 580; loss: 0.82; acc: 0.77
Batch: 600; loss: 1.12; acc: 0.72
Batch: 620; loss: 1.18; acc: 0.64
Batch: 640; loss: 0.5; acc: 0.83
Batch: 660; loss: 0.72; acc: 0.84
Batch: 680; loss: 0.73; acc: 0.78
Batch: 700; loss: 1.04; acc: 0.7
Batch: 720; loss: 0.87; acc: 0.72
Batch: 740; loss: 0.88; acc: 0.73
Batch: 760; loss: 0.55; acc: 0.84
Batch: 780; loss: 0.64; acc: 0.81
Train Epoch over. train_loss: 0.82; train_accuracy: 0.74 

2.248917007818818e-05
8.819636605039705e-06
Batch: 0; loss: 0.94; acc: 0.73
Batch: 20; loss: 0.84; acc: 0.69
Batch: 40; loss: 0.46; acc: 0.81
Batch: 60; loss: 0.86; acc: 0.75
Batch: 80; loss: 0.5; acc: 0.86
Batch: 100; loss: 0.44; acc: 0.89
Batch: 120; loss: 1.1; acc: 0.7
Batch: 140; loss: 0.5; acc: 0.86
Val Epoch over. val_loss: 0.7871969655440871; val_accuracy: 0.7597531847133758 

The current subspace-distance is: 8.819636605039705e-06 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 1.02; acc: 0.69
Batch: 20; loss: 0.57; acc: 0.86
Batch: 40; loss: 0.68; acc: 0.77
Batch: 60; loss: 1.22; acc: 0.66
Batch: 80; loss: 0.8; acc: 0.75
Batch: 100; loss: 0.53; acc: 0.86
Batch: 120; loss: 0.75; acc: 0.77
Batch: 140; loss: 0.89; acc: 0.69
Batch: 160; loss: 0.74; acc: 0.83
Batch: 180; loss: 1.17; acc: 0.72
Batch: 200; loss: 0.74; acc: 0.69
Batch: 220; loss: 0.58; acc: 0.78
Batch: 240; loss: 0.74; acc: 0.78
Batch: 260; loss: 0.81; acc: 0.75
Batch: 280; loss: 0.64; acc: 0.78
Batch: 300; loss: 0.96; acc: 0.67
Batch: 320; loss: 1.01; acc: 0.69
Batch: 340; loss: 0.83; acc: 0.75
Batch: 360; loss: 0.71; acc: 0.84
Batch: 380; loss: 0.79; acc: 0.67
Batch: 400; loss: 0.95; acc: 0.61
Batch: 420; loss: 0.65; acc: 0.75
Batch: 440; loss: 0.97; acc: 0.66
Batch: 460; loss: 0.74; acc: 0.77
Batch: 480; loss: 0.9; acc: 0.67
Batch: 500; loss: 0.82; acc: 0.7
Batch: 520; loss: 0.87; acc: 0.78
Batch: 540; loss: 0.92; acc: 0.7
Batch: 560; loss: 0.86; acc: 0.73
Batch: 580; loss: 0.74; acc: 0.69
Batch: 600; loss: 0.89; acc: 0.77
Batch: 620; loss: 1.06; acc: 0.67
Batch: 640; loss: 0.91; acc: 0.72
Batch: 660; loss: 1.03; acc: 0.62
Batch: 680; loss: 1.04; acc: 0.77
Batch: 700; loss: 0.78; acc: 0.75
Batch: 720; loss: 0.83; acc: 0.73
Batch: 740; loss: 0.67; acc: 0.77
Batch: 760; loss: 0.85; acc: 0.69
Batch: 780; loss: 0.87; acc: 0.67
Train Epoch over. train_loss: 0.81; train_accuracy: 0.74 

2.289304757141508e-05
8.582384907640517e-06
Batch: 0; loss: 1.24; acc: 0.52
Batch: 20; loss: 1.87; acc: 0.5
Batch: 40; loss: 0.84; acc: 0.73
Batch: 60; loss: 1.45; acc: 0.56
Batch: 80; loss: 0.96; acc: 0.66
Batch: 100; loss: 1.16; acc: 0.56
Batch: 120; loss: 1.78; acc: 0.59
Batch: 140; loss: 1.37; acc: 0.56
Val Epoch over. val_loss: 1.2845070278568633; val_accuracy: 0.6084792993630573 

The current subspace-distance is: 8.582384907640517e-06 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 1.54; acc: 0.55
Batch: 20; loss: 0.71; acc: 0.77
Batch: 40; loss: 0.97; acc: 0.7
Batch: 60; loss: 0.8; acc: 0.72
Batch: 80; loss: 0.51; acc: 0.84
Batch: 100; loss: 0.93; acc: 0.7
Batch: 120; loss: 0.74; acc: 0.73
Batch: 140; loss: 1.01; acc: 0.66
Batch: 160; loss: 0.56; acc: 0.8
Batch: 180; loss: 0.7; acc: 0.8
Batch: 200; loss: 0.75; acc: 0.8
Batch: 220; loss: 1.12; acc: 0.61
Batch: 240; loss: 1.16; acc: 0.64
Batch: 260; loss: 0.9; acc: 0.64
Batch: 280; loss: 0.73; acc: 0.8
Batch: 300; loss: 0.52; acc: 0.83
Batch: 320; loss: 0.91; acc: 0.72
Batch: 340; loss: 0.83; acc: 0.67
Batch: 360; loss: 0.78; acc: 0.77
Batch: 380; loss: 0.71; acc: 0.8
Batch: 400; loss: 0.88; acc: 0.7
Batch: 420; loss: 0.76; acc: 0.7
Batch: 440; loss: 0.73; acc: 0.78
Batch: 460; loss: 0.65; acc: 0.81
Batch: 480; loss: 0.79; acc: 0.77
Batch: 500; loss: 0.66; acc: 0.73
Batch: 520; loss: 0.8; acc: 0.72
Batch: 540; loss: 0.83; acc: 0.81
Batch: 560; loss: 0.85; acc: 0.73
Batch: 580; loss: 0.75; acc: 0.77
Batch: 600; loss: 0.61; acc: 0.77
Batch: 620; loss: 0.99; acc: 0.72
Batch: 640; loss: 0.82; acc: 0.7
Batch: 660; loss: 0.78; acc: 0.78
Batch: 680; loss: 0.78; acc: 0.77
Batch: 700; loss: 1.02; acc: 0.66
Batch: 720; loss: 0.96; acc: 0.7
Batch: 740; loss: 1.01; acc: 0.73
Batch: 760; loss: 0.64; acc: 0.78
Batch: 780; loss: 0.97; acc: 0.75
Train Epoch over. train_loss: 0.81; train_accuracy: 0.74 

2.409454100416042e-05
8.856844942783937e-06
Batch: 0; loss: 1.04; acc: 0.67
Batch: 20; loss: 0.99; acc: 0.67
Batch: 40; loss: 0.59; acc: 0.8
Batch: 60; loss: 1.13; acc: 0.72
Batch: 80; loss: 0.73; acc: 0.73
Batch: 100; loss: 0.63; acc: 0.83
Batch: 120; loss: 1.25; acc: 0.69
Batch: 140; loss: 0.68; acc: 0.75
Val Epoch over. val_loss: 0.969053714138687; val_accuracy: 0.6989450636942676 

The current subspace-distance is: 8.856844942783937e-06 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.89; acc: 0.7
Batch: 20; loss: 0.59; acc: 0.83
Batch: 40; loss: 0.95; acc: 0.73
Batch: 60; loss: 0.92; acc: 0.75
Batch: 80; loss: 0.51; acc: 0.84
Batch: 100; loss: 0.89; acc: 0.72
Batch: 120; loss: 0.71; acc: 0.77
Batch: 140; loss: 0.64; acc: 0.8
Batch: 160; loss: 0.73; acc: 0.73
Batch: 180; loss: 0.65; acc: 0.78
Batch: 200; loss: 0.89; acc: 0.77
Batch: 220; loss: 0.79; acc: 0.77
Batch: 240; loss: 0.97; acc: 0.78
Batch: 260; loss: 0.72; acc: 0.78
Batch: 280; loss: 0.52; acc: 0.78
Batch: 300; loss: 0.71; acc: 0.73
Batch: 320; loss: 0.92; acc: 0.75
Batch: 340; loss: 0.72; acc: 0.77
Batch: 360; loss: 0.94; acc: 0.73
Batch: 380; loss: 0.69; acc: 0.73
Batch: 400; loss: 1.15; acc: 0.73
Batch: 420; loss: 0.58; acc: 0.77
Batch: 440; loss: 0.69; acc: 0.73
Batch: 460; loss: 0.74; acc: 0.77
Batch: 480; loss: 0.51; acc: 0.81
Batch: 500; loss: 0.68; acc: 0.75
Batch: 520; loss: 0.86; acc: 0.7
Batch: 540; loss: 1.01; acc: 0.72
Batch: 560; loss: 1.11; acc: 0.67
Batch: 580; loss: 0.78; acc: 0.75
Batch: 600; loss: 0.73; acc: 0.77
Batch: 620; loss: 0.63; acc: 0.78
Batch: 640; loss: 0.58; acc: 0.8
Batch: 660; loss: 0.7; acc: 0.8
Batch: 680; loss: 0.98; acc: 0.77
Batch: 700; loss: 0.46; acc: 0.88
Batch: 720; loss: 0.71; acc: 0.77
Batch: 740; loss: 0.72; acc: 0.81
Batch: 760; loss: 0.63; acc: 0.86
Batch: 780; loss: 0.65; acc: 0.8
Train Epoch over. train_loss: 0.77; train_accuracy: 0.76 

2.304294685018249e-05
8.192968380171806e-06
Batch: 0; loss: 0.79; acc: 0.77
Batch: 20; loss: 1.01; acc: 0.67
Batch: 40; loss: 0.39; acc: 0.86
Batch: 60; loss: 0.87; acc: 0.78
Batch: 80; loss: 0.41; acc: 0.89
Batch: 100; loss: 0.58; acc: 0.81
Batch: 120; loss: 1.19; acc: 0.69
Batch: 140; loss: 0.57; acc: 0.81
Val Epoch over. val_loss: 0.7838317351356433; val_accuracy: 0.7576632165605095 

The current subspace-distance is: 8.192968380171806e-06 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.88; acc: 0.67
Batch: 20; loss: 0.86; acc: 0.73
Batch: 40; loss: 0.5; acc: 0.88
Batch: 60; loss: 0.68; acc: 0.75
Batch: 80; loss: 0.61; acc: 0.8
Batch: 100; loss: 0.93; acc: 0.69
Batch: 120; loss: 0.85; acc: 0.7
Batch: 140; loss: 0.82; acc: 0.7
Batch: 160; loss: 0.54; acc: 0.83
Batch: 180; loss: 0.49; acc: 0.84
Batch: 200; loss: 0.5; acc: 0.84
Batch: 220; loss: 0.71; acc: 0.78
Batch: 240; loss: 0.68; acc: 0.81
Batch: 260; loss: 0.68; acc: 0.8
Batch: 280; loss: 0.59; acc: 0.8
Batch: 300; loss: 0.6; acc: 0.83
Batch: 320; loss: 0.7; acc: 0.77
Batch: 340; loss: 0.64; acc: 0.78
Batch: 360; loss: 0.98; acc: 0.77
Batch: 380; loss: 0.66; acc: 0.78
Batch: 400; loss: 0.89; acc: 0.77
Batch: 420; loss: 0.83; acc: 0.75
Batch: 440; loss: 0.89; acc: 0.7
Batch: 460; loss: 0.9; acc: 0.72
Batch: 480; loss: 0.95; acc: 0.77
Batch: 500; loss: 0.96; acc: 0.62
Batch: 520; loss: 0.65; acc: 0.78
Batch: 540; loss: 0.96; acc: 0.61
Batch: 560; loss: 0.72; acc: 0.81
Batch: 580; loss: 0.65; acc: 0.8
Batch: 600; loss: 0.79; acc: 0.75
Batch: 620; loss: 0.8; acc: 0.73
Batch: 640; loss: 0.73; acc: 0.77
Batch: 660; loss: 0.81; acc: 0.73
Batch: 680; loss: 0.9; acc: 0.69
Batch: 700; loss: 0.65; acc: 0.77
Batch: 720; loss: 0.77; acc: 0.78
Batch: 740; loss: 1.02; acc: 0.73
Batch: 760; loss: 0.99; acc: 0.67
Batch: 780; loss: 0.8; acc: 0.77
Train Epoch over. train_loss: 0.77; train_accuracy: 0.76 

2.3167143808677793e-05
8.329445336130448e-06
Batch: 0; loss: 0.86; acc: 0.73
Batch: 20; loss: 0.85; acc: 0.73
Batch: 40; loss: 0.41; acc: 0.86
Batch: 60; loss: 0.94; acc: 0.75
Batch: 80; loss: 0.49; acc: 0.84
Batch: 100; loss: 0.45; acc: 0.89
Batch: 120; loss: 1.15; acc: 0.69
Batch: 140; loss: 0.58; acc: 0.8
Val Epoch over. val_loss: 0.7945893579607557; val_accuracy: 0.7575636942675159 

The current subspace-distance is: 8.329445336130448e-06 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.7; acc: 0.8
Batch: 20; loss: 1.0; acc: 0.64
Batch: 40; loss: 0.99; acc: 0.69
Batch: 60; loss: 0.79; acc: 0.75
Batch: 80; loss: 0.73; acc: 0.78
Batch: 100; loss: 0.64; acc: 0.8
Batch: 120; loss: 0.83; acc: 0.78
Batch: 140; loss: 0.59; acc: 0.81
Batch: 160; loss: 0.66; acc: 0.83
Batch: 180; loss: 0.69; acc: 0.81
Batch: 200; loss: 0.71; acc: 0.8
Batch: 220; loss: 0.84; acc: 0.8
Batch: 240; loss: 0.81; acc: 0.75
Batch: 260; loss: 0.56; acc: 0.83
Batch: 280; loss: 0.86; acc: 0.75
Batch: 300; loss: 0.75; acc: 0.8
Batch: 320; loss: 0.82; acc: 0.75
Batch: 340; loss: 0.48; acc: 0.84
Batch: 360; loss: 0.73; acc: 0.81
Batch: 380; loss: 0.96; acc: 0.69
Batch: 400; loss: 0.64; acc: 0.83
Batch: 420; loss: 0.74; acc: 0.8
Batch: 440; loss: 0.77; acc: 0.78
Batch: 460; loss: 0.71; acc: 0.81
Batch: 480; loss: 0.58; acc: 0.89
Batch: 500; loss: 0.63; acc: 0.81
Batch: 520; loss: 1.08; acc: 0.69
Batch: 540; loss: 0.74; acc: 0.75
Batch: 560; loss: 0.65; acc: 0.77
Batch: 580; loss: 0.85; acc: 0.69
Batch: 600; loss: 1.05; acc: 0.67
Batch: 620; loss: 0.77; acc: 0.73
Batch: 640; loss: 0.93; acc: 0.7
Batch: 660; loss: 0.71; acc: 0.84
Batch: 680; loss: 0.66; acc: 0.73
Batch: 700; loss: 1.09; acc: 0.66
Batch: 720; loss: 0.47; acc: 0.86
Batch: 740; loss: 0.68; acc: 0.8
Batch: 760; loss: 0.88; acc: 0.75
Batch: 780; loss: 0.98; acc: 0.72
Train Epoch over. train_loss: 0.77; train_accuracy: 0.76 

2.1517671484616585e-05
7.672924766666256e-06
Batch: 0; loss: 0.83; acc: 0.77
Batch: 20; loss: 0.9; acc: 0.75
Batch: 40; loss: 0.36; acc: 0.88
Batch: 60; loss: 0.89; acc: 0.78
Batch: 80; loss: 0.42; acc: 0.84
Batch: 100; loss: 0.47; acc: 0.86
Batch: 120; loss: 1.27; acc: 0.69
Batch: 140; loss: 0.55; acc: 0.83
Val Epoch over. val_loss: 0.7306116010732712; val_accuracy: 0.7773686305732485 

The current subspace-distance is: 7.672924766666256e-06 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.62; acc: 0.77
Batch: 20; loss: 0.72; acc: 0.83
Batch: 40; loss: 0.52; acc: 0.83
Batch: 60; loss: 0.62; acc: 0.8
Batch: 80; loss: 0.65; acc: 0.78
Batch: 100; loss: 0.69; acc: 0.77
Batch: 120; loss: 0.6; acc: 0.8
Batch: 140; loss: 0.98; acc: 0.7
Batch: 160; loss: 0.87; acc: 0.67
Batch: 180; loss: 0.55; acc: 0.8
Batch: 200; loss: 0.74; acc: 0.8
Batch: 220; loss: 0.83; acc: 0.77
Batch: 240; loss: 0.66; acc: 0.78
Batch: 260; loss: 0.54; acc: 0.83
Batch: 280; loss: 0.79; acc: 0.78
Batch: 300; loss: 0.69; acc: 0.77
Batch: 320; loss: 0.54; acc: 0.83
Batch: 340; loss: 0.76; acc: 0.75
Batch: 360; loss: 0.97; acc: 0.69
Batch: 380; loss: 0.52; acc: 0.86
Batch: 400; loss: 0.83; acc: 0.72
Batch: 420; loss: 0.84; acc: 0.72
Batch: 440; loss: 0.57; acc: 0.84
Batch: 460; loss: 0.54; acc: 0.84
Batch: 480; loss: 0.89; acc: 0.77
Batch: 500; loss: 0.66; acc: 0.81
Batch: 520; loss: 0.71; acc: 0.73
Batch: 540; loss: 0.61; acc: 0.86
Batch: 560; loss: 0.87; acc: 0.78
Batch: 580; loss: 0.58; acc: 0.77
Batch: 600; loss: 0.88; acc: 0.73
Batch: 620; loss: 0.77; acc: 0.77
Batch: 640; loss: 0.75; acc: 0.77
Batch: 660; loss: 0.84; acc: 0.77
Batch: 680; loss: 1.17; acc: 0.64
Batch: 700; loss: 0.64; acc: 0.77
Batch: 720; loss: 0.71; acc: 0.75
Batch: 740; loss: 0.6; acc: 0.81
Batch: 760; loss: 0.62; acc: 0.8
Batch: 780; loss: 0.75; acc: 0.8
Train Epoch over. train_loss: 0.77; train_accuracy: 0.76 

2.3201228032121435e-05
8.397728379350156e-06
Batch: 0; loss: 0.77; acc: 0.77
Batch: 20; loss: 0.89; acc: 0.62
Batch: 40; loss: 0.37; acc: 0.88
Batch: 60; loss: 0.93; acc: 0.77
Batch: 80; loss: 0.48; acc: 0.86
Batch: 100; loss: 0.48; acc: 0.88
Batch: 120; loss: 1.21; acc: 0.7
Batch: 140; loss: 0.51; acc: 0.81
Val Epoch over. val_loss: 0.7348799532765795; val_accuracy: 0.7763734076433121 

The current subspace-distance is: 8.397728379350156e-06 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.93; acc: 0.7
Batch: 20; loss: 0.62; acc: 0.8
Batch: 40; loss: 0.51; acc: 0.89
Batch: 60; loss: 0.67; acc: 0.83
Batch: 80; loss: 0.74; acc: 0.8
Batch: 100; loss: 0.8; acc: 0.7
Batch: 120; loss: 0.68; acc: 0.78
Batch: 140; loss: 0.69; acc: 0.77
Batch: 160; loss: 0.83; acc: 0.77
Batch: 180; loss: 0.86; acc: 0.78
Batch: 200; loss: 0.72; acc: 0.77
Batch: 220; loss: 0.91; acc: 0.72
Batch: 240; loss: 0.86; acc: 0.7
Batch: 260; loss: 0.74; acc: 0.72
Batch: 280; loss: 0.59; acc: 0.84
Batch: 300; loss: 0.86; acc: 0.81
Batch: 320; loss: 0.61; acc: 0.81
Batch: 340; loss: 0.68; acc: 0.78
Batch: 360; loss: 0.65; acc: 0.84
Batch: 380; loss: 1.07; acc: 0.69
Batch: 400; loss: 0.74; acc: 0.77
Batch: 420; loss: 0.86; acc: 0.77
Batch: 440; loss: 0.82; acc: 0.72
Batch: 460; loss: 0.95; acc: 0.69
Batch: 480; loss: 0.61; acc: 0.77
Batch: 500; loss: 0.51; acc: 0.88
Batch: 520; loss: 0.86; acc: 0.75
Batch: 540; loss: 0.55; acc: 0.86
Batch: 560; loss: 0.82; acc: 0.75
Batch: 580; loss: 0.75; acc: 0.77
Batch: 600; loss: 0.56; acc: 0.84
Batch: 620; loss: 0.73; acc: 0.73
Batch: 640; loss: 0.61; acc: 0.83
Batch: 660; loss: 0.69; acc: 0.8
Batch: 680; loss: 0.59; acc: 0.81
Batch: 700; loss: 0.65; acc: 0.83
Batch: 720; loss: 0.62; acc: 0.8
Batch: 740; loss: 0.5; acc: 0.83
Batch: 760; loss: 0.9; acc: 0.73
Batch: 780; loss: 0.42; acc: 0.88
Train Epoch over. train_loss: 0.77; train_accuracy: 0.76 

2.2416943465941586e-05
8.912368684832472e-06
Batch: 0; loss: 0.8; acc: 0.78
Batch: 20; loss: 0.9; acc: 0.67
Batch: 40; loss: 0.36; acc: 0.88
Batch: 60; loss: 0.91; acc: 0.77
Batch: 80; loss: 0.43; acc: 0.89
Batch: 100; loss: 0.52; acc: 0.88
Batch: 120; loss: 1.29; acc: 0.64
Batch: 140; loss: 0.56; acc: 0.77
Val Epoch over. val_loss: 0.7451582841432778; val_accuracy: 0.7668192675159236 

The current subspace-distance is: 8.912368684832472e-06 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.8; acc: 0.77
Batch: 20; loss: 0.81; acc: 0.73
Batch: 40; loss: 0.75; acc: 0.73
Batch: 60; loss: 0.45; acc: 0.89
Batch: 80; loss: 0.81; acc: 0.77
Batch: 100; loss: 0.84; acc: 0.75
Batch: 120; loss: 1.15; acc: 0.67
Batch: 140; loss: 0.56; acc: 0.84
Batch: 160; loss: 0.62; acc: 0.81
Batch: 180; loss: 0.85; acc: 0.77
Batch: 200; loss: 0.69; acc: 0.86
Batch: 220; loss: 0.65; acc: 0.81
Batch: 240; loss: 0.65; acc: 0.81
Batch: 260; loss: 0.79; acc: 0.69
Batch: 280; loss: 0.82; acc: 0.72
Batch: 300; loss: 0.43; acc: 0.81
Batch: 320; loss: 0.73; acc: 0.78
Batch: 340; loss: 0.91; acc: 0.73
Batch: 360; loss: 0.8; acc: 0.75
Batch: 380; loss: 0.74; acc: 0.77
Batch: 400; loss: 0.88; acc: 0.77
Batch: 420; loss: 0.96; acc: 0.73
Batch: 440; loss: 0.83; acc: 0.72
Batch: 460; loss: 0.76; acc: 0.73
Batch: 480; loss: 0.85; acc: 0.75
Batch: 500; loss: 1.05; acc: 0.73
Batch: 520; loss: 0.68; acc: 0.83
Batch: 540; loss: 0.88; acc: 0.67
Batch: 560; loss: 0.71; acc: 0.78
Batch: 580; loss: 0.93; acc: 0.7
Batch: 600; loss: 0.9; acc: 0.72
Batch: 620; loss: 0.7; acc: 0.84
Batch: 640; loss: 0.86; acc: 0.73
Batch: 660; loss: 0.65; acc: 0.75
Batch: 680; loss: 0.64; acc: 0.77
Batch: 700; loss: 0.8; acc: 0.72
Batch: 720; loss: 0.54; acc: 0.86
Batch: 740; loss: 0.74; acc: 0.77
Batch: 760; loss: 0.87; acc: 0.69
Batch: 780; loss: 0.65; acc: 0.8
Train Epoch over. train_loss: 0.77; train_accuracy: 0.76 

2.3466078346245922e-05
7.468029252777342e-06
Batch: 0; loss: 0.76; acc: 0.78
Batch: 20; loss: 0.89; acc: 0.73
Batch: 40; loss: 0.35; acc: 0.89
Batch: 60; loss: 0.89; acc: 0.77
Batch: 80; loss: 0.42; acc: 0.83
Batch: 100; loss: 0.47; acc: 0.83
Batch: 120; loss: 1.24; acc: 0.69
Batch: 140; loss: 0.52; acc: 0.81
Val Epoch over. val_loss: 0.7146015653185024; val_accuracy: 0.7802547770700637 

The current subspace-distance is: 7.468029252777342e-06 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.59; acc: 0.8
Batch: 20; loss: 0.72; acc: 0.72
Batch: 40; loss: 0.94; acc: 0.77
Batch: 60; loss: 0.86; acc: 0.73
Batch: 80; loss: 0.63; acc: 0.88
Batch: 100; loss: 0.83; acc: 0.73
Batch: 120; loss: 1.0; acc: 0.69
Batch: 140; loss: 0.52; acc: 0.8
Batch: 160; loss: 0.75; acc: 0.81
Batch: 180; loss: 0.84; acc: 0.69
Batch: 200; loss: 0.93; acc: 0.69
Batch: 220; loss: 0.43; acc: 0.92
Batch: 240; loss: 0.75; acc: 0.7
Batch: 260; loss: 0.8; acc: 0.8
Batch: 280; loss: 0.63; acc: 0.83
Batch: 300; loss: 0.91; acc: 0.73
Batch: 320; loss: 0.78; acc: 0.8
Batch: 340; loss: 0.58; acc: 0.78
Batch: 360; loss: 0.76; acc: 0.81
Batch: 380; loss: 1.17; acc: 0.72
Batch: 400; loss: 1.08; acc: 0.64
Batch: 420; loss: 0.75; acc: 0.78
Batch: 440; loss: 0.57; acc: 0.83
Batch: 460; loss: 0.63; acc: 0.78
Batch: 480; loss: 0.7; acc: 0.83
Batch: 500; loss: 0.66; acc: 0.78
Batch: 520; loss: 0.95; acc: 0.72
Batch: 540; loss: 0.99; acc: 0.72
Batch: 560; loss: 0.8; acc: 0.77
Batch: 580; loss: 0.49; acc: 0.84
Batch: 600; loss: 0.89; acc: 0.69
Batch: 620; loss: 0.73; acc: 0.75
Batch: 640; loss: 0.82; acc: 0.75
Batch: 660; loss: 0.54; acc: 0.84
Batch: 680; loss: 0.94; acc: 0.75
Batch: 700; loss: 0.76; acc: 0.75
Batch: 720; loss: 0.61; acc: 0.84
Batch: 740; loss: 0.7; acc: 0.78
Batch: 760; loss: 0.87; acc: 0.75
Batch: 780; loss: 1.0; acc: 0.69
Train Epoch over. train_loss: 0.77; train_accuracy: 0.76 

2.3616079488419928e-05
7.004970484558726e-06
Batch: 0; loss: 0.78; acc: 0.78
Batch: 20; loss: 0.87; acc: 0.69
Batch: 40; loss: 0.35; acc: 0.91
Batch: 60; loss: 0.89; acc: 0.77
Batch: 80; loss: 0.43; acc: 0.84
Batch: 100; loss: 0.51; acc: 0.84
Batch: 120; loss: 1.21; acc: 0.7
Batch: 140; loss: 0.48; acc: 0.84
Val Epoch over. val_loss: 0.7168669833499155; val_accuracy: 0.78234474522293 

The current subspace-distance is: 7.004970484558726e-06 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.97; acc: 0.67
Batch: 20; loss: 0.72; acc: 0.78
Batch: 40; loss: 1.0; acc: 0.62
Batch: 60; loss: 0.71; acc: 0.77
Batch: 80; loss: 0.41; acc: 0.86
Batch: 100; loss: 0.67; acc: 0.73
Batch: 120; loss: 0.87; acc: 0.7
Batch: 140; loss: 0.79; acc: 0.73
Batch: 160; loss: 0.77; acc: 0.77
Batch: 180; loss: 0.79; acc: 0.78
Batch: 200; loss: 0.68; acc: 0.78
Batch: 220; loss: 0.62; acc: 0.84
Batch: 240; loss: 0.74; acc: 0.77
Batch: 260; loss: 0.94; acc: 0.66
Batch: 280; loss: 0.85; acc: 0.72
Batch: 300; loss: 0.76; acc: 0.77
Batch: 320; loss: 0.86; acc: 0.67
Batch: 340; loss: 0.6; acc: 0.8
Batch: 360; loss: 0.5; acc: 0.86
Batch: 380; loss: 0.77; acc: 0.83
Batch: 400; loss: 0.57; acc: 0.75
Batch: 420; loss: 0.59; acc: 0.78
Batch: 440; loss: 0.86; acc: 0.72
Batch: 460; loss: 0.83; acc: 0.75
Batch: 480; loss: 0.59; acc: 0.8
Batch: 500; loss: 0.8; acc: 0.75
Batch: 520; loss: 0.64; acc: 0.81
Batch: 540; loss: 1.06; acc: 0.58
Batch: 560; loss: 1.07; acc: 0.7
Batch: 580; loss: 0.59; acc: 0.8
Batch: 600; loss: 0.88; acc: 0.67
Batch: 620; loss: 0.85; acc: 0.69
Batch: 640; loss: 0.68; acc: 0.8
Batch: 660; loss: 0.56; acc: 0.78
Batch: 680; loss: 0.63; acc: 0.83
Batch: 700; loss: 0.89; acc: 0.72
Batch: 720; loss: 0.59; acc: 0.83
Batch: 740; loss: 0.73; acc: 0.75
Batch: 760; loss: 0.84; acc: 0.7
Batch: 780; loss: 0.77; acc: 0.78
Train Epoch over. train_loss: 0.77; train_accuracy: 0.76 

2.342796142329462e-05
8.578543202020228e-06
Batch: 0; loss: 0.76; acc: 0.77
Batch: 20; loss: 0.93; acc: 0.67
Batch: 40; loss: 0.36; acc: 0.91
Batch: 60; loss: 0.88; acc: 0.75
Batch: 80; loss: 0.45; acc: 0.88
Batch: 100; loss: 0.5; acc: 0.84
Batch: 120; loss: 1.21; acc: 0.7
Batch: 140; loss: 0.52; acc: 0.84
Val Epoch over. val_loss: 0.7312215086381146; val_accuracy: 0.7771695859872612 

The current subspace-distance is: 8.578543202020228e-06 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.74; acc: 0.77
Batch: 20; loss: 0.92; acc: 0.78
Batch: 40; loss: 0.9; acc: 0.67
Batch: 60; loss: 0.76; acc: 0.77
Batch: 80; loss: 1.01; acc: 0.67
Batch: 100; loss: 1.05; acc: 0.69
Batch: 120; loss: 0.78; acc: 0.75
Batch: 140; loss: 0.85; acc: 0.73
Batch: 160; loss: 0.71; acc: 0.78
Batch: 180; loss: 0.77; acc: 0.77
Batch: 200; loss: 1.1; acc: 0.69
Batch: 220; loss: 0.68; acc: 0.81
Batch: 240; loss: 0.6; acc: 0.83
Batch: 260; loss: 0.82; acc: 0.78
Batch: 280; loss: 0.81; acc: 0.72
Batch: 300; loss: 1.07; acc: 0.62
Batch: 320; loss: 1.06; acc: 0.64
Batch: 340; loss: 0.82; acc: 0.8
Batch: 360; loss: 0.81; acc: 0.78
Batch: 380; loss: 0.62; acc: 0.8
Batch: 400; loss: 0.71; acc: 0.7
Batch: 420; loss: 0.75; acc: 0.77
Batch: 440; loss: 0.76; acc: 0.75
Batch: 460; loss: 0.87; acc: 0.75
Batch: 480; loss: 0.77; acc: 0.75
Batch: 500; loss: 0.58; acc: 0.84
Batch: 520; loss: 0.77; acc: 0.78
Batch: 540; loss: 0.73; acc: 0.8
Batch: 560; loss: 0.76; acc: 0.77
Batch: 580; loss: 0.77; acc: 0.81
Batch: 600; loss: 0.75; acc: 0.72
Batch: 620; loss: 0.77; acc: 0.7
Batch: 640; loss: 0.79; acc: 0.7
Batch: 660; loss: 0.62; acc: 0.77
Batch: 680; loss: 0.93; acc: 0.7
Batch: 700; loss: 0.59; acc: 0.83
Batch: 720; loss: 0.75; acc: 0.72
Batch: 740; loss: 0.61; acc: 0.81
Batch: 760; loss: 0.62; acc: 0.8
Batch: 780; loss: 0.56; acc: 0.84
Train Epoch over. train_loss: 0.77; train_accuracy: 0.76 

2.1433725123642944e-05
8.049557436606847e-06
Batch: 0; loss: 0.77; acc: 0.78
Batch: 20; loss: 0.94; acc: 0.7
Batch: 40; loss: 0.35; acc: 0.89
Batch: 60; loss: 0.87; acc: 0.75
Batch: 80; loss: 0.42; acc: 0.84
Batch: 100; loss: 0.51; acc: 0.83
Batch: 120; loss: 1.23; acc: 0.69
Batch: 140; loss: 0.53; acc: 0.86
Val Epoch over. val_loss: 0.7228853624717445; val_accuracy: 0.7765724522292994 

The current subspace-distance is: 8.049557436606847e-06 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.6; acc: 0.81
Batch: 20; loss: 0.84; acc: 0.75
Batch: 40; loss: 0.99; acc: 0.62
Batch: 60; loss: 0.65; acc: 0.84
Batch: 80; loss: 0.92; acc: 0.67
Batch: 100; loss: 0.75; acc: 0.77
Batch: 120; loss: 0.54; acc: 0.86
Batch: 140; loss: 0.56; acc: 0.81
Batch: 160; loss: 0.87; acc: 0.73
Batch: 180; loss: 0.48; acc: 0.84
Batch: 200; loss: 0.9; acc: 0.7
Batch: 220; loss: 0.97; acc: 0.67
Batch: 240; loss: 0.95; acc: 0.75
Batch: 260; loss: 0.57; acc: 0.83
Batch: 280; loss: 0.77; acc: 0.77
Batch: 300; loss: 0.75; acc: 0.77
Batch: 320; loss: 1.01; acc: 0.72
Batch: 340; loss: 0.53; acc: 0.83
Batch: 360; loss: 0.77; acc: 0.8
Batch: 380; loss: 0.87; acc: 0.7
Batch: 400; loss: 0.89; acc: 0.72
Batch: 420; loss: 0.59; acc: 0.83
Batch: 440; loss: 1.1; acc: 0.69
Batch: 460; loss: 0.83; acc: 0.75
Batch: 480; loss: 0.7; acc: 0.81
Batch: 500; loss: 0.69; acc: 0.8
Batch: 520; loss: 0.69; acc: 0.73
Batch: 540; loss: 0.49; acc: 0.86
Batch: 560; loss: 0.75; acc: 0.77
Batch: 580; loss: 0.71; acc: 0.78
Batch: 600; loss: 0.97; acc: 0.75
Batch: 620; loss: 0.98; acc: 0.69
Batch: 640; loss: 0.71; acc: 0.8
Batch: 660; loss: 0.63; acc: 0.78
Batch: 680; loss: 0.67; acc: 0.75
Batch: 700; loss: 0.76; acc: 0.77
Batch: 720; loss: 1.23; acc: 0.62
Batch: 740; loss: 0.78; acc: 0.7
Batch: 760; loss: 0.89; acc: 0.75
Batch: 780; loss: 0.39; acc: 0.86
Train Epoch over. train_loss: 0.77; train_accuracy: 0.76 

2.4847153326845728e-05
8.08843833510764e-06
Batch: 0; loss: 0.8; acc: 0.75
Batch: 20; loss: 0.94; acc: 0.64
Batch: 40; loss: 0.36; acc: 0.88
Batch: 60; loss: 0.94; acc: 0.77
Batch: 80; loss: 0.46; acc: 0.84
Batch: 100; loss: 0.51; acc: 0.83
Batch: 120; loss: 1.3; acc: 0.69
Batch: 140; loss: 0.56; acc: 0.78
Val Epoch over. val_loss: 0.7218669091060663; val_accuracy: 0.774781050955414 

The current subspace-distance is: 8.08843833510764e-06 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.09; acc: 0.69
Batch: 20; loss: 0.76; acc: 0.78
Batch: 40; loss: 0.86; acc: 0.77
Batch: 60; loss: 0.79; acc: 0.81
Batch: 80; loss: 0.75; acc: 0.81
Batch: 100; loss: 0.5; acc: 0.83
Batch: 120; loss: 0.98; acc: 0.72
Batch: 140; loss: 0.93; acc: 0.7
Batch: 160; loss: 0.67; acc: 0.83
Batch: 180; loss: 1.02; acc: 0.67
Batch: 200; loss: 0.66; acc: 0.77
Batch: 220; loss: 0.76; acc: 0.75
Batch: 240; loss: 0.64; acc: 0.81
Batch: 260; loss: 0.89; acc: 0.75
Batch: 280; loss: 0.61; acc: 0.77
Batch: 300; loss: 0.52; acc: 0.84
Batch: 320; loss: 0.51; acc: 0.81
Batch: 340; loss: 0.69; acc: 0.81
Batch: 360; loss: 0.74; acc: 0.77
Batch: 380; loss: 0.67; acc: 0.8
Batch: 400; loss: 0.69; acc: 0.8
Batch: 420; loss: 0.77; acc: 0.7
Batch: 440; loss: 0.64; acc: 0.78
Batch: 460; loss: 0.71; acc: 0.72
Batch: 480; loss: 0.81; acc: 0.7
Batch: 500; loss: 0.85; acc: 0.69
Batch: 520; loss: 0.89; acc: 0.69
Batch: 540; loss: 0.67; acc: 0.8
Batch: 560; loss: 0.78; acc: 0.67
Batch: 580; loss: 0.58; acc: 0.81
Batch: 600; loss: 0.55; acc: 0.78
Batch: 620; loss: 0.9; acc: 0.73
Batch: 640; loss: 0.7; acc: 0.81
Batch: 660; loss: 0.7; acc: 0.78
Batch: 680; loss: 0.61; acc: 0.8
Batch: 700; loss: 0.65; acc: 0.78
Batch: 720; loss: 0.76; acc: 0.7
Batch: 740; loss: 0.84; acc: 0.77
Batch: 760; loss: 0.77; acc: 0.78
Batch: 780; loss: 1.03; acc: 0.72
Train Epoch over. train_loss: 0.76; train_accuracy: 0.76 

2.1956955606583506e-05
9.41804773901822e-06
Batch: 0; loss: 0.77; acc: 0.8
Batch: 20; loss: 0.87; acc: 0.7
Batch: 40; loss: 0.35; acc: 0.89
Batch: 60; loss: 0.91; acc: 0.77
Batch: 80; loss: 0.45; acc: 0.88
Batch: 100; loss: 0.47; acc: 0.86
Batch: 120; loss: 1.21; acc: 0.69
Batch: 140; loss: 0.5; acc: 0.83
Val Epoch over. val_loss: 0.716138109659693; val_accuracy: 0.7827428343949044 

The current subspace-distance is: 9.41804773901822e-06 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.71; acc: 0.78
Batch: 20; loss: 0.56; acc: 0.81
Batch: 40; loss: 0.55; acc: 0.83
Batch: 60; loss: 0.53; acc: 0.83
Batch: 80; loss: 0.35; acc: 0.86
Batch: 100; loss: 0.66; acc: 0.77
Batch: 120; loss: 0.82; acc: 0.75
Batch: 140; loss: 0.78; acc: 0.78
Batch: 160; loss: 0.98; acc: 0.69
Batch: 180; loss: 0.64; acc: 0.72
Batch: 200; loss: 0.86; acc: 0.75
Batch: 220; loss: 0.48; acc: 0.86
Batch: 240; loss: 0.79; acc: 0.78
Batch: 260; loss: 0.6; acc: 0.84
Batch: 280; loss: 0.6; acc: 0.78
Batch: 300; loss: 0.82; acc: 0.77
Batch: 320; loss: 0.79; acc: 0.75
Batch: 340; loss: 0.73; acc: 0.69
Batch: 360; loss: 0.6; acc: 0.84
Batch: 380; loss: 0.75; acc: 0.77
Batch: 400; loss: 0.62; acc: 0.83
Batch: 420; loss: 0.8; acc: 0.73
Batch: 440; loss: 0.77; acc: 0.72
Batch: 460; loss: 0.62; acc: 0.8
Batch: 480; loss: 0.7; acc: 0.73
Batch: 500; loss: 0.58; acc: 0.81
Batch: 520; loss: 0.89; acc: 0.8
Batch: 540; loss: 0.87; acc: 0.73
Batch: 560; loss: 0.57; acc: 0.78
Batch: 580; loss: 0.69; acc: 0.84
Batch: 600; loss: 0.68; acc: 0.78
Batch: 620; loss: 0.69; acc: 0.78
Batch: 640; loss: 0.71; acc: 0.78
Batch: 660; loss: 0.63; acc: 0.77
Batch: 680; loss: 0.77; acc: 0.75
Batch: 700; loss: 0.5; acc: 0.84
Batch: 720; loss: 0.8; acc: 0.72
Batch: 740; loss: 0.77; acc: 0.7
Batch: 760; loss: 0.42; acc: 0.89
Batch: 780; loss: 0.54; acc: 0.84
Train Epoch over. train_loss: 0.76; train_accuracy: 0.76 

2.3846534531912766e-05
8.10513665783219e-06
Batch: 0; loss: 0.82; acc: 0.78
Batch: 20; loss: 0.9; acc: 0.7
Batch: 40; loss: 0.34; acc: 0.89
Batch: 60; loss: 0.9; acc: 0.77
Batch: 80; loss: 0.45; acc: 0.88
Batch: 100; loss: 0.48; acc: 0.86
Batch: 120; loss: 1.29; acc: 0.67
Batch: 140; loss: 0.5; acc: 0.84
Val Epoch over. val_loss: 0.7195923011394063; val_accuracy: 0.7810509554140127 

The current subspace-distance is: 8.10513665783219e-06 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.87; acc: 0.69
Batch: 20; loss: 0.84; acc: 0.72
Batch: 40; loss: 0.97; acc: 0.7
Batch: 60; loss: 0.69; acc: 0.84
Batch: 80; loss: 0.92; acc: 0.73
Batch: 100; loss: 0.77; acc: 0.73
Batch: 120; loss: 0.86; acc: 0.69
Batch: 140; loss: 0.77; acc: 0.83
Batch: 160; loss: 0.76; acc: 0.77
Batch: 180; loss: 0.86; acc: 0.73
Batch: 200; loss: 0.67; acc: 0.73
Batch: 220; loss: 0.78; acc: 0.73
Batch: 240; loss: 0.97; acc: 0.73
Batch: 260; loss: 0.78; acc: 0.77
Batch: 280; loss: 0.68; acc: 0.8
Batch: 300; loss: 0.73; acc: 0.81
Batch: 320; loss: 0.92; acc: 0.78
Batch: 340; loss: 0.55; acc: 0.83
Batch: 360; loss: 0.8; acc: 0.73
Batch: 380; loss: 1.03; acc: 0.66
Batch: 400; loss: 0.67; acc: 0.78
Batch: 420; loss: 0.73; acc: 0.8
Batch: 440; loss: 1.07; acc: 0.72
Batch: 460; loss: 1.11; acc: 0.7
Batch: 480; loss: 0.63; acc: 0.83
Batch: 500; loss: 0.75; acc: 0.73
Batch: 520; loss: 1.15; acc: 0.7
Batch: 540; loss: 0.8; acc: 0.73
Batch: 560; loss: 0.64; acc: 0.8
Batch: 580; loss: 0.71; acc: 0.83
Batch: 600; loss: 0.59; acc: 0.8
Batch: 620; loss: 0.88; acc: 0.73
Batch: 640; loss: 0.71; acc: 0.8
Batch: 660; loss: 0.62; acc: 0.78
Batch: 680; loss: 0.62; acc: 0.83
Batch: 700; loss: 0.61; acc: 0.83
Batch: 720; loss: 0.78; acc: 0.77
Batch: 740; loss: 0.72; acc: 0.84
Batch: 760; loss: 0.7; acc: 0.78
Batch: 780; loss: 0.61; acc: 0.8
Train Epoch over. train_loss: 0.76; train_accuracy: 0.76 

2.264024988107849e-05
9.821427738643251e-06
Batch: 0; loss: 0.79; acc: 0.78
Batch: 20; loss: 0.89; acc: 0.7
Batch: 40; loss: 0.36; acc: 0.91
Batch: 60; loss: 0.88; acc: 0.75
Batch: 80; loss: 0.42; acc: 0.88
Batch: 100; loss: 0.49; acc: 0.84
Batch: 120; loss: 1.22; acc: 0.69
Batch: 140; loss: 0.51; acc: 0.84
Val Epoch over. val_loss: 0.7241040933284031; val_accuracy: 0.7827428343949044 

The current subspace-distance is: 9.821427738643251e-06 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.7; acc: 0.77
Batch: 20; loss: 0.69; acc: 0.83
Batch: 40; loss: 0.62; acc: 0.83
Batch: 60; loss: 0.76; acc: 0.72
Batch: 80; loss: 0.65; acc: 0.77
Batch: 100; loss: 0.91; acc: 0.66
Batch: 120; loss: 0.84; acc: 0.78
Batch: 140; loss: 0.84; acc: 0.69
Batch: 160; loss: 0.82; acc: 0.73
Batch: 180; loss: 0.78; acc: 0.75
Batch: 200; loss: 0.54; acc: 0.81
Batch: 220; loss: 1.03; acc: 0.66
Batch: 240; loss: 0.76; acc: 0.75
Batch: 260; loss: 0.48; acc: 0.81
Batch: 280; loss: 0.58; acc: 0.78
Batch: 300; loss: 0.73; acc: 0.77
Batch: 320; loss: 0.52; acc: 0.86
Batch: 340; loss: 1.0; acc: 0.69
Batch: 360; loss: 0.82; acc: 0.78
Batch: 380; loss: 0.93; acc: 0.69
Batch: 400; loss: 0.89; acc: 0.72
Batch: 420; loss: 1.07; acc: 0.64
Batch: 440; loss: 0.57; acc: 0.8
Batch: 460; loss: 0.66; acc: 0.78
Batch: 480; loss: 0.62; acc: 0.81
Batch: 500; loss: 0.82; acc: 0.8
Batch: 520; loss: 0.66; acc: 0.81
Batch: 540; loss: 0.56; acc: 0.8
Batch: 560; loss: 0.74; acc: 0.81
Batch: 580; loss: 1.03; acc: 0.61
Batch: 600; loss: 0.76; acc: 0.72
Batch: 620; loss: 0.57; acc: 0.83
Batch: 640; loss: 0.94; acc: 0.66
Batch: 660; loss: 0.52; acc: 0.78
Batch: 680; loss: 0.81; acc: 0.77
Batch: 700; loss: 0.57; acc: 0.77
Batch: 720; loss: 0.65; acc: 0.81
Batch: 740; loss: 0.83; acc: 0.75
Batch: 760; loss: 0.75; acc: 0.75
Batch: 780; loss: 1.16; acc: 0.64
Train Epoch over. train_loss: 0.76; train_accuracy: 0.77 

2.297337050549686e-05
8.35925675346516e-06
Batch: 0; loss: 0.78; acc: 0.78
Batch: 20; loss: 0.88; acc: 0.72
Batch: 40; loss: 0.35; acc: 0.91
Batch: 60; loss: 0.87; acc: 0.77
Batch: 80; loss: 0.41; acc: 0.88
Batch: 100; loss: 0.49; acc: 0.84
Batch: 120; loss: 1.21; acc: 0.7
Batch: 140; loss: 0.51; acc: 0.84
Val Epoch over. val_loss: 0.7278585686425495; val_accuracy: 0.7806528662420382 

The current subspace-distance is: 8.35925675346516e-06 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.68; acc: 0.77
Batch: 20; loss: 0.75; acc: 0.7
Batch: 40; loss: 0.75; acc: 0.73
Batch: 60; loss: 0.67; acc: 0.8
Batch: 80; loss: 0.78; acc: 0.81
Batch: 100; loss: 0.93; acc: 0.73
Batch: 120; loss: 0.66; acc: 0.83
Batch: 140; loss: 0.6; acc: 0.77
Batch: 160; loss: 0.77; acc: 0.78
Batch: 180; loss: 0.69; acc: 0.75
Batch: 200; loss: 0.59; acc: 0.78
Batch: 220; loss: 0.7; acc: 0.77
Batch: 240; loss: 0.7; acc: 0.78
Batch: 260; loss: 0.6; acc: 0.83
Batch: 280; loss: 0.51; acc: 0.83
Batch: 300; loss: 0.66; acc: 0.84
Batch: 320; loss: 0.9; acc: 0.66
Batch: 340; loss: 0.5; acc: 0.84
Batch: 360; loss: 0.76; acc: 0.77
Batch: 380; loss: 0.85; acc: 0.72
Batch: 400; loss: 0.89; acc: 0.69
Batch: 420; loss: 0.63; acc: 0.77
Batch: 440; loss: 0.79; acc: 0.77
Batch: 460; loss: 0.89; acc: 0.73
Batch: 480; loss: 0.73; acc: 0.81
Batch: 500; loss: 0.93; acc: 0.7
Batch: 520; loss: 0.69; acc: 0.78
Batch: 540; loss: 0.98; acc: 0.78
Batch: 560; loss: 0.74; acc: 0.77
Batch: 580; loss: 0.66; acc: 0.77
Batch: 600; loss: 0.77; acc: 0.8
Batch: 620; loss: 0.66; acc: 0.77
Batch: 640; loss: 0.8; acc: 0.8
Batch: 660; loss: 0.99; acc: 0.73
Batch: 680; loss: 0.89; acc: 0.81
Batch: 700; loss: 0.59; acc: 0.8
Batch: 720; loss: 0.71; acc: 0.8
Batch: 740; loss: 0.64; acc: 0.81
Batch: 760; loss: 0.85; acc: 0.69
Batch: 780; loss: 0.7; acc: 0.78
Train Epoch over. train_loss: 0.76; train_accuracy: 0.76 

2.4640741685288958e-05
9.509684787190054e-06
Batch: 0; loss: 0.74; acc: 0.8
Batch: 20; loss: 0.93; acc: 0.7
Batch: 40; loss: 0.36; acc: 0.88
Batch: 60; loss: 0.91; acc: 0.77
Batch: 80; loss: 0.43; acc: 0.86
Batch: 100; loss: 0.49; acc: 0.83
Batch: 120; loss: 1.21; acc: 0.69
Batch: 140; loss: 0.55; acc: 0.81
Val Epoch over. val_loss: 0.7221059742247223; val_accuracy: 0.7758757961783439 

The current subspace-distance is: 9.509684787190054e-06 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.72; acc: 0.83
Batch: 20; loss: 0.79; acc: 0.75
Batch: 40; loss: 0.68; acc: 0.78
Batch: 60; loss: 0.85; acc: 0.73
Batch: 80; loss: 1.19; acc: 0.69
Batch: 100; loss: 1.16; acc: 0.64
Batch: 120; loss: 0.58; acc: 0.83
Batch: 140; loss: 0.84; acc: 0.81
Batch: 160; loss: 0.78; acc: 0.84
Batch: 180; loss: 0.7; acc: 0.77
Batch: 200; loss: 0.84; acc: 0.73
Batch: 220; loss: 0.96; acc: 0.69
Batch: 240; loss: 1.02; acc: 0.77
Batch: 260; loss: 0.98; acc: 0.72
Batch: 280; loss: 0.74; acc: 0.75
Batch: 300; loss: 0.9; acc: 0.73
Batch: 320; loss: 0.44; acc: 0.88
Batch: 340; loss: 0.63; acc: 0.83
Batch: 360; loss: 0.74; acc: 0.73
Batch: 380; loss: 0.69; acc: 0.8
Batch: 400; loss: 0.5; acc: 0.83
Batch: 420; loss: 0.87; acc: 0.7
Batch: 440; loss: 0.68; acc: 0.83
Batch: 460; loss: 1.0; acc: 0.73
Batch: 480; loss: 0.63; acc: 0.81
Batch: 500; loss: 0.57; acc: 0.8
Batch: 520; loss: 0.84; acc: 0.81
Batch: 540; loss: 0.76; acc: 0.78
Batch: 560; loss: 0.87; acc: 0.77
Batch: 580; loss: 0.94; acc: 0.7
Batch: 600; loss: 0.78; acc: 0.78
Batch: 620; loss: 0.96; acc: 0.67
Batch: 640; loss: 0.91; acc: 0.73
Batch: 660; loss: 1.03; acc: 0.64
Batch: 680; loss: 0.6; acc: 0.83
Batch: 700; loss: 0.74; acc: 0.77
Batch: 720; loss: 0.64; acc: 0.75
Batch: 740; loss: 0.89; acc: 0.73
Batch: 760; loss: 0.8; acc: 0.72
Batch: 780; loss: 0.6; acc: 0.78
Train Epoch over. train_loss: 0.76; train_accuracy: 0.76 

2.2949154299567454e-05
8.13409496913664e-06
Batch: 0; loss: 0.76; acc: 0.78
Batch: 20; loss: 0.89; acc: 0.7
Batch: 40; loss: 0.37; acc: 0.89
Batch: 60; loss: 0.9; acc: 0.75
Batch: 80; loss: 0.43; acc: 0.84
Batch: 100; loss: 0.48; acc: 0.83
Batch: 120; loss: 1.17; acc: 0.7
Batch: 140; loss: 0.5; acc: 0.86
Val Epoch over. val_loss: 0.7152971957519556; val_accuracy: 0.7825437898089171 

The current subspace-distance is: 8.13409496913664e-06 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.66; acc: 0.77
Batch: 20; loss: 0.84; acc: 0.72
Batch: 40; loss: 0.94; acc: 0.77
Batch: 60; loss: 1.17; acc: 0.67
Batch: 80; loss: 0.87; acc: 0.73
Batch: 100; loss: 0.8; acc: 0.77
Batch: 120; loss: 0.74; acc: 0.77
Batch: 140; loss: 0.6; acc: 0.83
Batch: 160; loss: 1.1; acc: 0.69
Batch: 180; loss: 0.76; acc: 0.78
Batch: 200; loss: 0.79; acc: 0.73
Batch: 220; loss: 0.68; acc: 0.75
Batch: 240; loss: 0.63; acc: 0.81
Batch: 260; loss: 0.7; acc: 0.77
Batch: 280; loss: 0.74; acc: 0.83
Batch: 300; loss: 0.73; acc: 0.8
Batch: 320; loss: 0.58; acc: 0.78
Batch: 340; loss: 0.58; acc: 0.83
Batch: 360; loss: 0.51; acc: 0.83
Batch: 380; loss: 0.61; acc: 0.84
Batch: 400; loss: 0.64; acc: 0.78
Batch: 420; loss: 0.97; acc: 0.73
Batch: 440; loss: 0.59; acc: 0.78
Batch: 460; loss: 0.63; acc: 0.78
Batch: 480; loss: 0.77; acc: 0.8
Batch: 500; loss: 0.64; acc: 0.83
Batch: 520; loss: 0.76; acc: 0.8
Batch: 540; loss: 0.65; acc: 0.84
Batch: 560; loss: 0.65; acc: 0.78
Batch: 580; loss: 0.77; acc: 0.75
Batch: 600; loss: 0.75; acc: 0.73
Batch: 620; loss: 1.09; acc: 0.67
Batch: 640; loss: 0.75; acc: 0.8
Batch: 660; loss: 0.73; acc: 0.8
Batch: 680; loss: 0.73; acc: 0.75
Batch: 700; loss: 0.94; acc: 0.72
Batch: 720; loss: 0.79; acc: 0.67
Batch: 740; loss: 0.74; acc: 0.73
Batch: 760; loss: 0.72; acc: 0.8
Batch: 780; loss: 0.58; acc: 0.8
Train Epoch over. train_loss: 0.76; train_accuracy: 0.76 

2.3603879526490346e-05
1.0241415111522656e-05
Batch: 0; loss: 0.76; acc: 0.8
Batch: 20; loss: 0.89; acc: 0.7
Batch: 40; loss: 0.35; acc: 0.89
Batch: 60; loss: 0.9; acc: 0.75
Batch: 80; loss: 0.44; acc: 0.83
Batch: 100; loss: 0.51; acc: 0.83
Batch: 120; loss: 1.24; acc: 0.69
Batch: 140; loss: 0.5; acc: 0.83
Val Epoch over. val_loss: 0.7131228416588655; val_accuracy: 0.7790605095541401 

The current subspace-distance is: 1.0241415111522656e-05 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.83; acc: 0.7
Batch: 20; loss: 0.78; acc: 0.81
Batch: 40; loss: 0.57; acc: 0.83
Batch: 60; loss: 0.77; acc: 0.77
Batch: 80; loss: 0.58; acc: 0.81
Batch: 100; loss: 0.65; acc: 0.72
Batch: 120; loss: 0.63; acc: 0.78
Batch: 140; loss: 0.67; acc: 0.78
Batch: 160; loss: 0.73; acc: 0.77
Batch: 180; loss: 0.85; acc: 0.72
Batch: 200; loss: 0.71; acc: 0.77
Batch: 220; loss: 0.75; acc: 0.73
Batch: 240; loss: 1.01; acc: 0.75
Batch: 260; loss: 0.85; acc: 0.8
Batch: 280; loss: 0.59; acc: 0.84
Batch: 300; loss: 0.84; acc: 0.72
Batch: 320; loss: 0.71; acc: 0.77
Batch: 340; loss: 0.77; acc: 0.72
Batch: 360; loss: 0.67; acc: 0.77
Batch: 380; loss: 0.45; acc: 0.83
Batch: 400; loss: 0.8; acc: 0.8
Batch: 420; loss: 0.86; acc: 0.7
Batch: 440; loss: 0.81; acc: 0.86
Batch: 460; loss: 0.64; acc: 0.77
Batch: 480; loss: 0.75; acc: 0.72
Batch: 500; loss: 0.64; acc: 0.83
Batch: 520; loss: 0.72; acc: 0.75
Batch: 540; loss: 0.97; acc: 0.73
Batch: 560; loss: 0.52; acc: 0.88
Batch: 580; loss: 0.78; acc: 0.78
Batch: 600; loss: 0.79; acc: 0.69
Batch: 620; loss: 0.46; acc: 0.86
Batch: 640; loss: 0.46; acc: 0.88
Batch: 660; loss: 0.98; acc: 0.7
Batch: 680; loss: 0.91; acc: 0.72
Batch: 700; loss: 0.71; acc: 0.81
Batch: 720; loss: 0.8; acc: 0.69
Batch: 740; loss: 0.95; acc: 0.72
Batch: 760; loss: 0.73; acc: 0.78
Batch: 780; loss: 1.1; acc: 0.77
Train Epoch over. train_loss: 0.76; train_accuracy: 0.77 

2.06667828024365e-05
9.882474842015654e-06
Batch: 0; loss: 0.75; acc: 0.8
Batch: 20; loss: 0.89; acc: 0.66
Batch: 40; loss: 0.35; acc: 0.88
Batch: 60; loss: 0.89; acc: 0.75
Batch: 80; loss: 0.43; acc: 0.88
Batch: 100; loss: 0.51; acc: 0.84
Batch: 120; loss: 1.22; acc: 0.66
Batch: 140; loss: 0.51; acc: 0.81
Val Epoch over. val_loss: 0.7159583891273305; val_accuracy: 0.7800557324840764 

The current subspace-distance is: 9.882474842015654e-06 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.82; acc: 0.8
Batch: 20; loss: 0.78; acc: 0.75
Batch: 40; loss: 0.75; acc: 0.78
Batch: 60; loss: 0.79; acc: 0.77
Batch: 80; loss: 0.5; acc: 0.78
Batch: 100; loss: 0.46; acc: 0.88
Batch: 120; loss: 0.78; acc: 0.73
Batch: 140; loss: 0.73; acc: 0.83
Batch: 160; loss: 0.87; acc: 0.7
Batch: 180; loss: 0.78; acc: 0.77
Batch: 200; loss: 0.71; acc: 0.72
Batch: 220; loss: 0.86; acc: 0.72
Batch: 240; loss: 0.7; acc: 0.8
Batch: 260; loss: 1.15; acc: 0.62
Batch: 280; loss: 0.85; acc: 0.78
Batch: 300; loss: 0.62; acc: 0.77
Batch: 320; loss: 0.59; acc: 0.86
Batch: 340; loss: 0.72; acc: 0.8
Batch: 360; loss: 0.6; acc: 0.83
Batch: 380; loss: 0.62; acc: 0.8
Batch: 400; loss: 0.75; acc: 0.72
Batch: 420; loss: 0.69; acc: 0.77
Batch: 440; loss: 0.78; acc: 0.73
Batch: 460; loss: 0.75; acc: 0.72
Batch: 480; loss: 0.67; acc: 0.8
Batch: 500; loss: 0.47; acc: 0.88
Batch: 520; loss: 0.89; acc: 0.75
Batch: 540; loss: 0.56; acc: 0.84
Batch: 560; loss: 0.82; acc: 0.75
Batch: 580; loss: 0.61; acc: 0.84
Batch: 600; loss: 0.94; acc: 0.7
Batch: 620; loss: 0.66; acc: 0.77
Batch: 640; loss: 0.58; acc: 0.8
Batch: 660; loss: 0.68; acc: 0.81
Batch: 680; loss: 0.76; acc: 0.77
Batch: 700; loss: 0.79; acc: 0.73
Batch: 720; loss: 0.83; acc: 0.75
Batch: 740; loss: 0.68; acc: 0.78
Batch: 760; loss: 0.81; acc: 0.72
Batch: 780; loss: 0.77; acc: 0.73
Train Epoch over. train_loss: 0.76; train_accuracy: 0.76 

2.2040121621103026e-05
6.958467565709725e-06
Batch: 0; loss: 0.78; acc: 0.81
Batch: 20; loss: 0.91; acc: 0.69
Batch: 40; loss: 0.35; acc: 0.88
Batch: 60; loss: 0.92; acc: 0.75
Batch: 80; loss: 0.46; acc: 0.83
Batch: 100; loss: 0.47; acc: 0.86
Batch: 120; loss: 1.24; acc: 0.69
Batch: 140; loss: 0.5; acc: 0.81
Val Epoch over. val_loss: 0.7106375701867851; val_accuracy: 0.783937101910828 

The current subspace-distance is: 6.958467565709725e-06 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.51; acc: 0.84
Batch: 20; loss: 0.85; acc: 0.73
Batch: 40; loss: 0.65; acc: 0.84
Batch: 60; loss: 0.99; acc: 0.64
Batch: 80; loss: 0.72; acc: 0.78
Batch: 100; loss: 0.73; acc: 0.83
Batch: 120; loss: 0.68; acc: 0.84
Batch: 140; loss: 0.77; acc: 0.73
Batch: 160; loss: 1.04; acc: 0.62
Batch: 180; loss: 0.47; acc: 0.84
Batch: 200; loss: 0.53; acc: 0.78
Batch: 220; loss: 0.78; acc: 0.75
Batch: 240; loss: 1.0; acc: 0.69
Batch: 260; loss: 0.65; acc: 0.75
Batch: 280; loss: 0.74; acc: 0.72
Batch: 300; loss: 0.92; acc: 0.73
Batch: 320; loss: 1.05; acc: 0.7
Batch: 340; loss: 0.55; acc: 0.83
Batch: 360; loss: 0.71; acc: 0.75
Batch: 380; loss: 0.77; acc: 0.73
Batch: 400; loss: 0.85; acc: 0.75
Batch: 420; loss: 0.64; acc: 0.75
Batch: 440; loss: 1.06; acc: 0.62
Batch: 460; loss: 0.82; acc: 0.73
Batch: 480; loss: 0.61; acc: 0.81
Batch: 500; loss: 0.59; acc: 0.84
Batch: 520; loss: 0.77; acc: 0.8
Batch: 540; loss: 0.75; acc: 0.72
Batch: 560; loss: 0.81; acc: 0.77
Batch: 580; loss: 0.8; acc: 0.72
Batch: 600; loss: 0.66; acc: 0.73
Batch: 620; loss: 0.87; acc: 0.77
Batch: 640; loss: 0.95; acc: 0.72
Batch: 660; loss: 0.51; acc: 0.86
Batch: 680; loss: 0.61; acc: 0.7
Batch: 700; loss: 0.78; acc: 0.83
Batch: 720; loss: 1.07; acc: 0.62
Batch: 740; loss: 0.85; acc: 0.75
Batch: 760; loss: 0.55; acc: 0.88
Batch: 780; loss: 0.62; acc: 0.8
Train Epoch over. train_loss: 0.76; train_accuracy: 0.76 

2.3140992198023014e-05
8.722046004550066e-06
Batch: 0; loss: 0.77; acc: 0.78
Batch: 20; loss: 0.88; acc: 0.73
Batch: 40; loss: 0.35; acc: 0.91
Batch: 60; loss: 0.88; acc: 0.75
Batch: 80; loss: 0.42; acc: 0.88
Batch: 100; loss: 0.47; acc: 0.83
Batch: 120; loss: 1.2; acc: 0.69
Batch: 140; loss: 0.49; acc: 0.84
Val Epoch over. val_loss: 0.7139814841519495; val_accuracy: 0.7829418789808917 

The current subspace-distance is: 8.722046004550066e-06 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.74; acc: 0.7
Batch: 20; loss: 0.73; acc: 0.77
Batch: 40; loss: 0.69; acc: 0.81
Batch: 60; loss: 0.75; acc: 0.73
Batch: 80; loss: 0.65; acc: 0.8
Batch: 100; loss: 0.57; acc: 0.84
Batch: 120; loss: 0.99; acc: 0.75
Batch: 140; loss: 1.04; acc: 0.69
Batch: 160; loss: 0.63; acc: 0.8
Batch: 180; loss: 0.65; acc: 0.81
Batch: 200; loss: 0.88; acc: 0.69
Batch: 220; loss: 0.91; acc: 0.69
Batch: 240; loss: 1.04; acc: 0.73
Batch: 260; loss: 0.78; acc: 0.83
Batch: 280; loss: 0.99; acc: 0.67
Batch: 300; loss: 1.0; acc: 0.67
Batch: 320; loss: 0.91; acc: 0.7
Batch: 340; loss: 0.9; acc: 0.73
Batch: 360; loss: 0.65; acc: 0.8
Batch: 380; loss: 0.68; acc: 0.75
Batch: 400; loss: 0.57; acc: 0.81
Batch: 420; loss: 0.73; acc: 0.75
Batch: 440; loss: 0.9; acc: 0.67
Batch: 460; loss: 0.87; acc: 0.77
Batch: 480; loss: 0.7; acc: 0.84
Batch: 500; loss: 0.58; acc: 0.81
Batch: 520; loss: 0.72; acc: 0.75
Batch: 540; loss: 0.92; acc: 0.72
Batch: 560; loss: 0.8; acc: 0.77
Batch: 580; loss: 0.64; acc: 0.8
Batch: 600; loss: 0.98; acc: 0.66
Batch: 620; loss: 0.52; acc: 0.86
Batch: 640; loss: 0.96; acc: 0.73
Batch: 660; loss: 0.7; acc: 0.75
Batch: 680; loss: 0.67; acc: 0.77
Batch: 700; loss: 0.61; acc: 0.78
Batch: 720; loss: 0.83; acc: 0.72
Batch: 740; loss: 0.92; acc: 0.73
Batch: 760; loss: 0.81; acc: 0.78
Batch: 780; loss: 0.5; acc: 0.84
Train Epoch over. train_loss: 0.75; train_accuracy: 0.77 

2.2542086298926733e-05
7.359780738624977e-06
Batch: 0; loss: 0.76; acc: 0.8
Batch: 20; loss: 0.9; acc: 0.72
Batch: 40; loss: 0.35; acc: 0.89
Batch: 60; loss: 0.9; acc: 0.75
Batch: 80; loss: 0.42; acc: 0.84
Batch: 100; loss: 0.49; acc: 0.83
Batch: 120; loss: 1.22; acc: 0.69
Batch: 140; loss: 0.51; acc: 0.84
Val Epoch over. val_loss: 0.7122680827690537; val_accuracy: 0.7818471337579618 

The current subspace-distance is: 7.359780738624977e-06 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.52; acc: 0.83
Batch: 20; loss: 0.67; acc: 0.75
Batch: 40; loss: 0.81; acc: 0.77
Batch: 60; loss: 0.88; acc: 0.75
Batch: 80; loss: 1.14; acc: 0.75
Batch: 100; loss: 0.84; acc: 0.72
Batch: 120; loss: 0.92; acc: 0.78
Batch: 140; loss: 0.96; acc: 0.77
Batch: 160; loss: 0.78; acc: 0.75
Batch: 180; loss: 0.75; acc: 0.7
Batch: 200; loss: 0.92; acc: 0.69
Batch: 220; loss: 0.88; acc: 0.72
Batch: 240; loss: 0.68; acc: 0.77
Batch: 260; loss: 0.71; acc: 0.73
Batch: 280; loss: 0.88; acc: 0.72
Batch: 300; loss: 1.46; acc: 0.61
Batch: 320; loss: 0.89; acc: 0.73
Batch: 340; loss: 1.02; acc: 0.75
Batch: 360; loss: 0.82; acc: 0.73
Batch: 380; loss: 0.63; acc: 0.83
Batch: 400; loss: 0.85; acc: 0.73
Batch: 420; loss: 0.73; acc: 0.88
Batch: 440; loss: 0.54; acc: 0.78
Batch: 460; loss: 0.94; acc: 0.73
Batch: 480; loss: 0.54; acc: 0.88
Batch: 500; loss: 0.79; acc: 0.67
Batch: 520; loss: 0.62; acc: 0.83
Batch: 540; loss: 0.63; acc: 0.81
Batch: 560; loss: 0.55; acc: 0.81
Batch: 580; loss: 0.72; acc: 0.78
Batch: 600; loss: 0.68; acc: 0.8
Batch: 620; loss: 0.95; acc: 0.73
Batch: 640; loss: 0.51; acc: 0.83
Batch: 660; loss: 0.48; acc: 0.8
Batch: 680; loss: 0.85; acc: 0.73
Batch: 700; loss: 0.78; acc: 0.75
Batch: 720; loss: 0.85; acc: 0.7
Batch: 740; loss: 0.76; acc: 0.73
Batch: 760; loss: 0.81; acc: 0.72
Batch: 780; loss: 0.58; acc: 0.86
Train Epoch over. train_loss: 0.75; train_accuracy: 0.77 

2.368095374549739e-05
8.960763807408512e-06
Batch: 0; loss: 0.76; acc: 0.8
Batch: 20; loss: 0.9; acc: 0.72
Batch: 40; loss: 0.34; acc: 0.89
Batch: 60; loss: 0.9; acc: 0.75
Batch: 80; loss: 0.43; acc: 0.86
Batch: 100; loss: 0.48; acc: 0.84
Batch: 120; loss: 1.23; acc: 0.69
Batch: 140; loss: 0.51; acc: 0.84
Val Epoch over. val_loss: 0.7116105683669922; val_accuracy: 0.7826433121019108 

The current subspace-distance is: 8.960763807408512e-06 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.67; acc: 0.81
Batch: 20; loss: 0.79; acc: 0.77
Batch: 40; loss: 0.66; acc: 0.78
Batch: 60; loss: 0.53; acc: 0.88
Batch: 80; loss: 0.76; acc: 0.75
Batch: 100; loss: 0.6; acc: 0.8
Batch: 120; loss: 0.72; acc: 0.73
Batch: 140; loss: 0.77; acc: 0.67
Batch: 160; loss: 0.57; acc: 0.81
Batch: 180; loss: 0.98; acc: 0.72
Batch: 200; loss: 0.85; acc: 0.69
Batch: 220; loss: 0.98; acc: 0.8
Batch: 240; loss: 0.88; acc: 0.72
Batch: 260; loss: 0.67; acc: 0.81
Batch: 280; loss: 0.89; acc: 0.72
Batch: 300; loss: 0.87; acc: 0.75
Batch: 320; loss: 0.81; acc: 0.75
Batch: 340; loss: 0.72; acc: 0.78
Batch: 360; loss: 0.6; acc: 0.83
Batch: 380; loss: 0.79; acc: 0.72
Batch: 400; loss: 0.67; acc: 0.81
Batch: 420; loss: 0.91; acc: 0.69
Batch: 440; loss: 0.7; acc: 0.83
Batch: 460; loss: 0.76; acc: 0.75
Batch: 480; loss: 0.64; acc: 0.81
Batch: 500; loss: 0.9; acc: 0.75
Batch: 520; loss: 0.71; acc: 0.78
Batch: 540; loss: 0.99; acc: 0.77
Batch: 560; loss: 0.74; acc: 0.77
Batch: 580; loss: 0.86; acc: 0.78
Batch: 600; loss: 0.67; acc: 0.83
Batch: 620; loss: 0.69; acc: 0.8
Batch: 640; loss: 0.95; acc: 0.69
Batch: 660; loss: 0.96; acc: 0.7
Batch: 680; loss: 0.96; acc: 0.7
Batch: 700; loss: 0.68; acc: 0.78
Batch: 720; loss: 0.66; acc: 0.77
Batch: 740; loss: 0.77; acc: 0.73
Batch: 760; loss: 0.75; acc: 0.77
Batch: 780; loss: 0.93; acc: 0.72
Train Epoch over. train_loss: 0.75; train_accuracy: 0.77 

2.3197857444756664e-05
8.985975000541657e-06
Batch: 0; loss: 0.77; acc: 0.78
Batch: 20; loss: 0.89; acc: 0.7
Batch: 40; loss: 0.35; acc: 0.89
Batch: 60; loss: 0.88; acc: 0.75
Batch: 80; loss: 0.42; acc: 0.86
Batch: 100; loss: 0.5; acc: 0.83
Batch: 120; loss: 1.22; acc: 0.69
Batch: 140; loss: 0.49; acc: 0.84
Val Epoch over. val_loss: 0.7118607774661605; val_accuracy: 0.7834394904458599 

The current subspace-distance is: 8.985975000541657e-06 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.76; acc: 0.75
Batch: 20; loss: 1.03; acc: 0.84
Batch: 40; loss: 0.89; acc: 0.75
Batch: 60; loss: 0.89; acc: 0.73
Batch: 80; loss: 0.66; acc: 0.8
Batch: 100; loss: 0.81; acc: 0.77
Batch: 120; loss: 0.93; acc: 0.69
Batch: 140; loss: 0.66; acc: 0.81
Batch: 160; loss: 0.86; acc: 0.73
Batch: 180; loss: 0.93; acc: 0.72
Batch: 200; loss: 0.61; acc: 0.86
Batch: 220; loss: 0.98; acc: 0.64
Batch: 240; loss: 0.76; acc: 0.72
Batch: 260; loss: 0.67; acc: 0.77
Batch: 280; loss: 0.63; acc: 0.8
Batch: 300; loss: 0.68; acc: 0.75
Batch: 320; loss: 0.89; acc: 0.78
Batch: 340; loss: 0.76; acc: 0.73
Batch: 360; loss: 0.69; acc: 0.8
Batch: 380; loss: 0.51; acc: 0.81
Batch: 400; loss: 0.99; acc: 0.66
Batch: 420; loss: 0.99; acc: 0.69
Batch: 440; loss: 0.91; acc: 0.75
Batch: 460; loss: 0.82; acc: 0.69
Batch: 480; loss: 0.59; acc: 0.75
Batch: 500; loss: 0.71; acc: 0.8
Batch: 520; loss: 0.57; acc: 0.84
Batch: 540; loss: 0.66; acc: 0.78
Batch: 560; loss: 0.67; acc: 0.83
Batch: 580; loss: 0.55; acc: 0.84
Batch: 600; loss: 0.87; acc: 0.77
Batch: 620; loss: 0.92; acc: 0.77
Batch: 640; loss: 0.62; acc: 0.8
Batch: 660; loss: 0.99; acc: 0.73
Batch: 680; loss: 0.8; acc: 0.72
Batch: 700; loss: 0.74; acc: 0.75
Batch: 720; loss: 0.64; acc: 0.78
Batch: 740; loss: 0.98; acc: 0.66
Batch: 760; loss: 0.7; acc: 0.81
Batch: 780; loss: 0.86; acc: 0.69
Train Epoch over. train_loss: 0.75; train_accuracy: 0.77 

2.1278961867210455e-05
7.851220289012417e-06
Batch: 0; loss: 0.77; acc: 0.81
Batch: 20; loss: 0.88; acc: 0.72
Batch: 40; loss: 0.35; acc: 0.89
Batch: 60; loss: 0.9; acc: 0.75
Batch: 80; loss: 0.43; acc: 0.86
Batch: 100; loss: 0.48; acc: 0.84
Batch: 120; loss: 1.23; acc: 0.69
Batch: 140; loss: 0.51; acc: 0.83
Val Epoch over. val_loss: 0.7125980390864572; val_accuracy: 0.7840366242038217 

The current subspace-distance is: 7.851220289012417e-06 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.73; acc: 0.77
Batch: 20; loss: 0.65; acc: 0.73
Batch: 40; loss: 0.78; acc: 0.8
Batch: 60; loss: 1.05; acc: 0.61
Batch: 80; loss: 0.62; acc: 0.8
Batch: 100; loss: 0.62; acc: 0.8
Batch: 120; loss: 0.77; acc: 0.69
Batch: 140; loss: 0.84; acc: 0.75
Batch: 160; loss: 0.57; acc: 0.86
Batch: 180; loss: 0.73; acc: 0.78
Batch: 200; loss: 0.7; acc: 0.81
Batch: 220; loss: 0.92; acc: 0.75
Batch: 240; loss: 0.72; acc: 0.72
Batch: 260; loss: 0.93; acc: 0.66
Batch: 280; loss: 0.96; acc: 0.69
Batch: 300; loss: 0.73; acc: 0.69
Batch: 320; loss: 0.8; acc: 0.73
Batch: 340; loss: 0.69; acc: 0.75
Batch: 360; loss: 0.81; acc: 0.72
Batch: 380; loss: 0.53; acc: 0.83
Batch: 400; loss: 0.82; acc: 0.75
Batch: 420; loss: 0.86; acc: 0.75
Batch: 440; loss: 0.76; acc: 0.75
Batch: 460; loss: 0.62; acc: 0.81
Batch: 480; loss: 0.56; acc: 0.83
Batch: 500; loss: 0.64; acc: 0.81
Batch: 520; loss: 0.75; acc: 0.78
Batch: 540; loss: 0.83; acc: 0.69
Batch: 560; loss: 0.56; acc: 0.8
Batch: 580; loss: 1.12; acc: 0.67
Batch: 600; loss: 0.72; acc: 0.77
Batch: 620; loss: 0.88; acc: 0.7
Batch: 640; loss: 0.72; acc: 0.75
Batch: 660; loss: 0.87; acc: 0.72
Batch: 680; loss: 0.6; acc: 0.8
Batch: 700; loss: 0.66; acc: 0.75
Batch: 720; loss: 1.05; acc: 0.66
Batch: 740; loss: 0.75; acc: 0.77
Batch: 760; loss: 0.83; acc: 0.81
Batch: 780; loss: 0.56; acc: 0.84
Train Epoch over. train_loss: 0.75; train_accuracy: 0.77 

2.3979002435225993e-05
9.30099304241594e-06
Batch: 0; loss: 0.77; acc: 0.81
Batch: 20; loss: 0.89; acc: 0.7
Batch: 40; loss: 0.35; acc: 0.91
Batch: 60; loss: 0.9; acc: 0.75
Batch: 80; loss: 0.44; acc: 0.86
Batch: 100; loss: 0.48; acc: 0.84
Batch: 120; loss: 1.21; acc: 0.7
Batch: 140; loss: 0.5; acc: 0.86
Val Epoch over. val_loss: 0.7139136842481649; val_accuracy: 0.7848328025477707 

The current subspace-distance is: 9.30099304241594e-06 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.61; acc: 0.84
Batch: 20; loss: 1.33; acc: 0.67
Batch: 40; loss: 0.74; acc: 0.69
Batch: 60; loss: 0.83; acc: 0.78
Batch: 80; loss: 0.56; acc: 0.88
Batch: 100; loss: 0.86; acc: 0.69
Batch: 120; loss: 0.91; acc: 0.7
Batch: 140; loss: 0.79; acc: 0.75
Batch: 160; loss: 0.73; acc: 0.78
Batch: 180; loss: 0.89; acc: 0.69
Batch: 200; loss: 0.61; acc: 0.8
Batch: 220; loss: 0.86; acc: 0.72
Batch: 240; loss: 0.55; acc: 0.83
Batch: 260; loss: 0.89; acc: 0.7
Batch: 280; loss: 1.06; acc: 0.72
Batch: 300; loss: 0.81; acc: 0.78
Batch: 320; loss: 0.73; acc: 0.73
Batch: 340; loss: 0.8; acc: 0.8
Batch: 360; loss: 0.9; acc: 0.72
Batch: 380; loss: 0.84; acc: 0.72
Batch: 400; loss: 0.57; acc: 0.77
Batch: 420; loss: 0.87; acc: 0.72
Batch: 440; loss: 0.74; acc: 0.8
Batch: 460; loss: 0.73; acc: 0.81
Batch: 480; loss: 0.99; acc: 0.7
Batch: 500; loss: 0.66; acc: 0.83
Batch: 520; loss: 0.7; acc: 0.78
Batch: 540; loss: 0.72; acc: 0.84
Batch: 560; loss: 0.77; acc: 0.72
Batch: 580; loss: 0.88; acc: 0.7
Batch: 600; loss: 0.66; acc: 0.8
Batch: 620; loss: 0.82; acc: 0.75
Batch: 640; loss: 1.28; acc: 0.61
Batch: 660; loss: 0.97; acc: 0.64
Batch: 680; loss: 0.69; acc: 0.81
Batch: 700; loss: 0.56; acc: 0.77
Batch: 720; loss: 0.73; acc: 0.81
Batch: 740; loss: 0.78; acc: 0.77
Batch: 760; loss: 0.94; acc: 0.7
Batch: 780; loss: 0.82; acc: 0.73
Train Epoch over. train_loss: 0.75; train_accuracy: 0.77 

2.404263796051964e-05
9.610025699657854e-06
Batch: 0; loss: 0.78; acc: 0.81
Batch: 20; loss: 0.9; acc: 0.72
Batch: 40; loss: 0.34; acc: 0.91
Batch: 60; loss: 0.88; acc: 0.75
Batch: 80; loss: 0.43; acc: 0.88
Batch: 100; loss: 0.49; acc: 0.84
Batch: 120; loss: 1.24; acc: 0.67
Batch: 140; loss: 0.5; acc: 0.84
Val Epoch over. val_loss: 0.7170847405673592; val_accuracy: 0.7821457006369427 

The current subspace-distance is: 9.610025699657854e-06 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.81; acc: 0.77
Batch: 20; loss: 0.87; acc: 0.7
Batch: 40; loss: 0.74; acc: 0.75
Batch: 60; loss: 0.83; acc: 0.83
Batch: 80; loss: 0.78; acc: 0.75
Batch: 100; loss: 0.71; acc: 0.8
Batch: 120; loss: 0.49; acc: 0.88
Batch: 140; loss: 0.72; acc: 0.73
Batch: 160; loss: 0.92; acc: 0.7
Batch: 180; loss: 0.66; acc: 0.84
Batch: 200; loss: 0.83; acc: 0.78
Batch: 220; loss: 0.79; acc: 0.72
Batch: 240; loss: 0.62; acc: 0.73
Batch: 260; loss: 0.74; acc: 0.75
Batch: 280; loss: 0.78; acc: 0.77
Batch: 300; loss: 0.8; acc: 0.77
Batch: 320; loss: 0.99; acc: 0.7
Batch: 340; loss: 1.12; acc: 0.73
Batch: 360; loss: 0.5; acc: 0.83
Batch: 380; loss: 0.68; acc: 0.77
Batch: 400; loss: 0.96; acc: 0.7
Batch: 420; loss: 0.72; acc: 0.78
Batch: 440; loss: 0.69; acc: 0.78
Batch: 460; loss: 0.9; acc: 0.73
Batch: 480; loss: 0.58; acc: 0.81
Batch: 500; loss: 0.69; acc: 0.78
Batch: 520; loss: 0.77; acc: 0.77
Batch: 540; loss: 1.02; acc: 0.72
Batch: 560; loss: 0.67; acc: 0.73
Batch: 580; loss: 0.7; acc: 0.75
Batch: 600; loss: 0.67; acc: 0.78
Batch: 620; loss: 0.67; acc: 0.81
Batch: 640; loss: 0.79; acc: 0.69
Batch: 660; loss: 0.73; acc: 0.73
Batch: 680; loss: 0.69; acc: 0.84
Batch: 700; loss: 0.82; acc: 0.72
Batch: 720; loss: 0.69; acc: 0.73
Batch: 740; loss: 0.69; acc: 0.78
Batch: 760; loss: 0.64; acc: 0.81
Batch: 780; loss: 0.96; acc: 0.69
Train Epoch over. train_loss: 0.75; train_accuracy: 0.77 

2.2515041564474814e-05
8.050094947975595e-06
Batch: 0; loss: 0.77; acc: 0.78
Batch: 20; loss: 0.9; acc: 0.73
Batch: 40; loss: 0.34; acc: 0.89
Batch: 60; loss: 0.89; acc: 0.75
Batch: 80; loss: 0.43; acc: 0.86
Batch: 100; loss: 0.49; acc: 0.84
Batch: 120; loss: 1.23; acc: 0.69
Batch: 140; loss: 0.49; acc: 0.84
Val Epoch over. val_loss: 0.7103836995780848; val_accuracy: 0.783937101910828 

The current subspace-distance is: 8.050094947975595e-06 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.46; acc: 0.89
Batch: 20; loss: 0.73; acc: 0.75
Batch: 40; loss: 0.74; acc: 0.72
Batch: 60; loss: 0.67; acc: 0.81
Batch: 80; loss: 0.58; acc: 0.83
Batch: 100; loss: 0.6; acc: 0.81
Batch: 120; loss: 0.73; acc: 0.78
Batch: 140; loss: 1.04; acc: 0.77
Batch: 160; loss: 0.66; acc: 0.77
Batch: 180; loss: 0.59; acc: 0.81
Batch: 200; loss: 0.77; acc: 0.73
Batch: 220; loss: 0.84; acc: 0.73
Batch: 240; loss: 0.84; acc: 0.7
Batch: 260; loss: 0.63; acc: 0.78
Batch: 280; loss: 0.73; acc: 0.7
Batch: 300; loss: 0.78; acc: 0.73
Batch: 320; loss: 0.78; acc: 0.78
Batch: 340; loss: 0.71; acc: 0.81
Batch: 360; loss: 0.6; acc: 0.81
Batch: 380; loss: 0.74; acc: 0.69
Batch: 400; loss: 0.56; acc: 0.83
Batch: 420; loss: 0.86; acc: 0.72
Batch: 440; loss: 0.77; acc: 0.73
Batch: 460; loss: 0.83; acc: 0.67
Batch: 480; loss: 0.71; acc: 0.75
Batch: 500; loss: 0.66; acc: 0.78
Batch: 520; loss: 0.54; acc: 0.81
Batch: 540; loss: 0.76; acc: 0.78
Batch: 560; loss: 0.96; acc: 0.75
Batch: 580; loss: 0.56; acc: 0.84
Batch: 600; loss: 1.21; acc: 0.61
Batch: 620; loss: 0.69; acc: 0.75
Batch: 640; loss: 0.72; acc: 0.78
Batch: 660; loss: 0.77; acc: 0.77
Batch: 680; loss: 0.89; acc: 0.72
Batch: 700; loss: 0.97; acc: 0.66
Batch: 720; loss: 0.56; acc: 0.8
Batch: 740; loss: 0.92; acc: 0.77
Batch: 760; loss: 0.79; acc: 0.75
Batch: 780; loss: 0.63; acc: 0.8
Train Epoch over. train_loss: 0.75; train_accuracy: 0.77 

2.4532504539820366e-05
7.750717486487702e-06
Batch: 0; loss: 0.76; acc: 0.81
Batch: 20; loss: 0.89; acc: 0.72
Batch: 40; loss: 0.35; acc: 0.89
Batch: 60; loss: 0.9; acc: 0.75
Batch: 80; loss: 0.44; acc: 0.88
Batch: 100; loss: 0.47; acc: 0.84
Batch: 120; loss: 1.22; acc: 0.69
Batch: 140; loss: 0.51; acc: 0.84
Val Epoch over. val_loss: 0.7149204723774247; val_accuracy: 0.783140923566879 

The current subspace-distance is: 7.750717486487702e-06 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.96; acc: 0.77
Batch: 20; loss: 0.71; acc: 0.81
Batch: 40; loss: 0.63; acc: 0.78
Batch: 60; loss: 0.59; acc: 0.83
Batch: 80; loss: 1.0; acc: 0.78
Batch: 100; loss: 0.96; acc: 0.75
Batch: 120; loss: 0.77; acc: 0.73
Batch: 140; loss: 0.57; acc: 0.83
Batch: 160; loss: 0.76; acc: 0.7
Batch: 180; loss: 0.67; acc: 0.75
Batch: 200; loss: 0.9; acc: 0.7
Batch: 220; loss: 0.85; acc: 0.72
Batch: 240; loss: 0.7; acc: 0.78
Batch: 260; loss: 0.97; acc: 0.77
Batch: 280; loss: 0.66; acc: 0.81
Batch: 300; loss: 0.8; acc: 0.72
Batch: 320; loss: 0.64; acc: 0.78
Batch: 340; loss: 0.82; acc: 0.72
Batch: 360; loss: 0.43; acc: 0.88
Batch: 380; loss: 0.69; acc: 0.73
Batch: 400; loss: 0.64; acc: 0.84
Batch: 420; loss: 0.69; acc: 0.81
Batch: 440; loss: 0.46; acc: 0.81
Batch: 460; loss: 0.5; acc: 0.86
Batch: 480; loss: 0.73; acc: 0.77
Batch: 500; loss: 0.73; acc: 0.83
Batch: 520; loss: 0.74; acc: 0.8
Batch: 540; loss: 0.57; acc: 0.83
Batch: 560; loss: 0.72; acc: 0.78
Batch: 580; loss: 0.83; acc: 0.75
Batch: 600; loss: 0.74; acc: 0.75
Batch: 620; loss: 0.89; acc: 0.7
Batch: 640; loss: 0.47; acc: 0.83
Batch: 660; loss: 0.52; acc: 0.8
Batch: 680; loss: 0.55; acc: 0.8
Batch: 700; loss: 0.83; acc: 0.61
Batch: 720; loss: 0.78; acc: 0.75
Batch: 740; loss: 0.83; acc: 0.77
Batch: 760; loss: 0.83; acc: 0.72
Batch: 780; loss: 0.71; acc: 0.78
Train Epoch over. train_loss: 0.75; train_accuracy: 0.77 

2.3310052711167373e-05
7.858016033424065e-06
Batch: 0; loss: 0.77; acc: 0.8
Batch: 20; loss: 0.9; acc: 0.7
Batch: 40; loss: 0.35; acc: 0.89
Batch: 60; loss: 0.9; acc: 0.75
Batch: 80; loss: 0.43; acc: 0.86
Batch: 100; loss: 0.49; acc: 0.83
Batch: 120; loss: 1.23; acc: 0.69
Batch: 140; loss: 0.51; acc: 0.83
Val Epoch over. val_loss: 0.7110107565761372; val_accuracy: 0.7837380573248408 

The current subspace-distance is: 7.858016033424065e-06 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.73; acc: 0.78
Batch: 20; loss: 0.56; acc: 0.81
Batch: 40; loss: 0.75; acc: 0.69
Batch: 60; loss: 0.96; acc: 0.73
Batch: 80; loss: 0.48; acc: 0.84
Batch: 100; loss: 0.95; acc: 0.7
Batch: 120; loss: 0.7; acc: 0.78
Batch: 140; loss: 0.78; acc: 0.77
Batch: 160; loss: 0.94; acc: 0.72
Batch: 180; loss: 0.79; acc: 0.77
Batch: 200; loss: 0.64; acc: 0.78
Batch: 220; loss: 0.5; acc: 0.89
Batch: 240; loss: 0.75; acc: 0.77
Batch: 260; loss: 0.64; acc: 0.8
Batch: 280; loss: 0.93; acc: 0.67
Batch: 300; loss: 1.04; acc: 0.75
Batch: 320; loss: 0.73; acc: 0.8
Batch: 340; loss: 0.98; acc: 0.7
Batch: 360; loss: 0.59; acc: 0.81
Batch: 380; loss: 0.72; acc: 0.77
Batch: 400; loss: 0.6; acc: 0.8
Batch: 420; loss: 0.71; acc: 0.84
Batch: 440; loss: 0.66; acc: 0.73
Batch: 460; loss: 0.84; acc: 0.75
Batch: 480; loss: 0.55; acc: 0.8
Batch: 500; loss: 0.78; acc: 0.73
Batch: 520; loss: 0.49; acc: 0.86
Batch: 540; loss: 0.58; acc: 0.84
Batch: 560; loss: 0.75; acc: 0.73
Batch: 580; loss: 0.83; acc: 0.75
Batch: 600; loss: 0.77; acc: 0.69
Batch: 620; loss: 0.73; acc: 0.73
Batch: 640; loss: 0.91; acc: 0.67
Batch: 660; loss: 0.68; acc: 0.81
Batch: 680; loss: 0.78; acc: 0.72
Batch: 700; loss: 0.8; acc: 0.72
Batch: 720; loss: 0.71; acc: 0.83
Batch: 740; loss: 0.96; acc: 0.73
Batch: 760; loss: 0.77; acc: 0.73
Batch: 780; loss: 0.63; acc: 0.77
Train Epoch over. train_loss: 0.75; train_accuracy: 0.77 

2.3898463041405194e-05
9.973909072868992e-06
Batch: 0; loss: 0.79; acc: 0.8
Batch: 20; loss: 0.89; acc: 0.75
Batch: 40; loss: 0.34; acc: 0.89
Batch: 60; loss: 0.9; acc: 0.75
Batch: 80; loss: 0.44; acc: 0.86
Batch: 100; loss: 0.47; acc: 0.88
Batch: 120; loss: 1.24; acc: 0.69
Batch: 140; loss: 0.5; acc: 0.83
Val Epoch over. val_loss: 0.7152288332106961; val_accuracy: 0.7840366242038217 

The current subspace-distance is: 9.973909072868992e-06 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.64; acc: 0.77
Batch: 20; loss: 0.67; acc: 0.8
Batch: 40; loss: 0.7; acc: 0.77
Batch: 60; loss: 1.11; acc: 0.66
Batch: 80; loss: 0.66; acc: 0.75
Batch: 100; loss: 0.9; acc: 0.78
Batch: 120; loss: 0.61; acc: 0.78
Batch: 140; loss: 0.69; acc: 0.8
Batch: 160; loss: 0.72; acc: 0.78
Batch: 180; loss: 0.72; acc: 0.73
Batch: 200; loss: 0.69; acc: 0.75
Batch: 220; loss: 0.8; acc: 0.75
Batch: 240; loss: 0.89; acc: 0.73
Batch: 260; loss: 0.69; acc: 0.78
Batch: 280; loss: 0.88; acc: 0.75
Batch: 300; loss: 0.7; acc: 0.78
Batch: 320; loss: 0.87; acc: 0.75
Batch: 340; loss: 0.72; acc: 0.75
Batch: 360; loss: 0.9; acc: 0.83
Batch: 380; loss: 0.93; acc: 0.69
Batch: 400; loss: 0.84; acc: 0.7
Batch: 420; loss: 0.69; acc: 0.8
Batch: 440; loss: 0.73; acc: 0.83
Batch: 460; loss: 0.74; acc: 0.75
Batch: 480; loss: 0.63; acc: 0.8
Batch: 500; loss: 0.43; acc: 0.88
Batch: 520; loss: 0.87; acc: 0.72
Batch: 540; loss: 0.68; acc: 0.81
Batch: 560; loss: 0.67; acc: 0.81
Batch: 580; loss: 1.1; acc: 0.7
Batch: 600; loss: 0.78; acc: 0.73
Batch: 620; loss: 0.69; acc: 0.78
Batch: 640; loss: 0.55; acc: 0.86
Batch: 660; loss: 0.64; acc: 0.75
Batch: 680; loss: 0.64; acc: 0.8
Batch: 700; loss: 0.62; acc: 0.81
Batch: 720; loss: 0.78; acc: 0.8
Batch: 740; loss: 0.81; acc: 0.75
Batch: 760; loss: 0.67; acc: 0.73
Batch: 780; loss: 0.82; acc: 0.72
Train Epoch over. train_loss: 0.75; train_accuracy: 0.77 

2.4046148610068485e-05
8.801082913123537e-06
Batch: 0; loss: 0.76; acc: 0.78
Batch: 20; loss: 0.88; acc: 0.72
Batch: 40; loss: 0.35; acc: 0.89
Batch: 60; loss: 0.9; acc: 0.75
Batch: 80; loss: 0.43; acc: 0.88
Batch: 100; loss: 0.48; acc: 0.84
Batch: 120; loss: 1.21; acc: 0.69
Batch: 140; loss: 0.5; acc: 0.84
Val Epoch over. val_loss: 0.7112031113949551; val_accuracy: 0.7843351910828026 

The current subspace-distance is: 8.801082913123537e-06 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.69; acc: 0.81
Batch: 20; loss: 0.98; acc: 0.75
Batch: 40; loss: 0.85; acc: 0.7
Batch: 60; loss: 0.58; acc: 0.84
Batch: 80; loss: 0.89; acc: 0.69
Batch: 100; loss: 0.72; acc: 0.73
Batch: 120; loss: 1.02; acc: 0.67
Batch: 140; loss: 0.63; acc: 0.8
Batch: 160; loss: 0.91; acc: 0.69
Batch: 180; loss: 0.81; acc: 0.75
Batch: 200; loss: 0.96; acc: 0.8
Batch: 220; loss: 0.74; acc: 0.78
Batch: 240; loss: 0.49; acc: 0.84
Batch: 260; loss: 0.72; acc: 0.81
Batch: 280; loss: 0.68; acc: 0.77
Batch: 300; loss: 1.01; acc: 0.72
Batch: 320; loss: 0.7; acc: 0.75
Batch: 340; loss: 0.6; acc: 0.83
Batch: 360; loss: 0.56; acc: 0.84
Batch: 380; loss: 0.71; acc: 0.73
Batch: 400; loss: 0.6; acc: 0.75
Batch: 420; loss: 0.69; acc: 0.75
Batch: 440; loss: 0.79; acc: 0.75
Batch: 460; loss: 0.55; acc: 0.81
Batch: 480; loss: 0.7; acc: 0.81
Batch: 500; loss: 0.86; acc: 0.69
Batch: 520; loss: 0.7; acc: 0.78
Batch: 540; loss: 0.86; acc: 0.75
Batch: 560; loss: 0.75; acc: 0.77
Batch: 580; loss: 0.72; acc: 0.77
Batch: 600; loss: 0.97; acc: 0.69
Batch: 620; loss: 0.57; acc: 0.8
Batch: 640; loss: 0.58; acc: 0.81
Batch: 660; loss: 0.95; acc: 0.66
Batch: 680; loss: 0.71; acc: 0.8
Batch: 700; loss: 0.65; acc: 0.83
Batch: 720; loss: 0.79; acc: 0.77
Batch: 740; loss: 0.6; acc: 0.8
Batch: 760; loss: 0.62; acc: 0.78
Batch: 780; loss: 0.89; acc: 0.69
Train Epoch over. train_loss: 0.75; train_accuracy: 0.77 

2.113894879585132e-05
9.156920896202791e-06
Batch: 0; loss: 0.76; acc: 0.78
Batch: 20; loss: 0.89; acc: 0.72
Batch: 40; loss: 0.35; acc: 0.89
Batch: 60; loss: 0.9; acc: 0.75
Batch: 80; loss: 0.43; acc: 0.88
Batch: 100; loss: 0.49; acc: 0.84
Batch: 120; loss: 1.22; acc: 0.69
Batch: 140; loss: 0.5; acc: 0.84
Val Epoch over. val_loss: 0.7113710078084545; val_accuracy: 0.7841361464968153 

The current subspace-distance is: 9.156920896202791e-06 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.66; acc: 0.8
Batch: 20; loss: 1.03; acc: 0.73
Batch: 40; loss: 0.96; acc: 0.75
Batch: 60; loss: 0.55; acc: 0.84
Batch: 80; loss: 0.71; acc: 0.8
Batch: 100; loss: 0.93; acc: 0.72
Batch: 120; loss: 0.78; acc: 0.77
Batch: 140; loss: 0.86; acc: 0.78
Batch: 160; loss: 0.56; acc: 0.8
Batch: 180; loss: 0.82; acc: 0.72
Batch: 200; loss: 0.7; acc: 0.86
Batch: 220; loss: 0.81; acc: 0.83
Batch: 240; loss: 0.98; acc: 0.7
Batch: 260; loss: 0.86; acc: 0.75
Batch: 280; loss: 0.9; acc: 0.7
Batch: 300; loss: 0.91; acc: 0.69
Batch: 320; loss: 0.89; acc: 0.69
Batch: 340; loss: 0.76; acc: 0.75
Batch: 360; loss: 0.73; acc: 0.75
Batch: 380; loss: 0.7; acc: 0.78
Batch: 400; loss: 0.54; acc: 0.83
Batch: 420; loss: 0.66; acc: 0.86
Batch: 440; loss: 0.59; acc: 0.88
Batch: 460; loss: 0.76; acc: 0.7
Batch: 480; loss: 0.61; acc: 0.84
Batch: 500; loss: 0.69; acc: 0.75
Batch: 520; loss: 1.15; acc: 0.69
Batch: 540; loss: 0.68; acc: 0.77
Batch: 560; loss: 0.47; acc: 0.86
Batch: 580; loss: 0.83; acc: 0.75
Batch: 600; loss: 0.58; acc: 0.78
Batch: 620; loss: 0.82; acc: 0.75
Batch: 640; loss: 0.62; acc: 0.75
Batch: 660; loss: 0.63; acc: 0.77
Batch: 680; loss: 0.68; acc: 0.77
Batch: 700; loss: 0.63; acc: 0.83
Batch: 720; loss: 0.66; acc: 0.78
Batch: 740; loss: 0.82; acc: 0.72
Batch: 760; loss: 0.86; acc: 0.69
Batch: 780; loss: 0.8; acc: 0.78
Train Epoch over. train_loss: 0.75; train_accuracy: 0.77 

2.4086331904982217e-05
9.599796612747014e-06
Batch: 0; loss: 0.76; acc: 0.81
Batch: 20; loss: 0.89; acc: 0.69
Batch: 40; loss: 0.35; acc: 0.89
Batch: 60; loss: 0.9; acc: 0.75
Batch: 80; loss: 0.43; acc: 0.88
Batch: 100; loss: 0.48; acc: 0.84
Batch: 120; loss: 1.22; acc: 0.69
Batch: 140; loss: 0.51; acc: 0.84
Val Epoch over. val_loss: 0.7112144789877971; val_accuracy: 0.7844347133757962 

The current subspace-distance is: 9.599796612747014e-06 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.77; acc: 0.72
Batch: 20; loss: 1.05; acc: 0.69
Batch: 40; loss: 0.63; acc: 0.8
Batch: 60; loss: 1.1; acc: 0.66
Batch: 80; loss: 0.71; acc: 0.78
Batch: 100; loss: 0.93; acc: 0.7
Batch: 120; loss: 0.79; acc: 0.78
Batch: 140; loss: 0.57; acc: 0.86
Batch: 160; loss: 0.78; acc: 0.8
Batch: 180; loss: 0.62; acc: 0.78
Batch: 200; loss: 0.84; acc: 0.78
Batch: 220; loss: 0.77; acc: 0.73
Batch: 240; loss: 0.85; acc: 0.77
Batch: 260; loss: 0.91; acc: 0.69
Batch: 280; loss: 0.84; acc: 0.78
Batch: 300; loss: 0.87; acc: 0.72
Batch: 320; loss: 0.78; acc: 0.73
Batch: 340; loss: 0.97; acc: 0.72
Batch: 360; loss: 0.67; acc: 0.77
Batch: 380; loss: 0.7; acc: 0.77
Batch: 400; loss: 1.17; acc: 0.67
Batch: 420; loss: 0.78; acc: 0.69
Batch: 440; loss: 0.9; acc: 0.75
Batch: 460; loss: 0.55; acc: 0.86
Batch: 480; loss: 0.66; acc: 0.8
Batch: 500; loss: 1.17; acc: 0.66
Batch: 520; loss: 0.76; acc: 0.83
Batch: 540; loss: 0.92; acc: 0.69
Batch: 560; loss: 0.67; acc: 0.77
Batch: 580; loss: 0.86; acc: 0.77
Batch: 600; loss: 0.57; acc: 0.84
Batch: 620; loss: 0.84; acc: 0.75
Batch: 640; loss: 0.88; acc: 0.75
Batch: 660; loss: 1.03; acc: 0.66
Batch: 680; loss: 0.76; acc: 0.81
Batch: 700; loss: 0.91; acc: 0.73
Batch: 720; loss: 0.7; acc: 0.72
Batch: 740; loss: 0.95; acc: 0.7
Batch: 760; loss: 0.69; acc: 0.81
Batch: 780; loss: 0.8; acc: 0.77
Train Epoch over. train_loss: 0.75; train_accuracy: 0.77 

2.4401233531534672e-05
8.669573617225979e-06
Batch: 0; loss: 0.76; acc: 0.8
Batch: 20; loss: 0.9; acc: 0.7
Batch: 40; loss: 0.35; acc: 0.89
Batch: 60; loss: 0.9; acc: 0.75
Batch: 80; loss: 0.44; acc: 0.86
Batch: 100; loss: 0.48; acc: 0.84
Batch: 120; loss: 1.22; acc: 0.69
Batch: 140; loss: 0.51; acc: 0.84
Val Epoch over. val_loss: 0.7104595692674066; val_accuracy: 0.7830414012738853 

The current subspace-distance is: 8.669573617225979e-06 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.78; acc: 0.75
Batch: 20; loss: 0.55; acc: 0.77
Batch: 40; loss: 0.57; acc: 0.8
Batch: 60; loss: 0.59; acc: 0.81
Batch: 80; loss: 0.75; acc: 0.78
Batch: 100; loss: 0.73; acc: 0.72
Batch: 120; loss: 1.07; acc: 0.67
Batch: 140; loss: 0.73; acc: 0.81
Batch: 160; loss: 0.51; acc: 0.84
Batch: 180; loss: 0.49; acc: 0.84
Batch: 200; loss: 0.73; acc: 0.77
Batch: 220; loss: 0.65; acc: 0.72
Batch: 240; loss: 0.87; acc: 0.7
Batch: 260; loss: 0.55; acc: 0.81
Batch: 280; loss: 0.91; acc: 0.72
Batch: 300; loss: 0.57; acc: 0.83
Batch: 320; loss: 0.76; acc: 0.78
Batch: 340; loss: 0.62; acc: 0.83
Batch: 360; loss: 0.91; acc: 0.75
Batch: 380; loss: 0.65; acc: 0.78
Batch: 400; loss: 0.66; acc: 0.81
Batch: 420; loss: 0.84; acc: 0.8
Batch: 440; loss: 0.85; acc: 0.77
Batch: 460; loss: 0.65; acc: 0.83
Batch: 480; loss: 0.71; acc: 0.8
Batch: 500; loss: 0.93; acc: 0.75
Batch: 520; loss: 0.53; acc: 0.78
Batch: 540; loss: 0.69; acc: 0.72
Batch: 560; loss: 0.47; acc: 0.84
Batch: 580; loss: 0.63; acc: 0.8
Batch: 600; loss: 0.76; acc: 0.83
Batch: 620; loss: 0.82; acc: 0.77
Batch: 640; loss: 0.63; acc: 0.8
Batch: 660; loss: 1.1; acc: 0.61
Batch: 680; loss: 1.09; acc: 0.69
Batch: 700; loss: 0.82; acc: 0.75
Batch: 720; loss: 0.95; acc: 0.78
Batch: 740; loss: 0.76; acc: 0.78
Batch: 760; loss: 0.88; acc: 0.75
Batch: 780; loss: 0.82; acc: 0.75
Train Epoch over. train_loss: 0.75; train_accuracy: 0.77 

2.116667019436136e-05
8.991715731099248e-06
Batch: 0; loss: 0.78; acc: 0.78
Batch: 20; loss: 0.89; acc: 0.7
Batch: 40; loss: 0.35; acc: 0.89
Batch: 60; loss: 0.89; acc: 0.75
Batch: 80; loss: 0.43; acc: 0.86
Batch: 100; loss: 0.48; acc: 0.84
Batch: 120; loss: 1.22; acc: 0.7
Batch: 140; loss: 0.49; acc: 0.84
Val Epoch over. val_loss: 0.7109932740023182; val_accuracy: 0.7859275477707006 

The current subspace-distance is: 8.991715731099248e-06 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.59; acc: 0.83
Batch: 20; loss: 0.71; acc: 0.73
Batch: 40; loss: 0.7; acc: 0.77
Batch: 60; loss: 0.76; acc: 0.75
Batch: 80; loss: 0.83; acc: 0.72
Batch: 100; loss: 0.68; acc: 0.77
Batch: 120; loss: 1.04; acc: 0.69
Batch: 140; loss: 0.78; acc: 0.69
Batch: 160; loss: 0.88; acc: 0.73
Batch: 180; loss: 0.75; acc: 0.67
Batch: 200; loss: 0.7; acc: 0.77
Batch: 220; loss: 0.79; acc: 0.8
Batch: 240; loss: 0.73; acc: 0.78
Batch: 260; loss: 0.72; acc: 0.78
Batch: 280; loss: 0.76; acc: 0.77
Batch: 300; loss: 0.79; acc: 0.77
Batch: 320; loss: 0.99; acc: 0.73
Batch: 340; loss: 0.82; acc: 0.72
Batch: 360; loss: 0.95; acc: 0.75
Batch: 380; loss: 0.89; acc: 0.67
Batch: 400; loss: 0.72; acc: 0.78
Batch: 420; loss: 0.95; acc: 0.67
Batch: 440; loss: 1.03; acc: 0.69
Batch: 460; loss: 0.78; acc: 0.83
Batch: 480; loss: 0.76; acc: 0.73
Batch: 500; loss: 0.68; acc: 0.81
Batch: 520; loss: 0.75; acc: 0.75
Batch: 540; loss: 1.17; acc: 0.75
Batch: 560; loss: 0.77; acc: 0.78
Batch: 580; loss: 1.08; acc: 0.66
Batch: 600; loss: 0.76; acc: 0.81
Batch: 620; loss: 1.25; acc: 0.69
Batch: 640; loss: 0.72; acc: 0.81
Batch: 660; loss: 0.7; acc: 0.73
Batch: 680; loss: 0.83; acc: 0.78
Batch: 700; loss: 0.7; acc: 0.78
Batch: 720; loss: 0.98; acc: 0.72
Batch: 740; loss: 0.88; acc: 0.75
Batch: 760; loss: 0.84; acc: 0.69
Batch: 780; loss: 0.61; acc: 0.91
Train Epoch over. train_loss: 0.75; train_accuracy: 0.77 

2.5183811885653995e-05
9.310737368650734e-06
Batch: 0; loss: 0.76; acc: 0.8
Batch: 20; loss: 0.89; acc: 0.7
Batch: 40; loss: 0.35; acc: 0.89
Batch: 60; loss: 0.89; acc: 0.75
Batch: 80; loss: 0.43; acc: 0.88
Batch: 100; loss: 0.48; acc: 0.84
Batch: 120; loss: 1.21; acc: 0.7
Batch: 140; loss: 0.5; acc: 0.84
Val Epoch over. val_loss: 0.7128552397724929; val_accuracy: 0.7830414012738853 

The current subspace-distance is: 9.310737368650734e-06 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.72; acc: 0.78
Batch: 20; loss: 0.8; acc: 0.75
Batch: 40; loss: 0.83; acc: 0.73
Batch: 60; loss: 0.85; acc: 0.73
Batch: 80; loss: 0.81; acc: 0.7
Batch: 100; loss: 0.9; acc: 0.75
Batch: 120; loss: 0.77; acc: 0.72
Batch: 140; loss: 1.13; acc: 0.64
Batch: 160; loss: 0.74; acc: 0.81
Batch: 180; loss: 0.87; acc: 0.73
Batch: 200; loss: 0.87; acc: 0.73
Batch: 220; loss: 0.6; acc: 0.83
Batch: 240; loss: 0.53; acc: 0.83
Batch: 260; loss: 0.87; acc: 0.7
Batch: 280; loss: 0.42; acc: 0.88
Batch: 300; loss: 0.5; acc: 0.78
Batch: 320; loss: 0.95; acc: 0.69
Batch: 340; loss: 0.8; acc: 0.77
Batch: 360; loss: 0.93; acc: 0.7
Batch: 380; loss: 0.62; acc: 0.81
Batch: 400; loss: 0.48; acc: 0.84
Batch: 420; loss: 0.55; acc: 0.78
Batch: 440; loss: 0.77; acc: 0.7
Batch: 460; loss: 0.81; acc: 0.75
Batch: 480; loss: 0.8; acc: 0.69
Batch: 500; loss: 0.79; acc: 0.73
Batch: 520; loss: 0.59; acc: 0.84
Batch: 540; loss: 0.66; acc: 0.78
Batch: 560; loss: 0.71; acc: 0.77
Batch: 580; loss: 0.62; acc: 0.8
Batch: 600; loss: 0.43; acc: 0.86
Batch: 620; loss: 0.71; acc: 0.78
Batch: 640; loss: 0.77; acc: 0.77
Batch: 660; loss: 0.72; acc: 0.8
Batch: 680; loss: 0.77; acc: 0.75
Batch: 700; loss: 0.78; acc: 0.73
Batch: 720; loss: 0.72; acc: 0.81
Batch: 740; loss: 0.76; acc: 0.75
Batch: 760; loss: 0.83; acc: 0.73
Batch: 780; loss: 0.67; acc: 0.78
Train Epoch over. train_loss: 0.75; train_accuracy: 0.77 

2.2785434339311905e-05
9.206901268044021e-06
Batch: 0; loss: 0.78; acc: 0.8
Batch: 20; loss: 0.89; acc: 0.73
Batch: 40; loss: 0.35; acc: 0.89
Batch: 60; loss: 0.89; acc: 0.75
Batch: 80; loss: 0.44; acc: 0.84
Batch: 100; loss: 0.47; acc: 0.84
Batch: 120; loss: 1.22; acc: 0.69
Batch: 140; loss: 0.49; acc: 0.84
Val Epoch over. val_loss: 0.7106543259256205; val_accuracy: 0.7854299363057324 

The current subspace-distance is: 9.206901268044021e-06 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.42; acc: 0.91
Batch: 20; loss: 0.83; acc: 0.7
Batch: 40; loss: 0.57; acc: 0.83
Batch: 60; loss: 0.97; acc: 0.72
Batch: 80; loss: 0.79; acc: 0.73
Batch: 100; loss: 0.66; acc: 0.81
Batch: 120; loss: 0.8; acc: 0.78
Batch: 140; loss: 0.77; acc: 0.73
Batch: 160; loss: 0.74; acc: 0.75
Batch: 180; loss: 1.08; acc: 0.67
Batch: 200; loss: 0.87; acc: 0.75
Batch: 220; loss: 0.56; acc: 0.86
Batch: 240; loss: 0.66; acc: 0.77
Batch: 260; loss: 0.87; acc: 0.7
Batch: 280; loss: 0.8; acc: 0.78
Batch: 300; loss: 0.54; acc: 0.84
Batch: 320; loss: 0.79; acc: 0.73
Batch: 340; loss: 0.65; acc: 0.81
Batch: 360; loss: 0.75; acc: 0.75
Batch: 380; loss: 0.66; acc: 0.81
Batch: 400; loss: 0.75; acc: 0.75
Batch: 420; loss: 0.58; acc: 0.83
Batch: 440; loss: 0.66; acc: 0.73
Batch: 460; loss: 0.66; acc: 0.77
Batch: 480; loss: 0.89; acc: 0.69
Batch: 500; loss: 0.99; acc: 0.73
Batch: 520; loss: 0.67; acc: 0.78
Batch: 540; loss: 1.01; acc: 0.72
Batch: 560; loss: 0.87; acc: 0.75
Batch: 580; loss: 0.51; acc: 0.83
Batch: 600; loss: 0.65; acc: 0.78
Batch: 620; loss: 0.51; acc: 0.86
Batch: 640; loss: 0.5; acc: 0.81
Batch: 660; loss: 0.63; acc: 0.78
Batch: 680; loss: 0.66; acc: 0.78
Batch: 700; loss: 0.64; acc: 0.81
Batch: 720; loss: 0.64; acc: 0.83
Batch: 740; loss: 0.74; acc: 0.77
Batch: 760; loss: 0.94; acc: 0.7
Batch: 780; loss: 0.85; acc: 0.81
Train Epoch over. train_loss: 0.75; train_accuracy: 0.77 

2.3020835214992985e-05
8.976956451078877e-06
Batch: 0; loss: 0.76; acc: 0.81
Batch: 20; loss: 0.89; acc: 0.7
Batch: 40; loss: 0.35; acc: 0.89
Batch: 60; loss: 0.89; acc: 0.75
Batch: 80; loss: 0.43; acc: 0.88
Batch: 100; loss: 0.48; acc: 0.84
Batch: 120; loss: 1.21; acc: 0.69
Batch: 140; loss: 0.51; acc: 0.84
Val Epoch over. val_loss: 0.7129146842060575; val_accuracy: 0.783140923566879 

The current subspace-distance is: 8.976956451078877e-06 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.68; acc: 0.77
Batch: 20; loss: 0.74; acc: 0.77
Batch: 40; loss: 0.78; acc: 0.75
Batch: 60; loss: 0.75; acc: 0.77
Batch: 80; loss: 0.85; acc: 0.72
Batch: 100; loss: 0.63; acc: 0.83
Batch: 120; loss: 0.6; acc: 0.8
Batch: 140; loss: 0.97; acc: 0.7
Batch: 160; loss: 1.1; acc: 0.64
Batch: 180; loss: 0.58; acc: 0.78
Batch: 200; loss: 0.76; acc: 0.75
Batch: 220; loss: 0.9; acc: 0.73
Batch: 240; loss: 0.77; acc: 0.75
Batch: 260; loss: 0.62; acc: 0.78
Batch: 280; loss: 0.83; acc: 0.77
Batch: 300; loss: 0.74; acc: 0.75
Batch: 320; loss: 0.66; acc: 0.72
Batch: 340; loss: 0.77; acc: 0.83
Batch: 360; loss: 0.93; acc: 0.66
Batch: 380; loss: 0.74; acc: 0.78
Batch: 400; loss: 0.64; acc: 0.75
Batch: 420; loss: 0.67; acc: 0.78
Batch: 440; loss: 0.55; acc: 0.78
Batch: 460; loss: 0.78; acc: 0.75
Batch: 480; loss: 0.8; acc: 0.78
Batch: 500; loss: 0.94; acc: 0.72
Batch: 520; loss: 0.62; acc: 0.8
Batch: 540; loss: 1.06; acc: 0.64
Batch: 560; loss: 0.68; acc: 0.8
Batch: 580; loss: 0.56; acc: 0.8
Batch: 600; loss: 0.76; acc: 0.78
Batch: 620; loss: 0.58; acc: 0.83
Batch: 640; loss: 0.84; acc: 0.77
Batch: 660; loss: 0.56; acc: 0.8
Batch: 680; loss: 0.73; acc: 0.77
Batch: 700; loss: 0.68; acc: 0.77
Batch: 720; loss: 0.72; acc: 0.8
Batch: 740; loss: 0.78; acc: 0.72
Batch: 760; loss: 0.95; acc: 0.75
Batch: 780; loss: 0.64; acc: 0.83
Train Epoch over. train_loss: 0.75; train_accuracy: 0.77 

2.567330011515878e-05
6.991218469920568e-06
Batch: 0; loss: 0.77; acc: 0.78
Batch: 20; loss: 0.9; acc: 0.72
Batch: 40; loss: 0.35; acc: 0.89
Batch: 60; loss: 0.89; acc: 0.75
Batch: 80; loss: 0.43; acc: 0.84
Batch: 100; loss: 0.48; acc: 0.84
Batch: 120; loss: 1.23; acc: 0.7
Batch: 140; loss: 0.49; acc: 0.84
Val Epoch over. val_loss: 0.7101233761022046; val_accuracy: 0.7849323248407644 

The current subspace-distance is: 6.991218469920568e-06 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.76; acc: 0.78
Batch: 20; loss: 0.7; acc: 0.8
Batch: 40; loss: 0.72; acc: 0.8
Batch: 60; loss: 0.66; acc: 0.72
Batch: 80; loss: 0.67; acc: 0.8
Batch: 100; loss: 0.98; acc: 0.72
Batch: 120; loss: 0.83; acc: 0.8
Batch: 140; loss: 0.63; acc: 0.8
Batch: 160; loss: 0.62; acc: 0.83
Batch: 180; loss: 0.77; acc: 0.78
Batch: 200; loss: 0.82; acc: 0.72
Batch: 220; loss: 0.74; acc: 0.75
Batch: 240; loss: 0.8; acc: 0.8
Batch: 260; loss: 0.68; acc: 0.81
Batch: 280; loss: 0.71; acc: 0.81
Batch: 300; loss: 0.93; acc: 0.73
Batch: 320; loss: 0.54; acc: 0.75
Batch: 340; loss: 0.8; acc: 0.73
Batch: 360; loss: 0.83; acc: 0.72
Batch: 380; loss: 0.74; acc: 0.77
Batch: 400; loss: 0.77; acc: 0.77
Batch: 420; loss: 0.72; acc: 0.7
Batch: 440; loss: 0.67; acc: 0.8
Batch: 460; loss: 0.74; acc: 0.8
Batch: 480; loss: 0.95; acc: 0.72
Batch: 500; loss: 0.53; acc: 0.86
Batch: 520; loss: 1.0; acc: 0.69
Batch: 540; loss: 0.74; acc: 0.78
Batch: 560; loss: 0.78; acc: 0.77
Batch: 580; loss: 0.66; acc: 0.78
Batch: 600; loss: 1.03; acc: 0.69
Batch: 620; loss: 0.64; acc: 0.8
Batch: 640; loss: 0.81; acc: 0.72
Batch: 660; loss: 0.63; acc: 0.8
Batch: 680; loss: 0.69; acc: 0.75
Batch: 700; loss: 0.67; acc: 0.8
Batch: 720; loss: 0.5; acc: 0.88
Batch: 740; loss: 0.9; acc: 0.72
Batch: 760; loss: 0.76; acc: 0.73
Batch: 780; loss: 0.73; acc: 0.77
Train Epoch over. train_loss: 0.75; train_accuracy: 0.77 

2.46881627390394e-05
8.4997336671222e-06
Batch: 0; loss: 0.77; acc: 0.78
Batch: 20; loss: 0.89; acc: 0.72
Batch: 40; loss: 0.35; acc: 0.89
Batch: 60; loss: 0.89; acc: 0.75
Batch: 80; loss: 0.43; acc: 0.86
Batch: 100; loss: 0.48; acc: 0.86
Batch: 120; loss: 1.22; acc: 0.7
Batch: 140; loss: 0.49; acc: 0.84
Val Epoch over. val_loss: 0.71022577080757; val_accuracy: 0.7860270700636943 

The current subspace-distance is: 8.4997336671222e-06 

plots/subspace_training/reg_lenet_3/2020-01-22 20:51:04/d_dim_75_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
nonzero elements in E: 20966
elements in E: 4499000
fraction nonzero: 0.004660146699266504
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.31; acc: 0.08
Batch: 20; loss: 2.29; acc: 0.03
Batch: 40; loss: 2.3; acc: 0.11
Batch: 60; loss: 2.3; acc: 0.02
Batch: 80; loss: 2.3; acc: 0.08
Batch: 100; loss: 2.3; acc: 0.11
Batch: 120; loss: 2.31; acc: 0.11
Batch: 140; loss: 2.32; acc: 0.08
Batch: 160; loss: 2.3; acc: 0.08
Batch: 180; loss: 2.3; acc: 0.11
Batch: 200; loss: 2.3; acc: 0.14
Batch: 220; loss: 2.31; acc: 0.06
Batch: 240; loss: 2.31; acc: 0.05
Batch: 260; loss: 2.3; acc: 0.09
Batch: 280; loss: 2.29; acc: 0.06
Batch: 300; loss: 2.3; acc: 0.05
Batch: 320; loss: 2.31; acc: 0.08
Batch: 340; loss: 2.3; acc: 0.06
Batch: 360; loss: 2.29; acc: 0.16
Batch: 380; loss: 2.3; acc: 0.11
Batch: 400; loss: 2.31; acc: 0.14
Batch: 420; loss: 2.31; acc: 0.06
Batch: 440; loss: 2.29; acc: 0.2
Batch: 460; loss: 2.31; acc: 0.14
Batch: 480; loss: 2.3; acc: 0.09
Batch: 500; loss: 2.3; acc: 0.09
Batch: 520; loss: 2.27; acc: 0.23
Batch: 540; loss: 2.29; acc: 0.16
Batch: 560; loss: 2.29; acc: 0.22
Batch: 580; loss: 2.28; acc: 0.16
Batch: 600; loss: 2.29; acc: 0.17
Batch: 620; loss: 2.28; acc: 0.2
Batch: 640; loss: 2.28; acc: 0.22
Batch: 660; loss: 2.28; acc: 0.17
Batch: 680; loss: 2.3; acc: 0.09
Batch: 700; loss: 2.29; acc: 0.16
Batch: 720; loss: 2.31; acc: 0.09
Batch: 740; loss: 2.28; acc: 0.19
Batch: 760; loss: 2.29; acc: 0.09
Batch: 780; loss: 2.29; acc: 0.23
Train Epoch over. train_loss: 2.3; train_accuracy: 0.12 

4.868028554483317e-06
8.700034754838271e-07
Batch: 0; loss: 2.28; acc: 0.16
Batch: 20; loss: 2.27; acc: 0.27
Batch: 40; loss: 2.28; acc: 0.22
Batch: 60; loss: 2.27; acc: 0.3
Batch: 80; loss: 2.27; acc: 0.22
Batch: 100; loss: 2.28; acc: 0.25
Batch: 120; loss: 2.28; acc: 0.16
Batch: 140; loss: 2.29; acc: 0.2
Val Epoch over. val_loss: 2.282389159415178; val_accuracy: 0.1916799363057325 

The current subspace-distance is: 8.700034754838271e-07 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 2.29; acc: 0.14
Batch: 20; loss: 2.29; acc: 0.17
Batch: 40; loss: 2.29; acc: 0.14
Batch: 60; loss: 2.26; acc: 0.28
Batch: 80; loss: 2.27; acc: 0.14
Batch: 100; loss: 2.29; acc: 0.17
Batch: 120; loss: 2.25; acc: 0.23
Batch: 140; loss: 2.28; acc: 0.23
Batch: 160; loss: 2.27; acc: 0.23
Batch: 180; loss: 2.26; acc: 0.16
Batch: 200; loss: 2.26; acc: 0.19
Batch: 220; loss: 2.26; acc: 0.12
Batch: 240; loss: 2.24; acc: 0.19
Batch: 260; loss: 2.27; acc: 0.09
Batch: 280; loss: 2.24; acc: 0.17
Batch: 300; loss: 2.26; acc: 0.09
Batch: 320; loss: 2.24; acc: 0.08
Batch: 340; loss: 2.22; acc: 0.12
Batch: 360; loss: 2.16; acc: 0.19
Batch: 380; loss: 2.21; acc: 0.22
Batch: 400; loss: 2.22; acc: 0.12
Batch: 420; loss: 2.17; acc: 0.2
Batch: 440; loss: 2.23; acc: 0.16
Batch: 460; loss: 2.16; acc: 0.27
Batch: 480; loss: 2.18; acc: 0.3
Batch: 500; loss: 2.11; acc: 0.39
Batch: 520; loss: 2.12; acc: 0.34
Batch: 540; loss: 2.11; acc: 0.34
Batch: 560; loss: 2.05; acc: 0.42
Batch: 580; loss: 2.05; acc: 0.34
Batch: 600; loss: 1.94; acc: 0.39
Batch: 620; loss: 1.88; acc: 0.45
Batch: 640; loss: 1.89; acc: 0.39
Batch: 660; loss: 1.77; acc: 0.44
Batch: 680; loss: 1.58; acc: 0.42
Batch: 700; loss: 1.59; acc: 0.48
Batch: 720; loss: 1.5; acc: 0.52
Batch: 740; loss: 1.49; acc: 0.48
Batch: 760; loss: 1.59; acc: 0.47
Batch: 780; loss: 1.31; acc: 0.58
Train Epoch over. train_loss: 2.08; train_accuracy: 0.28 

9.528374903311487e-06
4.3885775085072964e-06
Batch: 0; loss: 1.44; acc: 0.52
Batch: 20; loss: 1.67; acc: 0.41
Batch: 40; loss: 1.03; acc: 0.62
Batch: 60; loss: 1.19; acc: 0.59
Batch: 80; loss: 1.19; acc: 0.67
Batch: 100; loss: 1.25; acc: 0.61
Batch: 120; loss: 1.49; acc: 0.52
Batch: 140; loss: 1.42; acc: 0.5
Val Epoch over. val_loss: 1.342180231953882; val_accuracy: 0.5710589171974523 

The current subspace-distance is: 4.3885775085072964e-06 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 1.49; acc: 0.55
Batch: 20; loss: 1.25; acc: 0.59
Batch: 40; loss: 1.13; acc: 0.64
Batch: 60; loss: 1.28; acc: 0.53
Batch: 80; loss: 1.27; acc: 0.58
Batch: 100; loss: 1.45; acc: 0.53
Batch: 120; loss: 1.22; acc: 0.53
Batch: 140; loss: 1.43; acc: 0.55
Batch: 160; loss: 0.97; acc: 0.77
Batch: 180; loss: 1.03; acc: 0.66
Batch: 200; loss: 1.23; acc: 0.64
Batch: 220; loss: 1.2; acc: 0.59
Batch: 240; loss: 1.34; acc: 0.59
Batch: 260; loss: 1.03; acc: 0.64
Batch: 280; loss: 1.04; acc: 0.66
Batch: 300; loss: 0.86; acc: 0.73
Batch: 320; loss: 0.99; acc: 0.7
Batch: 340; loss: 0.92; acc: 0.75
Batch: 360; loss: 1.01; acc: 0.72
Batch: 380; loss: 0.87; acc: 0.8
Batch: 400; loss: 1.21; acc: 0.55
Batch: 420; loss: 0.93; acc: 0.66
Batch: 440; loss: 0.84; acc: 0.69
Batch: 460; loss: 1.24; acc: 0.56
Batch: 480; loss: 1.09; acc: 0.69
Batch: 500; loss: 0.96; acc: 0.7
Batch: 520; loss: 0.79; acc: 0.72
Batch: 540; loss: 1.05; acc: 0.7
Batch: 560; loss: 1.15; acc: 0.64
Batch: 580; loss: 0.98; acc: 0.73
Batch: 600; loss: 0.87; acc: 0.72
Batch: 620; loss: 1.17; acc: 0.67
Batch: 640; loss: 0.92; acc: 0.72
Batch: 660; loss: 1.12; acc: 0.7
Batch: 680; loss: 1.1; acc: 0.72
Batch: 700; loss: 0.88; acc: 0.69
Batch: 720; loss: 0.76; acc: 0.75
Batch: 740; loss: 1.17; acc: 0.69
Batch: 760; loss: 1.04; acc: 0.7
Batch: 780; loss: 1.01; acc: 0.69
Train Epoch over. train_loss: 1.06; train_accuracy: 0.67 

1.882738433778286e-05
6.384329935826827e-06
Batch: 0; loss: 0.79; acc: 0.73
Batch: 20; loss: 1.17; acc: 0.66
Batch: 40; loss: 0.4; acc: 0.86
Batch: 60; loss: 0.9; acc: 0.72
Batch: 80; loss: 0.64; acc: 0.8
Batch: 100; loss: 0.64; acc: 0.84
Batch: 120; loss: 1.01; acc: 0.66
Batch: 140; loss: 0.84; acc: 0.69
Val Epoch over. val_loss: 0.9071749467758616; val_accuracy: 0.7234275477707006 

The current subspace-distance is: 6.384329935826827e-06 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.81; acc: 0.72
Batch: 20; loss: 1.02; acc: 0.69
Batch: 40; loss: 1.01; acc: 0.73
Batch: 60; loss: 0.86; acc: 0.77
Batch: 80; loss: 0.7; acc: 0.8
Batch: 100; loss: 0.59; acc: 0.8
Batch: 120; loss: 1.04; acc: 0.67
Batch: 140; loss: 0.82; acc: 0.75
Batch: 160; loss: 0.74; acc: 0.81
Batch: 180; loss: 0.84; acc: 0.73
Batch: 200; loss: 0.86; acc: 0.77
Batch: 220; loss: 1.07; acc: 0.8
Batch: 240; loss: 0.99; acc: 0.69
Batch: 260; loss: 0.86; acc: 0.75
Batch: 280; loss: 1.07; acc: 0.77
Batch: 300; loss: 1.24; acc: 0.69
Batch: 320; loss: 0.85; acc: 0.7
Batch: 340; loss: 0.96; acc: 0.69
Batch: 360; loss: 0.79; acc: 0.73
Batch: 380; loss: 0.7; acc: 0.81
Batch: 400; loss: 0.82; acc: 0.75
Batch: 420; loss: 0.94; acc: 0.73
Batch: 440; loss: 0.54; acc: 0.88
Batch: 460; loss: 0.57; acc: 0.84
Batch: 480; loss: 0.91; acc: 0.69
Batch: 500; loss: 0.76; acc: 0.75
Batch: 520; loss: 0.74; acc: 0.73
Batch: 540; loss: 0.7; acc: 0.75
Batch: 560; loss: 0.93; acc: 0.7
Batch: 580; loss: 0.87; acc: 0.72
Batch: 600; loss: 0.7; acc: 0.72
Batch: 620; loss: 0.96; acc: 0.73
Batch: 640; loss: 1.38; acc: 0.55
Batch: 660; loss: 0.82; acc: 0.81
Batch: 680; loss: 0.99; acc: 0.77
Batch: 700; loss: 0.78; acc: 0.73
Batch: 720; loss: 0.92; acc: 0.72
Batch: 740; loss: 0.66; acc: 0.83
Batch: 760; loss: 0.73; acc: 0.83
Batch: 780; loss: 0.83; acc: 0.7
Train Epoch over. train_loss: 0.85; train_accuracy: 0.74 

2.1275956896715797e-05
6.33803438176983e-06
Batch: 0; loss: 0.56; acc: 0.77
Batch: 20; loss: 0.7; acc: 0.81
Batch: 40; loss: 0.31; acc: 0.91
Batch: 60; loss: 0.73; acc: 0.77
Batch: 80; loss: 0.42; acc: 0.88
Batch: 100; loss: 0.57; acc: 0.84
Batch: 120; loss: 0.82; acc: 0.75
Batch: 140; loss: 0.53; acc: 0.83
Val Epoch over. val_loss: 0.6927017723299136; val_accuracy: 0.790406050955414 

The current subspace-distance is: 6.33803438176983e-06 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.8; acc: 0.77
Batch: 20; loss: 0.75; acc: 0.77
Batch: 40; loss: 0.64; acc: 0.73
Batch: 60; loss: 0.83; acc: 0.73
Batch: 80; loss: 0.83; acc: 0.72
Batch: 100; loss: 0.8; acc: 0.83
Batch: 120; loss: 0.63; acc: 0.77
Batch: 140; loss: 1.09; acc: 0.7
Batch: 160; loss: 0.42; acc: 0.89
Batch: 180; loss: 0.51; acc: 0.86
Batch: 200; loss: 0.59; acc: 0.83
Batch: 220; loss: 1.01; acc: 0.78
Batch: 240; loss: 0.61; acc: 0.8
Batch: 260; loss: 0.86; acc: 0.69
Batch: 280; loss: 0.77; acc: 0.77
Batch: 300; loss: 0.66; acc: 0.8
Batch: 320; loss: 0.67; acc: 0.78
Batch: 340; loss: 0.49; acc: 0.88
Batch: 360; loss: 0.85; acc: 0.67
Batch: 380; loss: 0.37; acc: 0.91
Batch: 400; loss: 0.66; acc: 0.81
Batch: 420; loss: 0.73; acc: 0.75
Batch: 440; loss: 0.83; acc: 0.73
Batch: 460; loss: 0.69; acc: 0.81
Batch: 480; loss: 1.17; acc: 0.61
Batch: 500; loss: 0.79; acc: 0.78
Batch: 520; loss: 0.6; acc: 0.78
Batch: 540; loss: 0.5; acc: 0.86
Batch: 560; loss: 0.93; acc: 0.7
Batch: 580; loss: 0.88; acc: 0.81
Batch: 600; loss: 0.69; acc: 0.78
Batch: 620; loss: 0.61; acc: 0.8
Batch: 640; loss: 0.77; acc: 0.8
Batch: 660; loss: 1.37; acc: 0.66
Batch: 680; loss: 0.57; acc: 0.84
Batch: 700; loss: 0.49; acc: 0.8
Batch: 720; loss: 0.36; acc: 0.88
Batch: 740; loss: 0.55; acc: 0.83
Batch: 760; loss: 0.56; acc: 0.81
Batch: 780; loss: 0.77; acc: 0.81
Train Epoch over. train_loss: 0.73; train_accuracy: 0.78 

2.3583483198308386e-05
9.012942427943926e-06
Batch: 0; loss: 0.61; acc: 0.84
Batch: 20; loss: 0.58; acc: 0.81
Batch: 40; loss: 0.3; acc: 0.89
Batch: 60; loss: 0.65; acc: 0.73
Batch: 80; loss: 0.46; acc: 0.88
Batch: 100; loss: 0.48; acc: 0.88
Batch: 120; loss: 0.86; acc: 0.7
Batch: 140; loss: 0.48; acc: 0.86
Val Epoch over. val_loss: 0.6145282858496259; val_accuracy: 0.8115047770700637 

The current subspace-distance is: 9.012942427943926e-06 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.73; acc: 0.78
Batch: 20; loss: 0.58; acc: 0.78
Batch: 40; loss: 0.93; acc: 0.73
Batch: 60; loss: 0.86; acc: 0.77
Batch: 80; loss: 0.61; acc: 0.81
Batch: 100; loss: 0.73; acc: 0.73
Batch: 120; loss: 0.69; acc: 0.81
Batch: 140; loss: 0.85; acc: 0.72
Batch: 160; loss: 1.02; acc: 0.7
Batch: 180; loss: 0.82; acc: 0.73
Batch: 200; loss: 0.76; acc: 0.78
Batch: 220; loss: 0.54; acc: 0.91
Batch: 240; loss: 0.57; acc: 0.83
Batch: 260; loss: 0.82; acc: 0.77
Batch: 280; loss: 0.61; acc: 0.83
Batch: 300; loss: 0.87; acc: 0.72
Batch: 320; loss: 0.62; acc: 0.83
Batch: 340; loss: 0.52; acc: 0.89
Batch: 360; loss: 0.98; acc: 0.7
Batch: 380; loss: 0.95; acc: 0.69
Batch: 400; loss: 0.68; acc: 0.75
Batch: 420; loss: 0.43; acc: 0.89
Batch: 440; loss: 0.5; acc: 0.88
Batch: 460; loss: 0.71; acc: 0.78
Batch: 480; loss: 0.56; acc: 0.8
Batch: 500; loss: 0.91; acc: 0.73
Batch: 520; loss: 0.87; acc: 0.75
Batch: 540; loss: 0.71; acc: 0.8
Batch: 560; loss: 0.57; acc: 0.86
Batch: 580; loss: 0.65; acc: 0.78
Batch: 600; loss: 0.69; acc: 0.77
Batch: 620; loss: 0.37; acc: 0.91
Batch: 640; loss: 0.45; acc: 0.86
Batch: 660; loss: 1.21; acc: 0.66
Batch: 680; loss: 0.35; acc: 0.91
Batch: 700; loss: 0.44; acc: 0.91
Batch: 720; loss: 0.75; acc: 0.77
Batch: 740; loss: 0.53; acc: 0.83
Batch: 760; loss: 0.62; acc: 0.81
Batch: 780; loss: 0.39; acc: 0.91
Train Epoch over. train_loss: 0.67; train_accuracy: 0.79 

2.17203614738537e-05
7.68357676861342e-06
Batch: 0; loss: 0.76; acc: 0.69
Batch: 20; loss: 0.86; acc: 0.77
Batch: 40; loss: 0.37; acc: 0.84
Batch: 60; loss: 0.53; acc: 0.83
Batch: 80; loss: 0.48; acc: 0.88
Batch: 100; loss: 0.69; acc: 0.81
Batch: 120; loss: 1.03; acc: 0.7
Batch: 140; loss: 0.41; acc: 0.88
Val Epoch over. val_loss: 0.6398775708523525; val_accuracy: 0.8020501592356688 

The current subspace-distance is: 7.68357676861342e-06 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.67; acc: 0.86
Batch: 20; loss: 0.33; acc: 0.88
Batch: 40; loss: 0.92; acc: 0.69
Batch: 60; loss: 1.08; acc: 0.72
Batch: 80; loss: 0.43; acc: 0.89
Batch: 100; loss: 0.69; acc: 0.86
Batch: 120; loss: 0.64; acc: 0.81
Batch: 140; loss: 0.69; acc: 0.8
Batch: 160; loss: 0.83; acc: 0.73
Batch: 180; loss: 0.62; acc: 0.8
Batch: 200; loss: 0.77; acc: 0.78
Batch: 220; loss: 0.63; acc: 0.8
Batch: 240; loss: 0.69; acc: 0.81
Batch: 260; loss: 0.6; acc: 0.81
Batch: 280; loss: 0.76; acc: 0.72
Batch: 300; loss: 0.57; acc: 0.83
Batch: 320; loss: 0.61; acc: 0.83
Batch: 340; loss: 0.5; acc: 0.81
Batch: 360; loss: 0.71; acc: 0.81
Batch: 380; loss: 0.73; acc: 0.75
Batch: 400; loss: 0.69; acc: 0.75
Batch: 420; loss: 0.77; acc: 0.72
Batch: 440; loss: 0.85; acc: 0.78
Batch: 460; loss: 0.33; acc: 0.89
Batch: 480; loss: 0.9; acc: 0.73
Batch: 500; loss: 0.38; acc: 0.84
Batch: 520; loss: 0.54; acc: 0.77
Batch: 540; loss: 0.58; acc: 0.83
Batch: 560; loss: 0.57; acc: 0.84
Batch: 580; loss: 0.38; acc: 0.95
Batch: 600; loss: 0.3; acc: 0.91
Batch: 620; loss: 1.22; acc: 0.69
Batch: 640; loss: 0.78; acc: 0.77
Batch: 660; loss: 0.57; acc: 0.83
Batch: 680; loss: 0.72; acc: 0.83
Batch: 700; loss: 0.6; acc: 0.81
Batch: 720; loss: 0.58; acc: 0.84
Batch: 740; loss: 0.41; acc: 0.86
Batch: 760; loss: 0.56; acc: 0.84
Batch: 780; loss: 0.46; acc: 0.83
Train Epoch over. train_loss: 0.62; train_accuracy: 0.81 

2.1846477466169745e-05
8.599706234235782e-06
Batch: 0; loss: 0.56; acc: 0.77
Batch: 20; loss: 0.68; acc: 0.86
Batch: 40; loss: 0.31; acc: 0.92
Batch: 60; loss: 0.57; acc: 0.73
Batch: 80; loss: 0.48; acc: 0.91
Batch: 100; loss: 0.53; acc: 0.84
Batch: 120; loss: 0.68; acc: 0.77
Batch: 140; loss: 0.34; acc: 0.86
Val Epoch over. val_loss: 0.6173021113796598; val_accuracy: 0.8046377388535032 

The current subspace-distance is: 8.599706234235782e-06 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.79; acc: 0.77
Batch: 20; loss: 0.33; acc: 0.91
Batch: 40; loss: 0.48; acc: 0.8
Batch: 60; loss: 0.54; acc: 0.86
Batch: 80; loss: 0.88; acc: 0.73
Batch: 100; loss: 0.55; acc: 0.84
Batch: 120; loss: 0.58; acc: 0.83
Batch: 140; loss: 0.89; acc: 0.77
Batch: 160; loss: 0.45; acc: 0.83
Batch: 180; loss: 0.29; acc: 0.92
Batch: 200; loss: 0.44; acc: 0.83
Batch: 220; loss: 0.51; acc: 0.86
Batch: 240; loss: 0.52; acc: 0.83
Batch: 260; loss: 0.53; acc: 0.86
Batch: 280; loss: 0.9; acc: 0.72
Batch: 300; loss: 0.85; acc: 0.72
Batch: 320; loss: 0.81; acc: 0.78
Batch: 340; loss: 0.79; acc: 0.75
Batch: 360; loss: 0.51; acc: 0.86
Batch: 380; loss: 0.42; acc: 0.88
Batch: 400; loss: 0.67; acc: 0.78
Batch: 420; loss: 0.58; acc: 0.84
Batch: 440; loss: 0.72; acc: 0.75
Batch: 460; loss: 0.52; acc: 0.8
Batch: 480; loss: 0.46; acc: 0.91
Batch: 500; loss: 0.44; acc: 0.84
Batch: 520; loss: 0.44; acc: 0.83
Batch: 540; loss: 0.65; acc: 0.84
Batch: 560; loss: 0.44; acc: 0.89
Batch: 580; loss: 0.5; acc: 0.83
Batch: 600; loss: 0.7; acc: 0.77
Batch: 620; loss: 0.48; acc: 0.88
Batch: 640; loss: 0.22; acc: 0.92
Batch: 660; loss: 0.71; acc: 0.78
Batch: 680; loss: 0.61; acc: 0.81
Batch: 700; loss: 0.44; acc: 0.83
Batch: 720; loss: 0.55; acc: 0.86
Batch: 740; loss: 0.59; acc: 0.77
Batch: 760; loss: 0.39; acc: 0.91
Batch: 780; loss: 0.59; acc: 0.86
Train Epoch over. train_loss: 0.59; train_accuracy: 0.82 

2.1853004000149667e-05
7.6184219324204605e-06
Batch: 0; loss: 0.55; acc: 0.75
Batch: 20; loss: 0.58; acc: 0.78
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.54; acc: 0.86
Batch: 80; loss: 0.65; acc: 0.8
Batch: 100; loss: 0.53; acc: 0.88
Batch: 120; loss: 0.77; acc: 0.77
Batch: 140; loss: 0.32; acc: 0.88
Val Epoch over. val_loss: 0.6071066207187191; val_accuracy: 0.8169785031847133 

The current subspace-distance is: 7.6184219324204605e-06 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.58; acc: 0.81
Batch: 20; loss: 0.45; acc: 0.84
Batch: 40; loss: 0.37; acc: 0.86
Batch: 60; loss: 0.72; acc: 0.81
Batch: 80; loss: 0.75; acc: 0.75
Batch: 100; loss: 0.4; acc: 0.86
Batch: 120; loss: 0.38; acc: 0.88
Batch: 140; loss: 0.69; acc: 0.8
Batch: 160; loss: 0.8; acc: 0.8
Batch: 180; loss: 1.15; acc: 0.7
Batch: 200; loss: 0.47; acc: 0.86
Batch: 220; loss: 0.55; acc: 0.86
Batch: 240; loss: 0.47; acc: 0.88
Batch: 260; loss: 0.65; acc: 0.83
Batch: 280; loss: 0.6; acc: 0.8
Batch: 300; loss: 0.6; acc: 0.83
Batch: 320; loss: 0.42; acc: 0.84
Batch: 340; loss: 0.56; acc: 0.81
Batch: 360; loss: 0.64; acc: 0.84
Batch: 380; loss: 0.34; acc: 0.91
Batch: 400; loss: 0.48; acc: 0.84
Batch: 420; loss: 0.4; acc: 0.88
Batch: 440; loss: 0.6; acc: 0.73
Batch: 460; loss: 0.39; acc: 0.88
Batch: 480; loss: 0.61; acc: 0.81
Batch: 500; loss: 0.62; acc: 0.77
Batch: 520; loss: 0.59; acc: 0.78
Batch: 540; loss: 0.59; acc: 0.83
Batch: 560; loss: 0.68; acc: 0.83
Batch: 580; loss: 0.83; acc: 0.72
Batch: 600; loss: 0.59; acc: 0.75
Batch: 620; loss: 0.85; acc: 0.7
Batch: 640; loss: 0.98; acc: 0.73
Batch: 660; loss: 0.73; acc: 0.8
Batch: 680; loss: 0.85; acc: 0.78
Batch: 700; loss: 0.6; acc: 0.83
Batch: 720; loss: 0.38; acc: 0.88
Batch: 740; loss: 0.56; acc: 0.8
Batch: 760; loss: 0.67; acc: 0.77
Batch: 780; loss: 0.53; acc: 0.81
Train Epoch over. train_loss: 0.58; train_accuracy: 0.82 

2.23814004129963e-05
8.201623131753877e-06
Batch: 0; loss: 0.55; acc: 0.8
Batch: 20; loss: 0.75; acc: 0.75
Batch: 40; loss: 0.35; acc: 0.86
Batch: 60; loss: 0.56; acc: 0.8
Batch: 80; loss: 0.45; acc: 0.88
Batch: 100; loss: 0.58; acc: 0.84
Batch: 120; loss: 0.72; acc: 0.77
Batch: 140; loss: 0.35; acc: 0.91
Val Epoch over. val_loss: 0.6109073187705059; val_accuracy: 0.8066281847133758 

The current subspace-distance is: 8.201623131753877e-06 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.81; acc: 0.8
Batch: 20; loss: 0.51; acc: 0.83
Batch: 40; loss: 0.72; acc: 0.81
Batch: 60; loss: 0.44; acc: 0.86
Batch: 80; loss: 0.45; acc: 0.89
Batch: 100; loss: 0.8; acc: 0.8
Batch: 120; loss: 0.39; acc: 0.88
Batch: 140; loss: 0.66; acc: 0.78
Batch: 160; loss: 0.4; acc: 0.88
Batch: 180; loss: 0.41; acc: 0.88
Batch: 200; loss: 0.64; acc: 0.81
Batch: 220; loss: 0.63; acc: 0.83
Batch: 240; loss: 0.65; acc: 0.78
Batch: 260; loss: 0.66; acc: 0.8
Batch: 280; loss: 0.41; acc: 0.91
Batch: 300; loss: 0.33; acc: 0.91
Batch: 320; loss: 0.81; acc: 0.77
Batch: 340; loss: 0.54; acc: 0.8
Batch: 360; loss: 0.7; acc: 0.83
Batch: 380; loss: 0.37; acc: 0.88
Batch: 400; loss: 0.88; acc: 0.8
Batch: 420; loss: 0.59; acc: 0.73
Batch: 440; loss: 0.31; acc: 0.91
Batch: 460; loss: 0.4; acc: 0.88
Batch: 480; loss: 0.7; acc: 0.77
Batch: 500; loss: 0.44; acc: 0.88
Batch: 520; loss: 0.54; acc: 0.86
Batch: 540; loss: 0.42; acc: 0.88
Batch: 560; loss: 0.69; acc: 0.8
Batch: 580; loss: 0.58; acc: 0.84
Batch: 600; loss: 0.56; acc: 0.83
Batch: 620; loss: 0.68; acc: 0.81
Batch: 640; loss: 0.52; acc: 0.83
Batch: 660; loss: 0.46; acc: 0.81
Batch: 680; loss: 0.42; acc: 0.88
Batch: 700; loss: 0.45; acc: 0.84
Batch: 720; loss: 0.6; acc: 0.84
Batch: 740; loss: 0.87; acc: 0.8
Batch: 760; loss: 0.49; acc: 0.84
Batch: 780; loss: 0.76; acc: 0.78
Train Epoch over. train_loss: 0.57; train_accuracy: 0.83 

2.338469130336307e-05
8.091982635960449e-06
Batch: 0; loss: 0.93; acc: 0.66
Batch: 20; loss: 1.12; acc: 0.69
Batch: 40; loss: 0.51; acc: 0.89
Batch: 60; loss: 0.99; acc: 0.64
Batch: 80; loss: 0.99; acc: 0.77
Batch: 100; loss: 0.77; acc: 0.77
Batch: 120; loss: 1.23; acc: 0.69
Batch: 140; loss: 0.47; acc: 0.83
Val Epoch over. val_loss: 0.8810818275068976; val_accuracy: 0.734375 

The current subspace-distance is: 8.091982635960449e-06 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.91; acc: 0.75
Batch: 20; loss: 0.43; acc: 0.84
Batch: 40; loss: 0.43; acc: 0.88
Batch: 60; loss: 0.4; acc: 0.84
Batch: 80; loss: 0.38; acc: 0.88
Batch: 100; loss: 0.67; acc: 0.86
Batch: 120; loss: 0.48; acc: 0.86
Batch: 140; loss: 0.48; acc: 0.86
Batch: 160; loss: 0.59; acc: 0.83
Batch: 180; loss: 0.51; acc: 0.88
Batch: 200; loss: 0.66; acc: 0.78
Batch: 220; loss: 0.57; acc: 0.83
Batch: 240; loss: 0.6; acc: 0.83
Batch: 260; loss: 0.49; acc: 0.84
Batch: 280; loss: 0.38; acc: 0.89
Batch: 300; loss: 0.45; acc: 0.83
Batch: 320; loss: 0.65; acc: 0.81
Batch: 340; loss: 0.34; acc: 0.94
Batch: 360; loss: 0.71; acc: 0.83
Batch: 380; loss: 0.55; acc: 0.83
Batch: 400; loss: 0.87; acc: 0.8
Batch: 420; loss: 0.53; acc: 0.81
Batch: 440; loss: 0.45; acc: 0.84
Batch: 460; loss: 0.6; acc: 0.8
Batch: 480; loss: 0.35; acc: 0.84
Batch: 500; loss: 0.49; acc: 0.84
Batch: 520; loss: 0.43; acc: 0.88
Batch: 540; loss: 0.78; acc: 0.83
Batch: 560; loss: 0.68; acc: 0.84
Batch: 580; loss: 0.6; acc: 0.77
Batch: 600; loss: 0.42; acc: 0.88
Batch: 620; loss: 0.27; acc: 0.94
Batch: 640; loss: 0.42; acc: 0.84
Batch: 660; loss: 0.44; acc: 0.84
Batch: 680; loss: 0.42; acc: 0.86
Batch: 700; loss: 0.31; acc: 0.92
Batch: 720; loss: 0.63; acc: 0.81
Batch: 740; loss: 0.62; acc: 0.81
Batch: 760; loss: 0.57; acc: 0.81
Batch: 780; loss: 0.52; acc: 0.84
Train Epoch over. train_loss: 0.51; train_accuracy: 0.84 

2.262556881760247e-05
8.16995270724874e-06
Batch: 0; loss: 0.53; acc: 0.84
Batch: 20; loss: 0.5; acc: 0.83
Batch: 40; loss: 0.26; acc: 0.91
Batch: 60; loss: 0.51; acc: 0.83
Batch: 80; loss: 0.41; acc: 0.88
Batch: 100; loss: 0.45; acc: 0.91
Batch: 120; loss: 0.72; acc: 0.73
Batch: 140; loss: 0.28; acc: 0.91
Val Epoch over. val_loss: 0.5050040468763394; val_accuracy: 0.8429538216560509 

The current subspace-distance is: 8.16995270724874e-06 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.73; acc: 0.78
Batch: 20; loss: 0.4; acc: 0.86
Batch: 40; loss: 0.5; acc: 0.84
Batch: 60; loss: 0.45; acc: 0.84
Batch: 80; loss: 0.55; acc: 0.84
Batch: 100; loss: 0.36; acc: 0.88
Batch: 120; loss: 0.52; acc: 0.84
Batch: 140; loss: 0.48; acc: 0.83
Batch: 160; loss: 0.44; acc: 0.89
Batch: 180; loss: 0.39; acc: 0.92
Batch: 200; loss: 0.53; acc: 0.83
Batch: 220; loss: 0.58; acc: 0.84
Batch: 240; loss: 0.33; acc: 0.88
Batch: 260; loss: 0.43; acc: 0.81
Batch: 280; loss: 0.5; acc: 0.83
Batch: 300; loss: 0.28; acc: 0.92
Batch: 320; loss: 0.37; acc: 0.88
Batch: 340; loss: 0.51; acc: 0.89
Batch: 360; loss: 0.59; acc: 0.83
Batch: 380; loss: 0.55; acc: 0.83
Batch: 400; loss: 0.58; acc: 0.77
Batch: 420; loss: 0.55; acc: 0.86
Batch: 440; loss: 0.8; acc: 0.83
Batch: 460; loss: 0.67; acc: 0.83
Batch: 480; loss: 0.6; acc: 0.78
Batch: 500; loss: 0.6; acc: 0.8
Batch: 520; loss: 0.53; acc: 0.91
Batch: 540; loss: 0.54; acc: 0.84
Batch: 560; loss: 0.56; acc: 0.84
Batch: 580; loss: 0.45; acc: 0.86
Batch: 600; loss: 0.48; acc: 0.88
Batch: 620; loss: 0.4; acc: 0.92
Batch: 640; loss: 0.46; acc: 0.81
Batch: 660; loss: 0.6; acc: 0.78
Batch: 680; loss: 0.67; acc: 0.78
Batch: 700; loss: 0.35; acc: 0.88
Batch: 720; loss: 0.39; acc: 0.86
Batch: 740; loss: 0.69; acc: 0.78
Batch: 760; loss: 1.11; acc: 0.8
Batch: 780; loss: 0.49; acc: 0.84
Train Epoch over. train_loss: 0.51; train_accuracy: 0.85 

2.4875706003513187e-05
7.340225693042157e-06
Batch: 0; loss: 0.67; acc: 0.73
Batch: 20; loss: 0.53; acc: 0.84
Batch: 40; loss: 0.29; acc: 0.91
Batch: 60; loss: 0.71; acc: 0.73
Batch: 80; loss: 0.68; acc: 0.83
Batch: 100; loss: 0.47; acc: 0.83
Batch: 120; loss: 0.75; acc: 0.72
Batch: 140; loss: 0.32; acc: 0.88
Val Epoch over. val_loss: 0.6476006878029769; val_accuracy: 0.796875 

The current subspace-distance is: 7.340225693042157e-06 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.69; acc: 0.77
Batch: 20; loss: 0.58; acc: 0.81
Batch: 40; loss: 0.56; acc: 0.84
Batch: 60; loss: 0.42; acc: 0.92
Batch: 80; loss: 0.53; acc: 0.86
Batch: 100; loss: 0.42; acc: 0.88
Batch: 120; loss: 0.44; acc: 0.84
Batch: 140; loss: 0.52; acc: 0.84
Batch: 160; loss: 0.68; acc: 0.83
Batch: 180; loss: 0.45; acc: 0.84
Batch: 200; loss: 0.41; acc: 0.89
Batch: 220; loss: 0.42; acc: 0.84
Batch: 240; loss: 0.38; acc: 0.89
Batch: 260; loss: 0.47; acc: 0.83
Batch: 280; loss: 0.43; acc: 0.88
Batch: 300; loss: 0.65; acc: 0.81
Batch: 320; loss: 0.64; acc: 0.78
Batch: 340; loss: 0.4; acc: 0.89
Batch: 360; loss: 0.48; acc: 0.83
Batch: 380; loss: 0.37; acc: 0.88
Batch: 400; loss: 0.48; acc: 0.86
Batch: 420; loss: 0.45; acc: 0.86
Batch: 440; loss: 0.48; acc: 0.88
Batch: 460; loss: 0.32; acc: 0.88
Batch: 480; loss: 0.39; acc: 0.86
Batch: 500; loss: 0.5; acc: 0.88
Batch: 520; loss: 0.41; acc: 0.91
Batch: 540; loss: 0.6; acc: 0.77
Batch: 560; loss: 0.33; acc: 0.91
Batch: 580; loss: 0.47; acc: 0.83
Batch: 600; loss: 0.54; acc: 0.83
Batch: 620; loss: 0.47; acc: 0.83
Batch: 640; loss: 0.4; acc: 0.88
Batch: 660; loss: 0.49; acc: 0.81
Batch: 680; loss: 0.63; acc: 0.8
Batch: 700; loss: 0.81; acc: 0.75
Batch: 720; loss: 0.41; acc: 0.88
Batch: 740; loss: 0.4; acc: 0.89
Batch: 760; loss: 0.54; acc: 0.84
Batch: 780; loss: 0.69; acc: 0.8
Train Epoch over. train_loss: 0.51; train_accuracy: 0.85 

2.2930798877496272e-05
9.322262485511601e-06
Batch: 0; loss: 0.45; acc: 0.84
Batch: 20; loss: 0.54; acc: 0.84
Batch: 40; loss: 0.22; acc: 0.92
Batch: 60; loss: 0.45; acc: 0.84
Batch: 80; loss: 0.47; acc: 0.88
Batch: 100; loss: 0.39; acc: 0.88
Batch: 120; loss: 0.73; acc: 0.72
Batch: 140; loss: 0.25; acc: 0.94
Val Epoch over. val_loss: 0.4764091693291998; val_accuracy: 0.8522093949044586 

The current subspace-distance is: 9.322262485511601e-06 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.33; acc: 0.92
Batch: 20; loss: 0.44; acc: 0.86
Batch: 40; loss: 0.44; acc: 0.84
Batch: 60; loss: 0.37; acc: 0.89
Batch: 80; loss: 0.4; acc: 0.86
Batch: 100; loss: 0.52; acc: 0.84
Batch: 120; loss: 0.41; acc: 0.84
Batch: 140; loss: 0.47; acc: 0.83
Batch: 160; loss: 0.64; acc: 0.77
Batch: 180; loss: 0.35; acc: 0.89
Batch: 200; loss: 0.53; acc: 0.91
Batch: 220; loss: 0.78; acc: 0.8
Batch: 240; loss: 0.45; acc: 0.83
Batch: 260; loss: 0.42; acc: 0.86
Batch: 280; loss: 0.71; acc: 0.72
Batch: 300; loss: 0.59; acc: 0.81
Batch: 320; loss: 0.3; acc: 0.92
Batch: 340; loss: 0.58; acc: 0.83
Batch: 360; loss: 0.5; acc: 0.91
Batch: 380; loss: 0.4; acc: 0.84
Batch: 400; loss: 0.57; acc: 0.83
Batch: 420; loss: 0.46; acc: 0.8
Batch: 440; loss: 0.53; acc: 0.88
Batch: 460; loss: 0.45; acc: 0.83
Batch: 480; loss: 0.6; acc: 0.83
Batch: 500; loss: 0.55; acc: 0.83
Batch: 520; loss: 0.44; acc: 0.89
Batch: 540; loss: 0.42; acc: 0.83
Batch: 560; loss: 0.86; acc: 0.8
Batch: 580; loss: 0.43; acc: 0.89
Batch: 600; loss: 0.71; acc: 0.77
Batch: 620; loss: 0.53; acc: 0.84
Batch: 640; loss: 0.46; acc: 0.83
Batch: 660; loss: 0.38; acc: 0.89
Batch: 680; loss: 0.87; acc: 0.77
Batch: 700; loss: 0.36; acc: 0.88
Batch: 720; loss: 0.44; acc: 0.8
Batch: 740; loss: 0.35; acc: 0.88
Batch: 760; loss: 0.36; acc: 0.86
Batch: 780; loss: 0.54; acc: 0.86
Train Epoch over. train_loss: 0.51; train_accuracy: 0.85 

2.3156999304774217e-05
8.226040336012375e-06
Batch: 0; loss: 0.48; acc: 0.81
Batch: 20; loss: 0.56; acc: 0.8
Batch: 40; loss: 0.25; acc: 0.89
Batch: 60; loss: 0.43; acc: 0.8
Batch: 80; loss: 0.44; acc: 0.86
Batch: 100; loss: 0.4; acc: 0.89
Batch: 120; loss: 0.75; acc: 0.75
Batch: 140; loss: 0.24; acc: 0.88
Val Epoch over. val_loss: 0.47500685711575164; val_accuracy: 0.850218949044586 

The current subspace-distance is: 8.226040336012375e-06 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.52; acc: 0.81
Batch: 20; loss: 0.55; acc: 0.83
Batch: 40; loss: 0.4; acc: 0.89
Batch: 60; loss: 0.54; acc: 0.83
Batch: 80; loss: 0.46; acc: 0.86
Batch: 100; loss: 0.56; acc: 0.8
Batch: 120; loss: 0.5; acc: 0.84
Batch: 140; loss: 0.59; acc: 0.88
Batch: 160; loss: 0.46; acc: 0.86
Batch: 180; loss: 0.45; acc: 0.83
Batch: 200; loss: 0.52; acc: 0.84
Batch: 220; loss: 0.42; acc: 0.78
Batch: 240; loss: 0.48; acc: 0.88
Batch: 260; loss: 0.61; acc: 0.78
Batch: 280; loss: 0.36; acc: 0.88
Batch: 300; loss: 0.66; acc: 0.86
Batch: 320; loss: 0.39; acc: 0.89
Batch: 340; loss: 0.45; acc: 0.84
Batch: 360; loss: 0.4; acc: 0.91
Batch: 380; loss: 0.46; acc: 0.84
Batch: 400; loss: 0.52; acc: 0.81
Batch: 420; loss: 0.6; acc: 0.78
Batch: 440; loss: 0.47; acc: 0.88
Batch: 460; loss: 1.14; acc: 0.69
Batch: 480; loss: 0.44; acc: 0.84
Batch: 500; loss: 0.39; acc: 0.86
Batch: 520; loss: 0.49; acc: 0.84
Batch: 540; loss: 0.31; acc: 0.88
Batch: 560; loss: 0.48; acc: 0.81
Batch: 580; loss: 0.53; acc: 0.8
Batch: 600; loss: 0.22; acc: 0.97
Batch: 620; loss: 0.5; acc: 0.84
Batch: 640; loss: 0.52; acc: 0.86
Batch: 660; loss: 0.45; acc: 0.86
Batch: 680; loss: 0.53; acc: 0.86
Batch: 700; loss: 0.41; acc: 0.91
Batch: 720; loss: 0.5; acc: 0.86
Batch: 740; loss: 0.49; acc: 0.88
Batch: 760; loss: 0.56; acc: 0.83
Batch: 780; loss: 0.45; acc: 0.84
Train Epoch over. train_loss: 0.51; train_accuracy: 0.85 

2.317865983059164e-05
8.250034625234548e-06
Batch: 0; loss: 0.47; acc: 0.84
Batch: 20; loss: 0.53; acc: 0.81
Batch: 40; loss: 0.23; acc: 0.92
Batch: 60; loss: 0.47; acc: 0.77
Batch: 80; loss: 0.46; acc: 0.88
Batch: 100; loss: 0.38; acc: 0.89
Batch: 120; loss: 0.74; acc: 0.75
Batch: 140; loss: 0.26; acc: 0.88
Val Epoch over. val_loss: 0.48932082096862184; val_accuracy: 0.8445461783439491 

The current subspace-distance is: 8.250034625234548e-06 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.56; acc: 0.78
Batch: 20; loss: 0.59; acc: 0.84
Batch: 40; loss: 0.48; acc: 0.84
Batch: 60; loss: 0.27; acc: 0.97
Batch: 80; loss: 0.55; acc: 0.8
Batch: 100; loss: 0.43; acc: 0.81
Batch: 120; loss: 0.95; acc: 0.72
Batch: 140; loss: 0.59; acc: 0.84
Batch: 160; loss: 0.64; acc: 0.84
Batch: 180; loss: 0.55; acc: 0.83
Batch: 200; loss: 0.33; acc: 0.89
Batch: 220; loss: 0.31; acc: 0.89
Batch: 240; loss: 0.64; acc: 0.83
Batch: 260; loss: 0.66; acc: 0.78
Batch: 280; loss: 0.9; acc: 0.78
Batch: 300; loss: 0.29; acc: 0.92
Batch: 320; loss: 0.4; acc: 0.86
Batch: 340; loss: 0.76; acc: 0.8
Batch: 360; loss: 0.48; acc: 0.88
Batch: 380; loss: 0.39; acc: 0.86
Batch: 400; loss: 0.64; acc: 0.77
Batch: 420; loss: 0.59; acc: 0.84
Batch: 440; loss: 0.6; acc: 0.77
Batch: 460; loss: 0.47; acc: 0.84
Batch: 480; loss: 0.38; acc: 0.88
Batch: 500; loss: 0.84; acc: 0.77
Batch: 520; loss: 0.33; acc: 0.89
Batch: 540; loss: 0.5; acc: 0.86
Batch: 560; loss: 0.48; acc: 0.83
Batch: 580; loss: 0.51; acc: 0.83
Batch: 600; loss: 0.68; acc: 0.78
Batch: 620; loss: 0.4; acc: 0.86
Batch: 640; loss: 0.43; acc: 0.89
Batch: 660; loss: 0.55; acc: 0.84
Batch: 680; loss: 0.3; acc: 0.89
Batch: 700; loss: 0.48; acc: 0.81
Batch: 720; loss: 0.53; acc: 0.83
Batch: 740; loss: 0.47; acc: 0.88
Batch: 760; loss: 0.44; acc: 0.89
Batch: 780; loss: 0.56; acc: 0.89
Train Epoch over. train_loss: 0.51; train_accuracy: 0.85 

2.2975851607043296e-05
8.559939487895463e-06
Batch: 0; loss: 0.47; acc: 0.81
Batch: 20; loss: 0.62; acc: 0.78
Batch: 40; loss: 0.28; acc: 0.91
Batch: 60; loss: 0.57; acc: 0.81
Batch: 80; loss: 0.47; acc: 0.86
Batch: 100; loss: 0.53; acc: 0.86
Batch: 120; loss: 0.88; acc: 0.75
Batch: 140; loss: 0.37; acc: 0.88
Val Epoch over. val_loss: 0.5531203380910454; val_accuracy: 0.8265326433121019 

The current subspace-distance is: 8.559939487895463e-06 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.44; acc: 0.84
Batch: 20; loss: 0.56; acc: 0.81
Batch: 40; loss: 0.67; acc: 0.84
Batch: 60; loss: 0.74; acc: 0.8
Batch: 80; loss: 0.72; acc: 0.8
Batch: 100; loss: 0.57; acc: 0.84
Batch: 120; loss: 0.73; acc: 0.81
Batch: 140; loss: 0.37; acc: 0.88
Batch: 160; loss: 0.7; acc: 0.88
Batch: 180; loss: 0.84; acc: 0.75
Batch: 200; loss: 0.59; acc: 0.81
Batch: 220; loss: 0.28; acc: 0.88
Batch: 240; loss: 0.78; acc: 0.84
Batch: 260; loss: 0.47; acc: 0.91
Batch: 280; loss: 0.45; acc: 0.84
Batch: 300; loss: 0.62; acc: 0.81
Batch: 320; loss: 0.4; acc: 0.91
Batch: 340; loss: 0.5; acc: 0.88
Batch: 360; loss: 0.62; acc: 0.78
Batch: 380; loss: 0.64; acc: 0.8
Batch: 400; loss: 0.71; acc: 0.81
Batch: 420; loss: 0.68; acc: 0.81
Batch: 440; loss: 0.52; acc: 0.86
Batch: 460; loss: 0.4; acc: 0.89
Batch: 480; loss: 0.54; acc: 0.83
Batch: 500; loss: 0.44; acc: 0.84
Batch: 520; loss: 0.73; acc: 0.78
Batch: 540; loss: 0.52; acc: 0.8
Batch: 560; loss: 1.04; acc: 0.78
Batch: 580; loss: 0.42; acc: 0.83
Batch: 600; loss: 0.57; acc: 0.81
Batch: 620; loss: 0.43; acc: 0.91
Batch: 640; loss: 0.64; acc: 0.78
Batch: 660; loss: 0.36; acc: 0.88
Batch: 680; loss: 0.37; acc: 0.91
Batch: 700; loss: 0.32; acc: 0.89
Batch: 720; loss: 0.38; acc: 0.89
Batch: 740; loss: 0.77; acc: 0.86
Batch: 760; loss: 0.5; acc: 0.89
Batch: 780; loss: 0.52; acc: 0.78
Train Epoch over. train_loss: 0.51; train_accuracy: 0.85 

2.213801235484425e-05
9.028220119944308e-06
Batch: 0; loss: 0.45; acc: 0.89
Batch: 20; loss: 0.55; acc: 0.86
Batch: 40; loss: 0.23; acc: 0.89
Batch: 60; loss: 0.36; acc: 0.88
Batch: 80; loss: 0.4; acc: 0.92
Batch: 100; loss: 0.43; acc: 0.88
Batch: 120; loss: 0.76; acc: 0.72
Batch: 140; loss: 0.22; acc: 0.94
Val Epoch over. val_loss: 0.4695016216890068; val_accuracy: 0.8570859872611465 

The current subspace-distance is: 9.028220119944308e-06 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.82; acc: 0.78
Batch: 20; loss: 0.53; acc: 0.83
Batch: 40; loss: 0.63; acc: 0.84
Batch: 60; loss: 0.49; acc: 0.83
Batch: 80; loss: 0.33; acc: 0.86
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.54; acc: 0.83
Batch: 140; loss: 0.43; acc: 0.86
Batch: 160; loss: 0.45; acc: 0.88
Batch: 180; loss: 0.48; acc: 0.83
Batch: 200; loss: 0.41; acc: 0.84
Batch: 220; loss: 0.32; acc: 0.88
Batch: 240; loss: 0.63; acc: 0.78
Batch: 260; loss: 0.53; acc: 0.81
Batch: 280; loss: 0.48; acc: 0.89
Batch: 300; loss: 0.44; acc: 0.84
Batch: 320; loss: 0.68; acc: 0.78
Batch: 340; loss: 0.49; acc: 0.88
Batch: 360; loss: 0.35; acc: 0.88
Batch: 380; loss: 0.36; acc: 0.86
Batch: 400; loss: 0.49; acc: 0.84
Batch: 420; loss: 0.33; acc: 0.91
Batch: 440; loss: 0.52; acc: 0.83
Batch: 460; loss: 0.79; acc: 0.72
Batch: 480; loss: 0.36; acc: 0.86
Batch: 500; loss: 0.64; acc: 0.73
Batch: 520; loss: 0.35; acc: 0.88
Batch: 540; loss: 0.55; acc: 0.8
Batch: 560; loss: 0.57; acc: 0.84
Batch: 580; loss: 0.32; acc: 0.89
Batch: 600; loss: 0.51; acc: 0.81
Batch: 620; loss: 0.53; acc: 0.81
Batch: 640; loss: 0.42; acc: 0.86
Batch: 660; loss: 0.35; acc: 0.89
Batch: 680; loss: 0.3; acc: 0.92
Batch: 700; loss: 0.5; acc: 0.81
Batch: 720; loss: 0.33; acc: 0.88
Batch: 740; loss: 0.44; acc: 0.89
Batch: 760; loss: 0.42; acc: 0.88
Batch: 780; loss: 0.3; acc: 0.94
Train Epoch over. train_loss: 0.51; train_accuracy: 0.85 

2.8145776013843715e-05
8.864289156917948e-06
Batch: 0; loss: 0.47; acc: 0.89
Batch: 20; loss: 0.56; acc: 0.81
Batch: 40; loss: 0.26; acc: 0.91
Batch: 60; loss: 0.39; acc: 0.84
Batch: 80; loss: 0.43; acc: 0.86
Batch: 100; loss: 0.43; acc: 0.86
Batch: 120; loss: 0.81; acc: 0.7
Batch: 140; loss: 0.26; acc: 0.92
Val Epoch over. val_loss: 0.474783221342761; val_accuracy: 0.8565883757961783 

The current subspace-distance is: 8.864289156917948e-06 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.72; acc: 0.8
Batch: 20; loss: 0.41; acc: 0.86
Batch: 40; loss: 0.57; acc: 0.88
Batch: 60; loss: 0.61; acc: 0.89
Batch: 80; loss: 0.88; acc: 0.78
Batch: 100; loss: 0.89; acc: 0.83
Batch: 120; loss: 0.33; acc: 0.88
Batch: 140; loss: 0.45; acc: 0.89
Batch: 160; loss: 0.44; acc: 0.91
Batch: 180; loss: 0.44; acc: 0.84
Batch: 200; loss: 0.78; acc: 0.81
Batch: 220; loss: 0.38; acc: 0.89
Batch: 240; loss: 0.57; acc: 0.8
Batch: 260; loss: 0.61; acc: 0.83
Batch: 280; loss: 0.56; acc: 0.84
Batch: 300; loss: 0.58; acc: 0.8
Batch: 320; loss: 0.57; acc: 0.83
Batch: 340; loss: 0.62; acc: 0.83
Batch: 360; loss: 0.41; acc: 0.88
Batch: 380; loss: 0.42; acc: 0.84
Batch: 400; loss: 0.66; acc: 0.78
Batch: 420; loss: 0.37; acc: 0.88
Batch: 440; loss: 0.43; acc: 0.89
Batch: 460; loss: 0.41; acc: 0.81
Batch: 480; loss: 0.53; acc: 0.86
Batch: 500; loss: 0.38; acc: 0.92
Batch: 520; loss: 0.65; acc: 0.84
Batch: 540; loss: 0.57; acc: 0.81
Batch: 560; loss: 0.49; acc: 0.84
Batch: 580; loss: 0.43; acc: 0.91
Batch: 600; loss: 0.36; acc: 0.88
Batch: 620; loss: 0.52; acc: 0.84
Batch: 640; loss: 0.59; acc: 0.81
Batch: 660; loss: 0.35; acc: 0.89
Batch: 680; loss: 0.65; acc: 0.86
Batch: 700; loss: 0.3; acc: 0.86
Batch: 720; loss: 0.38; acc: 0.92
Batch: 740; loss: 0.45; acc: 0.86
Batch: 760; loss: 0.42; acc: 0.89
Batch: 780; loss: 0.48; acc: 0.88
Train Epoch over. train_loss: 0.5; train_accuracy: 0.85 

2.5384590117027983e-05
9.698183021100704e-06
Batch: 0; loss: 0.4; acc: 0.89
Batch: 20; loss: 0.7; acc: 0.78
Batch: 40; loss: 0.22; acc: 0.91
Batch: 60; loss: 0.34; acc: 0.89
Batch: 80; loss: 0.43; acc: 0.88
Batch: 100; loss: 0.41; acc: 0.88
Batch: 120; loss: 0.79; acc: 0.7
Batch: 140; loss: 0.26; acc: 0.92
Val Epoch over. val_loss: 0.5155904568304681; val_accuracy: 0.8471337579617835 

The current subspace-distance is: 9.698183021100704e-06 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.37; acc: 0.92
Batch: 20; loss: 0.42; acc: 0.86
Batch: 40; loss: 0.49; acc: 0.84
Batch: 60; loss: 0.35; acc: 0.88
Batch: 80; loss: 0.44; acc: 0.84
Batch: 100; loss: 0.51; acc: 0.81
Batch: 120; loss: 0.33; acc: 0.92
Batch: 140; loss: 0.43; acc: 0.81
Batch: 160; loss: 0.59; acc: 0.77
Batch: 180; loss: 0.42; acc: 0.83
Batch: 200; loss: 0.56; acc: 0.86
Batch: 220; loss: 0.75; acc: 0.75
Batch: 240; loss: 0.58; acc: 0.88
Batch: 260; loss: 0.43; acc: 0.91
Batch: 280; loss: 0.37; acc: 0.95
Batch: 300; loss: 0.46; acc: 0.88
Batch: 320; loss: 0.54; acc: 0.83
Batch: 340; loss: 0.35; acc: 0.91
Batch: 360; loss: 0.33; acc: 0.86
Batch: 380; loss: 0.55; acc: 0.86
Batch: 400; loss: 0.63; acc: 0.78
Batch: 420; loss: 0.49; acc: 0.88
Batch: 440; loss: 0.41; acc: 0.88
Batch: 460; loss: 0.49; acc: 0.83
Batch: 480; loss: 0.49; acc: 0.84
Batch: 500; loss: 0.43; acc: 0.89
Batch: 520; loss: 0.56; acc: 0.81
Batch: 540; loss: 0.29; acc: 0.91
Batch: 560; loss: 0.57; acc: 0.81
Batch: 580; loss: 0.44; acc: 0.81
Batch: 600; loss: 0.52; acc: 0.8
Batch: 620; loss: 0.83; acc: 0.7
Batch: 640; loss: 0.44; acc: 0.89
Batch: 660; loss: 0.4; acc: 0.86
Batch: 680; loss: 0.58; acc: 0.86
Batch: 700; loss: 0.66; acc: 0.83
Batch: 720; loss: 0.52; acc: 0.86
Batch: 740; loss: 0.65; acc: 0.83
Batch: 760; loss: 0.87; acc: 0.81
Batch: 780; loss: 0.57; acc: 0.84
Train Epoch over. train_loss: 0.5; train_accuracy: 0.85 

2.3260505258804187e-05
8.204701771319378e-06
Batch: 0; loss: 0.39; acc: 0.83
Batch: 20; loss: 0.63; acc: 0.81
Batch: 40; loss: 0.29; acc: 0.91
Batch: 60; loss: 0.33; acc: 0.88
Batch: 80; loss: 0.41; acc: 0.91
Batch: 100; loss: 0.41; acc: 0.88
Batch: 120; loss: 0.85; acc: 0.72
Batch: 140; loss: 0.24; acc: 0.95
Val Epoch over. val_loss: 0.5003589074702779; val_accuracy: 0.8504179936305732 

The current subspace-distance is: 8.204701771319378e-06 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.87; acc: 0.73
Batch: 20; loss: 0.32; acc: 0.92
Batch: 40; loss: 0.57; acc: 0.81
Batch: 60; loss: 0.39; acc: 0.88
Batch: 80; loss: 0.64; acc: 0.81
Batch: 100; loss: 0.42; acc: 0.91
Batch: 120; loss: 0.52; acc: 0.83
Batch: 140; loss: 0.59; acc: 0.84
Batch: 160; loss: 0.55; acc: 0.89
Batch: 180; loss: 0.49; acc: 0.88
Batch: 200; loss: 0.36; acc: 0.91
Batch: 220; loss: 0.36; acc: 0.89
Batch: 240; loss: 0.29; acc: 0.89
Batch: 260; loss: 0.43; acc: 0.89
Batch: 280; loss: 0.37; acc: 0.88
Batch: 300; loss: 0.33; acc: 0.91
Batch: 320; loss: 0.6; acc: 0.84
Batch: 340; loss: 0.54; acc: 0.78
Batch: 360; loss: 0.45; acc: 0.89
Batch: 380; loss: 0.64; acc: 0.78
Batch: 400; loss: 0.43; acc: 0.83
Batch: 420; loss: 0.37; acc: 0.89
Batch: 440; loss: 0.31; acc: 0.91
Batch: 460; loss: 0.46; acc: 0.89
Batch: 480; loss: 0.41; acc: 0.91
Batch: 500; loss: 0.8; acc: 0.77
Batch: 520; loss: 0.39; acc: 0.86
Batch: 540; loss: 0.45; acc: 0.86
Batch: 560; loss: 0.42; acc: 0.78
Batch: 580; loss: 0.32; acc: 0.92
Batch: 600; loss: 0.55; acc: 0.84
Batch: 620; loss: 0.71; acc: 0.73
Batch: 640; loss: 0.42; acc: 0.91
Batch: 660; loss: 0.51; acc: 0.86
Batch: 680; loss: 0.42; acc: 0.86
Batch: 700; loss: 0.46; acc: 0.88
Batch: 720; loss: 0.42; acc: 0.88
Batch: 740; loss: 0.57; acc: 0.86
Batch: 760; loss: 0.57; acc: 0.83
Batch: 780; loss: 0.68; acc: 0.77
Train Epoch over. train_loss: 0.48; train_accuracy: 0.86 

2.2807964342064224e-05
8.307606549351476e-06
Batch: 0; loss: 0.44; acc: 0.91
Batch: 20; loss: 0.43; acc: 0.81
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.38; acc: 0.86
Batch: 80; loss: 0.42; acc: 0.89
Batch: 100; loss: 0.41; acc: 0.88
Batch: 120; loss: 0.72; acc: 0.69
Batch: 140; loss: 0.19; acc: 0.92
Val Epoch over. val_loss: 0.44505001552355516; val_accuracy: 0.8637539808917197 

The current subspace-distance is: 8.307606549351476e-06 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.53; acc: 0.86
Batch: 20; loss: 0.52; acc: 0.89
Batch: 40; loss: 0.42; acc: 0.86
Batch: 60; loss: 0.45; acc: 0.86
Batch: 80; loss: 0.31; acc: 0.94
Batch: 100; loss: 0.35; acc: 0.91
Batch: 120; loss: 0.58; acc: 0.81
Batch: 140; loss: 0.43; acc: 0.89
Batch: 160; loss: 0.43; acc: 0.84
Batch: 180; loss: 0.4; acc: 0.88
Batch: 200; loss: 0.58; acc: 0.84
Batch: 220; loss: 0.24; acc: 0.92
Batch: 240; loss: 0.33; acc: 0.92
Batch: 260; loss: 0.5; acc: 0.86
Batch: 280; loss: 0.34; acc: 0.92
Batch: 300; loss: 0.52; acc: 0.83
Batch: 320; loss: 0.59; acc: 0.77
Batch: 340; loss: 0.28; acc: 0.94
Batch: 360; loss: 0.33; acc: 0.89
Batch: 380; loss: 0.52; acc: 0.84
Batch: 400; loss: 0.54; acc: 0.91
Batch: 420; loss: 0.58; acc: 0.86
Batch: 440; loss: 0.68; acc: 0.8
Batch: 460; loss: 0.39; acc: 0.88
Batch: 480; loss: 0.41; acc: 0.84
Batch: 500; loss: 0.45; acc: 0.88
Batch: 520; loss: 0.52; acc: 0.89
Batch: 540; loss: 0.56; acc: 0.83
Batch: 560; loss: 0.37; acc: 0.86
Batch: 580; loss: 0.52; acc: 0.8
Batch: 600; loss: 0.37; acc: 0.89
Batch: 620; loss: 0.27; acc: 0.94
Batch: 640; loss: 0.35; acc: 0.86
Batch: 660; loss: 0.55; acc: 0.88
Batch: 680; loss: 0.49; acc: 0.86
Batch: 700; loss: 0.15; acc: 0.95
Batch: 720; loss: 0.54; acc: 0.88
Batch: 740; loss: 0.41; acc: 0.92
Batch: 760; loss: 0.27; acc: 0.92
Batch: 780; loss: 0.41; acc: 0.91
Train Epoch over. train_loss: 0.48; train_accuracy: 0.86 

2.5125629690592177e-05
9.874683200905565e-06
Batch: 0; loss: 0.44; acc: 0.88
Batch: 20; loss: 0.48; acc: 0.81
Batch: 40; loss: 0.25; acc: 0.94
Batch: 60; loss: 0.38; acc: 0.83
Batch: 80; loss: 0.41; acc: 0.88
Batch: 100; loss: 0.41; acc: 0.86
Batch: 120; loss: 0.75; acc: 0.7
Batch: 140; loss: 0.2; acc: 0.94
Val Epoch over. val_loss: 0.45162290277754424; val_accuracy: 0.8608678343949044 

The current subspace-distance is: 9.874683200905565e-06 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.31; acc: 0.91
Batch: 20; loss: 0.61; acc: 0.83
Batch: 40; loss: 0.69; acc: 0.78
Batch: 60; loss: 0.5; acc: 0.86
Batch: 80; loss: 0.59; acc: 0.77
Batch: 100; loss: 0.42; acc: 0.84
Batch: 120; loss: 0.61; acc: 0.81
Batch: 140; loss: 0.39; acc: 0.88
Batch: 160; loss: 0.54; acc: 0.88
Batch: 180; loss: 0.52; acc: 0.88
Batch: 200; loss: 0.48; acc: 0.86
Batch: 220; loss: 0.45; acc: 0.84
Batch: 240; loss: 0.76; acc: 0.81
Batch: 260; loss: 0.39; acc: 0.81
Batch: 280; loss: 0.36; acc: 0.86
Batch: 300; loss: 0.41; acc: 0.89
Batch: 320; loss: 0.67; acc: 0.8
Batch: 340; loss: 0.87; acc: 0.77
Batch: 360; loss: 0.75; acc: 0.84
Batch: 380; loss: 0.45; acc: 0.86
Batch: 400; loss: 0.68; acc: 0.75
Batch: 420; loss: 0.45; acc: 0.89
Batch: 440; loss: 0.91; acc: 0.78
Batch: 460; loss: 0.34; acc: 0.91
Batch: 480; loss: 0.45; acc: 0.88
Batch: 500; loss: 0.48; acc: 0.8
Batch: 520; loss: 0.54; acc: 0.78
Batch: 540; loss: 0.46; acc: 0.86
Batch: 560; loss: 0.56; acc: 0.88
Batch: 580; loss: 0.71; acc: 0.84
Batch: 600; loss: 0.47; acc: 0.86
Batch: 620; loss: 0.37; acc: 0.91
Batch: 640; loss: 0.44; acc: 0.88
Batch: 660; loss: 0.32; acc: 0.88
Batch: 680; loss: 0.53; acc: 0.84
Batch: 700; loss: 0.4; acc: 0.91
Batch: 720; loss: 0.37; acc: 0.88
Batch: 740; loss: 0.59; acc: 0.86
Batch: 760; loss: 0.34; acc: 0.89
Batch: 780; loss: 0.52; acc: 0.83
Train Epoch over. train_loss: 0.48; train_accuracy: 0.86 

2.3233556930790655e-05
7.509143415518338e-06
Batch: 0; loss: 0.39; acc: 0.89
Batch: 20; loss: 0.46; acc: 0.86
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.36; acc: 0.84
Batch: 80; loss: 0.42; acc: 0.88
Batch: 100; loss: 0.38; acc: 0.89
Batch: 120; loss: 0.68; acc: 0.75
Batch: 140; loss: 0.21; acc: 0.94
Val Epoch over. val_loss: 0.4518084052451857; val_accuracy: 0.8628582802547771 

The current subspace-distance is: 7.509143415518338e-06 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.49; acc: 0.81
Batch: 20; loss: 0.36; acc: 0.89
Batch: 40; loss: 0.55; acc: 0.84
Batch: 60; loss: 0.57; acc: 0.81
Batch: 80; loss: 0.67; acc: 0.89
Batch: 100; loss: 0.48; acc: 0.88
Batch: 120; loss: 0.38; acc: 0.84
Batch: 140; loss: 0.55; acc: 0.78
Batch: 160; loss: 0.39; acc: 0.88
Batch: 180; loss: 0.42; acc: 0.88
Batch: 200; loss: 0.24; acc: 0.92
Batch: 220; loss: 0.55; acc: 0.86
Batch: 240; loss: 0.49; acc: 0.88
Batch: 260; loss: 0.49; acc: 0.89
Batch: 280; loss: 0.41; acc: 0.84
Batch: 300; loss: 0.46; acc: 0.84
Batch: 320; loss: 0.43; acc: 0.86
Batch: 340; loss: 0.74; acc: 0.81
Batch: 360; loss: 0.56; acc: 0.84
Batch: 380; loss: 0.61; acc: 0.84
Batch: 400; loss: 0.42; acc: 0.86
Batch: 420; loss: 0.58; acc: 0.83
Batch: 440; loss: 0.38; acc: 0.89
Batch: 460; loss: 0.41; acc: 0.84
Batch: 480; loss: 0.44; acc: 0.83
Batch: 500; loss: 0.32; acc: 0.92
Batch: 520; loss: 0.24; acc: 0.92
Batch: 540; loss: 0.34; acc: 0.91
Batch: 560; loss: 0.41; acc: 0.86
Batch: 580; loss: 0.73; acc: 0.81
Batch: 600; loss: 0.42; acc: 0.86
Batch: 620; loss: 0.45; acc: 0.88
Batch: 640; loss: 0.64; acc: 0.78
Batch: 660; loss: 0.37; acc: 0.88
Batch: 680; loss: 0.54; acc: 0.81
Batch: 700; loss: 0.29; acc: 0.95
Batch: 720; loss: 0.54; acc: 0.86
Batch: 740; loss: 0.59; acc: 0.78
Batch: 760; loss: 0.61; acc: 0.81
Batch: 780; loss: 0.85; acc: 0.75
Train Epoch over. train_loss: 0.47; train_accuracy: 0.86 

2.3322792912949808e-05
8.085467015916947e-06
Batch: 0; loss: 0.4; acc: 0.88
Batch: 20; loss: 0.47; acc: 0.84
Batch: 40; loss: 0.24; acc: 0.94
Batch: 60; loss: 0.41; acc: 0.83
Batch: 80; loss: 0.42; acc: 0.86
Batch: 100; loss: 0.41; acc: 0.88
Batch: 120; loss: 0.71; acc: 0.69
Batch: 140; loss: 0.24; acc: 0.94
Val Epoch over. val_loss: 0.45879831222022416; val_accuracy: 0.8606687898089171 

The current subspace-distance is: 8.085467015916947e-06 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.35; acc: 0.86
Batch: 20; loss: 0.6; acc: 0.84
Batch: 40; loss: 0.43; acc: 0.88
Batch: 60; loss: 0.49; acc: 0.84
Batch: 80; loss: 0.57; acc: 0.8
Batch: 100; loss: 0.42; acc: 0.88
Batch: 120; loss: 0.28; acc: 0.91
Batch: 140; loss: 0.36; acc: 0.92
Batch: 160; loss: 0.34; acc: 0.91
Batch: 180; loss: 0.43; acc: 0.88
Batch: 200; loss: 0.43; acc: 0.84
Batch: 220; loss: 0.33; acc: 0.88
Batch: 240; loss: 0.54; acc: 0.86
Batch: 260; loss: 0.3; acc: 0.92
Batch: 280; loss: 0.4; acc: 0.88
Batch: 300; loss: 0.38; acc: 0.89
Batch: 320; loss: 0.26; acc: 0.89
Batch: 340; loss: 0.58; acc: 0.83
Batch: 360; loss: 0.21; acc: 0.94
Batch: 380; loss: 0.7; acc: 0.81
Batch: 400; loss: 0.54; acc: 0.83
Batch: 420; loss: 0.71; acc: 0.78
Batch: 440; loss: 0.48; acc: 0.84
Batch: 460; loss: 0.91; acc: 0.77
Batch: 480; loss: 0.59; acc: 0.77
Batch: 500; loss: 0.51; acc: 0.84
Batch: 520; loss: 0.42; acc: 0.86
Batch: 540; loss: 0.74; acc: 0.75
Batch: 560; loss: 0.27; acc: 0.92
Batch: 580; loss: 0.46; acc: 0.83
Batch: 600; loss: 0.45; acc: 0.84
Batch: 620; loss: 0.39; acc: 0.86
Batch: 640; loss: 0.33; acc: 0.88
Batch: 660; loss: 0.47; acc: 0.8
Batch: 680; loss: 0.45; acc: 0.84
Batch: 700; loss: 0.2; acc: 0.94
Batch: 720; loss: 0.5; acc: 0.88
Batch: 740; loss: 0.45; acc: 0.86
Batch: 760; loss: 0.51; acc: 0.83
Batch: 780; loss: 0.48; acc: 0.89
Train Epoch over. train_loss: 0.47; train_accuracy: 0.86 

2.3669625079492107e-05
9.544140993966721e-06
Batch: 0; loss: 0.4; acc: 0.88
Batch: 20; loss: 0.47; acc: 0.83
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.37; acc: 0.86
Batch: 80; loss: 0.41; acc: 0.88
Batch: 100; loss: 0.39; acc: 0.86
Batch: 120; loss: 0.73; acc: 0.7
Batch: 140; loss: 0.23; acc: 0.94
Val Epoch over. val_loss: 0.44290703103231016; val_accuracy: 0.8663415605095541 

The current subspace-distance is: 9.544140993966721e-06 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.41; acc: 0.91
Batch: 20; loss: 0.68; acc: 0.83
Batch: 40; loss: 0.33; acc: 0.88
Batch: 60; loss: 0.4; acc: 0.91
Batch: 80; loss: 0.75; acc: 0.81
Batch: 100; loss: 0.67; acc: 0.83
Batch: 120; loss: 0.23; acc: 0.94
Batch: 140; loss: 0.53; acc: 0.78
Batch: 160; loss: 0.5; acc: 0.88
Batch: 180; loss: 0.39; acc: 0.88
Batch: 200; loss: 0.55; acc: 0.8
Batch: 220; loss: 0.66; acc: 0.8
Batch: 240; loss: 0.36; acc: 0.91
Batch: 260; loss: 0.39; acc: 0.86
Batch: 280; loss: 0.38; acc: 0.91
Batch: 300; loss: 0.61; acc: 0.84
Batch: 320; loss: 0.48; acc: 0.83
Batch: 340; loss: 0.39; acc: 0.84
Batch: 360; loss: 0.51; acc: 0.83
Batch: 380; loss: 0.58; acc: 0.84
Batch: 400; loss: 0.42; acc: 0.84
Batch: 420; loss: 0.51; acc: 0.86
Batch: 440; loss: 0.41; acc: 0.89
Batch: 460; loss: 0.8; acc: 0.81
Batch: 480; loss: 0.67; acc: 0.86
Batch: 500; loss: 0.45; acc: 0.86
Batch: 520; loss: 0.44; acc: 0.89
Batch: 540; loss: 0.44; acc: 0.91
Batch: 560; loss: 0.46; acc: 0.84
Batch: 580; loss: 0.4; acc: 0.91
Batch: 600; loss: 0.28; acc: 0.89
Batch: 620; loss: 0.55; acc: 0.83
Batch: 640; loss: 0.52; acc: 0.83
Batch: 660; loss: 0.59; acc: 0.84
Batch: 680; loss: 0.39; acc: 0.89
Batch: 700; loss: 0.42; acc: 0.88
Batch: 720; loss: 0.42; acc: 0.84
Batch: 740; loss: 0.52; acc: 0.83
Batch: 760; loss: 0.73; acc: 0.77
Batch: 780; loss: 0.27; acc: 0.89
Train Epoch over. train_loss: 0.47; train_accuracy: 0.86 

2.3760383555782028e-05
1.0348859177611303e-05
Batch: 0; loss: 0.41; acc: 0.86
Batch: 20; loss: 0.49; acc: 0.83
Batch: 40; loss: 0.25; acc: 0.92
Batch: 60; loss: 0.35; acc: 0.88
Batch: 80; loss: 0.4; acc: 0.88
Batch: 100; loss: 0.39; acc: 0.86
Batch: 120; loss: 0.75; acc: 0.72
Batch: 140; loss: 0.21; acc: 0.95
Val Epoch over. val_loss: 0.4384416863322258; val_accuracy: 0.8681329617834395 

The current subspace-distance is: 1.0348859177611303e-05 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.37; acc: 0.91
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.48; acc: 0.86
Batch: 60; loss: 0.61; acc: 0.81
Batch: 80; loss: 0.43; acc: 0.91
Batch: 100; loss: 0.39; acc: 0.86
Batch: 120; loss: 0.43; acc: 0.89
Batch: 140; loss: 0.44; acc: 0.84
Batch: 160; loss: 0.67; acc: 0.78
Batch: 180; loss: 0.48; acc: 0.86
Batch: 200; loss: 0.41; acc: 0.88
Batch: 220; loss: 0.37; acc: 0.92
Batch: 240; loss: 0.38; acc: 0.91
Batch: 260; loss: 0.39; acc: 0.89
Batch: 280; loss: 0.4; acc: 0.88
Batch: 300; loss: 0.42; acc: 0.91
Batch: 320; loss: 0.38; acc: 0.89
Batch: 340; loss: 0.48; acc: 0.84
Batch: 360; loss: 0.36; acc: 0.89
Batch: 380; loss: 0.41; acc: 0.88
Batch: 400; loss: 0.18; acc: 0.95
Batch: 420; loss: 0.57; acc: 0.78
Batch: 440; loss: 0.43; acc: 0.86
Batch: 460; loss: 0.32; acc: 0.92
Batch: 480; loss: 0.52; acc: 0.88
Batch: 500; loss: 0.28; acc: 0.92
Batch: 520; loss: 0.29; acc: 0.94
Batch: 540; loss: 0.6; acc: 0.88
Batch: 560; loss: 0.47; acc: 0.81
Batch: 580; loss: 0.63; acc: 0.81
Batch: 600; loss: 0.66; acc: 0.77
Batch: 620; loss: 0.81; acc: 0.81
Batch: 640; loss: 0.49; acc: 0.88
Batch: 660; loss: 0.82; acc: 0.8
Batch: 680; loss: 0.55; acc: 0.83
Batch: 700; loss: 0.68; acc: 0.81
Batch: 720; loss: 0.42; acc: 0.88
Batch: 740; loss: 0.58; acc: 0.8
Batch: 760; loss: 0.43; acc: 0.84
Batch: 780; loss: 0.45; acc: 0.86
Train Epoch over. train_loss: 0.47; train_accuracy: 0.86 

2.5337612896692008e-05
7.888631444075145e-06
Batch: 0; loss: 0.58; acc: 0.8
Batch: 20; loss: 0.47; acc: 0.83
Batch: 40; loss: 0.25; acc: 0.92
Batch: 60; loss: 0.4; acc: 0.84
Batch: 80; loss: 0.43; acc: 0.89
Batch: 100; loss: 0.43; acc: 0.84
Batch: 120; loss: 0.75; acc: 0.69
Batch: 140; loss: 0.18; acc: 0.92
Val Epoch over. val_loss: 0.4593997470037952; val_accuracy: 0.8592754777070064 

The current subspace-distance is: 7.888631444075145e-06 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.48; acc: 0.83
Batch: 20; loss: 0.48; acc: 0.92
Batch: 40; loss: 0.3; acc: 0.91
Batch: 60; loss: 0.66; acc: 0.77
Batch: 80; loss: 0.19; acc: 0.97
Batch: 100; loss: 0.39; acc: 0.86
Batch: 120; loss: 0.46; acc: 0.88
Batch: 140; loss: 0.51; acc: 0.88
Batch: 160; loss: 0.4; acc: 0.88
Batch: 180; loss: 0.36; acc: 0.91
Batch: 200; loss: 0.36; acc: 0.86
Batch: 220; loss: 0.73; acc: 0.72
Batch: 240; loss: 0.58; acc: 0.83
Batch: 260; loss: 0.43; acc: 0.84
Batch: 280; loss: 0.25; acc: 0.91
Batch: 300; loss: 0.84; acc: 0.77
Batch: 320; loss: 0.21; acc: 0.97
Batch: 340; loss: 0.6; acc: 0.8
Batch: 360; loss: 0.65; acc: 0.78
Batch: 380; loss: 0.52; acc: 0.83
Batch: 400; loss: 0.43; acc: 0.88
Batch: 420; loss: 0.52; acc: 0.88
Batch: 440; loss: 0.53; acc: 0.89
Batch: 460; loss: 0.78; acc: 0.81
Batch: 480; loss: 0.49; acc: 0.81
Batch: 500; loss: 0.37; acc: 0.89
Batch: 520; loss: 0.33; acc: 0.91
Batch: 540; loss: 0.52; acc: 0.81
Batch: 560; loss: 0.49; acc: 0.83
Batch: 580; loss: 0.35; acc: 0.89
Batch: 600; loss: 0.35; acc: 0.91
Batch: 620; loss: 0.32; acc: 0.92
Batch: 640; loss: 0.19; acc: 0.95
Batch: 660; loss: 0.46; acc: 0.89
Batch: 680; loss: 0.41; acc: 0.88
Batch: 700; loss: 0.45; acc: 0.84
Batch: 720; loss: 0.49; acc: 0.83
Batch: 740; loss: 0.54; acc: 0.8
Batch: 760; loss: 0.58; acc: 0.81
Batch: 780; loss: 0.66; acc: 0.83
Train Epoch over. train_loss: 0.47; train_accuracy: 0.86 

2.3325515940086916e-05
8.557253750041127e-06
Batch: 0; loss: 0.47; acc: 0.86
Batch: 20; loss: 0.45; acc: 0.84
Batch: 40; loss: 0.25; acc: 0.94
Batch: 60; loss: 0.37; acc: 0.88
Batch: 80; loss: 0.38; acc: 0.91
Batch: 100; loss: 0.41; acc: 0.88
Batch: 120; loss: 0.71; acc: 0.7
Batch: 140; loss: 0.19; acc: 0.94
Val Epoch over. val_loss: 0.4328797558785244; val_accuracy: 0.8682324840764332 

The current subspace-distance is: 8.557253750041127e-06 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.6; acc: 0.81
Batch: 20; loss: 0.6; acc: 0.78
Batch: 40; loss: 0.29; acc: 0.92
Batch: 60; loss: 0.43; acc: 0.84
Batch: 80; loss: 0.34; acc: 0.89
Batch: 100; loss: 0.24; acc: 0.95
Batch: 120; loss: 0.37; acc: 0.86
Batch: 140; loss: 0.4; acc: 0.91
Batch: 160; loss: 0.51; acc: 0.84
Batch: 180; loss: 0.48; acc: 0.84
Batch: 200; loss: 0.43; acc: 0.84
Batch: 220; loss: 0.63; acc: 0.83
Batch: 240; loss: 0.25; acc: 0.92
Batch: 260; loss: 1.12; acc: 0.67
Batch: 280; loss: 0.77; acc: 0.83
Batch: 300; loss: 0.71; acc: 0.8
Batch: 320; loss: 0.4; acc: 0.84
Batch: 340; loss: 0.42; acc: 0.86
Batch: 360; loss: 0.6; acc: 0.8
Batch: 380; loss: 0.58; acc: 0.83
Batch: 400; loss: 0.39; acc: 0.91
Batch: 420; loss: 0.64; acc: 0.8
Batch: 440; loss: 0.46; acc: 0.84
Batch: 460; loss: 0.54; acc: 0.83
Batch: 480; loss: 0.34; acc: 0.86
Batch: 500; loss: 0.47; acc: 0.86
Batch: 520; loss: 0.39; acc: 0.86
Batch: 540; loss: 0.27; acc: 0.91
Batch: 560; loss: 0.48; acc: 0.84
Batch: 580; loss: 0.69; acc: 0.77
Batch: 600; loss: 0.54; acc: 0.8
Batch: 620; loss: 0.41; acc: 0.83
Batch: 640; loss: 0.36; acc: 0.88
Batch: 660; loss: 0.36; acc: 0.89
Batch: 680; loss: 0.59; acc: 0.88
Batch: 700; loss: 0.69; acc: 0.78
Batch: 720; loss: 0.38; acc: 0.88
Batch: 740; loss: 0.33; acc: 0.91
Batch: 760; loss: 0.39; acc: 0.89
Batch: 780; loss: 0.29; acc: 0.91
Train Epoch over. train_loss: 0.47; train_accuracy: 0.86 

2.5537559849908575e-05
7.743679816485383e-06
Batch: 0; loss: 0.44; acc: 0.86
Batch: 20; loss: 0.46; acc: 0.81
Batch: 40; loss: 0.25; acc: 0.94
Batch: 60; loss: 0.38; acc: 0.88
Batch: 80; loss: 0.42; acc: 0.88
Batch: 100; loss: 0.4; acc: 0.88
Batch: 120; loss: 0.76; acc: 0.69
Batch: 140; loss: 0.2; acc: 0.94
Val Epoch over. val_loss: 0.44233649181332557; val_accuracy: 0.8660429936305732 

The current subspace-distance is: 7.743679816485383e-06 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.35; acc: 0.88
Batch: 20; loss: 0.73; acc: 0.8
Batch: 40; loss: 0.42; acc: 0.84
Batch: 60; loss: 0.82; acc: 0.77
Batch: 80; loss: 0.34; acc: 0.89
Batch: 100; loss: 0.52; acc: 0.86
Batch: 120; loss: 0.41; acc: 0.91
Batch: 140; loss: 0.48; acc: 0.88
Batch: 160; loss: 0.64; acc: 0.8
Batch: 180; loss: 0.45; acc: 0.89
Batch: 200; loss: 0.25; acc: 0.92
Batch: 220; loss: 0.54; acc: 0.86
Batch: 240; loss: 0.56; acc: 0.86
Batch: 260; loss: 0.3; acc: 0.89
Batch: 280; loss: 0.41; acc: 0.83
Batch: 300; loss: 0.58; acc: 0.84
Batch: 320; loss: 0.5; acc: 0.88
Batch: 340; loss: 0.24; acc: 0.91
Batch: 360; loss: 0.47; acc: 0.88
Batch: 380; loss: 0.46; acc: 0.86
Batch: 400; loss: 0.55; acc: 0.78
Batch: 420; loss: 0.26; acc: 0.94
Batch: 440; loss: 0.76; acc: 0.84
Batch: 460; loss: 0.55; acc: 0.88
Batch: 480; loss: 0.41; acc: 0.88
Batch: 500; loss: 0.28; acc: 0.94
Batch: 520; loss: 0.52; acc: 0.86
Batch: 540; loss: 0.34; acc: 0.88
Batch: 560; loss: 0.48; acc: 0.88
Batch: 580; loss: 0.51; acc: 0.89
Batch: 600; loss: 0.51; acc: 0.81
Batch: 620; loss: 0.57; acc: 0.91
Batch: 640; loss: 0.64; acc: 0.84
Batch: 660; loss: 0.31; acc: 0.91
Batch: 680; loss: 0.46; acc: 0.86
Batch: 700; loss: 0.46; acc: 0.84
Batch: 720; loss: 0.38; acc: 0.88
Batch: 740; loss: 0.4; acc: 0.86
Batch: 760; loss: 0.35; acc: 0.91
Batch: 780; loss: 0.39; acc: 0.89
Train Epoch over. train_loss: 0.47; train_accuracy: 0.86 

2.569724529166706e-05
7.822854968253523e-06
Batch: 0; loss: 0.4; acc: 0.88
Batch: 20; loss: 0.48; acc: 0.84
Batch: 40; loss: 0.24; acc: 0.94
Batch: 60; loss: 0.35; acc: 0.89
Batch: 80; loss: 0.38; acc: 0.89
Batch: 100; loss: 0.4; acc: 0.88
Batch: 120; loss: 0.72; acc: 0.73
Batch: 140; loss: 0.21; acc: 0.94
Val Epoch over. val_loss: 0.4350449794037327; val_accuracy: 0.8706210191082803 

The current subspace-distance is: 7.822854968253523e-06 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.51; acc: 0.89
Batch: 20; loss: 0.65; acc: 0.8
Batch: 40; loss: 0.31; acc: 0.94
Batch: 60; loss: 0.7; acc: 0.8
Batch: 80; loss: 0.45; acc: 0.88
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.7; acc: 0.83
Batch: 140; loss: 0.98; acc: 0.77
Batch: 160; loss: 0.45; acc: 0.89
Batch: 180; loss: 0.23; acc: 0.92
Batch: 200; loss: 0.5; acc: 0.84
Batch: 220; loss: 0.28; acc: 0.92
Batch: 240; loss: 0.48; acc: 0.83
Batch: 260; loss: 0.42; acc: 0.92
Batch: 280; loss: 0.62; acc: 0.81
Batch: 300; loss: 0.5; acc: 0.86
Batch: 320; loss: 0.51; acc: 0.84
Batch: 340; loss: 0.45; acc: 0.88
Batch: 360; loss: 0.4; acc: 0.89
Batch: 380; loss: 0.25; acc: 0.95
Batch: 400; loss: 0.44; acc: 0.88
Batch: 420; loss: 0.48; acc: 0.88
Batch: 440; loss: 0.76; acc: 0.75
Batch: 460; loss: 0.62; acc: 0.83
Batch: 480; loss: 0.45; acc: 0.91
Batch: 500; loss: 0.32; acc: 0.89
Batch: 520; loss: 0.42; acc: 0.86
Batch: 540; loss: 0.49; acc: 0.83
Batch: 560; loss: 0.37; acc: 0.88
Batch: 580; loss: 0.52; acc: 0.81
Batch: 600; loss: 0.63; acc: 0.83
Batch: 620; loss: 0.26; acc: 0.89
Batch: 640; loss: 0.69; acc: 0.84
Batch: 660; loss: 0.43; acc: 0.86
Batch: 680; loss: 0.32; acc: 0.91
Batch: 700; loss: 0.41; acc: 0.91
Batch: 720; loss: 0.45; acc: 0.88
Batch: 740; loss: 0.49; acc: 0.8
Batch: 760; loss: 0.73; acc: 0.81
Batch: 780; loss: 0.52; acc: 0.81
Train Epoch over. train_loss: 0.47; train_accuracy: 0.86 

2.4012044377741404e-05
9.449066055822186e-06
Batch: 0; loss: 0.44; acc: 0.89
Batch: 20; loss: 0.46; acc: 0.84
Batch: 40; loss: 0.24; acc: 0.94
Batch: 60; loss: 0.36; acc: 0.89
Batch: 80; loss: 0.39; acc: 0.89
Batch: 100; loss: 0.41; acc: 0.88
Batch: 120; loss: 0.71; acc: 0.7
Batch: 140; loss: 0.2; acc: 0.94
Val Epoch over. val_loss: 0.4313148766471322; val_accuracy: 0.8691281847133758 

The current subspace-distance is: 9.449066055822186e-06 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.52; acc: 0.81
Batch: 20; loss: 0.36; acc: 0.86
Batch: 40; loss: 0.58; acc: 0.83
Batch: 60; loss: 0.49; acc: 0.86
Batch: 80; loss: 0.54; acc: 0.84
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.52; acc: 0.84
Batch: 140; loss: 0.42; acc: 0.86
Batch: 160; loss: 0.37; acc: 0.91
Batch: 180; loss: 0.35; acc: 0.92
Batch: 200; loss: 0.41; acc: 0.86
Batch: 220; loss: 0.7; acc: 0.8
Batch: 240; loss: 0.32; acc: 0.91
Batch: 260; loss: 0.49; acc: 0.86
Batch: 280; loss: 0.65; acc: 0.86
Batch: 300; loss: 1.09; acc: 0.81
Batch: 320; loss: 0.34; acc: 0.91
Batch: 340; loss: 0.62; acc: 0.88
Batch: 360; loss: 0.37; acc: 0.95
Batch: 380; loss: 0.42; acc: 0.83
Batch: 400; loss: 0.42; acc: 0.84
Batch: 420; loss: 0.33; acc: 0.88
Batch: 440; loss: 0.39; acc: 0.91
Batch: 460; loss: 0.6; acc: 0.86
Batch: 480; loss: 0.25; acc: 0.91
Batch: 500; loss: 0.47; acc: 0.88
Batch: 520; loss: 0.47; acc: 0.92
Batch: 540; loss: 0.43; acc: 0.83
Batch: 560; loss: 0.34; acc: 0.91
Batch: 580; loss: 0.45; acc: 0.89
Batch: 600; loss: 0.34; acc: 0.88
Batch: 620; loss: 0.74; acc: 0.81
Batch: 640; loss: 0.24; acc: 0.91
Batch: 660; loss: 0.3; acc: 0.89
Batch: 680; loss: 0.45; acc: 0.88
Batch: 700; loss: 0.45; acc: 0.88
Batch: 720; loss: 0.67; acc: 0.78
Batch: 740; loss: 0.36; acc: 0.91
Batch: 760; loss: 0.46; acc: 0.89
Batch: 780; loss: 0.34; acc: 0.88
Train Epoch over. train_loss: 0.47; train_accuracy: 0.86 

2.277925523230806e-05
7.839533282094635e-06
Batch: 0; loss: 0.45; acc: 0.86
Batch: 20; loss: 0.46; acc: 0.83
Batch: 40; loss: 0.24; acc: 0.92
Batch: 60; loss: 0.37; acc: 0.88
Batch: 80; loss: 0.42; acc: 0.88
Batch: 100; loss: 0.41; acc: 0.88
Batch: 120; loss: 0.73; acc: 0.7
Batch: 140; loss: 0.21; acc: 0.94
Val Epoch over. val_loss: 0.4351413180209269; val_accuracy: 0.8679339171974523 

The current subspace-distance is: 7.839533282094635e-06 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.59; acc: 0.8
Batch: 40; loss: 0.48; acc: 0.86
Batch: 60; loss: 0.46; acc: 0.89
Batch: 80; loss: 0.47; acc: 0.84
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.34; acc: 0.89
Batch: 140; loss: 0.5; acc: 0.8
Batch: 160; loss: 0.4; acc: 0.83
Batch: 180; loss: 0.59; acc: 0.81
Batch: 200; loss: 0.32; acc: 0.94
Batch: 220; loss: 0.32; acc: 0.92
Batch: 240; loss: 0.52; acc: 0.84
Batch: 260; loss: 0.46; acc: 0.83
Batch: 280; loss: 0.53; acc: 0.86
Batch: 300; loss: 0.52; acc: 0.84
Batch: 320; loss: 0.63; acc: 0.8
Batch: 340; loss: 0.43; acc: 0.84
Batch: 360; loss: 0.25; acc: 0.92
Batch: 380; loss: 0.42; acc: 0.86
Batch: 400; loss: 0.54; acc: 0.86
Batch: 420; loss: 0.52; acc: 0.84
Batch: 440; loss: 0.3; acc: 0.92
Batch: 460; loss: 0.47; acc: 0.88
Batch: 480; loss: 0.48; acc: 0.91
Batch: 500; loss: 0.47; acc: 0.83
Batch: 520; loss: 0.24; acc: 0.94
Batch: 540; loss: 0.25; acc: 0.94
Batch: 560; loss: 0.44; acc: 0.84
Batch: 580; loss: 0.38; acc: 0.91
Batch: 600; loss: 0.24; acc: 0.94
Batch: 620; loss: 0.61; acc: 0.84
Batch: 640; loss: 0.52; acc: 0.81
Batch: 660; loss: 0.47; acc: 0.84
Batch: 680; loss: 0.75; acc: 0.81
Batch: 700; loss: 0.46; acc: 0.91
Batch: 720; loss: 0.54; acc: 0.83
Batch: 740; loss: 0.38; acc: 0.94
Batch: 760; loss: 0.51; acc: 0.83
Batch: 780; loss: 0.58; acc: 0.8
Train Epoch over. train_loss: 0.47; train_accuracy: 0.86 

2.5883879061439075e-05
8.550962775188964e-06
Batch: 0; loss: 0.44; acc: 0.88
Batch: 20; loss: 0.46; acc: 0.83
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.37; acc: 0.88
Batch: 80; loss: 0.39; acc: 0.89
Batch: 100; loss: 0.4; acc: 0.86
Batch: 120; loss: 0.71; acc: 0.7
Batch: 140; loss: 0.2; acc: 0.94
Val Epoch over. val_loss: 0.43132831820636797; val_accuracy: 0.8695262738853503 

The current subspace-distance is: 8.550962775188964e-06 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.45; acc: 0.91
Batch: 20; loss: 0.49; acc: 0.88
Batch: 40; loss: 0.72; acc: 0.81
Batch: 60; loss: 0.53; acc: 0.86
Batch: 80; loss: 0.43; acc: 0.89
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.39; acc: 0.84
Batch: 140; loss: 0.59; acc: 0.81
Batch: 160; loss: 0.43; acc: 0.86
Batch: 180; loss: 0.39; acc: 0.86
Batch: 200; loss: 0.46; acc: 0.84
Batch: 220; loss: 0.51; acc: 0.84
Batch: 240; loss: 0.27; acc: 0.92
Batch: 260; loss: 0.58; acc: 0.78
Batch: 280; loss: 0.38; acc: 0.86
Batch: 300; loss: 0.47; acc: 0.86
Batch: 320; loss: 0.61; acc: 0.8
Batch: 340; loss: 0.46; acc: 0.83
Batch: 360; loss: 0.28; acc: 0.92
Batch: 380; loss: 0.31; acc: 0.91
Batch: 400; loss: 0.71; acc: 0.83
Batch: 420; loss: 0.49; acc: 0.88
Batch: 440; loss: 0.48; acc: 0.8
Batch: 460; loss: 0.36; acc: 0.86
Batch: 480; loss: 0.31; acc: 0.89
Batch: 500; loss: 0.3; acc: 0.91
Batch: 520; loss: 0.25; acc: 0.89
Batch: 540; loss: 0.36; acc: 0.89
Batch: 560; loss: 0.42; acc: 0.86
Batch: 580; loss: 0.47; acc: 0.88
Batch: 600; loss: 0.42; acc: 0.86
Batch: 620; loss: 0.4; acc: 0.83
Batch: 640; loss: 0.28; acc: 0.95
Batch: 660; loss: 0.57; acc: 0.86
Batch: 680; loss: 0.61; acc: 0.81
Batch: 700; loss: 0.47; acc: 0.81
Batch: 720; loss: 0.27; acc: 0.89
Batch: 740; loss: 0.53; acc: 0.81
Batch: 760; loss: 0.39; acc: 0.84
Batch: 780; loss: 0.44; acc: 0.88
Train Epoch over. train_loss: 0.47; train_accuracy: 0.86 

2.4088663849397562e-05
7.88969100540271e-06
Batch: 0; loss: 0.46; acc: 0.86
Batch: 20; loss: 0.44; acc: 0.84
Batch: 40; loss: 0.24; acc: 0.94
Batch: 60; loss: 0.4; acc: 0.88
Batch: 80; loss: 0.4; acc: 0.89
Batch: 100; loss: 0.42; acc: 0.88
Batch: 120; loss: 0.69; acc: 0.72
Batch: 140; loss: 0.22; acc: 0.94
Val Epoch over. val_loss: 0.4378147975654359; val_accuracy: 0.8681329617834395 

The current subspace-distance is: 7.88969100540271e-06 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.66; acc: 0.84
Batch: 20; loss: 0.27; acc: 0.91
Batch: 40; loss: 0.4; acc: 0.88
Batch: 60; loss: 0.78; acc: 0.8
Batch: 80; loss: 0.47; acc: 0.91
Batch: 100; loss: 0.52; acc: 0.89
Batch: 120; loss: 0.65; acc: 0.8
Batch: 140; loss: 0.38; acc: 0.89
Batch: 160; loss: 0.43; acc: 0.86
Batch: 180; loss: 0.52; acc: 0.83
Batch: 200; loss: 0.42; acc: 0.84
Batch: 220; loss: 0.67; acc: 0.83
Batch: 240; loss: 0.57; acc: 0.86
Batch: 260; loss: 0.56; acc: 0.77
Batch: 280; loss: 0.63; acc: 0.86
Batch: 300; loss: 0.42; acc: 0.83
Batch: 320; loss: 0.45; acc: 0.84
Batch: 340; loss: 0.51; acc: 0.86
Batch: 360; loss: 0.53; acc: 0.83
Batch: 380; loss: 0.48; acc: 0.86
Batch: 400; loss: 0.46; acc: 0.86
Batch: 420; loss: 0.64; acc: 0.77
Batch: 440; loss: 0.62; acc: 0.81
Batch: 460; loss: 0.38; acc: 0.86
Batch: 480; loss: 0.42; acc: 0.89
Batch: 500; loss: 0.3; acc: 0.95
Batch: 520; loss: 0.57; acc: 0.88
Batch: 540; loss: 0.53; acc: 0.88
Batch: 560; loss: 0.27; acc: 0.92
Batch: 580; loss: 0.43; acc: 0.89
Batch: 600; loss: 0.48; acc: 0.83
Batch: 620; loss: 0.49; acc: 0.83
Batch: 640; loss: 0.7; acc: 0.81
Batch: 660; loss: 0.41; acc: 0.89
Batch: 680; loss: 0.52; acc: 0.88
Batch: 700; loss: 0.45; acc: 0.88
Batch: 720; loss: 0.5; acc: 0.89
Batch: 740; loss: 0.47; acc: 0.83
Batch: 760; loss: 0.4; acc: 0.89
Batch: 780; loss: 0.43; acc: 0.86
Train Epoch over. train_loss: 0.47; train_accuracy: 0.86 

2.5680026737973094e-05
8.518097274645697e-06
Batch: 0; loss: 0.44; acc: 0.86
Batch: 20; loss: 0.46; acc: 0.84
Batch: 40; loss: 0.24; acc: 0.94
Batch: 60; loss: 0.38; acc: 0.88
Batch: 80; loss: 0.39; acc: 0.89
Batch: 100; loss: 0.4; acc: 0.86
Batch: 120; loss: 0.72; acc: 0.73
Batch: 140; loss: 0.21; acc: 0.94
Val Epoch over. val_loss: 0.4348004407658698; val_accuracy: 0.8689291401273885 

The current subspace-distance is: 8.518097274645697e-06 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.32; acc: 0.94
Batch: 20; loss: 0.65; acc: 0.78
Batch: 40; loss: 0.49; acc: 0.83
Batch: 60; loss: 0.35; acc: 0.89
Batch: 80; loss: 0.22; acc: 0.91
Batch: 100; loss: 0.48; acc: 0.86
Batch: 120; loss: 0.49; acc: 0.89
Batch: 140; loss: 0.42; acc: 0.86
Batch: 160; loss: 0.39; acc: 0.89
Batch: 180; loss: 0.62; acc: 0.86
Batch: 200; loss: 0.2; acc: 0.94
Batch: 220; loss: 0.42; acc: 0.92
Batch: 240; loss: 0.4; acc: 0.86
Batch: 260; loss: 0.48; acc: 0.86
Batch: 280; loss: 0.65; acc: 0.84
Batch: 300; loss: 0.71; acc: 0.83
Batch: 320; loss: 0.54; acc: 0.84
Batch: 340; loss: 0.45; acc: 0.86
Batch: 360; loss: 0.46; acc: 0.86
Batch: 380; loss: 0.7; acc: 0.83
Batch: 400; loss: 0.32; acc: 0.95
Batch: 420; loss: 0.36; acc: 0.88
Batch: 440; loss: 0.46; acc: 0.88
Batch: 460; loss: 0.51; acc: 0.86
Batch: 480; loss: 0.49; acc: 0.81
Batch: 500; loss: 0.41; acc: 0.86
Batch: 520; loss: 0.5; acc: 0.83
Batch: 540; loss: 0.44; acc: 0.84
Batch: 560; loss: 0.37; acc: 0.84
Batch: 580; loss: 0.67; acc: 0.81
Batch: 600; loss: 0.42; acc: 0.88
Batch: 620; loss: 0.53; acc: 0.84
Batch: 640; loss: 0.67; acc: 0.81
Batch: 660; loss: 0.52; acc: 0.86
Batch: 680; loss: 0.29; acc: 0.95
Batch: 700; loss: 0.24; acc: 0.89
Batch: 720; loss: 0.59; acc: 0.86
Batch: 740; loss: 0.51; acc: 0.81
Batch: 760; loss: 0.46; acc: 0.86
Batch: 780; loss: 0.55; acc: 0.84
Train Epoch over. train_loss: 0.47; train_accuracy: 0.86 

2.450219471938908e-05
9.25313634070335e-06
Batch: 0; loss: 0.43; acc: 0.88
Batch: 20; loss: 0.48; acc: 0.8
Batch: 40; loss: 0.24; acc: 0.94
Batch: 60; loss: 0.37; acc: 0.89
Batch: 80; loss: 0.4; acc: 0.89
Batch: 100; loss: 0.4; acc: 0.86
Batch: 120; loss: 0.74; acc: 0.72
Batch: 140; loss: 0.21; acc: 0.94
Val Epoch over. val_loss: 0.4363206891212494; val_accuracy: 0.8691281847133758 

The current subspace-distance is: 9.25313634070335e-06 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.5; acc: 0.83
Batch: 20; loss: 0.66; acc: 0.78
Batch: 40; loss: 0.5; acc: 0.86
Batch: 60; loss: 0.62; acc: 0.81
Batch: 80; loss: 0.43; acc: 0.84
Batch: 100; loss: 0.57; acc: 0.81
Batch: 120; loss: 0.38; acc: 0.89
Batch: 140; loss: 0.43; acc: 0.83
Batch: 160; loss: 0.64; acc: 0.78
Batch: 180; loss: 0.47; acc: 0.88
Batch: 200; loss: 0.42; acc: 0.86
Batch: 220; loss: 0.31; acc: 0.91
Batch: 240; loss: 0.51; acc: 0.8
Batch: 260; loss: 0.57; acc: 0.81
Batch: 280; loss: 0.37; acc: 0.88
Batch: 300; loss: 0.37; acc: 0.83
Batch: 320; loss: 0.48; acc: 0.84
Batch: 340; loss: 0.55; acc: 0.88
Batch: 360; loss: 0.48; acc: 0.83
Batch: 380; loss: 0.35; acc: 0.84
Batch: 400; loss: 0.38; acc: 0.88
Batch: 420; loss: 0.41; acc: 0.91
Batch: 440; loss: 0.29; acc: 0.89
Batch: 460; loss: 0.5; acc: 0.81
Batch: 480; loss: 0.45; acc: 0.81
Batch: 500; loss: 0.31; acc: 0.91
Batch: 520; loss: 0.26; acc: 0.94
Batch: 540; loss: 0.61; acc: 0.8
Batch: 560; loss: 0.3; acc: 0.88
Batch: 580; loss: 0.54; acc: 0.86
Batch: 600; loss: 0.44; acc: 0.88
Batch: 620; loss: 0.26; acc: 0.92
Batch: 640; loss: 0.58; acc: 0.86
Batch: 660; loss: 0.34; acc: 0.91
Batch: 680; loss: 0.37; acc: 0.89
Batch: 700; loss: 0.53; acc: 0.8
Batch: 720; loss: 0.49; acc: 0.86
Batch: 740; loss: 0.44; acc: 0.88
Batch: 760; loss: 0.45; acc: 0.86
Batch: 780; loss: 0.53; acc: 0.86
Train Epoch over. train_loss: 0.47; train_accuracy: 0.86 

2.13244875340024e-05
8.197065653803293e-06
Batch: 0; loss: 0.45; acc: 0.86
Batch: 20; loss: 0.45; acc: 0.83
Batch: 40; loss: 0.23; acc: 0.92
Batch: 60; loss: 0.37; acc: 0.86
Batch: 80; loss: 0.4; acc: 0.88
Batch: 100; loss: 0.4; acc: 0.86
Batch: 120; loss: 0.71; acc: 0.72
Batch: 140; loss: 0.2; acc: 0.94
Val Epoch over. val_loss: 0.4304899375909453; val_accuracy: 0.868531050955414 

The current subspace-distance is: 8.197065653803293e-06 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.47; acc: 0.86
Batch: 20; loss: 0.55; acc: 0.83
Batch: 40; loss: 0.23; acc: 0.97
Batch: 60; loss: 0.39; acc: 0.89
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.36; acc: 0.88
Batch: 120; loss: 0.57; acc: 0.84
Batch: 140; loss: 0.48; acc: 0.88
Batch: 160; loss: 0.41; acc: 0.83
Batch: 180; loss: 0.37; acc: 0.91
Batch: 200; loss: 0.4; acc: 0.88
Batch: 220; loss: 0.48; acc: 0.83
Batch: 240; loss: 0.57; acc: 0.83
Batch: 260; loss: 0.27; acc: 0.92
Batch: 280; loss: 0.46; acc: 0.81
Batch: 300; loss: 0.5; acc: 0.86
Batch: 320; loss: 0.41; acc: 0.86
Batch: 340; loss: 0.58; acc: 0.84
Batch: 360; loss: 0.54; acc: 0.88
Batch: 380; loss: 0.46; acc: 0.88
Batch: 400; loss: 0.26; acc: 0.88
Batch: 420; loss: 0.56; acc: 0.84
Batch: 440; loss: 0.43; acc: 0.81
Batch: 460; loss: 0.57; acc: 0.86
Batch: 480; loss: 0.54; acc: 0.86
Batch: 500; loss: 0.35; acc: 0.92
Batch: 520; loss: 0.55; acc: 0.84
Batch: 540; loss: 0.54; acc: 0.88
Batch: 560; loss: 0.54; acc: 0.81
Batch: 580; loss: 0.31; acc: 0.88
Batch: 600; loss: 0.56; acc: 0.8
Batch: 620; loss: 0.32; acc: 0.91
Batch: 640; loss: 0.31; acc: 0.94
Batch: 660; loss: 0.41; acc: 0.86
Batch: 680; loss: 0.47; acc: 0.81
Batch: 700; loss: 0.5; acc: 0.84
Batch: 720; loss: 0.35; acc: 0.89
Batch: 740; loss: 0.67; acc: 0.84
Batch: 760; loss: 0.24; acc: 0.94
Batch: 780; loss: 0.43; acc: 0.88
Train Epoch over. train_loss: 0.47; train_accuracy: 0.86 

2.5370205548824742e-05
9.731453246786259e-06
Batch: 0; loss: 0.43; acc: 0.88
Batch: 20; loss: 0.45; acc: 0.83
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.37; acc: 0.88
Batch: 80; loss: 0.41; acc: 0.88
Batch: 100; loss: 0.4; acc: 0.88
Batch: 120; loss: 0.7; acc: 0.73
Batch: 140; loss: 0.22; acc: 0.94
Val Epoch over. val_loss: 0.43464233602877633; val_accuracy: 0.8688296178343949 

The current subspace-distance is: 9.731453246786259e-06 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.61; acc: 0.81
Batch: 20; loss: 0.52; acc: 0.84
Batch: 40; loss: 0.33; acc: 0.89
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.47; acc: 0.91
Batch: 100; loss: 0.56; acc: 0.83
Batch: 120; loss: 0.53; acc: 0.84
Batch: 140; loss: 0.4; acc: 0.91
Batch: 160; loss: 0.21; acc: 0.92
Batch: 180; loss: 0.33; acc: 0.92
Batch: 200; loss: 0.62; acc: 0.78
Batch: 220; loss: 0.52; acc: 0.84
Batch: 240; loss: 0.47; acc: 0.83
Batch: 260; loss: 0.56; acc: 0.88
Batch: 280; loss: 0.72; acc: 0.81
Batch: 300; loss: 0.83; acc: 0.83
Batch: 320; loss: 0.38; acc: 0.88
Batch: 340; loss: 0.51; acc: 0.89
Batch: 360; loss: 0.23; acc: 0.95
Batch: 380; loss: 0.38; acc: 0.89
Batch: 400; loss: 0.44; acc: 0.91
Batch: 420; loss: 0.64; acc: 0.8
Batch: 440; loss: 0.29; acc: 0.89
Batch: 460; loss: 0.54; acc: 0.84
Batch: 480; loss: 0.35; acc: 0.92
Batch: 500; loss: 0.45; acc: 0.89
Batch: 520; loss: 0.56; acc: 0.84
Batch: 540; loss: 0.24; acc: 0.95
Batch: 560; loss: 0.57; acc: 0.84
Batch: 580; loss: 0.73; acc: 0.77
Batch: 600; loss: 0.39; acc: 0.86
Batch: 620; loss: 0.27; acc: 0.92
Batch: 640; loss: 0.42; acc: 0.84
Batch: 660; loss: 0.41; acc: 0.88
Batch: 680; loss: 0.44; acc: 0.84
Batch: 700; loss: 0.42; acc: 0.86
Batch: 720; loss: 0.42; acc: 0.8
Batch: 740; loss: 0.61; acc: 0.83
Batch: 760; loss: 0.25; acc: 0.92
Batch: 780; loss: 0.57; acc: 0.83
Train Epoch over. train_loss: 0.47; train_accuracy: 0.86 

2.42310379690025e-05
8.756712304602843e-06
Batch: 0; loss: 0.45; acc: 0.86
Batch: 20; loss: 0.47; acc: 0.83
Batch: 40; loss: 0.24; acc: 0.92
Batch: 60; loss: 0.4; acc: 0.86
Batch: 80; loss: 0.44; acc: 0.88
Batch: 100; loss: 0.4; acc: 0.86
Batch: 120; loss: 0.74; acc: 0.7
Batch: 140; loss: 0.22; acc: 0.94
Val Epoch over. val_loss: 0.44129255646543136; val_accuracy: 0.8664410828025477 

The current subspace-distance is: 8.756712304602843e-06 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.62; acc: 0.83
Batch: 20; loss: 0.38; acc: 0.88
Batch: 40; loss: 0.35; acc: 0.88
Batch: 60; loss: 0.64; acc: 0.84
Batch: 80; loss: 0.3; acc: 0.89
Batch: 100; loss: 0.34; acc: 0.86
Batch: 120; loss: 0.51; acc: 0.86
Batch: 140; loss: 0.41; acc: 0.88
Batch: 160; loss: 0.49; acc: 0.81
Batch: 180; loss: 0.54; acc: 0.84
Batch: 200; loss: 0.32; acc: 0.86
Batch: 220; loss: 0.33; acc: 0.92
Batch: 240; loss: 0.44; acc: 0.84
Batch: 260; loss: 0.6; acc: 0.81
Batch: 280; loss: 0.71; acc: 0.78
Batch: 300; loss: 0.45; acc: 0.8
Batch: 320; loss: 0.36; acc: 0.88
Batch: 340; loss: 0.55; acc: 0.84
Batch: 360; loss: 0.41; acc: 0.88
Batch: 380; loss: 0.59; acc: 0.83
Batch: 400; loss: 0.34; acc: 0.89
Batch: 420; loss: 0.46; acc: 0.83
Batch: 440; loss: 0.51; acc: 0.86
Batch: 460; loss: 0.52; acc: 0.86
Batch: 480; loss: 0.31; acc: 0.91
Batch: 500; loss: 0.42; acc: 0.84
Batch: 520; loss: 0.4; acc: 0.86
Batch: 540; loss: 0.34; acc: 0.86
Batch: 560; loss: 0.32; acc: 0.92
Batch: 580; loss: 0.6; acc: 0.8
Batch: 600; loss: 0.39; acc: 0.84
Batch: 620; loss: 0.38; acc: 0.86
Batch: 640; loss: 0.43; acc: 0.89
Batch: 660; loss: 0.52; acc: 0.86
Batch: 680; loss: 0.59; acc: 0.84
Batch: 700; loss: 0.57; acc: 0.8
Batch: 720; loss: 0.43; acc: 0.91
Batch: 740; loss: 0.34; acc: 0.88
Batch: 760; loss: 0.45; acc: 0.83
Batch: 780; loss: 0.3; acc: 0.94
Train Epoch over. train_loss: 0.47; train_accuracy: 0.86 

2.3158321710070595e-05
8.124533451336902e-06
Batch: 0; loss: 0.44; acc: 0.88
Batch: 20; loss: 0.46; acc: 0.81
Batch: 40; loss: 0.24; acc: 0.94
Batch: 60; loss: 0.37; acc: 0.88
Batch: 80; loss: 0.39; acc: 0.89
Batch: 100; loss: 0.4; acc: 0.86
Batch: 120; loss: 0.72; acc: 0.72
Batch: 140; loss: 0.21; acc: 0.94
Val Epoch over. val_loss: 0.431678050168001; val_accuracy: 0.8697253184713376 

The current subspace-distance is: 8.124533451336902e-06 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.27; acc: 0.94
Batch: 20; loss: 0.56; acc: 0.88
Batch: 40; loss: 0.41; acc: 0.83
Batch: 60; loss: 0.66; acc: 0.83
Batch: 80; loss: 0.68; acc: 0.8
Batch: 100; loss: 0.67; acc: 0.84
Batch: 120; loss: 0.46; acc: 0.91
Batch: 140; loss: 0.45; acc: 0.86
Batch: 160; loss: 0.38; acc: 0.88
Batch: 180; loss: 0.43; acc: 0.86
Batch: 200; loss: 0.38; acc: 0.88
Batch: 220; loss: 0.67; acc: 0.8
Batch: 240; loss: 0.71; acc: 0.81
Batch: 260; loss: 0.45; acc: 0.88
Batch: 280; loss: 0.55; acc: 0.89
Batch: 300; loss: 0.4; acc: 0.91
Batch: 320; loss: 0.48; acc: 0.83
Batch: 340; loss: 0.3; acc: 0.94
Batch: 360; loss: 0.7; acc: 0.84
Batch: 380; loss: 0.66; acc: 0.8
Batch: 400; loss: 0.68; acc: 0.77
Batch: 420; loss: 0.48; acc: 0.86
Batch: 440; loss: 0.43; acc: 0.83
Batch: 460; loss: 0.34; acc: 0.88
Batch: 480; loss: 0.25; acc: 0.94
Batch: 500; loss: 0.25; acc: 0.91
Batch: 520; loss: 0.45; acc: 0.86
Batch: 540; loss: 0.43; acc: 0.89
Batch: 560; loss: 0.6; acc: 0.86
Batch: 580; loss: 0.68; acc: 0.86
Batch: 600; loss: 0.6; acc: 0.8
Batch: 620; loss: 0.34; acc: 0.88
Batch: 640; loss: 0.38; acc: 0.88
Batch: 660; loss: 0.75; acc: 0.84
Batch: 680; loss: 0.45; acc: 0.88
Batch: 700; loss: 0.39; acc: 0.88
Batch: 720; loss: 0.59; acc: 0.86
Batch: 740; loss: 0.38; acc: 0.88
Batch: 760; loss: 0.26; acc: 0.91
Batch: 780; loss: 0.28; acc: 0.92
Train Epoch over. train_loss: 0.47; train_accuracy: 0.86 

2.4210539777413942e-05
8.932691343943588e-06
Batch: 0; loss: 0.45; acc: 0.88
Batch: 20; loss: 0.45; acc: 0.84
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.37; acc: 0.86
Batch: 80; loss: 0.39; acc: 0.88
Batch: 100; loss: 0.4; acc: 0.86
Batch: 120; loss: 0.7; acc: 0.72
Batch: 140; loss: 0.21; acc: 0.94
Val Epoch over. val_loss: 0.4296633998869331; val_accuracy: 0.8714171974522293 

The current subspace-distance is: 8.932691343943588e-06 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.39; acc: 0.88
Batch: 20; loss: 0.36; acc: 0.88
Batch: 40; loss: 0.49; acc: 0.91
Batch: 60; loss: 0.61; acc: 0.86
Batch: 80; loss: 0.55; acc: 0.81
Batch: 100; loss: 0.57; acc: 0.83
Batch: 120; loss: 0.57; acc: 0.83
Batch: 140; loss: 0.44; acc: 0.84
Batch: 160; loss: 0.54; acc: 0.81
Batch: 180; loss: 0.44; acc: 0.86
Batch: 200; loss: 0.39; acc: 0.92
Batch: 220; loss: 0.33; acc: 0.88
Batch: 240; loss: 0.46; acc: 0.83
Batch: 260; loss: 0.42; acc: 0.89
Batch: 280; loss: 0.44; acc: 0.86
Batch: 300; loss: 0.42; acc: 0.89
Batch: 320; loss: 0.6; acc: 0.81
Batch: 340; loss: 0.29; acc: 0.95
Batch: 360; loss: 0.45; acc: 0.86
Batch: 380; loss: 0.36; acc: 0.88
Batch: 400; loss: 0.46; acc: 0.89
Batch: 420; loss: 0.35; acc: 0.91
Batch: 440; loss: 0.37; acc: 0.88
Batch: 460; loss: 0.32; acc: 0.88
Batch: 480; loss: 0.36; acc: 0.86
Batch: 500; loss: 0.37; acc: 0.89
Batch: 520; loss: 0.48; acc: 0.86
Batch: 540; loss: 0.48; acc: 0.84
Batch: 560; loss: 0.42; acc: 0.86
Batch: 580; loss: 0.34; acc: 0.88
Batch: 600; loss: 0.7; acc: 0.8
Batch: 620; loss: 0.47; acc: 0.84
Batch: 640; loss: 0.31; acc: 0.92
Batch: 660; loss: 0.62; acc: 0.8
Batch: 680; loss: 0.31; acc: 0.91
Batch: 700; loss: 0.52; acc: 0.8
Batch: 720; loss: 0.45; acc: 0.83
Batch: 740; loss: 0.32; acc: 0.91
Batch: 760; loss: 0.46; acc: 0.86
Batch: 780; loss: 0.59; acc: 0.83
Train Epoch over. train_loss: 0.47; train_accuracy: 0.86 

2.325596688024234e-05
9.708978723210748e-06
Batch: 0; loss: 0.44; acc: 0.88
Batch: 20; loss: 0.46; acc: 0.84
Batch: 40; loss: 0.24; acc: 0.94
Batch: 60; loss: 0.36; acc: 0.89
Batch: 80; loss: 0.39; acc: 0.89
Batch: 100; loss: 0.41; acc: 0.86
Batch: 120; loss: 0.71; acc: 0.72
Batch: 140; loss: 0.21; acc: 0.94
Val Epoch over. val_loss: 0.4313939538825849; val_accuracy: 0.8702229299363057 

The current subspace-distance is: 9.708978723210748e-06 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.58; acc: 0.84
Batch: 20; loss: 0.47; acc: 0.84
Batch: 40; loss: 0.51; acc: 0.81
Batch: 60; loss: 0.55; acc: 0.84
Batch: 80; loss: 0.26; acc: 0.91
Batch: 100; loss: 0.51; acc: 0.84
Batch: 120; loss: 0.57; acc: 0.81
Batch: 140; loss: 0.51; acc: 0.81
Batch: 160; loss: 0.36; acc: 0.91
Batch: 180; loss: 0.83; acc: 0.73
Batch: 200; loss: 0.37; acc: 0.94
Batch: 220; loss: 0.41; acc: 0.81
Batch: 240; loss: 0.47; acc: 0.88
Batch: 260; loss: 0.36; acc: 0.89
Batch: 280; loss: 0.4; acc: 0.88
Batch: 300; loss: 0.48; acc: 0.81
Batch: 320; loss: 0.32; acc: 0.89
Batch: 340; loss: 0.41; acc: 0.89
Batch: 360; loss: 0.35; acc: 0.89
Batch: 380; loss: 0.42; acc: 0.86
Batch: 400; loss: 0.42; acc: 0.89
Batch: 420; loss: 0.56; acc: 0.83
Batch: 440; loss: 0.5; acc: 0.92
Batch: 460; loss: 0.59; acc: 0.84
Batch: 480; loss: 0.35; acc: 0.92
Batch: 500; loss: 0.37; acc: 0.92
Batch: 520; loss: 0.58; acc: 0.84
Batch: 540; loss: 0.56; acc: 0.8
Batch: 560; loss: 0.34; acc: 0.86
Batch: 580; loss: 0.55; acc: 0.83
Batch: 600; loss: 0.67; acc: 0.77
Batch: 620; loss: 0.55; acc: 0.81
Batch: 640; loss: 0.25; acc: 0.92
Batch: 660; loss: 0.44; acc: 0.89
Batch: 680; loss: 0.57; acc: 0.86
Batch: 700; loss: 0.33; acc: 0.89
Batch: 720; loss: 0.46; acc: 0.86
Batch: 740; loss: 0.62; acc: 0.84
Batch: 760; loss: 0.57; acc: 0.84
Batch: 780; loss: 0.69; acc: 0.81
Train Epoch over. train_loss: 0.47; train_accuracy: 0.86 

2.6556990633253008e-05
1.0204375030298252e-05
Batch: 0; loss: 0.43; acc: 0.89
Batch: 20; loss: 0.45; acc: 0.84
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.37; acc: 0.89
Batch: 80; loss: 0.4; acc: 0.89
Batch: 100; loss: 0.4; acc: 0.88
Batch: 120; loss: 0.7; acc: 0.73
Batch: 140; loss: 0.21; acc: 0.94
Val Epoch over. val_loss: 0.43183162675541675; val_accuracy: 0.8700238853503185 

The current subspace-distance is: 1.0204375030298252e-05 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.35; acc: 0.91
Batch: 20; loss: 0.58; acc: 0.77
Batch: 40; loss: 0.3; acc: 0.86
Batch: 60; loss: 0.82; acc: 0.78
Batch: 80; loss: 0.5; acc: 0.81
Batch: 100; loss: 0.48; acc: 0.83
Batch: 120; loss: 0.41; acc: 0.91
Batch: 140; loss: 0.5; acc: 0.88
Batch: 160; loss: 0.61; acc: 0.84
Batch: 180; loss: 0.45; acc: 0.86
Batch: 200; loss: 0.41; acc: 0.88
Batch: 220; loss: 0.49; acc: 0.83
Batch: 240; loss: 0.63; acc: 0.83
Batch: 260; loss: 0.63; acc: 0.78
Batch: 280; loss: 0.66; acc: 0.86
Batch: 300; loss: 0.61; acc: 0.84
Batch: 320; loss: 0.45; acc: 0.88
Batch: 340; loss: 0.38; acc: 0.84
Batch: 360; loss: 0.48; acc: 0.81
Batch: 380; loss: 0.42; acc: 0.88
Batch: 400; loss: 0.68; acc: 0.78
Batch: 420; loss: 0.36; acc: 0.88
Batch: 440; loss: 0.42; acc: 0.89
Batch: 460; loss: 0.43; acc: 0.89
Batch: 480; loss: 0.79; acc: 0.78
Batch: 500; loss: 0.69; acc: 0.83
Batch: 520; loss: 0.42; acc: 0.88
Batch: 540; loss: 0.43; acc: 0.84
Batch: 560; loss: 0.25; acc: 0.92
Batch: 580; loss: 0.55; acc: 0.77
Batch: 600; loss: 0.49; acc: 0.83
Batch: 620; loss: 0.46; acc: 0.86
Batch: 640; loss: 0.74; acc: 0.72
Batch: 660; loss: 0.72; acc: 0.83
Batch: 680; loss: 0.31; acc: 0.88
Batch: 700; loss: 0.46; acc: 0.84
Batch: 720; loss: 0.39; acc: 0.88
Batch: 740; loss: 0.68; acc: 0.8
Batch: 760; loss: 0.47; acc: 0.83
Batch: 780; loss: 0.33; acc: 0.92
Train Epoch over. train_loss: 0.47; train_accuracy: 0.86 

2.5478058887529187e-05
7.046958671708126e-06
Batch: 0; loss: 0.43; acc: 0.89
Batch: 20; loss: 0.46; acc: 0.84
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.37; acc: 0.89
Batch: 80; loss: 0.4; acc: 0.89
Batch: 100; loss: 0.39; acc: 0.86
Batch: 120; loss: 0.71; acc: 0.72
Batch: 140; loss: 0.21; acc: 0.94
Val Epoch over. val_loss: 0.4306089405895798; val_accuracy: 0.8707205414012739 

The current subspace-distance is: 7.046958671708126e-06 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.31; acc: 0.91
Batch: 20; loss: 0.35; acc: 0.89
Batch: 40; loss: 0.3; acc: 0.91
Batch: 60; loss: 0.45; acc: 0.91
Batch: 80; loss: 0.53; acc: 0.86
Batch: 100; loss: 0.37; acc: 0.94
Batch: 120; loss: 0.49; acc: 0.83
Batch: 140; loss: 0.43; acc: 0.88
Batch: 160; loss: 0.23; acc: 0.98
Batch: 180; loss: 0.25; acc: 0.92
Batch: 200; loss: 0.56; acc: 0.88
Batch: 220; loss: 0.35; acc: 0.88
Batch: 240; loss: 0.63; acc: 0.8
Batch: 260; loss: 0.36; acc: 0.91
Batch: 280; loss: 0.85; acc: 0.78
Batch: 300; loss: 0.33; acc: 0.92
Batch: 320; loss: 0.44; acc: 0.89
Batch: 340; loss: 0.33; acc: 0.88
Batch: 360; loss: 0.67; acc: 0.8
Batch: 380; loss: 0.4; acc: 0.88
Batch: 400; loss: 0.32; acc: 0.92
Batch: 420; loss: 0.4; acc: 0.86
Batch: 440; loss: 0.65; acc: 0.84
Batch: 460; loss: 0.36; acc: 0.88
Batch: 480; loss: 0.64; acc: 0.8
Batch: 500; loss: 0.43; acc: 0.88
Batch: 520; loss: 0.3; acc: 0.91
Batch: 540; loss: 0.53; acc: 0.83
Batch: 560; loss: 0.22; acc: 0.91
Batch: 580; loss: 0.35; acc: 0.86
Batch: 600; loss: 0.48; acc: 0.89
Batch: 620; loss: 0.49; acc: 0.86
Batch: 640; loss: 0.34; acc: 0.91
Batch: 660; loss: 0.55; acc: 0.83
Batch: 680; loss: 0.81; acc: 0.8
Batch: 700; loss: 0.65; acc: 0.81
Batch: 720; loss: 0.76; acc: 0.8
Batch: 740; loss: 0.63; acc: 0.84
Batch: 760; loss: 0.54; acc: 0.89
Batch: 780; loss: 0.53; acc: 0.88
Train Epoch over. train_loss: 0.47; train_accuracy: 0.86 

2.439434865664225e-05
9.336778930446599e-06
Batch: 0; loss: 0.42; acc: 0.89
Batch: 20; loss: 0.45; acc: 0.86
Batch: 40; loss: 0.23; acc: 0.92
Batch: 60; loss: 0.36; acc: 0.88
Batch: 80; loss: 0.4; acc: 0.89
Batch: 100; loss: 0.39; acc: 0.86
Batch: 120; loss: 0.7; acc: 0.73
Batch: 140; loss: 0.21; acc: 0.94
Val Epoch over. val_loss: 0.42962122903128336; val_accuracy: 0.8718152866242038 

The current subspace-distance is: 9.336778930446599e-06 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.33; acc: 0.86
Batch: 20; loss: 0.5; acc: 0.83
Batch: 40; loss: 0.37; acc: 0.88
Batch: 60; loss: 0.37; acc: 0.91
Batch: 80; loss: 0.44; acc: 0.84
Batch: 100; loss: 0.43; acc: 0.89
Batch: 120; loss: 0.46; acc: 0.84
Batch: 140; loss: 0.4; acc: 0.88
Batch: 160; loss: 0.54; acc: 0.84
Batch: 180; loss: 0.52; acc: 0.81
Batch: 200; loss: 0.32; acc: 0.88
Batch: 220; loss: 0.44; acc: 0.92
Batch: 240; loss: 0.38; acc: 0.88
Batch: 260; loss: 0.43; acc: 0.84
Batch: 280; loss: 0.58; acc: 0.8
Batch: 300; loss: 0.58; acc: 0.84
Batch: 320; loss: 0.75; acc: 0.88
Batch: 340; loss: 0.49; acc: 0.89
Batch: 360; loss: 0.49; acc: 0.88
Batch: 380; loss: 0.58; acc: 0.83
Batch: 400; loss: 0.28; acc: 0.91
Batch: 420; loss: 0.75; acc: 0.84
Batch: 440; loss: 0.57; acc: 0.84
Batch: 460; loss: 0.75; acc: 0.84
Batch: 480; loss: 0.59; acc: 0.8
Batch: 500; loss: 0.4; acc: 0.89
Batch: 520; loss: 0.68; acc: 0.8
Batch: 540; loss: 0.56; acc: 0.81
Batch: 560; loss: 0.39; acc: 0.88
Batch: 580; loss: 0.48; acc: 0.86
Batch: 600; loss: 0.46; acc: 0.88
Batch: 620; loss: 0.52; acc: 0.84
Batch: 640; loss: 0.45; acc: 0.89
Batch: 660; loss: 0.52; acc: 0.84
Batch: 680; loss: 0.4; acc: 0.89
Batch: 700; loss: 0.38; acc: 0.86
Batch: 720; loss: 0.48; acc: 0.81
Batch: 740; loss: 0.45; acc: 0.92
Batch: 760; loss: 0.46; acc: 0.91
Batch: 780; loss: 0.51; acc: 0.83
Train Epoch over. train_loss: 0.47; train_accuracy: 0.86 

2.399279946985189e-05
8.98819780559279e-06
Batch: 0; loss: 0.42; acc: 0.88
Batch: 20; loss: 0.46; acc: 0.86
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.36; acc: 0.88
Batch: 80; loss: 0.39; acc: 0.89
Batch: 100; loss: 0.39; acc: 0.86
Batch: 120; loss: 0.7; acc: 0.75
Batch: 140; loss: 0.22; acc: 0.94
Val Epoch over. val_loss: 0.4317458736573815; val_accuracy: 0.8706210191082803 

The current subspace-distance is: 8.98819780559279e-06 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.41; acc: 0.86
Batch: 20; loss: 0.41; acc: 0.84
Batch: 40; loss: 0.46; acc: 0.83
Batch: 60; loss: 0.56; acc: 0.83
Batch: 80; loss: 0.45; acc: 0.88
Batch: 100; loss: 0.78; acc: 0.78
Batch: 120; loss: 0.5; acc: 0.84
Batch: 140; loss: 0.66; acc: 0.73
Batch: 160; loss: 0.51; acc: 0.86
Batch: 180; loss: 0.32; acc: 0.86
Batch: 200; loss: 0.48; acc: 0.84
Batch: 220; loss: 0.46; acc: 0.91
Batch: 240; loss: 0.31; acc: 0.94
Batch: 260; loss: 0.5; acc: 0.78
Batch: 280; loss: 0.17; acc: 0.97
Batch: 300; loss: 0.5; acc: 0.86
Batch: 320; loss: 0.42; acc: 0.86
Batch: 340; loss: 0.61; acc: 0.83
Batch: 360; loss: 0.5; acc: 0.89
Batch: 380; loss: 0.37; acc: 0.92
Batch: 400; loss: 0.28; acc: 0.94
Batch: 420; loss: 0.58; acc: 0.83
Batch: 440; loss: 0.51; acc: 0.84
Batch: 460; loss: 0.38; acc: 0.91
Batch: 480; loss: 0.31; acc: 0.91
Batch: 500; loss: 0.39; acc: 0.86
Batch: 520; loss: 0.33; acc: 0.91
Batch: 540; loss: 0.48; acc: 0.86
Batch: 560; loss: 0.36; acc: 0.84
Batch: 580; loss: 0.28; acc: 0.95
Batch: 600; loss: 0.35; acc: 0.89
Batch: 620; loss: 0.52; acc: 0.86
Batch: 640; loss: 0.33; acc: 0.88
Batch: 660; loss: 0.34; acc: 0.91
Batch: 680; loss: 0.75; acc: 0.73
Batch: 700; loss: 0.66; acc: 0.84
Batch: 720; loss: 0.37; acc: 0.94
Batch: 740; loss: 0.62; acc: 0.86
Batch: 760; loss: 0.4; acc: 0.88
Batch: 780; loss: 0.44; acc: 0.88
Train Epoch over. train_loss: 0.47; train_accuracy: 0.86 

2.3586559109389782e-05
8.517065907653887e-06
Batch: 0; loss: 0.45; acc: 0.88
Batch: 20; loss: 0.47; acc: 0.83
Batch: 40; loss: 0.24; acc: 0.94
Batch: 60; loss: 0.37; acc: 0.88
Batch: 80; loss: 0.4; acc: 0.88
Batch: 100; loss: 0.4; acc: 0.86
Batch: 120; loss: 0.72; acc: 0.72
Batch: 140; loss: 0.21; acc: 0.94
Val Epoch over. val_loss: 0.4333335522823273; val_accuracy: 0.8696257961783439 

The current subspace-distance is: 8.517065907653887e-06 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.35; acc: 0.91
Batch: 20; loss: 0.4; acc: 0.84
Batch: 40; loss: 0.32; acc: 0.91
Batch: 60; loss: 0.57; acc: 0.8
Batch: 80; loss: 0.58; acc: 0.86
Batch: 100; loss: 0.42; acc: 0.83
Batch: 120; loss: 0.33; acc: 0.89
Batch: 140; loss: 0.62; acc: 0.83
Batch: 160; loss: 0.67; acc: 0.88
Batch: 180; loss: 0.58; acc: 0.86
Batch: 200; loss: 0.52; acc: 0.84
Batch: 220; loss: 0.24; acc: 0.92
Batch: 240; loss: 0.4; acc: 0.89
Batch: 260; loss: 0.72; acc: 0.83
Batch: 280; loss: 0.55; acc: 0.8
Batch: 300; loss: 0.45; acc: 0.91
Batch: 320; loss: 0.44; acc: 0.83
Batch: 340; loss: 0.45; acc: 0.88
Batch: 360; loss: 0.5; acc: 0.8
Batch: 380; loss: 0.54; acc: 0.84
Batch: 400; loss: 0.36; acc: 0.83
Batch: 420; loss: 0.57; acc: 0.81
Batch: 440; loss: 0.34; acc: 0.88
Batch: 460; loss: 0.48; acc: 0.86
Batch: 480; loss: 0.78; acc: 0.78
Batch: 500; loss: 0.76; acc: 0.84
Batch: 520; loss: 0.39; acc: 0.89
Batch: 540; loss: 0.64; acc: 0.83
Batch: 560; loss: 0.62; acc: 0.83
Batch: 580; loss: 0.34; acc: 0.91
Batch: 600; loss: 0.47; acc: 0.84
Batch: 620; loss: 0.31; acc: 0.92
Batch: 640; loss: 0.33; acc: 0.89
Batch: 660; loss: 0.32; acc: 0.88
Batch: 680; loss: 0.48; acc: 0.91
Batch: 700; loss: 0.53; acc: 0.84
Batch: 720; loss: 0.35; acc: 0.88
Batch: 740; loss: 0.54; acc: 0.84
Batch: 760; loss: 0.58; acc: 0.75
Batch: 780; loss: 0.47; acc: 0.91
Train Epoch over. train_loss: 0.47; train_accuracy: 0.86 

2.4523689717170782e-05
8.780034477240406e-06
Batch: 0; loss: 0.43; acc: 0.86
Batch: 20; loss: 0.47; acc: 0.83
Batch: 40; loss: 0.24; acc: 0.94
Batch: 60; loss: 0.36; acc: 0.86
Batch: 80; loss: 0.39; acc: 0.89
Batch: 100; loss: 0.4; acc: 0.86
Batch: 120; loss: 0.71; acc: 0.72
Batch: 140; loss: 0.22; acc: 0.94
Val Epoch over. val_loss: 0.4347608908536328; val_accuracy: 0.8703224522292994 

The current subspace-distance is: 8.780034477240406e-06 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.48; acc: 0.83
Batch: 40; loss: 0.4; acc: 0.86
Batch: 60; loss: 0.59; acc: 0.84
Batch: 80; loss: 0.56; acc: 0.86
Batch: 100; loss: 0.28; acc: 0.91
Batch: 120; loss: 0.38; acc: 0.88
Batch: 140; loss: 0.33; acc: 0.89
Batch: 160; loss: 0.59; acc: 0.77
Batch: 180; loss: 0.48; acc: 0.84
Batch: 200; loss: 0.52; acc: 0.84
Batch: 220; loss: 0.52; acc: 0.84
Batch: 240; loss: 0.44; acc: 0.86
Batch: 260; loss: 0.35; acc: 0.89
Batch: 280; loss: 0.63; acc: 0.83
Batch: 300; loss: 0.55; acc: 0.78
Batch: 320; loss: 0.32; acc: 0.94
Batch: 340; loss: 0.73; acc: 0.78
Batch: 360; loss: 0.4; acc: 0.88
Batch: 380; loss: 0.39; acc: 0.89
Batch: 400; loss: 0.48; acc: 0.88
Batch: 420; loss: 0.32; acc: 0.95
Batch: 440; loss: 0.21; acc: 0.95
Batch: 460; loss: 0.4; acc: 0.92
Batch: 480; loss: 0.39; acc: 0.91
Batch: 500; loss: 0.49; acc: 0.83
Batch: 520; loss: 0.62; acc: 0.83
Batch: 540; loss: 0.55; acc: 0.81
Batch: 560; loss: 0.52; acc: 0.86
Batch: 580; loss: 0.26; acc: 0.91
Batch: 600; loss: 0.45; acc: 0.88
Batch: 620; loss: 0.19; acc: 0.94
Batch: 640; loss: 0.56; acc: 0.78
Batch: 660; loss: 0.36; acc: 0.86
Batch: 680; loss: 0.51; acc: 0.86
Batch: 700; loss: 0.27; acc: 0.91
Batch: 720; loss: 0.43; acc: 0.91
Batch: 740; loss: 0.37; acc: 0.88
Batch: 760; loss: 0.51; acc: 0.84
Batch: 780; loss: 0.48; acc: 0.86
Train Epoch over. train_loss: 0.47; train_accuracy: 0.86 

2.433019290037919e-05
8.920251275412738e-06
Batch: 0; loss: 0.44; acc: 0.88
Batch: 20; loss: 0.47; acc: 0.81
Batch: 40; loss: 0.24; acc: 0.94
Batch: 60; loss: 0.36; acc: 0.89
Batch: 80; loss: 0.39; acc: 0.89
Batch: 100; loss: 0.39; acc: 0.86
Batch: 120; loss: 0.72; acc: 0.72
Batch: 140; loss: 0.21; acc: 0.94
Val Epoch over. val_loss: 0.43092572689056396; val_accuracy: 0.8700238853503185 

The current subspace-distance is: 8.920251275412738e-06 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.44; acc: 0.91
Batch: 20; loss: 0.56; acc: 0.83
Batch: 40; loss: 0.43; acc: 0.89
Batch: 60; loss: 0.31; acc: 0.91
Batch: 80; loss: 0.64; acc: 0.78
Batch: 100; loss: 0.57; acc: 0.86
Batch: 120; loss: 0.35; acc: 0.89
Batch: 140; loss: 0.43; acc: 0.89
Batch: 160; loss: 0.36; acc: 0.92
Batch: 180; loss: 0.39; acc: 0.91
Batch: 200; loss: 0.46; acc: 0.84
Batch: 220; loss: 0.64; acc: 0.78
Batch: 240; loss: 0.44; acc: 0.89
Batch: 260; loss: 0.71; acc: 0.83
Batch: 280; loss: 0.34; acc: 0.88
Batch: 300; loss: 0.52; acc: 0.84
Batch: 320; loss: 0.36; acc: 0.88
Batch: 340; loss: 0.38; acc: 0.86
Batch: 360; loss: 0.65; acc: 0.81
Batch: 380; loss: 0.6; acc: 0.86
Batch: 400; loss: 0.5; acc: 0.86
Batch: 420; loss: 0.7; acc: 0.83
Batch: 440; loss: 0.39; acc: 0.92
Batch: 460; loss: 0.34; acc: 0.89
Batch: 480; loss: 0.44; acc: 0.86
Batch: 500; loss: 0.51; acc: 0.88
Batch: 520; loss: 0.44; acc: 0.88
Batch: 540; loss: 0.32; acc: 0.89
Batch: 560; loss: 0.5; acc: 0.84
Batch: 580; loss: 0.61; acc: 0.8
Batch: 600; loss: 0.59; acc: 0.84
Batch: 620; loss: 0.49; acc: 0.86
Batch: 640; loss: 0.86; acc: 0.8
Batch: 660; loss: 0.56; acc: 0.83
Batch: 680; loss: 0.42; acc: 0.94
Batch: 700; loss: 0.22; acc: 0.94
Batch: 720; loss: 0.3; acc: 0.92
Batch: 740; loss: 0.67; acc: 0.78
Batch: 760; loss: 0.44; acc: 0.84
Batch: 780; loss: 0.39; acc: 0.91
Train Epoch over. train_loss: 0.47; train_accuracy: 0.86 

2.462962584104389e-05
8.513952707289718e-06
Batch: 0; loss: 0.43; acc: 0.89
Batch: 20; loss: 0.44; acc: 0.86
Batch: 40; loss: 0.24; acc: 0.94
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.4; acc: 0.89
Batch: 100; loss: 0.4; acc: 0.88
Batch: 120; loss: 0.7; acc: 0.73
Batch: 140; loss: 0.22; acc: 0.94
Val Epoch over. val_loss: 0.4312582802810487; val_accuracy: 0.8705214968152867 

The current subspace-distance is: 8.513952707289718e-06 

plots/subspace_training/reg_lenet_3/2020-01-22 20:51:04/d_dim_100_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
nonzero elements in E: 23239
elements in E: 4948900
fraction nonzero: 0.004695790983854998
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.31; acc: 0.08
Batch: 20; loss: 2.29; acc: 0.06
Batch: 40; loss: 2.3; acc: 0.06
Batch: 60; loss: 2.3; acc: 0.05
Batch: 80; loss: 2.3; acc: 0.06
Batch: 100; loss: 2.3; acc: 0.14
Batch: 120; loss: 2.31; acc: 0.08
Batch: 140; loss: 2.32; acc: 0.09
Batch: 160; loss: 2.3; acc: 0.06
Batch: 180; loss: 2.3; acc: 0.2
Batch: 200; loss: 2.29; acc: 0.16
Batch: 220; loss: 2.31; acc: 0.12
Batch: 240; loss: 2.31; acc: 0.11
Batch: 260; loss: 2.3; acc: 0.06
Batch: 280; loss: 2.29; acc: 0.19
Batch: 300; loss: 2.29; acc: 0.11
Batch: 320; loss: 2.3; acc: 0.12
Batch: 340; loss: 2.29; acc: 0.11
Batch: 360; loss: 2.29; acc: 0.19
Batch: 380; loss: 2.3; acc: 0.14
Batch: 400; loss: 2.3; acc: 0.17
Batch: 420; loss: 2.31; acc: 0.09
Batch: 440; loss: 2.29; acc: 0.2
Batch: 460; loss: 2.3; acc: 0.14
Batch: 480; loss: 2.29; acc: 0.16
Batch: 500; loss: 2.29; acc: 0.12
Batch: 520; loss: 2.27; acc: 0.25
Batch: 540; loss: 2.28; acc: 0.16
Batch: 560; loss: 2.28; acc: 0.2
Batch: 580; loss: 2.27; acc: 0.14
Batch: 600; loss: 2.29; acc: 0.2
Batch: 620; loss: 2.27; acc: 0.17
Batch: 640; loss: 2.27; acc: 0.19
Batch: 660; loss: 2.27; acc: 0.16
Batch: 680; loss: 2.29; acc: 0.09
Batch: 700; loss: 2.29; acc: 0.14
Batch: 720; loss: 2.29; acc: 0.12
Batch: 740; loss: 2.26; acc: 0.22
Batch: 760; loss: 2.28; acc: 0.22
Batch: 780; loss: 2.27; acc: 0.2
Train Epoch over. train_loss: 2.29; train_accuracy: 0.14 

5.1715928748308215e-06
9.551642961014295e-07
Batch: 0; loss: 2.26; acc: 0.28
Batch: 20; loss: 2.27; acc: 0.23
Batch: 40; loss: 2.27; acc: 0.27
Batch: 60; loss: 2.26; acc: 0.31
Batch: 80; loss: 2.25; acc: 0.33
Batch: 100; loss: 2.27; acc: 0.23
Batch: 120; loss: 2.28; acc: 0.17
Batch: 140; loss: 2.27; acc: 0.19
Val Epoch over. val_loss: 2.2652549834767726; val_accuracy: 0.25009952229299365 

The current subspace-distance is: 9.551642961014295e-07 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 2.27; acc: 0.28
Batch: 20; loss: 2.27; acc: 0.2
Batch: 40; loss: 2.26; acc: 0.23
Batch: 60; loss: 2.23; acc: 0.38
Batch: 80; loss: 2.25; acc: 0.22
Batch: 100; loss: 2.26; acc: 0.23
Batch: 120; loss: 2.24; acc: 0.33
Batch: 140; loss: 2.23; acc: 0.34
Batch: 160; loss: 2.25; acc: 0.25
Batch: 180; loss: 2.24; acc: 0.25
Batch: 200; loss: 2.2; acc: 0.33
Batch: 220; loss: 2.2; acc: 0.33
Batch: 240; loss: 2.14; acc: 0.42
Batch: 260; loss: 2.15; acc: 0.45
Batch: 280; loss: 2.08; acc: 0.39
Batch: 300; loss: 2.08; acc: 0.48
Batch: 320; loss: 2.12; acc: 0.38
Batch: 340; loss: 2.03; acc: 0.48
Batch: 360; loss: 1.87; acc: 0.53
Batch: 380; loss: 1.82; acc: 0.52
Batch: 400; loss: 1.69; acc: 0.61
Batch: 420; loss: 1.65; acc: 0.5
Batch: 440; loss: 1.57; acc: 0.45
Batch: 460; loss: 1.95; acc: 0.48
Batch: 480; loss: 1.41; acc: 0.53
Batch: 500; loss: 1.38; acc: 0.52
Batch: 520; loss: 1.29; acc: 0.52
Batch: 540; loss: 1.03; acc: 0.69
Batch: 560; loss: 1.02; acc: 0.62
Batch: 580; loss: 1.09; acc: 0.67
Batch: 600; loss: 1.14; acc: 0.64
Batch: 620; loss: 1.02; acc: 0.64
Batch: 640; loss: 1.27; acc: 0.58
Batch: 660; loss: 1.51; acc: 0.56
Batch: 680; loss: 0.98; acc: 0.7
Batch: 700; loss: 1.01; acc: 0.62
Batch: 720; loss: 1.0; acc: 0.69
Batch: 740; loss: 1.04; acc: 0.66
Batch: 760; loss: 1.16; acc: 0.67
Batch: 780; loss: 1.39; acc: 0.59
Train Epoch over. train_loss: 1.71; train_accuracy: 0.47 

1.3442941963148769e-05
7.126208856789162e-06
Batch: 0; loss: 0.96; acc: 0.78
Batch: 20; loss: 1.07; acc: 0.62
Batch: 40; loss: 0.7; acc: 0.75
Batch: 60; loss: 1.11; acc: 0.62
Batch: 80; loss: 0.8; acc: 0.72
Batch: 100; loss: 0.76; acc: 0.8
Batch: 120; loss: 1.15; acc: 0.67
Batch: 140; loss: 1.09; acc: 0.62
Val Epoch over. val_loss: 1.0221866042750656; val_accuracy: 0.6580414012738853 

The current subspace-distance is: 7.126208856789162e-06 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 1.04; acc: 0.7
Batch: 20; loss: 0.65; acc: 0.78
Batch: 40; loss: 0.78; acc: 0.77
Batch: 60; loss: 1.06; acc: 0.69
Batch: 80; loss: 0.92; acc: 0.73
Batch: 100; loss: 0.89; acc: 0.73
Batch: 120; loss: 0.83; acc: 0.73
Batch: 140; loss: 0.94; acc: 0.69
Batch: 160; loss: 0.74; acc: 0.77
Batch: 180; loss: 0.59; acc: 0.83
Batch: 200; loss: 0.73; acc: 0.77
Batch: 220; loss: 1.33; acc: 0.61
Batch: 240; loss: 0.97; acc: 0.72
Batch: 260; loss: 0.95; acc: 0.7
Batch: 280; loss: 1.01; acc: 0.69
Batch: 300; loss: 0.76; acc: 0.72
Batch: 320; loss: 0.84; acc: 0.7
Batch: 340; loss: 0.61; acc: 0.81
Batch: 360; loss: 0.81; acc: 0.7
Batch: 380; loss: 0.64; acc: 0.84
Batch: 400; loss: 0.9; acc: 0.73
Batch: 420; loss: 0.85; acc: 0.8
Batch: 440; loss: 0.63; acc: 0.83
Batch: 460; loss: 0.76; acc: 0.75
Batch: 480; loss: 1.22; acc: 0.62
Batch: 500; loss: 0.68; acc: 0.77
Batch: 520; loss: 0.63; acc: 0.78
Batch: 540; loss: 0.65; acc: 0.81
Batch: 560; loss: 0.79; acc: 0.72
Batch: 580; loss: 0.64; acc: 0.78
Batch: 600; loss: 0.64; acc: 0.86
Batch: 620; loss: 0.92; acc: 0.75
Batch: 640; loss: 0.45; acc: 0.86
Batch: 660; loss: 0.84; acc: 0.72
Batch: 680; loss: 0.83; acc: 0.75
Batch: 700; loss: 0.69; acc: 0.81
Batch: 720; loss: 0.39; acc: 0.84
Batch: 740; loss: 0.66; acc: 0.86
Batch: 760; loss: 0.5; acc: 0.86
Batch: 780; loss: 0.54; acc: 0.83
Train Epoch over. train_loss: 0.78; train_accuracy: 0.75 

2.084724656015169e-05
8.044998139666859e-06
Batch: 0; loss: 0.62; acc: 0.83
Batch: 20; loss: 0.99; acc: 0.67
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.79; acc: 0.73
Batch: 80; loss: 0.4; acc: 0.83
Batch: 100; loss: 0.66; acc: 0.84
Batch: 120; loss: 1.2; acc: 0.62
Batch: 140; loss: 0.68; acc: 0.78
Val Epoch over. val_loss: 0.7081961175248881; val_accuracy: 0.7806528662420382 

The current subspace-distance is: 8.044998139666859e-06 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.82; acc: 0.75
Batch: 20; loss: 0.67; acc: 0.78
Batch: 40; loss: 0.64; acc: 0.8
Batch: 60; loss: 0.85; acc: 0.73
Batch: 80; loss: 0.43; acc: 0.86
Batch: 100; loss: 0.42; acc: 0.84
Batch: 120; loss: 0.5; acc: 0.86
Batch: 140; loss: 0.73; acc: 0.8
Batch: 160; loss: 0.64; acc: 0.81
Batch: 180; loss: 0.79; acc: 0.8
Batch: 200; loss: 0.47; acc: 0.86
Batch: 220; loss: 0.73; acc: 0.77
Batch: 240; loss: 0.9; acc: 0.75
Batch: 260; loss: 0.65; acc: 0.8
Batch: 280; loss: 0.85; acc: 0.77
Batch: 300; loss: 0.64; acc: 0.77
Batch: 320; loss: 0.69; acc: 0.75
Batch: 340; loss: 0.55; acc: 0.8
Batch: 360; loss: 0.88; acc: 0.73
Batch: 380; loss: 0.65; acc: 0.81
Batch: 400; loss: 0.57; acc: 0.78
Batch: 420; loss: 0.77; acc: 0.84
Batch: 440; loss: 0.33; acc: 0.89
Batch: 460; loss: 0.36; acc: 0.86
Batch: 480; loss: 0.41; acc: 0.91
Batch: 500; loss: 0.43; acc: 0.84
Batch: 520; loss: 0.67; acc: 0.81
Batch: 540; loss: 0.6; acc: 0.78
Batch: 560; loss: 0.63; acc: 0.83
Batch: 580; loss: 0.63; acc: 0.83
Batch: 600; loss: 0.79; acc: 0.75
Batch: 620; loss: 0.73; acc: 0.84
Batch: 640; loss: 0.85; acc: 0.75
Batch: 660; loss: 0.8; acc: 0.83
Batch: 680; loss: 0.65; acc: 0.83
Batch: 700; loss: 0.45; acc: 0.86
Batch: 720; loss: 0.68; acc: 0.8
Batch: 740; loss: 0.51; acc: 0.86
Batch: 760; loss: 0.45; acc: 0.88
Batch: 780; loss: 0.43; acc: 0.91
Train Epoch over. train_loss: 0.59; train_accuracy: 0.82 

2.2261456251726486e-05
7.240607374114916e-06
Batch: 0; loss: 0.41; acc: 0.84
Batch: 20; loss: 0.82; acc: 0.72
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.62; acc: 0.81
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.5; acc: 0.89
Batch: 120; loss: 0.72; acc: 0.77
Batch: 140; loss: 0.53; acc: 0.8
Val Epoch over. val_loss: 0.576538648480063; val_accuracy: 0.8188694267515924 

The current subspace-distance is: 7.240607374114916e-06 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.69; acc: 0.75
Batch: 20; loss: 0.44; acc: 0.92
Batch: 40; loss: 0.59; acc: 0.77
Batch: 60; loss: 0.75; acc: 0.78
Batch: 80; loss: 0.7; acc: 0.78
Batch: 100; loss: 0.37; acc: 0.91
Batch: 120; loss: 0.47; acc: 0.84
Batch: 140; loss: 0.57; acc: 0.81
Batch: 160; loss: 0.34; acc: 0.89
Batch: 180; loss: 0.4; acc: 0.88
Batch: 200; loss: 0.32; acc: 0.89
Batch: 220; loss: 0.66; acc: 0.83
Batch: 240; loss: 0.4; acc: 0.88
Batch: 260; loss: 0.65; acc: 0.84
Batch: 280; loss: 0.42; acc: 0.89
Batch: 300; loss: 0.42; acc: 0.84
Batch: 320; loss: 0.51; acc: 0.84
Batch: 340; loss: 0.39; acc: 0.88
Batch: 360; loss: 0.73; acc: 0.8
Batch: 380; loss: 0.27; acc: 0.92
Batch: 400; loss: 0.66; acc: 0.8
Batch: 420; loss: 0.62; acc: 0.8
Batch: 440; loss: 0.76; acc: 0.72
Batch: 460; loss: 0.41; acc: 0.88
Batch: 480; loss: 0.47; acc: 0.84
Batch: 500; loss: 0.43; acc: 0.83
Batch: 520; loss: 0.57; acc: 0.86
Batch: 540; loss: 0.42; acc: 0.88
Batch: 560; loss: 0.68; acc: 0.8
Batch: 580; loss: 0.58; acc: 0.83
Batch: 600; loss: 0.47; acc: 0.86
Batch: 620; loss: 0.33; acc: 0.89
Batch: 640; loss: 0.32; acc: 0.89
Batch: 660; loss: 1.15; acc: 0.66
Batch: 680; loss: 0.66; acc: 0.8
Batch: 700; loss: 0.6; acc: 0.83
Batch: 720; loss: 0.34; acc: 0.89
Batch: 740; loss: 0.47; acc: 0.89
Batch: 760; loss: 0.45; acc: 0.83
Batch: 780; loss: 0.7; acc: 0.83
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

2.3576116291224025e-05
8.773525223659817e-06
Batch: 0; loss: 0.39; acc: 0.86
Batch: 20; loss: 0.72; acc: 0.67
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.65; acc: 0.83
Batch: 80; loss: 0.23; acc: 0.91
Batch: 100; loss: 0.35; acc: 0.89
Batch: 120; loss: 0.57; acc: 0.83
Batch: 140; loss: 0.41; acc: 0.88
Val Epoch over. val_loss: 0.4701114164985669; val_accuracy: 0.8570859872611465 

The current subspace-distance is: 8.773525223659817e-06 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.58; acc: 0.81
Batch: 20; loss: 0.41; acc: 0.88
Batch: 40; loss: 0.65; acc: 0.8
Batch: 60; loss: 0.69; acc: 0.78
Batch: 80; loss: 0.46; acc: 0.84
Batch: 100; loss: 0.39; acc: 0.88
Batch: 120; loss: 0.49; acc: 0.86
Batch: 140; loss: 0.71; acc: 0.77
Batch: 160; loss: 0.77; acc: 0.75
Batch: 180; loss: 0.65; acc: 0.78
Batch: 200; loss: 0.56; acc: 0.81
Batch: 220; loss: 0.37; acc: 0.86
Batch: 240; loss: 0.5; acc: 0.86
Batch: 260; loss: 0.54; acc: 0.83
Batch: 280; loss: 0.51; acc: 0.89
Batch: 300; loss: 0.61; acc: 0.72
Batch: 320; loss: 0.31; acc: 0.86
Batch: 340; loss: 0.37; acc: 0.91
Batch: 360; loss: 0.53; acc: 0.86
Batch: 380; loss: 0.73; acc: 0.8
Batch: 400; loss: 0.37; acc: 0.86
Batch: 420; loss: 0.45; acc: 0.89
Batch: 440; loss: 0.38; acc: 0.89
Batch: 460; loss: 0.68; acc: 0.81
Batch: 480; loss: 0.53; acc: 0.8
Batch: 500; loss: 0.55; acc: 0.88
Batch: 520; loss: 0.65; acc: 0.75
Batch: 540; loss: 0.41; acc: 0.84
Batch: 560; loss: 0.41; acc: 0.89
Batch: 580; loss: 0.54; acc: 0.78
Batch: 600; loss: 0.48; acc: 0.83
Batch: 620; loss: 0.43; acc: 0.86
Batch: 640; loss: 0.38; acc: 0.88
Batch: 660; loss: 0.64; acc: 0.84
Batch: 680; loss: 0.31; acc: 0.91
Batch: 700; loss: 0.49; acc: 0.89
Batch: 720; loss: 0.88; acc: 0.77
Batch: 740; loss: 0.46; acc: 0.83
Batch: 760; loss: 0.54; acc: 0.86
Batch: 780; loss: 0.46; acc: 0.91
Train Epoch over. train_loss: 0.5; train_accuracy: 0.85 

2.436881732137408e-05
1.0066293725685682e-05
Batch: 0; loss: 0.35; acc: 0.89
Batch: 20; loss: 0.57; acc: 0.8
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.56; acc: 0.83
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.38; acc: 0.89
Batch: 120; loss: 0.57; acc: 0.81
Batch: 140; loss: 0.25; acc: 0.94
Val Epoch over. val_loss: 0.4244615581289978; val_accuracy: 0.8753980891719745 

The current subspace-distance is: 1.0066293725685682e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.8; acc: 0.8
Batch: 20; loss: 0.39; acc: 0.84
Batch: 40; loss: 0.51; acc: 0.81
Batch: 60; loss: 0.43; acc: 0.83
Batch: 80; loss: 0.45; acc: 0.88
Batch: 100; loss: 0.39; acc: 0.86
Batch: 120; loss: 0.45; acc: 0.91
Batch: 140; loss: 0.71; acc: 0.75
Batch: 160; loss: 0.68; acc: 0.8
Batch: 180; loss: 0.5; acc: 0.83
Batch: 200; loss: 0.61; acc: 0.77
Batch: 220; loss: 0.42; acc: 0.86
Batch: 240; loss: 0.58; acc: 0.77
Batch: 260; loss: 0.41; acc: 0.88
Batch: 280; loss: 0.5; acc: 0.88
Batch: 300; loss: 0.54; acc: 0.84
Batch: 320; loss: 0.56; acc: 0.8
Batch: 340; loss: 0.48; acc: 0.83
Batch: 360; loss: 0.44; acc: 0.88
Batch: 380; loss: 0.63; acc: 0.78
Batch: 400; loss: 0.52; acc: 0.86
Batch: 420; loss: 0.84; acc: 0.78
Batch: 440; loss: 0.59; acc: 0.86
Batch: 460; loss: 0.28; acc: 0.97
Batch: 480; loss: 0.45; acc: 0.84
Batch: 500; loss: 0.21; acc: 0.95
Batch: 520; loss: 0.42; acc: 0.86
Batch: 540; loss: 0.4; acc: 0.88
Batch: 560; loss: 0.39; acc: 0.86
Batch: 580; loss: 0.37; acc: 0.88
Batch: 600; loss: 0.34; acc: 0.92
Batch: 620; loss: 0.48; acc: 0.84
Batch: 640; loss: 0.91; acc: 0.66
Batch: 660; loss: 0.55; acc: 0.84
Batch: 680; loss: 0.5; acc: 0.88
Batch: 700; loss: 0.61; acc: 0.78
Batch: 720; loss: 0.45; acc: 0.88
Batch: 740; loss: 0.55; acc: 0.77
Batch: 760; loss: 0.44; acc: 0.92
Batch: 780; loss: 0.33; acc: 0.86
Train Epoch over. train_loss: 0.5; train_accuracy: 0.85 

2.5350416763103567e-05
8.973564035841264e-06
Batch: 0; loss: 0.52; acc: 0.8
Batch: 20; loss: 0.78; acc: 0.81
Batch: 40; loss: 0.29; acc: 0.91
Batch: 60; loss: 0.77; acc: 0.8
Batch: 80; loss: 0.38; acc: 0.86
Batch: 100; loss: 0.51; acc: 0.86
Batch: 120; loss: 0.49; acc: 0.81
Batch: 140; loss: 0.46; acc: 0.78
Val Epoch over. val_loss: 0.5905254723349954; val_accuracy: 0.8090167197452229 

The current subspace-distance is: 8.973564035841264e-06 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.81; acc: 0.72
Batch: 20; loss: 0.33; acc: 0.92
Batch: 40; loss: 0.24; acc: 0.91
Batch: 60; loss: 0.35; acc: 0.88
Batch: 80; loss: 0.78; acc: 0.83
Batch: 100; loss: 0.45; acc: 0.88
Batch: 120; loss: 0.4; acc: 0.88
Batch: 140; loss: 0.56; acc: 0.78
Batch: 160; loss: 0.39; acc: 0.89
Batch: 180; loss: 0.31; acc: 0.89
Batch: 200; loss: 0.39; acc: 0.89
Batch: 220; loss: 0.72; acc: 0.8
Batch: 240; loss: 0.42; acc: 0.86
Batch: 260; loss: 0.43; acc: 0.88
Batch: 280; loss: 0.84; acc: 0.77
Batch: 300; loss: 0.65; acc: 0.78
Batch: 320; loss: 0.69; acc: 0.84
Batch: 340; loss: 0.65; acc: 0.78
Batch: 360; loss: 0.31; acc: 0.92
Batch: 380; loss: 0.3; acc: 0.92
Batch: 400; loss: 0.48; acc: 0.88
Batch: 420; loss: 0.22; acc: 0.94
Batch: 440; loss: 0.5; acc: 0.84
Batch: 460; loss: 0.38; acc: 0.86
Batch: 480; loss: 0.38; acc: 0.89
Batch: 500; loss: 0.34; acc: 0.88
Batch: 520; loss: 0.51; acc: 0.83
Batch: 540; loss: 0.46; acc: 0.83
Batch: 560; loss: 0.36; acc: 0.91
Batch: 580; loss: 0.38; acc: 0.86
Batch: 600; loss: 0.55; acc: 0.89
Batch: 620; loss: 0.47; acc: 0.84
Batch: 640; loss: 0.21; acc: 0.92
Batch: 660; loss: 0.43; acc: 0.84
Batch: 680; loss: 0.54; acc: 0.91
Batch: 700; loss: 0.69; acc: 0.86
Batch: 720; loss: 0.45; acc: 0.88
Batch: 740; loss: 0.37; acc: 0.84
Batch: 760; loss: 0.32; acc: 0.89
Batch: 780; loss: 0.65; acc: 0.81
Train Epoch over. train_loss: 0.49; train_accuracy: 0.85 

2.8153599487268366e-05
9.388630132889375e-06
Batch: 0; loss: 0.7; acc: 0.73
Batch: 20; loss: 0.85; acc: 0.7
Batch: 40; loss: 0.29; acc: 0.89
Batch: 60; loss: 0.78; acc: 0.83
Batch: 80; loss: 0.44; acc: 0.86
Batch: 100; loss: 0.56; acc: 0.78
Batch: 120; loss: 0.81; acc: 0.73
Batch: 140; loss: 0.3; acc: 0.91
Val Epoch over. val_loss: 0.6325452076211856; val_accuracy: 0.7986664012738853 

The current subspace-distance is: 9.388630132889375e-06 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.84; acc: 0.75
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.26; acc: 0.94
Batch: 60; loss: 0.54; acc: 0.86
Batch: 80; loss: 0.51; acc: 0.83
Batch: 100; loss: 0.36; acc: 0.88
Batch: 120; loss: 0.52; acc: 0.8
Batch: 140; loss: 0.56; acc: 0.77
Batch: 160; loss: 0.7; acc: 0.78
Batch: 180; loss: 0.71; acc: 0.8
Batch: 200; loss: 0.45; acc: 0.83
Batch: 220; loss: 0.46; acc: 0.84
Batch: 240; loss: 0.3; acc: 0.91
Batch: 260; loss: 0.5; acc: 0.81
Batch: 280; loss: 0.38; acc: 0.84
Batch: 300; loss: 0.49; acc: 0.78
Batch: 320; loss: 0.44; acc: 0.83
Batch: 340; loss: 0.43; acc: 0.84
Batch: 360; loss: 0.53; acc: 0.88
Batch: 380; loss: 0.35; acc: 0.92
Batch: 400; loss: 0.46; acc: 0.84
Batch: 420; loss: 0.47; acc: 0.88
Batch: 440; loss: 0.62; acc: 0.83
Batch: 460; loss: 0.37; acc: 0.84
Batch: 480; loss: 0.7; acc: 0.83
Batch: 500; loss: 0.58; acc: 0.84
Batch: 520; loss: 0.52; acc: 0.84
Batch: 540; loss: 0.42; acc: 0.84
Batch: 560; loss: 0.43; acc: 0.86
Batch: 580; loss: 0.51; acc: 0.83
Batch: 600; loss: 0.58; acc: 0.84
Batch: 620; loss: 0.64; acc: 0.8
Batch: 640; loss: 0.72; acc: 0.8
Batch: 660; loss: 0.51; acc: 0.8
Batch: 680; loss: 0.67; acc: 0.8
Batch: 700; loss: 0.54; acc: 0.81
Batch: 720; loss: 0.3; acc: 0.89
Batch: 740; loss: 0.44; acc: 0.86
Batch: 760; loss: 0.32; acc: 0.89
Batch: 780; loss: 0.42; acc: 0.91
Train Epoch over. train_loss: 0.48; train_accuracy: 0.85 

2.752110958681442e-05
9.736955689731985e-06
Batch: 0; loss: 0.45; acc: 0.83
Batch: 20; loss: 0.64; acc: 0.78
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.74; acc: 0.83
Batch: 80; loss: 0.23; acc: 0.91
Batch: 100; loss: 0.48; acc: 0.86
Batch: 120; loss: 0.54; acc: 0.86
Batch: 140; loss: 0.25; acc: 0.94
Val Epoch over. val_loss: 0.48351066625991446; val_accuracy: 0.8522093949044586 

The current subspace-distance is: 9.736955689731985e-06 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.65; acc: 0.86
Batch: 20; loss: 0.33; acc: 0.92
Batch: 40; loss: 0.73; acc: 0.83
Batch: 60; loss: 0.53; acc: 0.88
Batch: 80; loss: 0.39; acc: 0.91
Batch: 100; loss: 0.39; acc: 0.91
Batch: 120; loss: 0.55; acc: 0.84
Batch: 140; loss: 0.88; acc: 0.69
Batch: 160; loss: 0.38; acc: 0.88
Batch: 180; loss: 0.44; acc: 0.88
Batch: 200; loss: 0.33; acc: 0.88
Batch: 220; loss: 0.79; acc: 0.78
Batch: 240; loss: 0.41; acc: 0.86
Batch: 260; loss: 0.49; acc: 0.81
Batch: 280; loss: 0.31; acc: 0.92
Batch: 300; loss: 0.3; acc: 0.94
Batch: 320; loss: 0.81; acc: 0.83
Batch: 340; loss: 0.47; acc: 0.83
Batch: 360; loss: 0.44; acc: 0.88
Batch: 380; loss: 0.36; acc: 0.86
Batch: 400; loss: 0.55; acc: 0.84
Batch: 420; loss: 0.35; acc: 0.88
Batch: 440; loss: 0.31; acc: 0.84
Batch: 460; loss: 0.36; acc: 0.88
Batch: 480; loss: 0.49; acc: 0.84
Batch: 500; loss: 0.4; acc: 0.92
Batch: 520; loss: 0.48; acc: 0.81
Batch: 540; loss: 0.43; acc: 0.86
Batch: 560; loss: 0.54; acc: 0.84
Batch: 580; loss: 0.62; acc: 0.75
Batch: 600; loss: 0.42; acc: 0.86
Batch: 620; loss: 0.55; acc: 0.8
Batch: 640; loss: 0.37; acc: 0.89
Batch: 660; loss: 0.45; acc: 0.92
Batch: 680; loss: 0.47; acc: 0.84
Batch: 700; loss: 0.45; acc: 0.86
Batch: 720; loss: 0.59; acc: 0.81
Batch: 740; loss: 0.65; acc: 0.86
Batch: 760; loss: 0.25; acc: 0.91
Batch: 780; loss: 0.61; acc: 0.86
Train Epoch over. train_loss: 0.47; train_accuracy: 0.85 

2.4939310605986975e-05
9.594503353582695e-06
Batch: 0; loss: 0.57; acc: 0.75
Batch: 20; loss: 0.66; acc: 0.75
Batch: 40; loss: 0.2; acc: 0.94
Batch: 60; loss: 0.83; acc: 0.78
Batch: 80; loss: 0.34; acc: 0.86
Batch: 100; loss: 0.52; acc: 0.86
Batch: 120; loss: 0.55; acc: 0.83
Batch: 140; loss: 0.22; acc: 0.88
Val Epoch over. val_loss: 0.5306067716354018; val_accuracy: 0.82921974522293 

The current subspace-distance is: 9.594503353582695e-06 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.48; acc: 0.81
Batch: 20; loss: 0.42; acc: 0.84
Batch: 40; loss: 0.42; acc: 0.88
Batch: 60; loss: 0.4; acc: 0.88
Batch: 80; loss: 0.33; acc: 0.92
Batch: 100; loss: 0.36; acc: 0.89
Batch: 120; loss: 0.43; acc: 0.83
Batch: 140; loss: 0.42; acc: 0.89
Batch: 160; loss: 0.29; acc: 0.91
Batch: 180; loss: 0.35; acc: 0.89
Batch: 200; loss: 0.48; acc: 0.86
Batch: 220; loss: 0.43; acc: 0.88
Batch: 240; loss: 0.58; acc: 0.84
Batch: 260; loss: 0.32; acc: 0.88
Batch: 280; loss: 0.31; acc: 0.89
Batch: 300; loss: 0.3; acc: 0.89
Batch: 320; loss: 0.47; acc: 0.84
Batch: 340; loss: 0.42; acc: 0.92
Batch: 360; loss: 0.52; acc: 0.86
Batch: 380; loss: 0.58; acc: 0.84
Batch: 400; loss: 0.69; acc: 0.88
Batch: 420; loss: 0.41; acc: 0.86
Batch: 440; loss: 0.54; acc: 0.84
Batch: 460; loss: 0.28; acc: 0.89
Batch: 480; loss: 0.43; acc: 0.83
Batch: 500; loss: 0.48; acc: 0.88
Batch: 520; loss: 0.54; acc: 0.83
Batch: 540; loss: 0.53; acc: 0.84
Batch: 560; loss: 0.61; acc: 0.84
Batch: 580; loss: 0.47; acc: 0.89
Batch: 600; loss: 0.32; acc: 0.91
Batch: 620; loss: 0.34; acc: 0.94
Batch: 640; loss: 0.36; acc: 0.92
Batch: 660; loss: 0.65; acc: 0.78
Batch: 680; loss: 0.44; acc: 0.89
Batch: 700; loss: 0.26; acc: 0.91
Batch: 720; loss: 0.44; acc: 0.88
Batch: 740; loss: 0.36; acc: 0.89
Batch: 760; loss: 0.44; acc: 0.88
Batch: 780; loss: 0.38; acc: 0.88
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

2.4319515432580374e-05
7.697910405113362e-06
Batch: 0; loss: 0.36; acc: 0.88
Batch: 20; loss: 0.51; acc: 0.8
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.63; acc: 0.83
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.38; acc: 0.92
Batch: 120; loss: 0.52; acc: 0.83
Batch: 140; loss: 0.23; acc: 0.95
Val Epoch over. val_loss: 0.405655315252626; val_accuracy: 0.8779856687898089 

The current subspace-distance is: 7.697910405113362e-06 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.62; acc: 0.83
Batch: 20; loss: 0.37; acc: 0.88
Batch: 40; loss: 0.35; acc: 0.88
Batch: 60; loss: 0.44; acc: 0.89
Batch: 80; loss: 0.52; acc: 0.83
Batch: 100; loss: 0.43; acc: 0.84
Batch: 120; loss: 0.33; acc: 0.84
Batch: 140; loss: 0.41; acc: 0.86
Batch: 160; loss: 0.45; acc: 0.88
Batch: 180; loss: 0.29; acc: 0.89
Batch: 200; loss: 0.43; acc: 0.89
Batch: 220; loss: 0.37; acc: 0.89
Batch: 240; loss: 0.29; acc: 0.91
Batch: 260; loss: 0.25; acc: 0.92
Batch: 280; loss: 0.35; acc: 0.84
Batch: 300; loss: 0.3; acc: 0.92
Batch: 320; loss: 0.43; acc: 0.88
Batch: 340; loss: 0.32; acc: 0.92
Batch: 360; loss: 0.65; acc: 0.77
Batch: 380; loss: 0.5; acc: 0.88
Batch: 400; loss: 0.33; acc: 0.92
Batch: 420; loss: 0.43; acc: 0.86
Batch: 440; loss: 0.53; acc: 0.88
Batch: 460; loss: 0.53; acc: 0.84
Batch: 480; loss: 0.41; acc: 0.91
Batch: 500; loss: 0.54; acc: 0.83
Batch: 520; loss: 0.37; acc: 0.88
Batch: 540; loss: 0.48; acc: 0.84
Batch: 560; loss: 0.49; acc: 0.89
Batch: 580; loss: 0.39; acc: 0.88
Batch: 600; loss: 0.42; acc: 0.89
Batch: 620; loss: 0.45; acc: 0.88
Batch: 640; loss: 0.39; acc: 0.83
Batch: 660; loss: 0.37; acc: 0.81
Batch: 680; loss: 0.38; acc: 0.88
Batch: 700; loss: 0.5; acc: 0.84
Batch: 720; loss: 0.32; acc: 0.91
Batch: 740; loss: 0.72; acc: 0.83
Batch: 760; loss: 0.52; acc: 0.81
Batch: 780; loss: 0.32; acc: 0.86
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

2.6882687961915508e-05
1.1749335499189328e-05
Batch: 0; loss: 0.45; acc: 0.83
Batch: 20; loss: 0.58; acc: 0.78
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.75; acc: 0.84
Batch: 80; loss: 0.22; acc: 0.95
Batch: 100; loss: 0.39; acc: 0.92
Batch: 120; loss: 0.6; acc: 0.81
Batch: 140; loss: 0.28; acc: 0.91
Val Epoch over. val_loss: 0.45086716001580474; val_accuracy: 0.8626592356687898 

The current subspace-distance is: 1.1749335499189328e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.46; acc: 0.83
Batch: 20; loss: 0.57; acc: 0.84
Batch: 40; loss: 0.68; acc: 0.84
Batch: 60; loss: 0.34; acc: 0.94
Batch: 80; loss: 0.41; acc: 0.91
Batch: 100; loss: 0.33; acc: 0.88
Batch: 120; loss: 0.49; acc: 0.91
Batch: 140; loss: 0.33; acc: 0.88
Batch: 160; loss: 0.6; acc: 0.81
Batch: 180; loss: 0.35; acc: 0.89
Batch: 200; loss: 0.4; acc: 0.89
Batch: 220; loss: 0.38; acc: 0.91
Batch: 240; loss: 0.31; acc: 0.88
Batch: 260; loss: 0.24; acc: 0.91
Batch: 280; loss: 0.52; acc: 0.84
Batch: 300; loss: 0.45; acc: 0.81
Batch: 320; loss: 0.57; acc: 0.86
Batch: 340; loss: 0.3; acc: 0.95
Batch: 360; loss: 0.34; acc: 0.95
Batch: 380; loss: 0.5; acc: 0.83
Batch: 400; loss: 0.26; acc: 0.94
Batch: 420; loss: 0.5; acc: 0.88
Batch: 440; loss: 0.31; acc: 0.91
Batch: 460; loss: 0.42; acc: 0.91
Batch: 480; loss: 0.27; acc: 0.92
Batch: 500; loss: 0.25; acc: 0.92
Batch: 520; loss: 0.34; acc: 0.88
Batch: 540; loss: 0.72; acc: 0.77
Batch: 560; loss: 0.24; acc: 0.91
Batch: 580; loss: 0.56; acc: 0.81
Batch: 600; loss: 0.34; acc: 0.83
Batch: 620; loss: 0.46; acc: 0.88
Batch: 640; loss: 0.29; acc: 0.91
Batch: 660; loss: 0.3; acc: 0.92
Batch: 680; loss: 0.38; acc: 0.89
Batch: 700; loss: 0.81; acc: 0.75
Batch: 720; loss: 0.17; acc: 0.92
Batch: 740; loss: 0.32; acc: 0.88
Batch: 760; loss: 0.33; acc: 0.88
Batch: 780; loss: 0.51; acc: 0.86
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

2.436648719594814e-05
9.468697498959955e-06
Batch: 0; loss: 0.36; acc: 0.88
Batch: 20; loss: 0.49; acc: 0.78
Batch: 40; loss: 0.12; acc: 0.98
Batch: 60; loss: 0.6; acc: 0.88
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.38; acc: 0.86
Batch: 120; loss: 0.64; acc: 0.8
Batch: 140; loss: 0.22; acc: 0.94
Val Epoch over. val_loss: 0.3915582823145921; val_accuracy: 0.8811703821656051 

The current subspace-distance is: 9.468697498959955e-06 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.26; acc: 0.92
Batch: 20; loss: 0.55; acc: 0.86
Batch: 40; loss: 0.32; acc: 0.92
Batch: 60; loss: 0.35; acc: 0.91
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.62; acc: 0.81
Batch: 120; loss: 0.38; acc: 0.91
Batch: 140; loss: 0.55; acc: 0.86
Batch: 160; loss: 0.52; acc: 0.75
Batch: 180; loss: 0.29; acc: 0.94
Batch: 200; loss: 0.33; acc: 0.92
Batch: 220; loss: 0.55; acc: 0.83
Batch: 240; loss: 0.23; acc: 0.91
Batch: 260; loss: 0.39; acc: 0.89
Batch: 280; loss: 0.62; acc: 0.81
Batch: 300; loss: 0.41; acc: 0.88
Batch: 320; loss: 0.34; acc: 0.86
Batch: 340; loss: 0.47; acc: 0.84
Batch: 360; loss: 0.37; acc: 0.91
Batch: 380; loss: 0.25; acc: 0.94
Batch: 400; loss: 0.6; acc: 0.84
Batch: 420; loss: 0.57; acc: 0.83
Batch: 440; loss: 0.4; acc: 0.88
Batch: 460; loss: 0.4; acc: 0.84
Batch: 480; loss: 0.42; acc: 0.83
Batch: 500; loss: 0.44; acc: 0.84
Batch: 520; loss: 0.36; acc: 0.88
Batch: 540; loss: 0.42; acc: 0.86
Batch: 560; loss: 0.69; acc: 0.78
Batch: 580; loss: 0.34; acc: 0.92
Batch: 600; loss: 0.31; acc: 0.91
Batch: 620; loss: 0.66; acc: 0.84
Batch: 640; loss: 0.4; acc: 0.89
Batch: 660; loss: 0.49; acc: 0.84
Batch: 680; loss: 0.78; acc: 0.78
Batch: 700; loss: 0.51; acc: 0.86
Batch: 720; loss: 0.52; acc: 0.86
Batch: 740; loss: 0.18; acc: 0.95
Batch: 760; loss: 0.45; acc: 0.84
Batch: 780; loss: 0.4; acc: 0.89
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

2.6603036531014368e-05
8.144856110448018e-06
Batch: 0; loss: 0.49; acc: 0.83
Batch: 20; loss: 0.58; acc: 0.77
Batch: 40; loss: 0.21; acc: 0.92
Batch: 60; loss: 0.83; acc: 0.81
Batch: 80; loss: 0.26; acc: 0.97
Batch: 100; loss: 0.37; acc: 0.91
Batch: 120; loss: 0.61; acc: 0.8
Batch: 140; loss: 0.25; acc: 0.91
Val Epoch over. val_loss: 0.4706664177927242; val_accuracy: 0.8480294585987261 

The current subspace-distance is: 8.144856110448018e-06 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.59; acc: 0.8
Batch: 20; loss: 0.29; acc: 0.88
Batch: 40; loss: 0.44; acc: 0.88
Batch: 60; loss: 0.44; acc: 0.84
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.38; acc: 0.88
Batch: 120; loss: 0.49; acc: 0.86
Batch: 140; loss: 0.31; acc: 0.91
Batch: 160; loss: 0.33; acc: 0.91
Batch: 180; loss: 0.49; acc: 0.86
Batch: 200; loss: 0.39; acc: 0.88
Batch: 220; loss: 0.45; acc: 0.81
Batch: 240; loss: 0.54; acc: 0.84
Batch: 260; loss: 0.52; acc: 0.83
Batch: 280; loss: 0.33; acc: 0.86
Batch: 300; loss: 0.66; acc: 0.86
Batch: 320; loss: 0.47; acc: 0.84
Batch: 340; loss: 0.35; acc: 0.92
Batch: 360; loss: 0.38; acc: 0.89
Batch: 380; loss: 0.68; acc: 0.81
Batch: 400; loss: 0.36; acc: 0.89
Batch: 420; loss: 0.53; acc: 0.86
Batch: 440; loss: 0.41; acc: 0.86
Batch: 460; loss: 0.58; acc: 0.84
Batch: 480; loss: 0.41; acc: 0.88
Batch: 500; loss: 0.48; acc: 0.88
Batch: 520; loss: 0.53; acc: 0.91
Batch: 540; loss: 0.25; acc: 0.95
Batch: 560; loss: 0.46; acc: 0.89
Batch: 580; loss: 0.5; acc: 0.81
Batch: 600; loss: 0.33; acc: 0.89
Batch: 620; loss: 0.47; acc: 0.88
Batch: 640; loss: 0.43; acc: 0.88
Batch: 660; loss: 0.43; acc: 0.86
Batch: 680; loss: 0.49; acc: 0.88
Batch: 700; loss: 0.51; acc: 0.8
Batch: 720; loss: 0.42; acc: 0.89
Batch: 740; loss: 0.41; acc: 0.83
Batch: 760; loss: 0.65; acc: 0.8
Batch: 780; loss: 0.27; acc: 0.94
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

2.7749731088988483e-05
7.676965651626233e-06
Batch: 0; loss: 0.51; acc: 0.83
Batch: 20; loss: 0.6; acc: 0.75
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.81; acc: 0.81
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.38; acc: 0.91
Batch: 120; loss: 0.61; acc: 0.81
Batch: 140; loss: 0.31; acc: 0.92
Val Epoch over. val_loss: 0.45196991788733537; val_accuracy: 0.85828025477707 

The current subspace-distance is: 7.676965651626233e-06 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.43; acc: 0.84
Batch: 20; loss: 0.64; acc: 0.88
Batch: 40; loss: 0.48; acc: 0.86
Batch: 60; loss: 0.25; acc: 0.92
Batch: 80; loss: 0.37; acc: 0.91
Batch: 100; loss: 0.42; acc: 0.84
Batch: 120; loss: 0.56; acc: 0.83
Batch: 140; loss: 0.36; acc: 0.88
Batch: 160; loss: 0.55; acc: 0.84
Batch: 180; loss: 0.57; acc: 0.84
Batch: 200; loss: 0.39; acc: 0.86
Batch: 220; loss: 0.53; acc: 0.83
Batch: 240; loss: 0.31; acc: 0.91
Batch: 260; loss: 0.31; acc: 0.88
Batch: 280; loss: 0.74; acc: 0.81
Batch: 300; loss: 0.41; acc: 0.89
Batch: 320; loss: 0.65; acc: 0.8
Batch: 340; loss: 0.51; acc: 0.84
Batch: 360; loss: 0.4; acc: 0.89
Batch: 380; loss: 0.57; acc: 0.89
Batch: 400; loss: 0.55; acc: 0.81
Batch: 420; loss: 0.44; acc: 0.91
Batch: 440; loss: 0.47; acc: 0.84
Batch: 460; loss: 0.34; acc: 0.92
Batch: 480; loss: 0.28; acc: 0.89
Batch: 500; loss: 0.64; acc: 0.83
Batch: 520; loss: 0.23; acc: 0.91
Batch: 540; loss: 0.4; acc: 0.88
Batch: 560; loss: 0.51; acc: 0.84
Batch: 580; loss: 0.44; acc: 0.88
Batch: 600; loss: 0.47; acc: 0.83
Batch: 620; loss: 0.33; acc: 0.89
Batch: 640; loss: 0.42; acc: 0.86
Batch: 660; loss: 0.37; acc: 0.84
Batch: 680; loss: 0.36; acc: 0.91
Batch: 700; loss: 0.61; acc: 0.78
Batch: 720; loss: 0.36; acc: 0.88
Batch: 740; loss: 0.44; acc: 0.88
Batch: 760; loss: 0.64; acc: 0.8
Batch: 780; loss: 0.39; acc: 0.89
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

2.8229844247107394e-05
1.0056554856419098e-05
Batch: 0; loss: 0.41; acc: 0.88
Batch: 20; loss: 0.5; acc: 0.78
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.65; acc: 0.86
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.32; acc: 0.92
Batch: 120; loss: 0.68; acc: 0.75
Batch: 140; loss: 0.25; acc: 0.94
Val Epoch over. val_loss: 0.42913038150709903; val_accuracy: 0.8697253184713376 

The current subspace-distance is: 1.0056554856419098e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.27; acc: 0.92
Batch: 20; loss: 0.55; acc: 0.84
Batch: 40; loss: 0.48; acc: 0.8
Batch: 60; loss: 0.36; acc: 0.91
Batch: 80; loss: 0.59; acc: 0.84
Batch: 100; loss: 0.5; acc: 0.88
Batch: 120; loss: 0.43; acc: 0.89
Batch: 140; loss: 0.23; acc: 0.97
Batch: 160; loss: 0.64; acc: 0.89
Batch: 180; loss: 0.46; acc: 0.81
Batch: 200; loss: 0.52; acc: 0.88
Batch: 220; loss: 0.22; acc: 0.94
Batch: 240; loss: 0.61; acc: 0.75
Batch: 260; loss: 0.44; acc: 0.91
Batch: 280; loss: 0.41; acc: 0.91
Batch: 300; loss: 0.52; acc: 0.83
Batch: 320; loss: 0.32; acc: 0.88
Batch: 340; loss: 0.25; acc: 0.91
Batch: 360; loss: 0.47; acc: 0.83
Batch: 380; loss: 0.68; acc: 0.83
Batch: 400; loss: 0.5; acc: 0.84
Batch: 420; loss: 0.64; acc: 0.84
Batch: 440; loss: 0.41; acc: 0.89
Batch: 460; loss: 0.43; acc: 0.89
Batch: 480; loss: 0.51; acc: 0.86
Batch: 500; loss: 0.36; acc: 0.89
Batch: 520; loss: 0.46; acc: 0.84
Batch: 540; loss: 0.44; acc: 0.83
Batch: 560; loss: 0.63; acc: 0.81
Batch: 580; loss: 0.43; acc: 0.86
Batch: 600; loss: 0.53; acc: 0.89
Batch: 620; loss: 0.35; acc: 0.94
Batch: 640; loss: 0.35; acc: 0.86
Batch: 660; loss: 0.28; acc: 0.89
Batch: 680; loss: 0.34; acc: 0.86
Batch: 700; loss: 0.25; acc: 0.91
Batch: 720; loss: 0.4; acc: 0.86
Batch: 740; loss: 0.57; acc: 0.81
Batch: 760; loss: 0.33; acc: 0.91
Batch: 780; loss: 0.62; acc: 0.8
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

2.5062961867661215e-05
9.617656360205729e-06
Batch: 0; loss: 0.36; acc: 0.88
Batch: 20; loss: 0.46; acc: 0.84
Batch: 40; loss: 0.11; acc: 0.98
Batch: 60; loss: 0.62; acc: 0.88
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.32; acc: 0.88
Batch: 120; loss: 0.57; acc: 0.81
Batch: 140; loss: 0.18; acc: 0.95
Val Epoch over. val_loss: 0.37248108787521433; val_accuracy: 0.8886345541401274 

The current subspace-distance is: 9.617656360205729e-06 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.51; acc: 0.83
Batch: 20; loss: 0.38; acc: 0.84
Batch: 40; loss: 0.54; acc: 0.86
Batch: 60; loss: 0.39; acc: 0.84
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.39; acc: 0.89
Batch: 120; loss: 0.42; acc: 0.83
Batch: 140; loss: 0.47; acc: 0.81
Batch: 160; loss: 0.3; acc: 0.94
Batch: 180; loss: 0.42; acc: 0.89
Batch: 200; loss: 0.48; acc: 0.83
Batch: 220; loss: 0.21; acc: 0.97
Batch: 240; loss: 0.43; acc: 0.88
Batch: 260; loss: 0.62; acc: 0.84
Batch: 280; loss: 0.39; acc: 0.91
Batch: 300; loss: 0.3; acc: 0.88
Batch: 320; loss: 0.45; acc: 0.88
Batch: 340; loss: 0.52; acc: 0.84
Batch: 360; loss: 0.31; acc: 0.91
Batch: 380; loss: 0.29; acc: 0.91
Batch: 400; loss: 0.37; acc: 0.86
Batch: 420; loss: 0.45; acc: 0.86
Batch: 440; loss: 0.45; acc: 0.89
Batch: 460; loss: 0.45; acc: 0.83
Batch: 480; loss: 0.22; acc: 0.91
Batch: 500; loss: 0.3; acc: 0.86
Batch: 520; loss: 0.31; acc: 0.92
Batch: 540; loss: 0.41; acc: 0.86
Batch: 560; loss: 0.42; acc: 0.86
Batch: 580; loss: 0.3; acc: 0.89
Batch: 600; loss: 0.38; acc: 0.89
Batch: 620; loss: 0.38; acc: 0.86
Batch: 640; loss: 0.39; acc: 0.91
Batch: 660; loss: 0.25; acc: 0.97
Batch: 680; loss: 0.39; acc: 0.91
Batch: 700; loss: 0.44; acc: 0.89
Batch: 720; loss: 0.23; acc: 0.92
Batch: 740; loss: 0.38; acc: 0.86
Batch: 760; loss: 0.32; acc: 0.91
Batch: 780; loss: 0.5; acc: 0.88
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

2.7535379558685236e-05
6.478460818470921e-06
Batch: 0; loss: 0.44; acc: 0.88
Batch: 20; loss: 0.53; acc: 0.81
Batch: 40; loss: 0.13; acc: 0.98
Batch: 60; loss: 0.72; acc: 0.84
Batch: 80; loss: 0.18; acc: 0.97
Batch: 100; loss: 0.31; acc: 0.92
Batch: 120; loss: 0.47; acc: 0.88
Batch: 140; loss: 0.22; acc: 0.95
Val Epoch over. val_loss: 0.40531793255714854; val_accuracy: 0.8793789808917197 

The current subspace-distance is: 6.478460818470921e-06 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.53; acc: 0.81
Batch: 20; loss: 0.34; acc: 0.86
Batch: 40; loss: 0.58; acc: 0.81
Batch: 60; loss: 0.67; acc: 0.84
Batch: 80; loss: 0.53; acc: 0.84
Batch: 100; loss: 0.68; acc: 0.77
Batch: 120; loss: 0.33; acc: 0.88
Batch: 140; loss: 0.58; acc: 0.81
Batch: 160; loss: 0.38; acc: 0.91
Batch: 180; loss: 0.52; acc: 0.84
Batch: 200; loss: 0.66; acc: 0.83
Batch: 220; loss: 0.37; acc: 0.91
Batch: 240; loss: 0.4; acc: 0.88
Batch: 260; loss: 0.62; acc: 0.75
Batch: 280; loss: 0.38; acc: 0.88
Batch: 300; loss: 0.48; acc: 0.83
Batch: 320; loss: 0.6; acc: 0.8
Batch: 340; loss: 0.42; acc: 0.86
Batch: 360; loss: 0.39; acc: 0.92
Batch: 380; loss: 0.22; acc: 0.91
Batch: 400; loss: 0.54; acc: 0.81
Batch: 420; loss: 0.32; acc: 0.94
Batch: 440; loss: 0.35; acc: 0.91
Batch: 460; loss: 0.26; acc: 0.92
Batch: 480; loss: 0.48; acc: 0.88
Batch: 500; loss: 0.37; acc: 0.86
Batch: 520; loss: 0.64; acc: 0.81
Batch: 540; loss: 0.43; acc: 0.86
Batch: 560; loss: 0.31; acc: 0.94
Batch: 580; loss: 0.48; acc: 0.88
Batch: 600; loss: 0.31; acc: 0.92
Batch: 620; loss: 0.62; acc: 0.78
Batch: 640; loss: 0.59; acc: 0.89
Batch: 660; loss: 0.28; acc: 0.92
Batch: 680; loss: 0.68; acc: 0.81
Batch: 700; loss: 0.37; acc: 0.88
Batch: 720; loss: 0.44; acc: 0.89
Batch: 740; loss: 0.43; acc: 0.89
Batch: 760; loss: 0.39; acc: 0.84
Batch: 780; loss: 0.4; acc: 0.89
Train Epoch over. train_loss: 0.41; train_accuracy: 0.87 

2.66317292698659e-05
8.904394235287327e-06
Batch: 0; loss: 0.42; acc: 0.88
Batch: 20; loss: 0.58; acc: 0.78
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.67; acc: 0.86
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.29; acc: 0.95
Batch: 120; loss: 0.49; acc: 0.86
Batch: 140; loss: 0.25; acc: 0.91
Val Epoch over. val_loss: 0.428803926345649; val_accuracy: 0.8701234076433121 

The current subspace-distance is: 8.904394235287327e-06 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.32; acc: 0.92
Batch: 20; loss: 0.38; acc: 0.88
Batch: 40; loss: 0.41; acc: 0.88
Batch: 60; loss: 0.31; acc: 0.91
Batch: 80; loss: 0.34; acc: 0.88
Batch: 100; loss: 0.44; acc: 0.84
Batch: 120; loss: 0.29; acc: 0.91
Batch: 140; loss: 0.28; acc: 0.92
Batch: 160; loss: 0.49; acc: 0.83
Batch: 180; loss: 0.36; acc: 0.88
Batch: 200; loss: 0.36; acc: 0.91
Batch: 220; loss: 0.57; acc: 0.83
Batch: 240; loss: 0.44; acc: 0.86
Batch: 260; loss: 0.36; acc: 0.91
Batch: 280; loss: 0.35; acc: 0.94
Batch: 300; loss: 0.4; acc: 0.89
Batch: 320; loss: 0.61; acc: 0.84
Batch: 340; loss: 0.3; acc: 0.92
Batch: 360; loss: 0.4; acc: 0.83
Batch: 380; loss: 0.52; acc: 0.86
Batch: 400; loss: 0.32; acc: 0.91
Batch: 420; loss: 0.44; acc: 0.84
Batch: 440; loss: 0.52; acc: 0.86
Batch: 460; loss: 0.31; acc: 0.92
Batch: 480; loss: 0.37; acc: 0.89
Batch: 500; loss: 0.34; acc: 0.91
Batch: 520; loss: 0.47; acc: 0.86
Batch: 540; loss: 0.2; acc: 0.95
Batch: 560; loss: 0.51; acc: 0.83
Batch: 580; loss: 0.28; acc: 0.92
Batch: 600; loss: 0.47; acc: 0.84
Batch: 620; loss: 0.83; acc: 0.73
Batch: 640; loss: 0.32; acc: 0.89
Batch: 660; loss: 0.34; acc: 0.89
Batch: 680; loss: 0.35; acc: 0.88
Batch: 700; loss: 0.4; acc: 0.89
Batch: 720; loss: 0.43; acc: 0.84
Batch: 740; loss: 0.34; acc: 0.88
Batch: 760; loss: 0.4; acc: 0.86
Batch: 780; loss: 0.42; acc: 0.89
Train Epoch over. train_loss: 0.41; train_accuracy: 0.87 

3.265593113610521e-05
9.115440661844332e-06
Batch: 0; loss: 0.45; acc: 0.81
Batch: 20; loss: 0.53; acc: 0.81
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.64; acc: 0.88
Batch: 80; loss: 0.28; acc: 0.91
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.58; acc: 0.81
Batch: 140; loss: 0.23; acc: 0.95
Val Epoch over. val_loss: 0.4349652727128594; val_accuracy: 0.8667396496815286 

The current subspace-distance is: 9.115440661844332e-06 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.44; acc: 0.81
Batch: 20; loss: 0.2; acc: 0.92
Batch: 40; loss: 0.55; acc: 0.83
Batch: 60; loss: 0.39; acc: 0.88
Batch: 80; loss: 0.45; acc: 0.88
Batch: 100; loss: 0.43; acc: 0.83
Batch: 120; loss: 0.41; acc: 0.84
Batch: 140; loss: 0.26; acc: 0.91
Batch: 160; loss: 0.35; acc: 0.89
Batch: 180; loss: 0.41; acc: 0.86
Batch: 200; loss: 0.27; acc: 0.94
Batch: 220; loss: 0.33; acc: 0.91
Batch: 240; loss: 0.29; acc: 0.89
Batch: 260; loss: 0.48; acc: 0.86
Batch: 280; loss: 0.42; acc: 0.86
Batch: 300; loss: 0.26; acc: 0.92
Batch: 320; loss: 0.37; acc: 0.88
Batch: 340; loss: 0.27; acc: 0.94
Batch: 360; loss: 0.21; acc: 0.92
Batch: 380; loss: 0.43; acc: 0.88
Batch: 400; loss: 0.49; acc: 0.83
Batch: 420; loss: 0.39; acc: 0.88
Batch: 440; loss: 0.38; acc: 0.89
Batch: 460; loss: 0.38; acc: 0.91
Batch: 480; loss: 0.49; acc: 0.86
Batch: 500; loss: 0.45; acc: 0.84
Batch: 520; loss: 0.45; acc: 0.84
Batch: 540; loss: 0.21; acc: 0.91
Batch: 560; loss: 0.35; acc: 0.88
Batch: 580; loss: 0.28; acc: 0.95
Batch: 600; loss: 0.32; acc: 0.88
Batch: 620; loss: 0.48; acc: 0.86
Batch: 640; loss: 0.4; acc: 0.91
Batch: 660; loss: 0.41; acc: 0.84
Batch: 680; loss: 0.26; acc: 0.89
Batch: 700; loss: 0.32; acc: 0.91
Batch: 720; loss: 0.51; acc: 0.86
Batch: 740; loss: 0.37; acc: 0.88
Batch: 760; loss: 0.52; acc: 0.86
Batch: 780; loss: 0.67; acc: 0.77
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

2.6484633053769358e-05
8.60118234413676e-06
Batch: 0; loss: 0.38; acc: 0.88
Batch: 20; loss: 0.45; acc: 0.84
Batch: 40; loss: 0.11; acc: 0.98
Batch: 60; loss: 0.66; acc: 0.88
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.28; acc: 0.94
Batch: 120; loss: 0.51; acc: 0.84
Batch: 140; loss: 0.22; acc: 0.92
Val Epoch over. val_loss: 0.36895136800920886; val_accuracy: 0.8882364649681529 

The current subspace-distance is: 8.60118234413676e-06 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.29; acc: 0.94
Batch: 20; loss: 0.25; acc: 0.95
Batch: 40; loss: 0.22; acc: 0.92
Batch: 60; loss: 0.21; acc: 0.92
Batch: 80; loss: 0.29; acc: 0.89
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.55; acc: 0.81
Batch: 140; loss: 0.45; acc: 0.83
Batch: 160; loss: 0.41; acc: 0.94
Batch: 180; loss: 0.25; acc: 0.91
Batch: 200; loss: 0.39; acc: 0.91
Batch: 220; loss: 0.23; acc: 0.91
Batch: 240; loss: 0.29; acc: 0.95
Batch: 260; loss: 0.38; acc: 0.86
Batch: 280; loss: 0.33; acc: 0.86
Batch: 300; loss: 0.52; acc: 0.8
Batch: 320; loss: 0.3; acc: 0.91
Batch: 340; loss: 0.18; acc: 0.94
Batch: 360; loss: 0.28; acc: 0.92
Batch: 380; loss: 0.28; acc: 0.89
Batch: 400; loss: 0.46; acc: 0.83
Batch: 420; loss: 0.58; acc: 0.83
Batch: 440; loss: 0.38; acc: 0.83
Batch: 460; loss: 0.35; acc: 0.89
Batch: 480; loss: 0.22; acc: 0.91
Batch: 500; loss: 0.32; acc: 0.92
Batch: 520; loss: 0.36; acc: 0.89
Batch: 540; loss: 0.33; acc: 0.86
Batch: 560; loss: 0.39; acc: 0.91
Batch: 580; loss: 0.23; acc: 0.95
Batch: 600; loss: 0.26; acc: 0.89
Batch: 620; loss: 0.27; acc: 0.94
Batch: 640; loss: 0.47; acc: 0.83
Batch: 660; loss: 0.36; acc: 0.86
Batch: 680; loss: 0.31; acc: 0.92
Batch: 700; loss: 0.28; acc: 0.94
Batch: 720; loss: 0.37; acc: 0.91
Batch: 740; loss: 0.22; acc: 0.94
Batch: 760; loss: 0.38; acc: 0.89
Batch: 780; loss: 0.37; acc: 0.91
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

2.6193636585958302e-05
8.68021925271023e-06
Batch: 0; loss: 0.33; acc: 0.89
Batch: 20; loss: 0.52; acc: 0.83
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.62; acc: 0.86
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.26; acc: 0.95
Batch: 120; loss: 0.5; acc: 0.88
Batch: 140; loss: 0.23; acc: 0.94
Val Epoch over. val_loss: 0.37382876569298423; val_accuracy: 0.8893312101910829 

The current subspace-distance is: 8.68021925271023e-06 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.32; acc: 0.91
Batch: 20; loss: 0.33; acc: 0.88
Batch: 40; loss: 0.59; acc: 0.83
Batch: 60; loss: 0.53; acc: 0.84
Batch: 80; loss: 0.46; acc: 0.83
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.57; acc: 0.84
Batch: 140; loss: 0.27; acc: 0.88
Batch: 160; loss: 0.38; acc: 0.88
Batch: 180; loss: 0.47; acc: 0.86
Batch: 200; loss: 0.41; acc: 0.88
Batch: 220; loss: 0.18; acc: 0.95
Batch: 240; loss: 0.39; acc: 0.89
Batch: 260; loss: 0.45; acc: 0.86
Batch: 280; loss: 0.28; acc: 0.91
Batch: 300; loss: 0.2; acc: 0.92
Batch: 320; loss: 0.43; acc: 0.89
Batch: 340; loss: 0.34; acc: 0.91
Batch: 360; loss: 0.24; acc: 0.95
Batch: 380; loss: 0.53; acc: 0.89
Batch: 400; loss: 0.31; acc: 0.91
Batch: 420; loss: 0.25; acc: 0.89
Batch: 440; loss: 0.76; acc: 0.73
Batch: 460; loss: 0.45; acc: 0.89
Batch: 480; loss: 0.4; acc: 0.81
Batch: 500; loss: 0.4; acc: 0.86
Batch: 520; loss: 0.57; acc: 0.83
Batch: 540; loss: 0.36; acc: 0.86
Batch: 560; loss: 0.39; acc: 0.86
Batch: 580; loss: 0.34; acc: 0.91
Batch: 600; loss: 0.28; acc: 0.91
Batch: 620; loss: 0.33; acc: 0.91
Batch: 640; loss: 0.52; acc: 0.86
Batch: 660; loss: 0.26; acc: 0.92
Batch: 680; loss: 0.38; acc: 0.83
Batch: 700; loss: 0.26; acc: 0.97
Batch: 720; loss: 0.28; acc: 0.92
Batch: 740; loss: 0.28; acc: 0.88
Batch: 760; loss: 0.2; acc: 0.94
Batch: 780; loss: 0.35; acc: 0.84
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

2.8399377697496675e-05
9.131630577030592e-06
Batch: 0; loss: 0.34; acc: 0.89
Batch: 20; loss: 0.49; acc: 0.86
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.6; acc: 0.89
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.49; acc: 0.88
Batch: 140; loss: 0.19; acc: 0.94
Val Epoch over. val_loss: 0.35963070947842996; val_accuracy: 0.8912221337579618 

The current subspace-distance is: 9.131630577030592e-06 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.34; acc: 0.89
Batch: 20; loss: 0.28; acc: 0.92
Batch: 40; loss: 0.33; acc: 0.91
Batch: 60; loss: 0.57; acc: 0.8
Batch: 80; loss: 0.42; acc: 0.89
Batch: 100; loss: 0.5; acc: 0.83
Batch: 120; loss: 0.23; acc: 0.95
Batch: 140; loss: 0.3; acc: 0.86
Batch: 160; loss: 0.38; acc: 0.86
Batch: 180; loss: 0.33; acc: 0.94
Batch: 200; loss: 0.18; acc: 0.95
Batch: 220; loss: 0.57; acc: 0.84
Batch: 240; loss: 0.45; acc: 0.84
Batch: 260; loss: 0.43; acc: 0.89
Batch: 280; loss: 0.19; acc: 0.94
Batch: 300; loss: 0.31; acc: 0.91
Batch: 320; loss: 0.23; acc: 0.95
Batch: 340; loss: 0.58; acc: 0.86
Batch: 360; loss: 0.58; acc: 0.84
Batch: 380; loss: 0.43; acc: 0.88
Batch: 400; loss: 0.48; acc: 0.86
Batch: 420; loss: 0.44; acc: 0.86
Batch: 440; loss: 0.54; acc: 0.83
Batch: 460; loss: 0.23; acc: 0.89
Batch: 480; loss: 0.43; acc: 0.91
Batch: 500; loss: 0.3; acc: 0.88
Batch: 520; loss: 0.2; acc: 0.94
Batch: 540; loss: 0.37; acc: 0.88
Batch: 560; loss: 0.26; acc: 0.91
Batch: 580; loss: 0.61; acc: 0.81
Batch: 600; loss: 0.45; acc: 0.84
Batch: 620; loss: 0.3; acc: 0.88
Batch: 640; loss: 0.51; acc: 0.81
Batch: 660; loss: 0.39; acc: 0.83
Batch: 680; loss: 0.4; acc: 0.86
Batch: 700; loss: 0.39; acc: 0.86
Batch: 720; loss: 0.2; acc: 0.95
Batch: 740; loss: 0.34; acc: 0.89
Batch: 760; loss: 0.28; acc: 0.91
Batch: 780; loss: 0.7; acc: 0.84
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

2.6284478735760786e-05
1.0205314538325183e-05
Batch: 0; loss: 0.35; acc: 0.86
Batch: 20; loss: 0.47; acc: 0.83
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.68; acc: 0.86
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.3; acc: 0.94
Batch: 120; loss: 0.52; acc: 0.86
Batch: 140; loss: 0.22; acc: 0.95
Val Epoch over. val_loss: 0.3698004196119157; val_accuracy: 0.886046974522293 

The current subspace-distance is: 1.0205314538325183e-05 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.26; acc: 0.95
Batch: 20; loss: 0.46; acc: 0.88
Batch: 40; loss: 0.36; acc: 0.88
Batch: 60; loss: 0.39; acc: 0.89
Batch: 80; loss: 0.55; acc: 0.83
Batch: 100; loss: 0.49; acc: 0.84
Batch: 120; loss: 0.28; acc: 0.91
Batch: 140; loss: 0.32; acc: 0.92
Batch: 160; loss: 0.41; acc: 0.91
Batch: 180; loss: 0.43; acc: 0.88
Batch: 200; loss: 0.4; acc: 0.89
Batch: 220; loss: 0.29; acc: 0.86
Batch: 240; loss: 0.35; acc: 0.91
Batch: 260; loss: 0.13; acc: 0.95
Batch: 280; loss: 0.4; acc: 0.86
Batch: 300; loss: 0.29; acc: 0.92
Batch: 320; loss: 0.36; acc: 0.86
Batch: 340; loss: 0.47; acc: 0.8
Batch: 360; loss: 0.21; acc: 0.94
Batch: 380; loss: 0.36; acc: 0.89
Batch: 400; loss: 0.4; acc: 0.86
Batch: 420; loss: 0.29; acc: 0.89
Batch: 440; loss: 0.53; acc: 0.83
Batch: 460; loss: 0.68; acc: 0.84
Batch: 480; loss: 0.28; acc: 0.92
Batch: 500; loss: 0.5; acc: 0.86
Batch: 520; loss: 0.19; acc: 0.95
Batch: 540; loss: 0.38; acc: 0.86
Batch: 560; loss: 0.2; acc: 0.92
Batch: 580; loss: 0.43; acc: 0.84
Batch: 600; loss: 0.35; acc: 0.89
Batch: 620; loss: 0.44; acc: 0.91
Batch: 640; loss: 0.3; acc: 0.92
Batch: 660; loss: 0.64; acc: 0.77
Batch: 680; loss: 0.67; acc: 0.84
Batch: 700; loss: 0.18; acc: 0.92
Batch: 720; loss: 0.34; acc: 0.89
Batch: 740; loss: 0.28; acc: 0.95
Batch: 760; loss: 0.63; acc: 0.8
Batch: 780; loss: 0.36; acc: 0.86
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

2.5085375455091707e-05
7.802546861057635e-06
Batch: 0; loss: 0.33; acc: 0.88
Batch: 20; loss: 0.46; acc: 0.81
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.61; acc: 0.88
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.29; acc: 0.94
Batch: 120; loss: 0.51; acc: 0.84
Batch: 140; loss: 0.21; acc: 0.94
Val Epoch over. val_loss: 0.35650646734009883; val_accuracy: 0.8922173566878981 

The current subspace-distance is: 7.802546861057635e-06 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.4; acc: 0.84
Batch: 20; loss: 0.46; acc: 0.88
Batch: 40; loss: 0.32; acc: 0.88
Batch: 60; loss: 0.27; acc: 0.86
Batch: 80; loss: 0.68; acc: 0.84
Batch: 100; loss: 0.51; acc: 0.88
Batch: 120; loss: 0.26; acc: 0.94
Batch: 140; loss: 0.49; acc: 0.89
Batch: 160; loss: 0.39; acc: 0.86
Batch: 180; loss: 0.37; acc: 0.89
Batch: 200; loss: 0.46; acc: 0.86
Batch: 220; loss: 0.59; acc: 0.83
Batch: 240; loss: 0.38; acc: 0.92
Batch: 260; loss: 0.4; acc: 0.86
Batch: 280; loss: 0.36; acc: 0.92
Batch: 300; loss: 0.59; acc: 0.86
Batch: 320; loss: 0.46; acc: 0.83
Batch: 340; loss: 0.48; acc: 0.88
Batch: 360; loss: 0.4; acc: 0.88
Batch: 380; loss: 0.39; acc: 0.92
Batch: 400; loss: 0.26; acc: 0.94
Batch: 420; loss: 0.42; acc: 0.91
Batch: 440; loss: 0.23; acc: 0.92
Batch: 460; loss: 0.37; acc: 0.89
Batch: 480; loss: 0.4; acc: 0.91
Batch: 500; loss: 0.32; acc: 0.92
Batch: 520; loss: 0.32; acc: 0.89
Batch: 540; loss: 0.35; acc: 0.88
Batch: 560; loss: 0.33; acc: 0.88
Batch: 580; loss: 0.36; acc: 0.88
Batch: 600; loss: 0.31; acc: 0.91
Batch: 620; loss: 0.38; acc: 0.91
Batch: 640; loss: 0.48; acc: 0.84
Batch: 660; loss: 0.51; acc: 0.8
Batch: 680; loss: 0.32; acc: 0.92
Batch: 700; loss: 0.35; acc: 0.89
Batch: 720; loss: 0.32; acc: 0.94
Batch: 740; loss: 0.37; acc: 0.88
Batch: 760; loss: 0.45; acc: 0.89
Batch: 780; loss: 0.17; acc: 0.95
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

2.3548753233626485e-05
8.633421202830505e-06
Batch: 0; loss: 0.35; acc: 0.86
Batch: 20; loss: 0.43; acc: 0.83
Batch: 40; loss: 0.16; acc: 0.97
Batch: 60; loss: 0.61; acc: 0.89
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.31; acc: 0.92
Batch: 120; loss: 0.48; acc: 0.89
Batch: 140; loss: 0.18; acc: 0.94
Val Epoch over. val_loss: 0.3579833733428056; val_accuracy: 0.8900278662420382 

The current subspace-distance is: 8.633421202830505e-06 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.31; acc: 0.88
Batch: 20; loss: 0.41; acc: 0.89
Batch: 40; loss: 0.59; acc: 0.84
Batch: 60; loss: 0.72; acc: 0.83
Batch: 80; loss: 0.6; acc: 0.81
Batch: 100; loss: 0.35; acc: 0.84
Batch: 120; loss: 0.41; acc: 0.89
Batch: 140; loss: 0.25; acc: 0.94
Batch: 160; loss: 0.38; acc: 0.86
Batch: 180; loss: 0.4; acc: 0.86
Batch: 200; loss: 0.33; acc: 0.89
Batch: 220; loss: 0.36; acc: 0.88
Batch: 240; loss: 0.38; acc: 0.8
Batch: 260; loss: 0.48; acc: 0.91
Batch: 280; loss: 0.44; acc: 0.84
Batch: 300; loss: 0.37; acc: 0.91
Batch: 320; loss: 0.31; acc: 0.89
Batch: 340; loss: 0.24; acc: 0.89
Batch: 360; loss: 0.23; acc: 0.94
Batch: 380; loss: 0.56; acc: 0.86
Batch: 400; loss: 0.25; acc: 0.94
Batch: 420; loss: 0.57; acc: 0.83
Batch: 440; loss: 0.23; acc: 0.94
Batch: 460; loss: 0.48; acc: 0.91
Batch: 480; loss: 0.37; acc: 0.92
Batch: 500; loss: 0.23; acc: 0.94
Batch: 520; loss: 0.37; acc: 0.92
Batch: 540; loss: 0.42; acc: 0.89
Batch: 560; loss: 0.29; acc: 0.94
Batch: 580; loss: 0.36; acc: 0.89
Batch: 600; loss: 0.3; acc: 0.89
Batch: 620; loss: 0.46; acc: 0.86
Batch: 640; loss: 0.31; acc: 0.89
Batch: 660; loss: 0.47; acc: 0.89
Batch: 680; loss: 0.58; acc: 0.83
Batch: 700; loss: 0.68; acc: 0.83
Batch: 720; loss: 0.36; acc: 0.88
Batch: 740; loss: 0.31; acc: 0.92
Batch: 760; loss: 0.42; acc: 0.88
Batch: 780; loss: 0.31; acc: 0.84
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

2.563876478234306e-05
1.2441044418665115e-05
Batch: 0; loss: 0.31; acc: 0.89
Batch: 20; loss: 0.48; acc: 0.84
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.59; acc: 0.89
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.31; acc: 0.94
Batch: 120; loss: 0.48; acc: 0.89
Batch: 140; loss: 0.19; acc: 0.94
Val Epoch over. val_loss: 0.3525855334795964; val_accuracy: 0.8950039808917197 

The current subspace-distance is: 1.2441044418665115e-05 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.32; acc: 0.91
Batch: 40; loss: 0.26; acc: 0.89
Batch: 60; loss: 0.56; acc: 0.81
Batch: 80; loss: 0.31; acc: 0.88
Batch: 100; loss: 0.28; acc: 0.89
Batch: 120; loss: 0.37; acc: 0.86
Batch: 140; loss: 0.43; acc: 0.88
Batch: 160; loss: 0.34; acc: 0.89
Batch: 180; loss: 0.5; acc: 0.84
Batch: 200; loss: 0.27; acc: 0.89
Batch: 220; loss: 0.7; acc: 0.83
Batch: 240; loss: 0.38; acc: 0.91
Batch: 260; loss: 0.37; acc: 0.84
Batch: 280; loss: 0.22; acc: 0.91
Batch: 300; loss: 0.76; acc: 0.81
Batch: 320; loss: 0.24; acc: 0.94
Batch: 340; loss: 0.48; acc: 0.86
Batch: 360; loss: 0.4; acc: 0.86
Batch: 380; loss: 0.25; acc: 0.92
Batch: 400; loss: 0.54; acc: 0.89
Batch: 420; loss: 0.55; acc: 0.84
Batch: 440; loss: 0.32; acc: 0.89
Batch: 460; loss: 0.4; acc: 0.86
Batch: 480; loss: 0.45; acc: 0.86
Batch: 500; loss: 0.45; acc: 0.89
Batch: 520; loss: 0.26; acc: 0.92
Batch: 540; loss: 0.53; acc: 0.84
Batch: 560; loss: 0.38; acc: 0.94
Batch: 580; loss: 0.28; acc: 0.91
Batch: 600; loss: 0.32; acc: 0.89
Batch: 620; loss: 0.33; acc: 0.91
Batch: 640; loss: 0.17; acc: 0.91
Batch: 660; loss: 0.67; acc: 0.83
Batch: 680; loss: 0.26; acc: 0.91
Batch: 700; loss: 0.49; acc: 0.84
Batch: 720; loss: 0.37; acc: 0.84
Batch: 740; loss: 0.48; acc: 0.81
Batch: 760; loss: 0.54; acc: 0.8
Batch: 780; loss: 0.6; acc: 0.86
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

2.5725554223754443e-05
9.060114280146081e-06
Batch: 0; loss: 0.34; acc: 0.89
Batch: 20; loss: 0.47; acc: 0.81
Batch: 40; loss: 0.12; acc: 0.98
Batch: 60; loss: 0.64; acc: 0.86
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.3; acc: 0.94
Batch: 120; loss: 0.45; acc: 0.88
Batch: 140; loss: 0.2; acc: 0.94
Val Epoch over. val_loss: 0.36716998425448777; val_accuracy: 0.887937898089172 

The current subspace-distance is: 9.060114280146081e-06 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.5; acc: 0.83
Batch: 20; loss: 0.42; acc: 0.89
Batch: 40; loss: 0.24; acc: 0.91
Batch: 60; loss: 0.39; acc: 0.89
Batch: 80; loss: 0.24; acc: 0.86
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.37; acc: 0.91
Batch: 140; loss: 0.25; acc: 0.94
Batch: 160; loss: 0.39; acc: 0.89
Batch: 180; loss: 0.38; acc: 0.88
Batch: 200; loss: 0.32; acc: 0.91
Batch: 220; loss: 0.36; acc: 0.94
Batch: 240; loss: 0.31; acc: 0.94
Batch: 260; loss: 0.9; acc: 0.75
Batch: 280; loss: 0.56; acc: 0.78
Batch: 300; loss: 0.19; acc: 0.94
Batch: 320; loss: 0.25; acc: 0.92
Batch: 340; loss: 0.35; acc: 0.86
Batch: 360; loss: 0.56; acc: 0.84
Batch: 380; loss: 0.39; acc: 0.88
Batch: 400; loss: 0.44; acc: 0.88
Batch: 420; loss: 0.3; acc: 0.91
Batch: 440; loss: 0.56; acc: 0.8
Batch: 460; loss: 0.37; acc: 0.86
Batch: 480; loss: 0.34; acc: 0.91
Batch: 500; loss: 0.24; acc: 0.91
Batch: 520; loss: 0.41; acc: 0.89
Batch: 540; loss: 0.23; acc: 0.91
Batch: 560; loss: 0.3; acc: 0.88
Batch: 580; loss: 0.32; acc: 0.91
Batch: 600; loss: 0.44; acc: 0.83
Batch: 620; loss: 0.51; acc: 0.8
Batch: 640; loss: 0.31; acc: 0.89
Batch: 660; loss: 0.28; acc: 0.89
Batch: 680; loss: 0.3; acc: 0.91
Batch: 700; loss: 0.32; acc: 0.91
Batch: 720; loss: 0.33; acc: 0.83
Batch: 740; loss: 0.36; acc: 0.86
Batch: 760; loss: 0.34; acc: 0.88
Batch: 780; loss: 0.34; acc: 0.83
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

2.592872260720469e-05
8.01678379502846e-06
Batch: 0; loss: 0.36; acc: 0.86
Batch: 20; loss: 0.47; acc: 0.86
Batch: 40; loss: 0.18; acc: 0.97
Batch: 60; loss: 0.62; acc: 0.88
Batch: 80; loss: 0.24; acc: 0.92
Batch: 100; loss: 0.31; acc: 0.92
Batch: 120; loss: 0.55; acc: 0.84
Batch: 140; loss: 0.23; acc: 0.94
Val Epoch over. val_loss: 0.37545498707302055; val_accuracy: 0.8863455414012739 

The current subspace-distance is: 8.01678379502846e-06 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.41; acc: 0.83
Batch: 20; loss: 0.68; acc: 0.78
Batch: 40; loss: 0.39; acc: 0.94
Batch: 60; loss: 0.59; acc: 0.8
Batch: 80; loss: 0.23; acc: 0.94
Batch: 100; loss: 0.4; acc: 0.81
Batch: 120; loss: 0.21; acc: 0.95
Batch: 140; loss: 0.3; acc: 0.91
Batch: 160; loss: 0.38; acc: 0.91
Batch: 180; loss: 0.28; acc: 0.91
Batch: 200; loss: 0.33; acc: 0.88
Batch: 220; loss: 0.56; acc: 0.84
Batch: 240; loss: 0.25; acc: 0.91
Batch: 260; loss: 0.4; acc: 0.86
Batch: 280; loss: 0.22; acc: 0.92
Batch: 300; loss: 0.41; acc: 0.81
Batch: 320; loss: 0.49; acc: 0.83
Batch: 340; loss: 0.3; acc: 0.92
Batch: 360; loss: 0.23; acc: 0.91
Batch: 380; loss: 0.43; acc: 0.83
Batch: 400; loss: 0.32; acc: 0.92
Batch: 420; loss: 0.28; acc: 0.91
Batch: 440; loss: 0.45; acc: 0.88
Batch: 460; loss: 0.37; acc: 0.89
Batch: 480; loss: 0.37; acc: 0.88
Batch: 500; loss: 0.32; acc: 0.89
Batch: 520; loss: 0.36; acc: 0.89
Batch: 540; loss: 0.31; acc: 0.89
Batch: 560; loss: 0.34; acc: 0.91
Batch: 580; loss: 0.44; acc: 0.84
Batch: 600; loss: 0.27; acc: 0.91
Batch: 620; loss: 0.47; acc: 0.83
Batch: 640; loss: 0.58; acc: 0.78
Batch: 660; loss: 0.21; acc: 0.94
Batch: 680; loss: 0.29; acc: 0.89
Batch: 700; loss: 0.43; acc: 0.86
Batch: 720; loss: 0.43; acc: 0.86
Batch: 740; loss: 0.4; acc: 0.83
Batch: 760; loss: 0.4; acc: 0.91
Batch: 780; loss: 0.35; acc: 0.91
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

2.7015976229449734e-05
9.03929139894899e-06
Batch: 0; loss: 0.31; acc: 0.88
Batch: 20; loss: 0.45; acc: 0.84
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.6; acc: 0.89
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.29; acc: 0.94
Batch: 120; loss: 0.48; acc: 0.88
Batch: 140; loss: 0.2; acc: 0.94
Val Epoch over. val_loss: 0.35479245045382507; val_accuracy: 0.892515923566879 

The current subspace-distance is: 9.03929139894899e-06 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.24; acc: 0.92
Batch: 20; loss: 0.43; acc: 0.88
Batch: 40; loss: 0.33; acc: 0.92
Batch: 60; loss: 0.35; acc: 0.88
Batch: 80; loss: 0.33; acc: 0.86
Batch: 100; loss: 0.34; acc: 0.91
Batch: 120; loss: 0.95; acc: 0.8
Batch: 140; loss: 0.93; acc: 0.77
Batch: 160; loss: 0.43; acc: 0.89
Batch: 180; loss: 0.29; acc: 0.89
Batch: 200; loss: 0.4; acc: 0.86
Batch: 220; loss: 0.37; acc: 0.84
Batch: 240; loss: 0.58; acc: 0.91
Batch: 260; loss: 0.47; acc: 0.89
Batch: 280; loss: 0.37; acc: 0.91
Batch: 300; loss: 0.26; acc: 0.95
Batch: 320; loss: 0.54; acc: 0.84
Batch: 340; loss: 0.45; acc: 0.89
Batch: 360; loss: 0.14; acc: 0.95
Batch: 380; loss: 0.33; acc: 0.89
Batch: 400; loss: 0.32; acc: 0.92
Batch: 420; loss: 0.36; acc: 0.91
Batch: 440; loss: 0.47; acc: 0.86
Batch: 460; loss: 0.45; acc: 0.88
Batch: 480; loss: 0.28; acc: 0.92
Batch: 500; loss: 0.25; acc: 0.91
Batch: 520; loss: 0.36; acc: 0.86
Batch: 540; loss: 0.23; acc: 0.94
Batch: 560; loss: 0.37; acc: 0.89
Batch: 580; loss: 0.29; acc: 0.92
Batch: 600; loss: 0.63; acc: 0.84
Batch: 620; loss: 0.26; acc: 0.92
Batch: 640; loss: 0.67; acc: 0.8
Batch: 660; loss: 0.33; acc: 0.91
Batch: 680; loss: 0.22; acc: 0.94
Batch: 700; loss: 0.39; acc: 0.92
Batch: 720; loss: 0.46; acc: 0.86
Batch: 740; loss: 0.66; acc: 0.78
Batch: 760; loss: 0.4; acc: 0.89
Batch: 780; loss: 0.29; acc: 0.89
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

2.9289283702382818e-05
9.376268280902877e-06
Batch: 0; loss: 0.32; acc: 0.88
Batch: 20; loss: 0.44; acc: 0.86
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.6; acc: 0.89
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.29; acc: 0.94
Batch: 120; loss: 0.47; acc: 0.88
Batch: 140; loss: 0.2; acc: 0.94
Val Epoch over. val_loss: 0.34765064256016615; val_accuracy: 0.895203025477707 

The current subspace-distance is: 9.376268280902877e-06 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.46; acc: 0.89
Batch: 20; loss: 0.29; acc: 0.89
Batch: 40; loss: 0.46; acc: 0.88
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.38; acc: 0.91
Batch: 100; loss: 0.49; acc: 0.88
Batch: 120; loss: 0.52; acc: 0.91
Batch: 140; loss: 0.72; acc: 0.84
Batch: 160; loss: 0.42; acc: 0.84
Batch: 180; loss: 0.4; acc: 0.91
Batch: 200; loss: 0.38; acc: 0.91
Batch: 220; loss: 0.47; acc: 0.84
Batch: 240; loss: 0.23; acc: 0.94
Batch: 260; loss: 0.21; acc: 0.89
Batch: 280; loss: 0.5; acc: 0.88
Batch: 300; loss: 1.07; acc: 0.75
Batch: 320; loss: 0.4; acc: 0.86
Batch: 340; loss: 0.75; acc: 0.86
Batch: 360; loss: 0.22; acc: 0.94
Batch: 380; loss: 0.23; acc: 0.94
Batch: 400; loss: 0.32; acc: 0.86
Batch: 420; loss: 0.37; acc: 0.91
Batch: 440; loss: 0.18; acc: 0.94
Batch: 460; loss: 0.47; acc: 0.84
Batch: 480; loss: 0.17; acc: 0.95
Batch: 500; loss: 0.57; acc: 0.81
Batch: 520; loss: 0.32; acc: 0.89
Batch: 540; loss: 0.38; acc: 0.83
Batch: 560; loss: 0.26; acc: 0.95
Batch: 580; loss: 0.41; acc: 0.86
Batch: 600; loss: 0.25; acc: 0.92
Batch: 620; loss: 0.6; acc: 0.83
Batch: 640; loss: 0.19; acc: 0.92
Batch: 660; loss: 0.27; acc: 0.92
Batch: 680; loss: 0.3; acc: 0.89
Batch: 700; loss: 0.33; acc: 0.91
Batch: 720; loss: 0.43; acc: 0.84
Batch: 740; loss: 0.32; acc: 0.95
Batch: 760; loss: 0.57; acc: 0.8
Batch: 780; loss: 0.24; acc: 0.94
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

2.429935739201028e-05
8.273943421954755e-06
Batch: 0; loss: 0.32; acc: 0.88
Batch: 20; loss: 0.44; acc: 0.86
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.6; acc: 0.88
Batch: 80; loss: 0.18; acc: 0.92
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.48; acc: 0.88
Batch: 140; loss: 0.21; acc: 0.94
Val Epoch over. val_loss: 0.34977660745761957; val_accuracy: 0.8942078025477707 

The current subspace-distance is: 8.273943421954755e-06 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.5; acc: 0.89
Batch: 20; loss: 0.36; acc: 0.84
Batch: 40; loss: 0.38; acc: 0.88
Batch: 60; loss: 0.32; acc: 0.94
Batch: 80; loss: 0.33; acc: 0.89
Batch: 100; loss: 0.32; acc: 0.92
Batch: 120; loss: 0.36; acc: 0.84
Batch: 140; loss: 0.48; acc: 0.84
Batch: 160; loss: 0.27; acc: 0.92
Batch: 180; loss: 0.31; acc: 0.89
Batch: 200; loss: 0.46; acc: 0.91
Batch: 220; loss: 0.46; acc: 0.91
Batch: 240; loss: 0.43; acc: 0.83
Batch: 260; loss: 0.44; acc: 0.84
Batch: 280; loss: 0.31; acc: 0.91
Batch: 300; loss: 0.42; acc: 0.88
Batch: 320; loss: 0.41; acc: 0.86
Batch: 340; loss: 0.27; acc: 0.91
Batch: 360; loss: 0.24; acc: 0.94
Batch: 380; loss: 0.26; acc: 0.91
Batch: 400; loss: 0.4; acc: 0.89
Batch: 420; loss: 0.3; acc: 0.91
Batch: 440; loss: 0.16; acc: 0.95
Batch: 460; loss: 0.32; acc: 0.86
Batch: 480; loss: 0.34; acc: 0.88
Batch: 500; loss: 0.6; acc: 0.81
Batch: 520; loss: 0.26; acc: 0.91
Batch: 540; loss: 0.24; acc: 0.94
Batch: 560; loss: 0.41; acc: 0.88
Batch: 580; loss: 0.4; acc: 0.88
Batch: 600; loss: 0.27; acc: 0.89
Batch: 620; loss: 0.57; acc: 0.86
Batch: 640; loss: 0.6; acc: 0.8
Batch: 660; loss: 0.38; acc: 0.91
Batch: 680; loss: 0.63; acc: 0.8
Batch: 700; loss: 0.3; acc: 0.88
Batch: 720; loss: 0.51; acc: 0.88
Batch: 740; loss: 0.5; acc: 0.86
Batch: 760; loss: 0.52; acc: 0.84
Batch: 780; loss: 0.5; acc: 0.83
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

2.5799072318477556e-05
1.1448417353676632e-05
Batch: 0; loss: 0.31; acc: 0.88
Batch: 20; loss: 0.43; acc: 0.84
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.61; acc: 0.89
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.3; acc: 0.94
Batch: 120; loss: 0.46; acc: 0.88
Batch: 140; loss: 0.18; acc: 0.94
Val Epoch over. val_loss: 0.3466695795772941; val_accuracy: 0.8951035031847133 

The current subspace-distance is: 1.1448417353676632e-05 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.3; acc: 0.92
Batch: 20; loss: 0.33; acc: 0.92
Batch: 40; loss: 0.47; acc: 0.88
Batch: 60; loss: 0.34; acc: 0.84
Batch: 80; loss: 0.43; acc: 0.86
Batch: 100; loss: 0.21; acc: 0.94
Batch: 120; loss: 0.34; acc: 0.89
Batch: 140; loss: 0.28; acc: 0.92
Batch: 160; loss: 0.49; acc: 0.89
Batch: 180; loss: 0.32; acc: 0.89
Batch: 200; loss: 0.52; acc: 0.92
Batch: 220; loss: 0.57; acc: 0.83
Batch: 240; loss: 0.29; acc: 0.89
Batch: 260; loss: 0.21; acc: 0.92
Batch: 280; loss: 0.23; acc: 0.94
Batch: 300; loss: 0.42; acc: 0.88
Batch: 320; loss: 0.47; acc: 0.83
Batch: 340; loss: 0.36; acc: 0.88
Batch: 360; loss: 0.32; acc: 0.89
Batch: 380; loss: 0.17; acc: 0.94
Batch: 400; loss: 0.39; acc: 0.91
Batch: 420; loss: 0.32; acc: 0.89
Batch: 440; loss: 0.48; acc: 0.81
Batch: 460; loss: 0.29; acc: 0.91
Batch: 480; loss: 0.22; acc: 0.94
Batch: 500; loss: 0.27; acc: 0.89
Batch: 520; loss: 0.23; acc: 0.92
Batch: 540; loss: 0.43; acc: 0.89
Batch: 560; loss: 0.42; acc: 0.88
Batch: 580; loss: 0.25; acc: 0.92
Batch: 600; loss: 0.24; acc: 0.94
Batch: 620; loss: 0.29; acc: 0.94
Batch: 640; loss: 0.3; acc: 0.91
Batch: 660; loss: 0.54; acc: 0.83
Batch: 680; loss: 0.53; acc: 0.84
Batch: 700; loss: 0.67; acc: 0.78
Batch: 720; loss: 0.21; acc: 0.94
Batch: 740; loss: 0.58; acc: 0.81
Batch: 760; loss: 0.42; acc: 0.88
Batch: 780; loss: 0.28; acc: 0.88
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

2.9160428312025033e-05
1.1217648534511682e-05
Batch: 0; loss: 0.33; acc: 0.88
Batch: 20; loss: 0.41; acc: 0.84
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.62; acc: 0.88
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.29; acc: 0.94
Batch: 120; loss: 0.49; acc: 0.86
Batch: 140; loss: 0.21; acc: 0.94
Val Epoch over. val_loss: 0.3490021967204513; val_accuracy: 0.8961982484076433 

The current subspace-distance is: 1.1217648534511682e-05 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.46; acc: 0.91
Batch: 20; loss: 0.43; acc: 0.86
Batch: 40; loss: 0.35; acc: 0.89
Batch: 60; loss: 0.36; acc: 0.81
Batch: 80; loss: 0.4; acc: 0.91
Batch: 100; loss: 0.33; acc: 0.92
Batch: 120; loss: 0.42; acc: 0.88
Batch: 140; loss: 0.25; acc: 0.94
Batch: 160; loss: 0.3; acc: 0.92
Batch: 180; loss: 0.32; acc: 0.91
Batch: 200; loss: 0.38; acc: 0.89
Batch: 220; loss: 0.46; acc: 0.88
Batch: 240; loss: 0.39; acc: 0.91
Batch: 260; loss: 0.7; acc: 0.8
Batch: 280; loss: 0.44; acc: 0.84
Batch: 300; loss: 0.23; acc: 0.92
Batch: 320; loss: 0.53; acc: 0.83
Batch: 340; loss: 0.36; acc: 0.91
Batch: 360; loss: 0.61; acc: 0.84
Batch: 380; loss: 0.2; acc: 0.91
Batch: 400; loss: 0.59; acc: 0.86
Batch: 420; loss: 0.59; acc: 0.8
Batch: 440; loss: 0.47; acc: 0.89
Batch: 460; loss: 0.2; acc: 0.95
Batch: 480; loss: 0.34; acc: 0.89
Batch: 500; loss: 0.26; acc: 0.94
Batch: 520; loss: 0.45; acc: 0.86
Batch: 540; loss: 0.37; acc: 0.86
Batch: 560; loss: 0.24; acc: 0.94
Batch: 580; loss: 0.46; acc: 0.88
Batch: 600; loss: 0.43; acc: 0.89
Batch: 620; loss: 0.45; acc: 0.8
Batch: 640; loss: 0.59; acc: 0.8
Batch: 660; loss: 0.23; acc: 0.95
Batch: 680; loss: 0.27; acc: 0.94
Batch: 700; loss: 0.23; acc: 0.94
Batch: 720; loss: 0.41; acc: 0.84
Batch: 740; loss: 0.44; acc: 0.88
Batch: 760; loss: 0.47; acc: 0.89
Batch: 780; loss: 0.39; acc: 0.88
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

2.5735886083566584e-05
9.458297427045181e-06
Batch: 0; loss: 0.33; acc: 0.89
Batch: 20; loss: 0.42; acc: 0.84
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.61; acc: 0.88
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.46; acc: 0.86
Batch: 140; loss: 0.19; acc: 0.94
Val Epoch over. val_loss: 0.34803032092038233; val_accuracy: 0.8949044585987261 

The current subspace-distance is: 9.458297427045181e-06 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.52; acc: 0.86
Batch: 40; loss: 0.46; acc: 0.88
Batch: 60; loss: 0.31; acc: 0.91
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.23; acc: 0.95
Batch: 120; loss: 0.31; acc: 0.92
Batch: 140; loss: 0.45; acc: 0.84
Batch: 160; loss: 0.25; acc: 0.91
Batch: 180; loss: 0.55; acc: 0.83
Batch: 200; loss: 0.39; acc: 0.86
Batch: 220; loss: 0.27; acc: 0.89
Batch: 240; loss: 0.33; acc: 0.88
Batch: 260; loss: 0.46; acc: 0.88
Batch: 280; loss: 0.58; acc: 0.89
Batch: 300; loss: 0.49; acc: 0.86
Batch: 320; loss: 0.52; acc: 0.89
Batch: 340; loss: 0.44; acc: 0.89
Batch: 360; loss: 0.55; acc: 0.84
Batch: 380; loss: 0.49; acc: 0.91
Batch: 400; loss: 0.19; acc: 0.94
Batch: 420; loss: 0.5; acc: 0.8
Batch: 440; loss: 0.41; acc: 0.94
Batch: 460; loss: 0.38; acc: 0.86
Batch: 480; loss: 0.41; acc: 0.91
Batch: 500; loss: 0.35; acc: 0.92
Batch: 520; loss: 0.42; acc: 0.86
Batch: 540; loss: 0.46; acc: 0.88
Batch: 560; loss: 0.33; acc: 0.91
Batch: 580; loss: 0.5; acc: 0.83
Batch: 600; loss: 0.41; acc: 0.84
Batch: 620; loss: 0.36; acc: 0.91
Batch: 640; loss: 0.56; acc: 0.86
Batch: 660; loss: 0.47; acc: 0.83
Batch: 680; loss: 0.44; acc: 0.91
Batch: 700; loss: 0.17; acc: 0.95
Batch: 720; loss: 0.54; acc: 0.89
Batch: 740; loss: 0.27; acc: 0.91
Batch: 760; loss: 0.39; acc: 0.88
Batch: 780; loss: 0.45; acc: 0.8
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

2.533779297664296e-05
7.993930921657011e-06
Batch: 0; loss: 0.32; acc: 0.88
Batch: 20; loss: 0.45; acc: 0.84
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.6; acc: 0.89
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.3; acc: 0.94
Batch: 120; loss: 0.49; acc: 0.88
Batch: 140; loss: 0.19; acc: 0.95
Val Epoch over. val_loss: 0.3488906902872073; val_accuracy: 0.8939092356687898 

The current subspace-distance is: 7.993930921657011e-06 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.37; acc: 0.91
Batch: 20; loss: 0.48; acc: 0.83
Batch: 40; loss: 0.42; acc: 0.91
Batch: 60; loss: 0.39; acc: 0.88
Batch: 80; loss: 0.37; acc: 0.91
Batch: 100; loss: 0.25; acc: 0.91
Batch: 120; loss: 0.48; acc: 0.84
Batch: 140; loss: 0.19; acc: 0.94
Batch: 160; loss: 0.43; acc: 0.83
Batch: 180; loss: 0.22; acc: 0.94
Batch: 200; loss: 0.26; acc: 0.92
Batch: 220; loss: 0.36; acc: 0.86
Batch: 240; loss: 0.31; acc: 0.89
Batch: 260; loss: 0.23; acc: 0.94
Batch: 280; loss: 0.21; acc: 0.95
Batch: 300; loss: 0.29; acc: 0.91
Batch: 320; loss: 0.38; acc: 0.86
Batch: 340; loss: 0.8; acc: 0.75
Batch: 360; loss: 0.21; acc: 0.95
Batch: 380; loss: 0.31; acc: 0.91
Batch: 400; loss: 0.27; acc: 0.92
Batch: 420; loss: 0.37; acc: 0.92
Batch: 440; loss: 0.16; acc: 0.97
Batch: 460; loss: 0.4; acc: 0.86
Batch: 480; loss: 0.6; acc: 0.83
Batch: 500; loss: 0.13; acc: 0.97
Batch: 520; loss: 0.41; acc: 0.89
Batch: 540; loss: 0.66; acc: 0.81
Batch: 560; loss: 0.2; acc: 0.94
Batch: 580; loss: 0.48; acc: 0.84
Batch: 600; loss: 0.27; acc: 0.94
Batch: 620; loss: 0.29; acc: 0.91
Batch: 640; loss: 0.49; acc: 0.94
Batch: 660; loss: 0.3; acc: 0.86
Batch: 680; loss: 0.3; acc: 0.91
Batch: 700; loss: 0.54; acc: 0.86
Batch: 720; loss: 0.39; acc: 0.91
Batch: 740; loss: 0.36; acc: 0.89
Batch: 760; loss: 0.26; acc: 0.94
Batch: 780; loss: 0.43; acc: 0.83
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

2.832378595485352e-05
9.341379154648166e-06
Batch: 0; loss: 0.32; acc: 0.88
Batch: 20; loss: 0.43; acc: 0.88
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.6; acc: 0.89
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.3; acc: 0.94
Batch: 120; loss: 0.47; acc: 0.88
Batch: 140; loss: 0.18; acc: 0.94
Val Epoch over. val_loss: 0.3458185660516381; val_accuracy: 0.8949044585987261 

The current subspace-distance is: 9.341379154648166e-06 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.22; acc: 0.92
Batch: 20; loss: 0.35; acc: 0.91
Batch: 40; loss: 0.36; acc: 0.91
Batch: 60; loss: 0.29; acc: 0.89
Batch: 80; loss: 0.36; acc: 0.91
Batch: 100; loss: 0.36; acc: 0.89
Batch: 120; loss: 0.55; acc: 0.86
Batch: 140; loss: 0.45; acc: 0.81
Batch: 160; loss: 0.44; acc: 0.83
Batch: 180; loss: 0.18; acc: 0.95
Batch: 200; loss: 0.28; acc: 0.88
Batch: 220; loss: 0.44; acc: 0.91
Batch: 240; loss: 0.54; acc: 0.83
Batch: 260; loss: 0.45; acc: 0.86
Batch: 280; loss: 0.28; acc: 0.94
Batch: 300; loss: 0.37; acc: 0.91
Batch: 320; loss: 0.33; acc: 0.89
Batch: 340; loss: 0.34; acc: 0.89
Batch: 360; loss: 0.34; acc: 0.86
Batch: 380; loss: 0.51; acc: 0.8
Batch: 400; loss: 0.17; acc: 0.97
Batch: 420; loss: 0.48; acc: 0.89
Batch: 440; loss: 0.29; acc: 0.84
Batch: 460; loss: 0.31; acc: 0.91
Batch: 480; loss: 0.31; acc: 0.88
Batch: 500; loss: 0.24; acc: 0.92
Batch: 520; loss: 0.49; acc: 0.86
Batch: 540; loss: 0.49; acc: 0.86
Batch: 560; loss: 0.31; acc: 0.89
Batch: 580; loss: 0.3; acc: 0.92
Batch: 600; loss: 0.5; acc: 0.8
Batch: 620; loss: 0.27; acc: 0.91
Batch: 640; loss: 0.23; acc: 0.92
Batch: 660; loss: 0.36; acc: 0.86
Batch: 680; loss: 0.47; acc: 0.86
Batch: 700; loss: 0.55; acc: 0.84
Batch: 720; loss: 0.27; acc: 0.89
Batch: 740; loss: 0.29; acc: 0.88
Batch: 760; loss: 0.37; acc: 0.83
Batch: 780; loss: 0.52; acc: 0.86
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

2.6869924113270827e-05
9.110764949582517e-06
Batch: 0; loss: 0.31; acc: 0.88
Batch: 20; loss: 0.43; acc: 0.86
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.6; acc: 0.89
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.28; acc: 0.94
Batch: 120; loss: 0.47; acc: 0.88
Batch: 140; loss: 0.2; acc: 0.94
Val Epoch over. val_loss: 0.3471834435584439; val_accuracy: 0.8947054140127388 

The current subspace-distance is: 9.110764949582517e-06 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.47; acc: 0.86
Batch: 20; loss: 0.31; acc: 0.94
Batch: 40; loss: 0.29; acc: 0.91
Batch: 60; loss: 0.25; acc: 0.92
Batch: 80; loss: 0.68; acc: 0.89
Batch: 100; loss: 0.36; acc: 0.89
Batch: 120; loss: 0.37; acc: 0.88
Batch: 140; loss: 0.33; acc: 0.89
Batch: 160; loss: 0.31; acc: 0.92
Batch: 180; loss: 0.35; acc: 0.91
Batch: 200; loss: 0.38; acc: 0.88
Batch: 220; loss: 0.35; acc: 0.91
Batch: 240; loss: 0.37; acc: 0.88
Batch: 260; loss: 0.52; acc: 0.88
Batch: 280; loss: 0.49; acc: 0.86
Batch: 300; loss: 0.55; acc: 0.91
Batch: 320; loss: 0.47; acc: 0.86
Batch: 340; loss: 0.28; acc: 0.89
Batch: 360; loss: 0.16; acc: 0.97
Batch: 380; loss: 0.46; acc: 0.92
Batch: 400; loss: 0.24; acc: 0.94
Batch: 420; loss: 0.45; acc: 0.83
Batch: 440; loss: 0.18; acc: 0.94
Batch: 460; loss: 0.21; acc: 0.89
Batch: 480; loss: 0.37; acc: 0.86
Batch: 500; loss: 0.32; acc: 0.92
Batch: 520; loss: 0.48; acc: 0.86
Batch: 540; loss: 0.31; acc: 0.91
Batch: 560; loss: 0.55; acc: 0.84
Batch: 580; loss: 0.73; acc: 0.77
Batch: 600; loss: 0.24; acc: 0.91
Batch: 620; loss: 0.34; acc: 0.88
Batch: 640; loss: 0.34; acc: 0.92
Batch: 660; loss: 0.38; acc: 0.92
Batch: 680; loss: 0.25; acc: 0.94
Batch: 700; loss: 0.49; acc: 0.8
Batch: 720; loss: 0.68; acc: 0.84
Batch: 740; loss: 0.53; acc: 0.88
Batch: 760; loss: 0.27; acc: 0.92
Batch: 780; loss: 0.35; acc: 0.89
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

2.6669709768611938e-05
1.3261110325402115e-05
Batch: 0; loss: 0.31; acc: 0.88
Batch: 20; loss: 0.45; acc: 0.84
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.61; acc: 0.89
Batch: 80; loss: 0.2; acc: 0.91
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.5; acc: 0.88
Batch: 140; loss: 0.2; acc: 0.94
Val Epoch over. val_loss: 0.3465656092402282; val_accuracy: 0.8958001592356688 

The current subspace-distance is: 1.3261110325402115e-05 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.34; acc: 0.88
Batch: 20; loss: 0.39; acc: 0.88
Batch: 40; loss: 0.4; acc: 0.83
Batch: 60; loss: 0.48; acc: 0.81
Batch: 80; loss: 0.22; acc: 0.92
Batch: 100; loss: 0.33; acc: 0.91
Batch: 120; loss: 0.28; acc: 0.92
Batch: 140; loss: 0.44; acc: 0.84
Batch: 160; loss: 0.61; acc: 0.83
Batch: 180; loss: 0.32; acc: 0.91
Batch: 200; loss: 0.37; acc: 0.84
Batch: 220; loss: 0.46; acc: 0.84
Batch: 240; loss: 0.25; acc: 0.91
Batch: 260; loss: 0.46; acc: 0.84
Batch: 280; loss: 0.54; acc: 0.89
Batch: 300; loss: 0.58; acc: 0.77
Batch: 320; loss: 0.26; acc: 0.92
Batch: 340; loss: 0.61; acc: 0.84
Batch: 360; loss: 0.36; acc: 0.89
Batch: 380; loss: 0.34; acc: 0.91
Batch: 400; loss: 0.26; acc: 0.94
Batch: 420; loss: 0.44; acc: 0.91
Batch: 440; loss: 0.44; acc: 0.84
Batch: 460; loss: 0.35; acc: 0.91
Batch: 480; loss: 0.26; acc: 0.92
Batch: 500; loss: 0.72; acc: 0.77
Batch: 520; loss: 0.38; acc: 0.91
Batch: 540; loss: 0.22; acc: 0.92
Batch: 560; loss: 0.22; acc: 0.92
Batch: 580; loss: 0.43; acc: 0.89
Batch: 600; loss: 0.28; acc: 0.91
Batch: 620; loss: 0.26; acc: 0.88
Batch: 640; loss: 0.38; acc: 0.89
Batch: 660; loss: 0.26; acc: 0.92
Batch: 680; loss: 0.49; acc: 0.83
Batch: 700; loss: 0.32; acc: 0.92
Batch: 720; loss: 0.42; acc: 0.91
Batch: 740; loss: 0.47; acc: 0.84
Batch: 760; loss: 0.35; acc: 0.91
Batch: 780; loss: 0.3; acc: 0.94
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

2.560659595474135e-05
9.190132914227434e-06
Batch: 0; loss: 0.3; acc: 0.88
Batch: 20; loss: 0.44; acc: 0.84
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.6; acc: 0.89
Batch: 80; loss: 0.19; acc: 0.92
Batch: 100; loss: 0.29; acc: 0.94
Batch: 120; loss: 0.48; acc: 0.88
Batch: 140; loss: 0.2; acc: 0.95
Val Epoch over. val_loss: 0.34667559010777504; val_accuracy: 0.8953025477707006 

The current subspace-distance is: 9.190132914227434e-06 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.43; acc: 0.86
Batch: 20; loss: 0.35; acc: 0.89
Batch: 40; loss: 0.21; acc: 0.92
Batch: 60; loss: 0.44; acc: 0.86
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.56; acc: 0.81
Batch: 120; loss: 0.43; acc: 0.89
Batch: 140; loss: 0.36; acc: 0.91
Batch: 160; loss: 0.36; acc: 0.81
Batch: 180; loss: 0.35; acc: 0.91
Batch: 200; loss: 0.44; acc: 0.84
Batch: 220; loss: 0.56; acc: 0.88
Batch: 240; loss: 0.43; acc: 0.88
Batch: 260; loss: 0.23; acc: 0.92
Batch: 280; loss: 0.42; acc: 0.88
Batch: 300; loss: 0.38; acc: 0.89
Batch: 320; loss: 0.37; acc: 0.91
Batch: 340; loss: 0.19; acc: 0.94
Batch: 360; loss: 0.57; acc: 0.83
Batch: 380; loss: 0.7; acc: 0.84
Batch: 400; loss: 0.38; acc: 0.88
Batch: 420; loss: 0.35; acc: 0.89
Batch: 440; loss: 0.32; acc: 0.92
Batch: 460; loss: 0.34; acc: 0.84
Batch: 480; loss: 0.25; acc: 0.94
Batch: 500; loss: 0.23; acc: 0.91
Batch: 520; loss: 0.45; acc: 0.92
Batch: 540; loss: 0.42; acc: 0.89
Batch: 560; loss: 0.35; acc: 0.89
Batch: 580; loss: 0.29; acc: 0.88
Batch: 600; loss: 0.58; acc: 0.84
Batch: 620; loss: 0.21; acc: 0.92
Batch: 640; loss: 0.25; acc: 0.89
Batch: 660; loss: 0.47; acc: 0.83
Batch: 680; loss: 0.24; acc: 0.92
Batch: 700; loss: 0.33; acc: 0.91
Batch: 720; loss: 0.41; acc: 0.89
Batch: 740; loss: 0.29; acc: 0.91
Batch: 760; loss: 0.12; acc: 0.98
Batch: 780; loss: 0.42; acc: 0.91
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

2.7874870283994824e-05
1.3135222616256215e-05
Batch: 0; loss: 0.31; acc: 0.86
Batch: 20; loss: 0.42; acc: 0.86
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.59; acc: 0.91
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.47; acc: 0.88
Batch: 140; loss: 0.18; acc: 0.95
Val Epoch over. val_loss: 0.3437094677975223; val_accuracy: 0.8968949044585988 

The current subspace-distance is: 1.3135222616256215e-05 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.39; acc: 0.88
Batch: 20; loss: 0.35; acc: 0.92
Batch: 40; loss: 0.42; acc: 0.86
Batch: 60; loss: 0.4; acc: 0.88
Batch: 80; loss: 0.45; acc: 0.86
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.68; acc: 0.81
Batch: 140; loss: 0.35; acc: 0.88
Batch: 160; loss: 0.62; acc: 0.84
Batch: 180; loss: 0.39; acc: 0.89
Batch: 200; loss: 0.36; acc: 0.92
Batch: 220; loss: 0.29; acc: 0.92
Batch: 240; loss: 0.27; acc: 0.91
Batch: 260; loss: 0.3; acc: 0.92
Batch: 280; loss: 0.51; acc: 0.81
Batch: 300; loss: 0.41; acc: 0.89
Batch: 320; loss: 0.54; acc: 0.89
Batch: 340; loss: 0.21; acc: 0.91
Batch: 360; loss: 0.26; acc: 0.91
Batch: 380; loss: 0.23; acc: 0.92
Batch: 400; loss: 0.38; acc: 0.91
Batch: 420; loss: 0.39; acc: 0.88
Batch: 440; loss: 0.39; acc: 0.86
Batch: 460; loss: 0.32; acc: 0.91
Batch: 480; loss: 0.23; acc: 0.94
Batch: 500; loss: 0.35; acc: 0.88
Batch: 520; loss: 0.64; acc: 0.86
Batch: 540; loss: 0.42; acc: 0.86
Batch: 560; loss: 0.35; acc: 0.86
Batch: 580; loss: 0.31; acc: 0.89
Batch: 600; loss: 0.56; acc: 0.83
Batch: 620; loss: 0.37; acc: 0.86
Batch: 640; loss: 0.42; acc: 0.88
Batch: 660; loss: 0.39; acc: 0.86
Batch: 680; loss: 0.19; acc: 0.89
Batch: 700; loss: 0.5; acc: 0.88
Batch: 720; loss: 0.47; acc: 0.84
Batch: 740; loss: 0.42; acc: 0.89
Batch: 760; loss: 0.37; acc: 0.92
Batch: 780; loss: 0.49; acc: 0.84
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

2.518067958590109e-05
9.310101631854195e-06
Batch: 0; loss: 0.32; acc: 0.88
Batch: 20; loss: 0.41; acc: 0.86
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.59; acc: 0.89
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.47; acc: 0.88
Batch: 140; loss: 0.19; acc: 0.94
Val Epoch over. val_loss: 0.34419021271406464; val_accuracy: 0.8971934713375797 

The current subspace-distance is: 9.310101631854195e-06 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.36; acc: 0.91
Batch: 20; loss: 0.66; acc: 0.86
Batch: 40; loss: 0.3; acc: 0.88
Batch: 60; loss: 0.44; acc: 0.89
Batch: 80; loss: 0.23; acc: 0.95
Batch: 100; loss: 0.47; acc: 0.88
Batch: 120; loss: 0.31; acc: 0.91
Batch: 140; loss: 0.26; acc: 0.91
Batch: 160; loss: 0.31; acc: 0.89
Batch: 180; loss: 0.34; acc: 0.91
Batch: 200; loss: 0.28; acc: 0.91
Batch: 220; loss: 0.26; acc: 0.91
Batch: 240; loss: 0.51; acc: 0.89
Batch: 260; loss: 0.35; acc: 0.94
Batch: 280; loss: 0.43; acc: 0.83
Batch: 300; loss: 0.31; acc: 0.89
Batch: 320; loss: 0.34; acc: 0.84
Batch: 340; loss: 0.41; acc: 0.91
Batch: 360; loss: 0.23; acc: 0.94
Batch: 380; loss: 0.29; acc: 0.88
Batch: 400; loss: 0.49; acc: 0.8
Batch: 420; loss: 0.33; acc: 0.91
Batch: 440; loss: 0.2; acc: 0.95
Batch: 460; loss: 0.43; acc: 0.83
Batch: 480; loss: 0.3; acc: 0.94
Batch: 500; loss: 0.28; acc: 0.92
Batch: 520; loss: 0.66; acc: 0.81
Batch: 540; loss: 0.42; acc: 0.86
Batch: 560; loss: 0.3; acc: 0.92
Batch: 580; loss: 0.56; acc: 0.86
Batch: 600; loss: 0.57; acc: 0.88
Batch: 620; loss: 0.43; acc: 0.88
Batch: 640; loss: 0.26; acc: 0.92
Batch: 660; loss: 0.14; acc: 0.97
Batch: 680; loss: 0.27; acc: 0.92
Batch: 700; loss: 0.2; acc: 0.94
Batch: 720; loss: 0.41; acc: 0.88
Batch: 740; loss: 0.41; acc: 0.88
Batch: 760; loss: 0.36; acc: 0.92
Batch: 780; loss: 0.35; acc: 0.88
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

2.8266214940231293e-05
7.727434422122315e-06
Batch: 0; loss: 0.32; acc: 0.86
Batch: 20; loss: 0.42; acc: 0.86
Batch: 40; loss: 0.16; acc: 0.97
Batch: 60; loss: 0.58; acc: 0.89
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.49; acc: 0.88
Batch: 140; loss: 0.19; acc: 0.95
Val Epoch over. val_loss: 0.34516030474073567; val_accuracy: 0.8960987261146497 

The current subspace-distance is: 7.727434422122315e-06 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.29; acc: 0.88
Batch: 20; loss: 0.74; acc: 0.8
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.51; acc: 0.89
Batch: 80; loss: 0.35; acc: 0.91
Batch: 100; loss: 0.8; acc: 0.77
Batch: 120; loss: 0.44; acc: 0.86
Batch: 140; loss: 0.38; acc: 0.89
Batch: 160; loss: 0.4; acc: 0.88
Batch: 180; loss: 0.4; acc: 0.89
Batch: 200; loss: 0.42; acc: 0.88
Batch: 220; loss: 0.4; acc: 0.86
Batch: 240; loss: 0.63; acc: 0.84
Batch: 260; loss: 0.5; acc: 0.88
Batch: 280; loss: 0.35; acc: 0.92
Batch: 300; loss: 0.31; acc: 0.91
Batch: 320; loss: 0.39; acc: 0.88
Batch: 340; loss: 0.45; acc: 0.84
Batch: 360; loss: 0.27; acc: 0.91
Batch: 380; loss: 0.29; acc: 0.91
Batch: 400; loss: 0.56; acc: 0.8
Batch: 420; loss: 0.36; acc: 0.89
Batch: 440; loss: 0.51; acc: 0.89
Batch: 460; loss: 0.26; acc: 0.91
Batch: 480; loss: 0.5; acc: 0.81
Batch: 500; loss: 0.64; acc: 0.86
Batch: 520; loss: 0.28; acc: 0.91
Batch: 540; loss: 0.28; acc: 0.86
Batch: 560; loss: 0.31; acc: 0.92
Batch: 580; loss: 0.36; acc: 0.88
Batch: 600; loss: 0.24; acc: 0.92
Batch: 620; loss: 0.36; acc: 0.88
Batch: 640; loss: 0.56; acc: 0.81
Batch: 660; loss: 0.52; acc: 0.78
Batch: 680; loss: 0.37; acc: 0.89
Batch: 700; loss: 0.33; acc: 0.91
Batch: 720; loss: 0.33; acc: 0.86
Batch: 740; loss: 0.72; acc: 0.83
Batch: 760; loss: 0.37; acc: 0.91
Batch: 780; loss: 0.44; acc: 0.86
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

2.4933928216341883e-05
8.241994692070875e-06
Batch: 0; loss: 0.32; acc: 0.86
Batch: 20; loss: 0.41; acc: 0.86
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.59; acc: 0.91
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.48; acc: 0.88
Batch: 140; loss: 0.18; acc: 0.95
Val Epoch over. val_loss: 0.3437583969467005; val_accuracy: 0.897093949044586 

The current subspace-distance is: 8.241994692070875e-06 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.36; acc: 0.89
Batch: 20; loss: 0.25; acc: 0.86
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.52; acc: 0.88
Batch: 80; loss: 0.31; acc: 0.91
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.41; acc: 0.88
Batch: 140; loss: 0.23; acc: 0.91
Batch: 160; loss: 0.29; acc: 0.89
Batch: 180; loss: 0.29; acc: 0.94
Batch: 200; loss: 0.19; acc: 0.94
Batch: 220; loss: 0.31; acc: 0.89
Batch: 240; loss: 0.5; acc: 0.83
Batch: 260; loss: 0.37; acc: 0.91
Batch: 280; loss: 0.57; acc: 0.8
Batch: 300; loss: 0.24; acc: 0.92
Batch: 320; loss: 0.35; acc: 0.91
Batch: 340; loss: 0.23; acc: 0.94
Batch: 360; loss: 0.42; acc: 0.84
Batch: 380; loss: 0.34; acc: 0.94
Batch: 400; loss: 0.29; acc: 0.92
Batch: 420; loss: 0.37; acc: 0.88
Batch: 440; loss: 0.38; acc: 0.91
Batch: 460; loss: 0.27; acc: 0.91
Batch: 480; loss: 0.28; acc: 0.89
Batch: 500; loss: 0.34; acc: 0.89
Batch: 520; loss: 0.3; acc: 0.91
Batch: 540; loss: 0.36; acc: 0.86
Batch: 560; loss: 0.14; acc: 0.97
Batch: 580; loss: 0.26; acc: 0.94
Batch: 600; loss: 0.44; acc: 0.88
Batch: 620; loss: 0.34; acc: 0.88
Batch: 640; loss: 0.27; acc: 0.86
Batch: 660; loss: 0.49; acc: 0.86
Batch: 680; loss: 0.33; acc: 0.92
Batch: 700; loss: 0.34; acc: 0.89
Batch: 720; loss: 0.41; acc: 0.84
Batch: 740; loss: 0.43; acc: 0.91
Batch: 760; loss: 0.47; acc: 0.83
Batch: 780; loss: 0.43; acc: 0.86
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

2.5122903025476262e-05
9.066186066775117e-06
Batch: 0; loss: 0.31; acc: 0.86
Batch: 20; loss: 0.42; acc: 0.86
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.59; acc: 0.91
Batch: 80; loss: 0.21; acc: 0.91
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.48; acc: 0.88
Batch: 140; loss: 0.18; acc: 0.95
Val Epoch over. val_loss: 0.3437342607671288; val_accuracy: 0.8958001592356688 

The current subspace-distance is: 9.066186066775117e-06 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.39; acc: 0.91
Batch: 40; loss: 0.35; acc: 0.88
Batch: 60; loss: 0.42; acc: 0.83
Batch: 80; loss: 0.38; acc: 0.91
Batch: 100; loss: 0.4; acc: 0.92
Batch: 120; loss: 0.81; acc: 0.86
Batch: 140; loss: 0.48; acc: 0.83
Batch: 160; loss: 0.42; acc: 0.89
Batch: 180; loss: 0.22; acc: 0.92
Batch: 200; loss: 0.34; acc: 0.91
Batch: 220; loss: 0.5; acc: 0.88
Batch: 240; loss: 0.25; acc: 0.91
Batch: 260; loss: 0.4; acc: 0.86
Batch: 280; loss: 0.41; acc: 0.86
Batch: 300; loss: 0.51; acc: 0.89
Batch: 320; loss: 0.74; acc: 0.8
Batch: 340; loss: 0.26; acc: 0.88
Batch: 360; loss: 0.52; acc: 0.86
Batch: 380; loss: 0.44; acc: 0.84
Batch: 400; loss: 0.36; acc: 0.89
Batch: 420; loss: 0.55; acc: 0.84
Batch: 440; loss: 0.32; acc: 0.91
Batch: 460; loss: 0.54; acc: 0.89
Batch: 480; loss: 0.44; acc: 0.89
Batch: 500; loss: 0.36; acc: 0.89
Batch: 520; loss: 0.57; acc: 0.84
Batch: 540; loss: 0.62; acc: 0.84
Batch: 560; loss: 0.68; acc: 0.83
Batch: 580; loss: 0.29; acc: 0.86
Batch: 600; loss: 0.29; acc: 0.91
Batch: 620; loss: 0.35; acc: 0.89
Batch: 640; loss: 0.38; acc: 0.89
Batch: 660; loss: 0.2; acc: 0.95
Batch: 680; loss: 0.27; acc: 0.94
Batch: 700; loss: 0.46; acc: 0.88
Batch: 720; loss: 0.65; acc: 0.83
Batch: 740; loss: 0.38; acc: 0.92
Batch: 760; loss: 0.31; acc: 0.89
Batch: 780; loss: 0.33; acc: 0.88
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

2.5054683646885678e-05
8.177748895832337e-06
Batch: 0; loss: 0.32; acc: 0.86
Batch: 20; loss: 0.41; acc: 0.86
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.59; acc: 0.88
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.46; acc: 0.88
Batch: 140; loss: 0.19; acc: 0.95
Val Epoch over. val_loss: 0.34392943010208715; val_accuracy: 0.8951035031847133 

The current subspace-distance is: 8.177748895832337e-06 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.42; acc: 0.88
Batch: 40; loss: 0.39; acc: 0.89
Batch: 60; loss: 0.55; acc: 0.84
Batch: 80; loss: 0.5; acc: 0.84
Batch: 100; loss: 0.32; acc: 0.88
Batch: 120; loss: 0.37; acc: 0.88
Batch: 140; loss: 0.46; acc: 0.88
Batch: 160; loss: 0.44; acc: 0.83
Batch: 180; loss: 0.37; acc: 0.89
Batch: 200; loss: 0.47; acc: 0.84
Batch: 220; loss: 0.2; acc: 0.92
Batch: 240; loss: 0.18; acc: 0.95
Batch: 260; loss: 0.51; acc: 0.88
Batch: 280; loss: 0.13; acc: 0.95
Batch: 300; loss: 0.23; acc: 0.94
Batch: 320; loss: 0.55; acc: 0.81
Batch: 340; loss: 0.45; acc: 0.88
Batch: 360; loss: 0.47; acc: 0.81
Batch: 380; loss: 0.35; acc: 0.91
Batch: 400; loss: 0.33; acc: 0.92
Batch: 420; loss: 0.42; acc: 0.86
Batch: 440; loss: 0.38; acc: 0.91
Batch: 460; loss: 0.36; acc: 0.88
Batch: 480; loss: 0.22; acc: 0.91
Batch: 500; loss: 0.21; acc: 0.94
Batch: 520; loss: 0.24; acc: 0.95
Batch: 540; loss: 0.45; acc: 0.88
Batch: 560; loss: 0.3; acc: 0.92
Batch: 580; loss: 0.24; acc: 0.94
Batch: 600; loss: 0.35; acc: 0.86
Batch: 620; loss: 0.44; acc: 0.92
Batch: 640; loss: 0.31; acc: 0.89
Batch: 660; loss: 0.37; acc: 0.92
Batch: 680; loss: 0.59; acc: 0.83
Batch: 700; loss: 0.46; acc: 0.86
Batch: 720; loss: 0.43; acc: 0.88
Batch: 740; loss: 0.6; acc: 0.86
Batch: 760; loss: 0.42; acc: 0.86
Batch: 780; loss: 0.3; acc: 0.92
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

2.7071468139183708e-05
9.05527667782735e-06
Batch: 0; loss: 0.32; acc: 0.88
Batch: 20; loss: 0.42; acc: 0.86
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.6; acc: 0.88
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.29; acc: 0.94
Batch: 120; loss: 0.47; acc: 0.88
Batch: 140; loss: 0.19; acc: 0.95
Val Epoch over. val_loss: 0.3443863297913485; val_accuracy: 0.8950039808917197 

The current subspace-distance is: 9.05527667782735e-06 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.32; acc: 0.92
Batch: 20; loss: 0.36; acc: 0.86
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.47; acc: 0.88
Batch: 80; loss: 0.3; acc: 0.91
Batch: 100; loss: 0.47; acc: 0.92
Batch: 120; loss: 0.43; acc: 0.86
Batch: 140; loss: 0.44; acc: 0.84
Batch: 160; loss: 0.44; acc: 0.86
Batch: 180; loss: 0.35; acc: 0.91
Batch: 200; loss: 0.4; acc: 0.86
Batch: 220; loss: 0.2; acc: 0.92
Batch: 240; loss: 0.39; acc: 0.91
Batch: 260; loss: 0.63; acc: 0.81
Batch: 280; loss: 0.59; acc: 0.86
Batch: 300; loss: 0.37; acc: 0.91
Batch: 320; loss: 0.45; acc: 0.83
Batch: 340; loss: 0.35; acc: 0.89
Batch: 360; loss: 0.29; acc: 0.91
Batch: 380; loss: 0.43; acc: 0.86
Batch: 400; loss: 0.42; acc: 0.86
Batch: 420; loss: 0.55; acc: 0.8
Batch: 440; loss: 0.4; acc: 0.92
Batch: 460; loss: 0.36; acc: 0.88
Batch: 480; loss: 0.49; acc: 0.86
Batch: 500; loss: 0.57; acc: 0.78
Batch: 520; loss: 0.43; acc: 0.81
Batch: 540; loss: 0.58; acc: 0.88
Batch: 560; loss: 0.53; acc: 0.84
Batch: 580; loss: 0.21; acc: 0.95
Batch: 600; loss: 0.32; acc: 0.92
Batch: 620; loss: 0.32; acc: 0.94
Batch: 640; loss: 0.26; acc: 0.94
Batch: 660; loss: 0.31; acc: 0.88
Batch: 680; loss: 0.32; acc: 0.84
Batch: 700; loss: 0.42; acc: 0.84
Batch: 720; loss: 0.52; acc: 0.88
Batch: 740; loss: 0.41; acc: 0.88
Batch: 760; loss: 0.48; acc: 0.81
Batch: 780; loss: 0.37; acc: 0.88
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

2.7083726308774203e-05
1.3401454452832695e-05
Batch: 0; loss: 0.31; acc: 0.88
Batch: 20; loss: 0.42; acc: 0.84
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.6; acc: 0.89
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.48; acc: 0.88
Batch: 140; loss: 0.2; acc: 0.95
Val Epoch over. val_loss: 0.3450385624910616; val_accuracy: 0.8965963375796179 

The current subspace-distance is: 1.3401454452832695e-05 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.37; acc: 0.86
Batch: 20; loss: 0.38; acc: 0.84
Batch: 40; loss: 0.34; acc: 0.89
Batch: 60; loss: 0.41; acc: 0.89
Batch: 80; loss: 0.49; acc: 0.84
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.2; acc: 0.95
Batch: 140; loss: 0.28; acc: 0.92
Batch: 160; loss: 0.44; acc: 0.81
Batch: 180; loss: 0.36; acc: 0.92
Batch: 200; loss: 0.45; acc: 0.84
Batch: 220; loss: 0.4; acc: 0.89
Batch: 240; loss: 0.31; acc: 0.89
Batch: 260; loss: 0.31; acc: 0.89
Batch: 280; loss: 0.53; acc: 0.88
Batch: 300; loss: 0.45; acc: 0.84
Batch: 320; loss: 0.25; acc: 0.94
Batch: 340; loss: 0.33; acc: 0.89
Batch: 360; loss: 0.26; acc: 0.89
Batch: 380; loss: 0.4; acc: 0.86
Batch: 400; loss: 0.33; acc: 0.92
Batch: 420; loss: 0.35; acc: 0.88
Batch: 440; loss: 0.26; acc: 0.89
Batch: 460; loss: 0.19; acc: 0.94
Batch: 480; loss: 0.42; acc: 0.86
Batch: 500; loss: 0.37; acc: 0.88
Batch: 520; loss: 0.32; acc: 0.91
Batch: 540; loss: 0.56; acc: 0.88
Batch: 560; loss: 0.5; acc: 0.89
Batch: 580; loss: 0.23; acc: 0.92
Batch: 600; loss: 0.45; acc: 0.83
Batch: 620; loss: 0.15; acc: 0.97
Batch: 640; loss: 0.42; acc: 0.91
Batch: 660; loss: 0.22; acc: 0.94
Batch: 680; loss: 0.3; acc: 0.89
Batch: 700; loss: 0.13; acc: 0.97
Batch: 720; loss: 0.35; acc: 0.86
Batch: 740; loss: 0.44; acc: 0.88
Batch: 760; loss: 0.47; acc: 0.89
Batch: 780; loss: 0.37; acc: 0.84
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

2.686600601009559e-05
1.0836653018486686e-05
Batch: 0; loss: 0.32; acc: 0.86
Batch: 20; loss: 0.42; acc: 0.86
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.59; acc: 0.91
Batch: 80; loss: 0.21; acc: 0.91
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.49; acc: 0.88
Batch: 140; loss: 0.19; acc: 0.95
Val Epoch over. val_loss: 0.3445359275789018; val_accuracy: 0.8967953821656051 

The current subspace-distance is: 1.0836653018486686e-05 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.35; acc: 0.83
Batch: 20; loss: 0.39; acc: 0.88
Batch: 40; loss: 0.35; acc: 0.88
Batch: 60; loss: 0.35; acc: 0.92
Batch: 80; loss: 0.52; acc: 0.81
Batch: 100; loss: 0.44; acc: 0.86
Batch: 120; loss: 0.34; acc: 0.91
Batch: 140; loss: 0.53; acc: 0.84
Batch: 160; loss: 0.39; acc: 0.81
Batch: 180; loss: 0.37; acc: 0.88
Batch: 200; loss: 0.47; acc: 0.84
Batch: 220; loss: 0.45; acc: 0.88
Batch: 240; loss: 0.35; acc: 0.91
Batch: 260; loss: 0.35; acc: 0.89
Batch: 280; loss: 0.27; acc: 0.89
Batch: 300; loss: 0.35; acc: 0.84
Batch: 320; loss: 0.18; acc: 0.95
Batch: 340; loss: 0.4; acc: 0.86
Batch: 360; loss: 0.37; acc: 0.86
Batch: 380; loss: 0.4; acc: 0.88
Batch: 400; loss: 0.57; acc: 0.86
Batch: 420; loss: 0.43; acc: 0.89
Batch: 440; loss: 0.27; acc: 0.91
Batch: 460; loss: 0.35; acc: 0.92
Batch: 480; loss: 0.54; acc: 0.84
Batch: 500; loss: 0.6; acc: 0.83
Batch: 520; loss: 0.31; acc: 0.95
Batch: 540; loss: 0.35; acc: 0.88
Batch: 560; loss: 0.58; acc: 0.84
Batch: 580; loss: 0.4; acc: 0.88
Batch: 600; loss: 0.48; acc: 0.88
Batch: 620; loss: 0.31; acc: 0.91
Batch: 640; loss: 0.33; acc: 0.89
Batch: 660; loss: 0.33; acc: 0.86
Batch: 680; loss: 0.43; acc: 0.88
Batch: 700; loss: 0.27; acc: 0.95
Batch: 720; loss: 0.17; acc: 0.95
Batch: 740; loss: 0.58; acc: 0.84
Batch: 760; loss: 0.22; acc: 0.92
Batch: 780; loss: 0.4; acc: 0.86
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

2.5832945539150387e-05
7.126414402591763e-06
Batch: 0; loss: 0.32; acc: 0.88
Batch: 20; loss: 0.41; acc: 0.86
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.6; acc: 0.89
Batch: 80; loss: 0.22; acc: 0.92
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.47; acc: 0.88
Batch: 140; loss: 0.19; acc: 0.95
Val Epoch over. val_loss: 0.3435347867049989; val_accuracy: 0.8951035031847133 

The current subspace-distance is: 7.126414402591763e-06 

plots/subspace_training/reg_lenet_3/2020-01-22 20:51:04/d_dim_110_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
nonzero elements in E: 25398
elements in E: 5398800
fraction nonzero: 0.004704378750833518
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.31; acc: 0.08
Batch: 20; loss: 2.29; acc: 0.05
Batch: 40; loss: 2.3; acc: 0.06
Batch: 60; loss: 2.3; acc: 0.02
Batch: 80; loss: 2.3; acc: 0.05
Batch: 100; loss: 2.3; acc: 0.11
Batch: 120; loss: 2.31; acc: 0.11
Batch: 140; loss: 2.32; acc: 0.06
Batch: 160; loss: 2.3; acc: 0.09
Batch: 180; loss: 2.3; acc: 0.14
Batch: 200; loss: 2.3; acc: 0.12
Batch: 220; loss: 2.31; acc: 0.08
Batch: 240; loss: 2.31; acc: 0.05
Batch: 260; loss: 2.3; acc: 0.08
Batch: 280; loss: 2.29; acc: 0.14
Batch: 300; loss: 2.3; acc: 0.08
Batch: 320; loss: 2.3; acc: 0.11
Batch: 340; loss: 2.3; acc: 0.09
Batch: 360; loss: 2.29; acc: 0.19
Batch: 380; loss: 2.3; acc: 0.16
Batch: 400; loss: 2.3; acc: 0.17
Batch: 420; loss: 2.31; acc: 0.06
Batch: 440; loss: 2.29; acc: 0.16
Batch: 460; loss: 2.3; acc: 0.12
Batch: 480; loss: 2.3; acc: 0.06
Batch: 500; loss: 2.29; acc: 0.09
Batch: 520; loss: 2.27; acc: 0.2
Batch: 540; loss: 2.29; acc: 0.12
Batch: 560; loss: 2.29; acc: 0.2
Batch: 580; loss: 2.28; acc: 0.12
Batch: 600; loss: 2.29; acc: 0.14
Batch: 620; loss: 2.28; acc: 0.16
Batch: 640; loss: 2.28; acc: 0.14
Batch: 660; loss: 2.28; acc: 0.11
Batch: 680; loss: 2.29; acc: 0.05
Batch: 700; loss: 2.29; acc: 0.09
Batch: 720; loss: 2.29; acc: 0.08
Batch: 740; loss: 2.28; acc: 0.12
Batch: 760; loss: 2.28; acc: 0.06
Batch: 780; loss: 2.28; acc: 0.12
Train Epoch over. train_loss: 2.29; train_accuracy: 0.11 

5.637454705720302e-06
1.0620406101224944e-06
Batch: 0; loss: 2.28; acc: 0.19
Batch: 20; loss: 2.28; acc: 0.14
Batch: 40; loss: 2.27; acc: 0.14
Batch: 60; loss: 2.27; acc: 0.17
Batch: 80; loss: 2.27; acc: 0.16
Batch: 100; loss: 2.27; acc: 0.19
Batch: 120; loss: 2.28; acc: 0.19
Batch: 140; loss: 2.28; acc: 0.12
Val Epoch over. val_loss: 2.277378229578589; val_accuracy: 0.12519904458598727 

The current subspace-distance is: 1.0620406101224944e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 2.28; acc: 0.06
Batch: 20; loss: 2.28; acc: 0.14
Batch: 40; loss: 2.28; acc: 0.12
Batch: 60; loss: 2.26; acc: 0.17
Batch: 80; loss: 2.27; acc: 0.09
Batch: 100; loss: 2.27; acc: 0.11
Batch: 120; loss: 2.26; acc: 0.19
Batch: 140; loss: 2.27; acc: 0.14
Batch: 160; loss: 2.26; acc: 0.27
Batch: 180; loss: 2.26; acc: 0.22
Batch: 200; loss: 2.26; acc: 0.16
Batch: 220; loss: 2.25; acc: 0.23
Batch: 240; loss: 2.24; acc: 0.25
Batch: 260; loss: 2.25; acc: 0.33
Batch: 280; loss: 2.24; acc: 0.31
Batch: 300; loss: 2.24; acc: 0.36
Batch: 320; loss: 2.23; acc: 0.39
Batch: 340; loss: 2.23; acc: 0.34
Batch: 360; loss: 2.2; acc: 0.42
Batch: 380; loss: 2.2; acc: 0.38
Batch: 400; loss: 2.17; acc: 0.39
Batch: 420; loss: 2.14; acc: 0.44
Batch: 440; loss: 2.16; acc: 0.34
Batch: 460; loss: 2.13; acc: 0.38
Batch: 480; loss: 2.05; acc: 0.52
Batch: 500; loss: 2.02; acc: 0.55
Batch: 520; loss: 1.97; acc: 0.56
Batch: 540; loss: 1.98; acc: 0.47
Batch: 560; loss: 1.7; acc: 0.58
Batch: 580; loss: 1.74; acc: 0.41
Batch: 600; loss: 1.48; acc: 0.55
Batch: 620; loss: 1.31; acc: 0.69
Batch: 640; loss: 1.42; acc: 0.52
Batch: 660; loss: 1.34; acc: 0.53
Batch: 680; loss: 1.23; acc: 0.56
Batch: 700; loss: 1.18; acc: 0.62
Batch: 720; loss: 1.0; acc: 0.62
Batch: 740; loss: 0.88; acc: 0.78
Batch: 760; loss: 0.99; acc: 0.69
Batch: 780; loss: 1.01; acc: 0.69
Train Epoch over. train_loss: 1.92; train_accuracy: 0.39 

1.1605436156969517e-05
5.721068191633094e-06
Batch: 0; loss: 1.2; acc: 0.61
Batch: 20; loss: 1.33; acc: 0.5
Batch: 40; loss: 0.66; acc: 0.86
Batch: 60; loss: 0.95; acc: 0.72
Batch: 80; loss: 0.67; acc: 0.72
Batch: 100; loss: 0.98; acc: 0.75
Batch: 120; loss: 1.24; acc: 0.61
Batch: 140; loss: 0.97; acc: 0.69
Val Epoch over. val_loss: 1.053991834828808; val_accuracy: 0.6734673566878981 

The current subspace-distance is: 5.721068191633094e-06 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 1.13; acc: 0.59
Batch: 20; loss: 0.84; acc: 0.75
Batch: 40; loss: 0.79; acc: 0.77
Batch: 60; loss: 0.79; acc: 0.75
Batch: 80; loss: 1.09; acc: 0.69
Batch: 100; loss: 0.98; acc: 0.77
Batch: 120; loss: 1.39; acc: 0.59
Batch: 140; loss: 0.89; acc: 0.7
Batch: 160; loss: 0.65; acc: 0.84
Batch: 180; loss: 0.72; acc: 0.7
Batch: 200; loss: 0.86; acc: 0.73
Batch: 220; loss: 1.03; acc: 0.73
Batch: 240; loss: 1.09; acc: 0.67
Batch: 260; loss: 1.01; acc: 0.64
Batch: 280; loss: 1.1; acc: 0.66
Batch: 300; loss: 0.67; acc: 0.78
Batch: 320; loss: 1.08; acc: 0.64
Batch: 340; loss: 0.83; acc: 0.75
Batch: 360; loss: 0.99; acc: 0.73
Batch: 380; loss: 0.83; acc: 0.75
Batch: 400; loss: 0.95; acc: 0.67
Batch: 420; loss: 1.02; acc: 0.67
Batch: 440; loss: 0.75; acc: 0.75
Batch: 460; loss: 0.91; acc: 0.7
Batch: 480; loss: 0.79; acc: 0.72
Batch: 500; loss: 0.85; acc: 0.77
Batch: 520; loss: 0.73; acc: 0.73
Batch: 540; loss: 1.13; acc: 0.66
Batch: 560; loss: 0.91; acc: 0.7
Batch: 580; loss: 0.63; acc: 0.77
Batch: 600; loss: 0.64; acc: 0.81
Batch: 620; loss: 1.18; acc: 0.66
Batch: 640; loss: 0.6; acc: 0.83
Batch: 660; loss: 0.86; acc: 0.73
Batch: 680; loss: 0.76; acc: 0.73
Batch: 700; loss: 0.86; acc: 0.72
Batch: 720; loss: 0.33; acc: 0.84
Batch: 740; loss: 0.43; acc: 0.86
Batch: 760; loss: 0.76; acc: 0.72
Batch: 780; loss: 0.63; acc: 0.78
Train Epoch over. train_loss: 0.85; train_accuracy: 0.73 

1.949143006640952e-05
5.3220605877868365e-06
Batch: 0; loss: 0.52; acc: 0.81
Batch: 20; loss: 0.58; acc: 0.84
Batch: 40; loss: 0.27; acc: 0.92
Batch: 60; loss: 0.82; acc: 0.73
Batch: 80; loss: 0.49; acc: 0.86
Batch: 100; loss: 0.46; acc: 0.86
Batch: 120; loss: 0.9; acc: 0.7
Batch: 140; loss: 0.36; acc: 0.91
Val Epoch over. val_loss: 0.6210789823797858; val_accuracy: 0.8044386942675159 

The current subspace-distance is: 5.3220605877868365e-06 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.7; acc: 0.73
Batch: 20; loss: 0.82; acc: 0.77
Batch: 40; loss: 0.61; acc: 0.8
Batch: 60; loss: 0.72; acc: 0.77
Batch: 80; loss: 0.53; acc: 0.78
Batch: 100; loss: 0.46; acc: 0.81
Batch: 120; loss: 0.58; acc: 0.8
Batch: 140; loss: 0.57; acc: 0.77
Batch: 160; loss: 0.65; acc: 0.78
Batch: 180; loss: 1.09; acc: 0.62
Batch: 200; loss: 0.65; acc: 0.81
Batch: 220; loss: 0.97; acc: 0.73
Batch: 240; loss: 0.98; acc: 0.7
Batch: 260; loss: 0.67; acc: 0.8
Batch: 280; loss: 0.9; acc: 0.8
Batch: 300; loss: 0.72; acc: 0.72
Batch: 320; loss: 0.85; acc: 0.7
Batch: 340; loss: 0.7; acc: 0.77
Batch: 360; loss: 0.71; acc: 0.77
Batch: 380; loss: 0.6; acc: 0.81
Batch: 400; loss: 0.74; acc: 0.75
Batch: 420; loss: 1.02; acc: 0.7
Batch: 440; loss: 0.35; acc: 0.89
Batch: 460; loss: 0.48; acc: 0.86
Batch: 480; loss: 0.82; acc: 0.73
Batch: 500; loss: 0.46; acc: 0.88
Batch: 520; loss: 0.74; acc: 0.75
Batch: 540; loss: 0.82; acc: 0.67
Batch: 560; loss: 0.71; acc: 0.78
Batch: 580; loss: 0.97; acc: 0.7
Batch: 600; loss: 0.68; acc: 0.73
Batch: 620; loss: 0.69; acc: 0.86
Batch: 640; loss: 0.81; acc: 0.75
Batch: 660; loss: 0.74; acc: 0.83
Batch: 680; loss: 0.62; acc: 0.81
Batch: 700; loss: 0.58; acc: 0.81
Batch: 720; loss: 0.77; acc: 0.77
Batch: 740; loss: 0.74; acc: 0.8
Batch: 760; loss: 0.56; acc: 0.84
Batch: 780; loss: 0.69; acc: 0.72
Train Epoch over. train_loss: 0.68; train_accuracy: 0.78 

2.072143070108723e-05
7.110068509064149e-06
Batch: 0; loss: 0.82; acc: 0.69
Batch: 20; loss: 1.33; acc: 0.55
Batch: 40; loss: 0.46; acc: 0.81
Batch: 60; loss: 1.19; acc: 0.66
Batch: 80; loss: 0.68; acc: 0.73
Batch: 100; loss: 0.99; acc: 0.69
Batch: 120; loss: 1.14; acc: 0.69
Batch: 140; loss: 0.92; acc: 0.67
Val Epoch over. val_loss: 1.004714736133624; val_accuracy: 0.684812898089172 

The current subspace-distance is: 7.110068509064149e-06 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 1.1; acc: 0.69
Batch: 20; loss: 0.66; acc: 0.83
Batch: 40; loss: 0.97; acc: 0.73
Batch: 60; loss: 0.63; acc: 0.78
Batch: 80; loss: 0.93; acc: 0.72
Batch: 100; loss: 0.51; acc: 0.75
Batch: 120; loss: 0.58; acc: 0.83
Batch: 140; loss: 0.7; acc: 0.78
Batch: 160; loss: 0.47; acc: 0.81
Batch: 180; loss: 0.4; acc: 0.86
Batch: 200; loss: 0.4; acc: 0.91
Batch: 220; loss: 0.67; acc: 0.78
Batch: 240; loss: 0.6; acc: 0.83
Batch: 260; loss: 0.57; acc: 0.77
Batch: 280; loss: 0.55; acc: 0.86
Batch: 300; loss: 0.6; acc: 0.8
Batch: 320; loss: 0.73; acc: 0.72
Batch: 340; loss: 0.48; acc: 0.78
Batch: 360; loss: 0.59; acc: 0.78
Batch: 380; loss: 0.55; acc: 0.72
Batch: 400; loss: 0.87; acc: 0.75
Batch: 420; loss: 0.78; acc: 0.72
Batch: 440; loss: 0.78; acc: 0.77
Batch: 460; loss: 0.68; acc: 0.77
Batch: 480; loss: 0.67; acc: 0.77
Batch: 500; loss: 0.49; acc: 0.86
Batch: 520; loss: 0.58; acc: 0.8
Batch: 540; loss: 0.56; acc: 0.81
Batch: 560; loss: 0.48; acc: 0.83
Batch: 580; loss: 0.7; acc: 0.8
Batch: 600; loss: 0.51; acc: 0.84
Batch: 620; loss: 0.48; acc: 0.89
Batch: 640; loss: 0.47; acc: 0.86
Batch: 660; loss: 1.06; acc: 0.67
Batch: 680; loss: 0.64; acc: 0.77
Batch: 700; loss: 0.51; acc: 0.84
Batch: 720; loss: 0.49; acc: 0.86
Batch: 740; loss: 0.57; acc: 0.86
Batch: 760; loss: 0.48; acc: 0.83
Batch: 780; loss: 0.52; acc: 0.84
Train Epoch over. train_loss: 0.62; train_accuracy: 0.8 

2.07305984076811e-05
7.958143214636948e-06
Batch: 0; loss: 0.43; acc: 0.88
Batch: 20; loss: 0.7; acc: 0.73
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.68; acc: 0.78
Batch: 80; loss: 0.35; acc: 0.92
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.66; acc: 0.81
Batch: 140; loss: 0.4; acc: 0.91
Val Epoch over. val_loss: 0.5428398453695759; val_accuracy: 0.8276273885350318 

The current subspace-distance is: 7.958143214636948e-06 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.64; acc: 0.8
Batch: 20; loss: 0.35; acc: 0.91
Batch: 40; loss: 1.07; acc: 0.72
Batch: 60; loss: 0.82; acc: 0.73
Batch: 80; loss: 0.4; acc: 0.84
Batch: 100; loss: 0.7; acc: 0.78
Batch: 120; loss: 0.53; acc: 0.84
Batch: 140; loss: 0.91; acc: 0.73
Batch: 160; loss: 0.79; acc: 0.73
Batch: 180; loss: 0.47; acc: 0.83
Batch: 200; loss: 0.56; acc: 0.84
Batch: 220; loss: 0.49; acc: 0.84
Batch: 240; loss: 0.5; acc: 0.86
Batch: 260; loss: 0.48; acc: 0.88
Batch: 280; loss: 0.44; acc: 0.81
Batch: 300; loss: 0.73; acc: 0.81
Batch: 320; loss: 0.67; acc: 0.75
Batch: 340; loss: 0.48; acc: 0.83
Batch: 360; loss: 0.8; acc: 0.78
Batch: 380; loss: 0.67; acc: 0.78
Batch: 400; loss: 0.46; acc: 0.81
Batch: 420; loss: 0.46; acc: 0.83
Batch: 440; loss: 0.55; acc: 0.81
Batch: 460; loss: 0.82; acc: 0.77
Batch: 480; loss: 0.57; acc: 0.81
Batch: 500; loss: 0.64; acc: 0.75
Batch: 520; loss: 0.6; acc: 0.72
Batch: 540; loss: 0.41; acc: 0.91
Batch: 560; loss: 0.5; acc: 0.84
Batch: 580; loss: 0.74; acc: 0.78
Batch: 600; loss: 0.5; acc: 0.8
Batch: 620; loss: 0.57; acc: 0.78
Batch: 640; loss: 0.68; acc: 0.83
Batch: 660; loss: 0.67; acc: 0.84
Batch: 680; loss: 0.35; acc: 0.91
Batch: 700; loss: 0.37; acc: 0.84
Batch: 720; loss: 0.68; acc: 0.83
Batch: 740; loss: 0.48; acc: 0.84
Batch: 760; loss: 0.67; acc: 0.8
Batch: 780; loss: 0.46; acc: 0.83
Train Epoch over. train_loss: 0.58; train_accuracy: 0.81 

2.32089041674044e-05
7.936398105812259e-06
Batch: 0; loss: 0.5; acc: 0.78
Batch: 20; loss: 0.73; acc: 0.72
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.79; acc: 0.72
Batch: 80; loss: 0.37; acc: 0.86
Batch: 100; loss: 0.48; acc: 0.88
Batch: 120; loss: 0.63; acc: 0.81
Batch: 140; loss: 0.41; acc: 0.81
Val Epoch over. val_loss: 0.6067284029570355; val_accuracy: 0.799562101910828 

The current subspace-distance is: 7.936398105812259e-06 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.99; acc: 0.69
Batch: 20; loss: 0.52; acc: 0.78
Batch: 40; loss: 0.49; acc: 0.84
Batch: 60; loss: 0.41; acc: 0.88
Batch: 80; loss: 0.36; acc: 0.86
Batch: 100; loss: 0.57; acc: 0.81
Batch: 120; loss: 0.46; acc: 0.83
Batch: 140; loss: 0.52; acc: 0.78
Batch: 160; loss: 0.66; acc: 0.77
Batch: 180; loss: 0.63; acc: 0.78
Batch: 200; loss: 0.94; acc: 0.78
Batch: 220; loss: 0.47; acc: 0.81
Batch: 240; loss: 0.53; acc: 0.84
Batch: 260; loss: 0.61; acc: 0.8
Batch: 280; loss: 0.62; acc: 0.8
Batch: 300; loss: 0.44; acc: 0.88
Batch: 320; loss: 0.48; acc: 0.88
Batch: 340; loss: 0.56; acc: 0.8
Batch: 360; loss: 0.45; acc: 0.84
Batch: 380; loss: 0.77; acc: 0.75
Batch: 400; loss: 0.57; acc: 0.84
Batch: 420; loss: 0.44; acc: 0.88
Batch: 440; loss: 0.52; acc: 0.91
Batch: 460; loss: 0.3; acc: 0.91
Batch: 480; loss: 0.63; acc: 0.81
Batch: 500; loss: 0.3; acc: 0.86
Batch: 520; loss: 0.38; acc: 0.84
Batch: 540; loss: 0.51; acc: 0.91
Batch: 560; loss: 0.51; acc: 0.8
Batch: 580; loss: 0.5; acc: 0.92
Batch: 600; loss: 0.49; acc: 0.86
Batch: 620; loss: 0.54; acc: 0.83
Batch: 640; loss: 0.61; acc: 0.8
Batch: 660; loss: 0.7; acc: 0.8
Batch: 680; loss: 0.87; acc: 0.75
Batch: 700; loss: 0.5; acc: 0.84
Batch: 720; loss: 0.53; acc: 0.86
Batch: 740; loss: 0.44; acc: 0.86
Batch: 760; loss: 0.4; acc: 0.91
Batch: 780; loss: 0.43; acc: 0.84
Train Epoch over. train_loss: 0.54; train_accuracy: 0.83 

2.230832978966646e-05
8.261253242380917e-06
Batch: 0; loss: 0.41; acc: 0.83
Batch: 20; loss: 0.5; acc: 0.83
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.88; acc: 0.7
Batch: 80; loss: 0.37; acc: 0.89
Batch: 100; loss: 0.38; acc: 0.91
Batch: 120; loss: 0.69; acc: 0.78
Batch: 140; loss: 0.38; acc: 0.84
Val Epoch over. val_loss: 0.4931727344063437; val_accuracy: 0.84484474522293 

The current subspace-distance is: 8.261253242380917e-06 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.64; acc: 0.83
Batch: 20; loss: 0.53; acc: 0.84
Batch: 40; loss: 0.41; acc: 0.81
Batch: 60; loss: 0.43; acc: 0.84
Batch: 80; loss: 0.65; acc: 0.78
Batch: 100; loss: 0.47; acc: 0.83
Batch: 120; loss: 0.53; acc: 0.81
Batch: 140; loss: 0.52; acc: 0.89
Batch: 160; loss: 0.48; acc: 0.8
Batch: 180; loss: 0.33; acc: 0.89
Batch: 200; loss: 0.38; acc: 0.88
Batch: 220; loss: 0.88; acc: 0.72
Batch: 240; loss: 0.38; acc: 0.88
Batch: 260; loss: 0.32; acc: 0.91
Batch: 280; loss: 0.69; acc: 0.81
Batch: 300; loss: 0.92; acc: 0.73
Batch: 320; loss: 0.55; acc: 0.81
Batch: 340; loss: 0.59; acc: 0.8
Batch: 360; loss: 0.34; acc: 0.91
Batch: 380; loss: 0.25; acc: 0.91
Batch: 400; loss: 0.61; acc: 0.77
Batch: 420; loss: 0.36; acc: 0.89
Batch: 440; loss: 0.53; acc: 0.83
Batch: 460; loss: 0.47; acc: 0.84
Batch: 480; loss: 0.3; acc: 0.89
Batch: 500; loss: 0.5; acc: 0.78
Batch: 520; loss: 0.6; acc: 0.83
Batch: 540; loss: 0.67; acc: 0.78
Batch: 560; loss: 0.23; acc: 0.94
Batch: 580; loss: 0.53; acc: 0.81
Batch: 600; loss: 0.8; acc: 0.8
Batch: 620; loss: 0.46; acc: 0.89
Batch: 640; loss: 0.29; acc: 0.91
Batch: 660; loss: 0.54; acc: 0.78
Batch: 680; loss: 0.44; acc: 0.89
Batch: 700; loss: 0.76; acc: 0.75
Batch: 720; loss: 0.37; acc: 0.89
Batch: 740; loss: 0.43; acc: 0.84
Batch: 760; loss: 0.49; acc: 0.86
Batch: 780; loss: 0.55; acc: 0.81
Train Epoch over. train_loss: 0.53; train_accuracy: 0.83 

2.3206794139696285e-05
8.80423976923339e-06
Batch: 0; loss: 0.58; acc: 0.73
Batch: 20; loss: 0.75; acc: 0.77
Batch: 40; loss: 0.3; acc: 0.91
Batch: 60; loss: 0.9; acc: 0.81
Batch: 80; loss: 0.77; acc: 0.8
Batch: 100; loss: 0.58; acc: 0.84
Batch: 120; loss: 0.9; acc: 0.73
Batch: 140; loss: 0.34; acc: 0.84
Val Epoch over. val_loss: 0.6354764057382657; val_accuracy: 0.8075238853503185 

The current subspace-distance is: 8.80423976923339e-06 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.68; acc: 0.72
Batch: 20; loss: 0.32; acc: 0.86
Batch: 40; loss: 0.28; acc: 0.94
Batch: 60; loss: 0.71; acc: 0.83
Batch: 80; loss: 0.56; acc: 0.84
Batch: 100; loss: 0.35; acc: 0.92
Batch: 120; loss: 0.4; acc: 0.84
Batch: 140; loss: 0.52; acc: 0.78
Batch: 160; loss: 0.51; acc: 0.83
Batch: 180; loss: 0.89; acc: 0.75
Batch: 200; loss: 0.58; acc: 0.78
Batch: 220; loss: 0.63; acc: 0.77
Batch: 240; loss: 0.63; acc: 0.73
Batch: 260; loss: 0.52; acc: 0.86
Batch: 280; loss: 0.66; acc: 0.77
Batch: 300; loss: 0.56; acc: 0.77
Batch: 320; loss: 0.5; acc: 0.83
Batch: 340; loss: 0.51; acc: 0.86
Batch: 360; loss: 0.51; acc: 0.84
Batch: 380; loss: 0.42; acc: 0.84
Batch: 400; loss: 0.73; acc: 0.8
Batch: 420; loss: 0.3; acc: 0.89
Batch: 440; loss: 0.67; acc: 0.84
Batch: 460; loss: 0.26; acc: 0.91
Batch: 480; loss: 0.62; acc: 0.78
Batch: 500; loss: 0.7; acc: 0.8
Batch: 520; loss: 0.72; acc: 0.78
Batch: 540; loss: 0.69; acc: 0.84
Batch: 560; loss: 0.47; acc: 0.86
Batch: 580; loss: 0.68; acc: 0.78
Batch: 600; loss: 0.7; acc: 0.78
Batch: 620; loss: 0.51; acc: 0.78
Batch: 640; loss: 0.64; acc: 0.8
Batch: 660; loss: 0.53; acc: 0.86
Batch: 680; loss: 0.84; acc: 0.75
Batch: 700; loss: 0.57; acc: 0.78
Batch: 720; loss: 0.34; acc: 0.92
Batch: 740; loss: 0.57; acc: 0.84
Batch: 760; loss: 0.49; acc: 0.88
Batch: 780; loss: 0.47; acc: 0.88
Train Epoch over. train_loss: 0.53; train_accuracy: 0.83 

2.3280377718037926e-05
9.420893547940068e-06
Batch: 0; loss: 0.68; acc: 0.73
Batch: 20; loss: 0.82; acc: 0.67
Batch: 40; loss: 0.22; acc: 0.92
Batch: 60; loss: 1.05; acc: 0.66
Batch: 80; loss: 0.5; acc: 0.81
Batch: 100; loss: 0.75; acc: 0.78
Batch: 120; loss: 0.86; acc: 0.73
Batch: 140; loss: 0.56; acc: 0.8
Val Epoch over. val_loss: 0.714246447868408; val_accuracy: 0.7678144904458599 

The current subspace-distance is: 9.420893547940068e-06 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.74; acc: 0.77
Batch: 20; loss: 0.4; acc: 0.88
Batch: 40; loss: 0.7; acc: 0.81
Batch: 60; loss: 0.58; acc: 0.81
Batch: 80; loss: 0.58; acc: 0.8
Batch: 100; loss: 0.53; acc: 0.78
Batch: 120; loss: 0.48; acc: 0.88
Batch: 140; loss: 0.54; acc: 0.83
Batch: 160; loss: 0.47; acc: 0.88
Batch: 180; loss: 0.44; acc: 0.91
Batch: 200; loss: 0.38; acc: 0.88
Batch: 220; loss: 0.87; acc: 0.77
Batch: 240; loss: 0.46; acc: 0.84
Batch: 260; loss: 0.61; acc: 0.83
Batch: 280; loss: 0.44; acc: 0.84
Batch: 300; loss: 0.32; acc: 0.88
Batch: 320; loss: 1.08; acc: 0.73
Batch: 340; loss: 0.45; acc: 0.83
Batch: 360; loss: 0.37; acc: 0.86
Batch: 380; loss: 0.38; acc: 0.88
Batch: 400; loss: 0.69; acc: 0.78
Batch: 420; loss: 0.41; acc: 0.8
Batch: 440; loss: 0.44; acc: 0.84
Batch: 460; loss: 0.38; acc: 0.89
Batch: 480; loss: 0.58; acc: 0.8
Batch: 500; loss: 0.38; acc: 0.88
Batch: 520; loss: 0.52; acc: 0.81
Batch: 540; loss: 0.42; acc: 0.86
Batch: 560; loss: 0.7; acc: 0.78
Batch: 580; loss: 0.51; acc: 0.84
Batch: 600; loss: 0.33; acc: 0.94
Batch: 620; loss: 0.69; acc: 0.8
Batch: 640; loss: 0.43; acc: 0.89
Batch: 660; loss: 0.59; acc: 0.83
Batch: 680; loss: 0.48; acc: 0.86
Batch: 700; loss: 0.57; acc: 0.81
Batch: 720; loss: 0.89; acc: 0.77
Batch: 740; loss: 0.65; acc: 0.84
Batch: 760; loss: 0.44; acc: 0.88
Batch: 780; loss: 0.7; acc: 0.8
Train Epoch over. train_loss: 0.53; train_accuracy: 0.83 

2.1845984520041384e-05
7.633374480064958e-06
Batch: 0; loss: 0.66; acc: 0.78
Batch: 20; loss: 0.75; acc: 0.73
Batch: 40; loss: 0.2; acc: 0.91
Batch: 60; loss: 1.1; acc: 0.66
Batch: 80; loss: 0.72; acc: 0.78
Batch: 100; loss: 0.62; acc: 0.81
Batch: 120; loss: 0.96; acc: 0.69
Batch: 140; loss: 0.46; acc: 0.84
Val Epoch over. val_loss: 0.6303859541940081; val_accuracy: 0.7834394904458599 

The current subspace-distance is: 7.633374480064958e-06 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.67; acc: 0.78
Batch: 20; loss: 0.58; acc: 0.8
Batch: 40; loss: 0.51; acc: 0.86
Batch: 60; loss: 0.36; acc: 0.86
Batch: 80; loss: 0.37; acc: 0.83
Batch: 100; loss: 0.37; acc: 0.88
Batch: 120; loss: 0.56; acc: 0.84
Batch: 140; loss: 0.51; acc: 0.88
Batch: 160; loss: 0.37; acc: 0.84
Batch: 180; loss: 0.35; acc: 0.89
Batch: 200; loss: 0.73; acc: 0.81
Batch: 220; loss: 0.4; acc: 0.88
Batch: 240; loss: 0.36; acc: 0.88
Batch: 260; loss: 0.51; acc: 0.81
Batch: 280; loss: 0.37; acc: 0.89
Batch: 300; loss: 0.47; acc: 0.86
Batch: 320; loss: 0.54; acc: 0.83
Batch: 340; loss: 0.33; acc: 0.91
Batch: 360; loss: 0.43; acc: 0.84
Batch: 380; loss: 0.55; acc: 0.81
Batch: 400; loss: 0.62; acc: 0.83
Batch: 420; loss: 0.42; acc: 0.89
Batch: 440; loss: 0.43; acc: 0.86
Batch: 460; loss: 0.33; acc: 0.89
Batch: 480; loss: 0.4; acc: 0.91
Batch: 500; loss: 0.42; acc: 0.81
Batch: 520; loss: 0.69; acc: 0.83
Batch: 540; loss: 0.57; acc: 0.81
Batch: 560; loss: 0.49; acc: 0.84
Batch: 580; loss: 0.54; acc: 0.84
Batch: 600; loss: 0.4; acc: 0.89
Batch: 620; loss: 0.38; acc: 0.89
Batch: 640; loss: 0.34; acc: 0.89
Batch: 660; loss: 0.59; acc: 0.83
Batch: 680; loss: 0.4; acc: 0.86
Batch: 700; loss: 0.33; acc: 0.86
Batch: 720; loss: 0.49; acc: 0.86
Batch: 740; loss: 0.38; acc: 0.91
Batch: 760; loss: 0.4; acc: 0.86
Batch: 780; loss: 0.37; acc: 0.84
Train Epoch over. train_loss: 0.47; train_accuracy: 0.86 

2.4611474145785905e-05
8.563122719351668e-06
Batch: 0; loss: 0.41; acc: 0.83
Batch: 20; loss: 0.51; acc: 0.84
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.89; acc: 0.7
Batch: 80; loss: 0.35; acc: 0.88
Batch: 100; loss: 0.38; acc: 0.89
Batch: 120; loss: 0.69; acc: 0.83
Batch: 140; loss: 0.31; acc: 0.91
Val Epoch over. val_loss: 0.4429536573826128; val_accuracy: 0.8644506369426752 

The current subspace-distance is: 8.563122719351668e-06 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.85; acc: 0.81
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.64; acc: 0.8
Batch: 60; loss: 0.63; acc: 0.86
Batch: 80; loss: 0.62; acc: 0.81
Batch: 100; loss: 0.38; acc: 0.84
Batch: 120; loss: 0.5; acc: 0.81
Batch: 140; loss: 0.39; acc: 0.88
Batch: 160; loss: 0.34; acc: 0.91
Batch: 180; loss: 0.38; acc: 0.88
Batch: 200; loss: 0.41; acc: 0.88
Batch: 220; loss: 0.56; acc: 0.8
Batch: 240; loss: 0.46; acc: 0.89
Batch: 260; loss: 0.35; acc: 0.91
Batch: 280; loss: 0.3; acc: 0.94
Batch: 300; loss: 0.37; acc: 0.84
Batch: 320; loss: 0.48; acc: 0.83
Batch: 340; loss: 0.44; acc: 0.88
Batch: 360; loss: 0.64; acc: 0.81
Batch: 380; loss: 0.44; acc: 0.86
Batch: 400; loss: 0.38; acc: 0.89
Batch: 420; loss: 0.64; acc: 0.8
Batch: 440; loss: 0.44; acc: 0.88
Batch: 460; loss: 0.49; acc: 0.86
Batch: 480; loss: 0.45; acc: 0.92
Batch: 500; loss: 0.71; acc: 0.81
Batch: 520; loss: 0.3; acc: 0.91
Batch: 540; loss: 0.64; acc: 0.88
Batch: 560; loss: 0.47; acc: 0.86
Batch: 580; loss: 0.52; acc: 0.83
Batch: 600; loss: 0.4; acc: 0.83
Batch: 620; loss: 0.55; acc: 0.8
Batch: 640; loss: 0.42; acc: 0.89
Batch: 660; loss: 0.4; acc: 0.84
Batch: 680; loss: 0.76; acc: 0.81
Batch: 700; loss: 0.28; acc: 0.91
Batch: 720; loss: 0.51; acc: 0.86
Batch: 740; loss: 0.73; acc: 0.81
Batch: 760; loss: 0.79; acc: 0.81
Batch: 780; loss: 0.29; acc: 0.89
Train Epoch over. train_loss: 0.46; train_accuracy: 0.86 

2.4387794837821275e-05
9.719881745695602e-06
Batch: 0; loss: 0.4; acc: 0.86
Batch: 20; loss: 0.51; acc: 0.86
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.97; acc: 0.73
Batch: 80; loss: 0.44; acc: 0.88
Batch: 100; loss: 0.33; acc: 0.94
Batch: 120; loss: 0.71; acc: 0.8
Batch: 140; loss: 0.25; acc: 0.94
Val Epoch over. val_loss: 0.4833312817629735; val_accuracy: 0.8511146496815286 

The current subspace-distance is: 9.719881745695602e-06 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.4; acc: 0.89
Batch: 20; loss: 0.55; acc: 0.81
Batch: 40; loss: 0.51; acc: 0.88
Batch: 60; loss: 0.31; acc: 0.86
Batch: 80; loss: 0.42; acc: 0.88
Batch: 100; loss: 0.48; acc: 0.84
Batch: 120; loss: 0.42; acc: 0.83
Batch: 140; loss: 0.46; acc: 0.88
Batch: 160; loss: 0.63; acc: 0.81
Batch: 180; loss: 0.35; acc: 0.88
Batch: 200; loss: 0.4; acc: 0.89
Batch: 220; loss: 0.45; acc: 0.86
Batch: 240; loss: 0.49; acc: 0.84
Batch: 260; loss: 0.39; acc: 0.88
Batch: 280; loss: 0.47; acc: 0.83
Batch: 300; loss: 0.46; acc: 0.84
Batch: 320; loss: 0.68; acc: 0.83
Batch: 340; loss: 0.35; acc: 0.89
Batch: 360; loss: 0.35; acc: 0.92
Batch: 380; loss: 0.63; acc: 0.75
Batch: 400; loss: 0.31; acc: 0.91
Batch: 420; loss: 0.25; acc: 0.94
Batch: 440; loss: 0.46; acc: 0.84
Batch: 460; loss: 0.35; acc: 0.88
Batch: 480; loss: 0.29; acc: 0.91
Batch: 500; loss: 0.5; acc: 0.84
Batch: 520; loss: 0.67; acc: 0.81
Batch: 540; loss: 0.62; acc: 0.8
Batch: 560; loss: 0.27; acc: 0.94
Batch: 580; loss: 0.47; acc: 0.8
Batch: 600; loss: 0.51; acc: 0.81
Batch: 620; loss: 0.43; acc: 0.88
Batch: 640; loss: 0.48; acc: 0.86
Batch: 660; loss: 0.51; acc: 0.86
Batch: 680; loss: 0.53; acc: 0.84
Batch: 700; loss: 0.75; acc: 0.7
Batch: 720; loss: 0.23; acc: 0.92
Batch: 740; loss: 0.45; acc: 0.88
Batch: 760; loss: 0.49; acc: 0.81
Batch: 780; loss: 0.6; acc: 0.89
Train Epoch over. train_loss: 0.46; train_accuracy: 0.86 

2.4286971893161535e-05
1.0903668226092122e-05
Batch: 0; loss: 0.51; acc: 0.81
Batch: 20; loss: 0.64; acc: 0.81
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 1.08; acc: 0.75
Batch: 80; loss: 0.61; acc: 0.81
Batch: 100; loss: 0.44; acc: 0.84
Batch: 120; loss: 1.05; acc: 0.72
Batch: 140; loss: 0.37; acc: 0.84
Val Epoch over. val_loss: 0.5582800264571123; val_accuracy: 0.8244426751592356 

The current subspace-distance is: 1.0903668226092122e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.56; acc: 0.83
Batch: 20; loss: 0.42; acc: 0.84
Batch: 40; loss: 0.24; acc: 0.95
Batch: 60; loss: 0.3; acc: 0.89
Batch: 80; loss: 0.28; acc: 0.89
Batch: 100; loss: 0.42; acc: 0.86
Batch: 120; loss: 0.54; acc: 0.89
Batch: 140; loss: 0.64; acc: 0.83
Batch: 160; loss: 0.51; acc: 0.84
Batch: 180; loss: 0.25; acc: 0.91
Batch: 200; loss: 0.39; acc: 0.88
Batch: 220; loss: 0.64; acc: 0.86
Batch: 240; loss: 0.23; acc: 0.91
Batch: 260; loss: 0.46; acc: 0.84
Batch: 280; loss: 0.55; acc: 0.81
Batch: 300; loss: 0.5; acc: 0.84
Batch: 320; loss: 0.26; acc: 0.91
Batch: 340; loss: 0.51; acc: 0.83
Batch: 360; loss: 0.62; acc: 0.83
Batch: 380; loss: 0.24; acc: 0.92
Batch: 400; loss: 0.58; acc: 0.83
Batch: 420; loss: 0.36; acc: 0.88
Batch: 440; loss: 0.49; acc: 0.84
Batch: 460; loss: 0.36; acc: 0.84
Batch: 480; loss: 0.69; acc: 0.8
Batch: 500; loss: 0.62; acc: 0.78
Batch: 520; loss: 0.38; acc: 0.88
Batch: 540; loss: 0.46; acc: 0.84
Batch: 560; loss: 0.65; acc: 0.86
Batch: 580; loss: 0.4; acc: 0.88
Batch: 600; loss: 0.57; acc: 0.81
Batch: 620; loss: 0.69; acc: 0.78
Batch: 640; loss: 0.43; acc: 0.88
Batch: 660; loss: 0.5; acc: 0.83
Batch: 680; loss: 0.67; acc: 0.78
Batch: 700; loss: 0.34; acc: 0.88
Batch: 720; loss: 0.4; acc: 0.84
Batch: 740; loss: 0.3; acc: 0.89
Batch: 760; loss: 0.41; acc: 0.88
Batch: 780; loss: 0.48; acc: 0.83
Train Epoch over. train_loss: 0.46; train_accuracy: 0.86 

2.5682173145469278e-05
9.287979992222972e-06
Batch: 0; loss: 0.38; acc: 0.84
Batch: 20; loss: 0.42; acc: 0.81
Batch: 40; loss: 0.13; acc: 0.98
Batch: 60; loss: 0.94; acc: 0.73
Batch: 80; loss: 0.38; acc: 0.92
Batch: 100; loss: 0.34; acc: 0.91
Batch: 120; loss: 0.69; acc: 0.81
Batch: 140; loss: 0.23; acc: 0.92
Val Epoch over. val_loss: 0.44232563370731987; val_accuracy: 0.8590764331210191 

The current subspace-distance is: 9.287979992222972e-06 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.55; acc: 0.86
Batch: 20; loss: 0.33; acc: 0.88
Batch: 40; loss: 0.4; acc: 0.89
Batch: 60; loss: 0.56; acc: 0.8
Batch: 80; loss: 0.39; acc: 0.92
Batch: 100; loss: 0.52; acc: 0.78
Batch: 120; loss: 0.47; acc: 0.88
Batch: 140; loss: 0.4; acc: 0.88
Batch: 160; loss: 0.48; acc: 0.88
Batch: 180; loss: 0.81; acc: 0.77
Batch: 200; loss: 0.45; acc: 0.89
Batch: 220; loss: 0.56; acc: 0.8
Batch: 240; loss: 0.58; acc: 0.81
Batch: 260; loss: 0.51; acc: 0.86
Batch: 280; loss: 0.27; acc: 0.94
Batch: 300; loss: 0.61; acc: 0.86
Batch: 320; loss: 0.56; acc: 0.86
Batch: 340; loss: 0.4; acc: 0.86
Batch: 360; loss: 0.44; acc: 0.88
Batch: 380; loss: 0.4; acc: 0.88
Batch: 400; loss: 0.34; acc: 0.91
Batch: 420; loss: 0.55; acc: 0.8
Batch: 440; loss: 0.51; acc: 0.89
Batch: 460; loss: 0.43; acc: 0.84
Batch: 480; loss: 0.36; acc: 0.89
Batch: 500; loss: 0.49; acc: 0.86
Batch: 520; loss: 0.57; acc: 0.86
Batch: 540; loss: 0.32; acc: 0.91
Batch: 560; loss: 0.42; acc: 0.86
Batch: 580; loss: 0.37; acc: 0.84
Batch: 600; loss: 0.41; acc: 0.84
Batch: 620; loss: 0.4; acc: 0.84
Batch: 640; loss: 0.45; acc: 0.86
Batch: 660; loss: 0.33; acc: 0.83
Batch: 680; loss: 0.48; acc: 0.91
Batch: 700; loss: 0.53; acc: 0.86
Batch: 720; loss: 0.46; acc: 0.86
Batch: 740; loss: 0.37; acc: 0.86
Batch: 760; loss: 0.69; acc: 0.78
Batch: 780; loss: 0.22; acc: 0.92
Train Epoch over. train_loss: 0.46; train_accuracy: 0.86 

2.32778002100531e-05
8.38391588331433e-06
Batch: 0; loss: 0.33; acc: 0.88
Batch: 20; loss: 0.51; acc: 0.83
Batch: 40; loss: 0.1; acc: 0.98
Batch: 60; loss: 0.89; acc: 0.78
Batch: 80; loss: 0.37; acc: 0.92
Batch: 100; loss: 0.27; acc: 0.94
Batch: 120; loss: 0.72; acc: 0.81
Batch: 140; loss: 0.21; acc: 0.94
Val Epoch over. val_loss: 0.41591152283036786; val_accuracy: 0.8741042993630573 

The current subspace-distance is: 8.38391588331433e-06 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.45; acc: 0.88
Batch: 20; loss: 0.65; acc: 0.84
Batch: 40; loss: 0.39; acc: 0.86
Batch: 60; loss: 0.34; acc: 0.88
Batch: 80; loss: 0.4; acc: 0.88
Batch: 100; loss: 0.52; acc: 0.84
Batch: 120; loss: 0.84; acc: 0.78
Batch: 140; loss: 0.2; acc: 0.94
Batch: 160; loss: 0.54; acc: 0.81
Batch: 180; loss: 0.59; acc: 0.86
Batch: 200; loss: 0.4; acc: 0.86
Batch: 220; loss: 0.52; acc: 0.86
Batch: 240; loss: 0.46; acc: 0.84
Batch: 260; loss: 0.58; acc: 0.8
Batch: 280; loss: 0.91; acc: 0.77
Batch: 300; loss: 0.41; acc: 0.89
Batch: 320; loss: 0.47; acc: 0.88
Batch: 340; loss: 0.62; acc: 0.8
Batch: 360; loss: 0.53; acc: 0.86
Batch: 380; loss: 0.47; acc: 0.89
Batch: 400; loss: 0.44; acc: 0.89
Batch: 420; loss: 0.5; acc: 0.89
Batch: 440; loss: 0.48; acc: 0.83
Batch: 460; loss: 0.35; acc: 0.89
Batch: 480; loss: 0.35; acc: 0.89
Batch: 500; loss: 0.68; acc: 0.75
Batch: 520; loss: 0.29; acc: 0.95
Batch: 540; loss: 0.46; acc: 0.86
Batch: 560; loss: 0.55; acc: 0.88
Batch: 580; loss: 0.49; acc: 0.84
Batch: 600; loss: 0.48; acc: 0.83
Batch: 620; loss: 0.49; acc: 0.84
Batch: 640; loss: 0.43; acc: 0.84
Batch: 660; loss: 0.36; acc: 0.88
Batch: 680; loss: 0.35; acc: 0.91
Batch: 700; loss: 0.51; acc: 0.86
Batch: 720; loss: 0.41; acc: 0.81
Batch: 740; loss: 0.36; acc: 0.88
Batch: 760; loss: 0.47; acc: 0.86
Batch: 780; loss: 0.41; acc: 0.84
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

2.3316088118008338e-05
7.98961082182359e-06
Batch: 0; loss: 0.4; acc: 0.89
Batch: 20; loss: 0.49; acc: 0.78
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 1.16; acc: 0.73
Batch: 80; loss: 0.53; acc: 0.83
Batch: 100; loss: 0.48; acc: 0.83
Batch: 120; loss: 0.98; acc: 0.72
Batch: 140; loss: 0.39; acc: 0.86
Val Epoch over. val_loss: 0.5415682041910803; val_accuracy: 0.8293192675159236 

The current subspace-distance is: 7.98961082182359e-06 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.43; acc: 0.88
Batch: 20; loss: 0.72; acc: 0.75
Batch: 40; loss: 0.56; acc: 0.78
Batch: 60; loss: 0.4; acc: 0.88
Batch: 80; loss: 0.44; acc: 0.88
Batch: 100; loss: 0.52; acc: 0.88
Batch: 120; loss: 0.55; acc: 0.81
Batch: 140; loss: 0.27; acc: 0.89
Batch: 160; loss: 0.79; acc: 0.81
Batch: 180; loss: 0.54; acc: 0.81
Batch: 200; loss: 0.69; acc: 0.78
Batch: 220; loss: 0.37; acc: 0.88
Batch: 240; loss: 0.77; acc: 0.78
Batch: 260; loss: 0.43; acc: 0.89
Batch: 280; loss: 0.32; acc: 0.92
Batch: 300; loss: 0.57; acc: 0.81
Batch: 320; loss: 0.32; acc: 0.91
Batch: 340; loss: 0.38; acc: 0.88
Batch: 360; loss: 0.63; acc: 0.8
Batch: 380; loss: 0.71; acc: 0.8
Batch: 400; loss: 0.4; acc: 0.86
Batch: 420; loss: 0.59; acc: 0.88
Batch: 440; loss: 0.37; acc: 0.86
Batch: 460; loss: 0.23; acc: 0.94
Batch: 480; loss: 0.48; acc: 0.88
Batch: 500; loss: 0.41; acc: 0.89
Batch: 520; loss: 0.53; acc: 0.81
Batch: 540; loss: 0.41; acc: 0.86
Batch: 560; loss: 0.51; acc: 0.81
Batch: 580; loss: 0.32; acc: 0.86
Batch: 600; loss: 0.46; acc: 0.84
Batch: 620; loss: 0.48; acc: 0.83
Batch: 640; loss: 0.42; acc: 0.83
Batch: 660; loss: 0.31; acc: 0.88
Batch: 680; loss: 0.46; acc: 0.84
Batch: 700; loss: 0.4; acc: 0.89
Batch: 720; loss: 0.31; acc: 0.91
Batch: 740; loss: 0.64; acc: 0.81
Batch: 760; loss: 0.47; acc: 0.84
Batch: 780; loss: 0.58; acc: 0.83
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

2.311094976903405e-05
9.257812962459866e-06
Batch: 0; loss: 0.32; acc: 0.86
Batch: 20; loss: 0.49; acc: 0.81
Batch: 40; loss: 0.12; acc: 0.98
Batch: 60; loss: 0.91; acc: 0.75
Batch: 80; loss: 0.36; acc: 0.91
Batch: 100; loss: 0.33; acc: 0.92
Batch: 120; loss: 0.69; acc: 0.8
Batch: 140; loss: 0.2; acc: 0.94
Val Epoch over. val_loss: 0.41025694602044527; val_accuracy: 0.8735071656050956 

The current subspace-distance is: 9.257812962459866e-06 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.63; acc: 0.86
Batch: 20; loss: 0.46; acc: 0.84
Batch: 40; loss: 0.64; acc: 0.83
Batch: 60; loss: 0.54; acc: 0.88
Batch: 80; loss: 0.24; acc: 0.88
Batch: 100; loss: 0.41; acc: 0.88
Batch: 120; loss: 0.39; acc: 0.88
Batch: 140; loss: 0.53; acc: 0.8
Batch: 160; loss: 0.46; acc: 0.84
Batch: 180; loss: 0.46; acc: 0.81
Batch: 200; loss: 0.38; acc: 0.91
Batch: 220; loss: 0.38; acc: 0.89
Batch: 240; loss: 0.65; acc: 0.77
Batch: 260; loss: 0.56; acc: 0.83
Batch: 280; loss: 0.44; acc: 0.86
Batch: 300; loss: 0.55; acc: 0.84
Batch: 320; loss: 0.46; acc: 0.84
Batch: 340; loss: 0.45; acc: 0.86
Batch: 360; loss: 0.29; acc: 0.91
Batch: 380; loss: 0.23; acc: 0.94
Batch: 400; loss: 0.46; acc: 0.84
Batch: 420; loss: 0.42; acc: 0.88
Batch: 440; loss: 0.44; acc: 0.89
Batch: 460; loss: 0.38; acc: 0.84
Batch: 480; loss: 0.28; acc: 0.89
Batch: 500; loss: 0.49; acc: 0.88
Batch: 520; loss: 0.36; acc: 0.86
Batch: 540; loss: 0.37; acc: 0.88
Batch: 560; loss: 0.61; acc: 0.84
Batch: 580; loss: 0.28; acc: 0.92
Batch: 600; loss: 0.49; acc: 0.8
Batch: 620; loss: 0.51; acc: 0.8
Batch: 640; loss: 0.35; acc: 0.94
Batch: 660; loss: 0.27; acc: 0.94
Batch: 680; loss: 0.23; acc: 0.95
Batch: 700; loss: 0.64; acc: 0.81
Batch: 720; loss: 0.36; acc: 0.91
Batch: 740; loss: 0.36; acc: 0.94
Batch: 760; loss: 0.38; acc: 0.89
Batch: 780; loss: 0.49; acc: 0.84
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

2.6083371267304756e-05
9.092438631341793e-06
Batch: 0; loss: 0.31; acc: 0.89
Batch: 20; loss: 0.48; acc: 0.81
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.88; acc: 0.72
Batch: 80; loss: 0.3; acc: 0.92
Batch: 100; loss: 0.3; acc: 0.94
Batch: 120; loss: 0.65; acc: 0.83
Batch: 140; loss: 0.19; acc: 0.95
Val Epoch over. val_loss: 0.41843123748234123; val_accuracy: 0.8708200636942676 

The current subspace-distance is: 9.092438631341793e-06 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.56; acc: 0.81
Batch: 20; loss: 0.37; acc: 0.88
Batch: 40; loss: 0.71; acc: 0.8
Batch: 60; loss: 0.5; acc: 0.83
Batch: 80; loss: 0.62; acc: 0.83
Batch: 100; loss: 0.84; acc: 0.83
Batch: 120; loss: 0.45; acc: 0.89
Batch: 140; loss: 0.44; acc: 0.86
Batch: 160; loss: 0.33; acc: 0.86
Batch: 180; loss: 0.37; acc: 0.88
Batch: 200; loss: 0.72; acc: 0.77
Batch: 220; loss: 0.5; acc: 0.88
Batch: 240; loss: 0.3; acc: 0.89
Batch: 260; loss: 0.53; acc: 0.81
Batch: 280; loss: 0.45; acc: 0.83
Batch: 300; loss: 0.63; acc: 0.8
Batch: 320; loss: 0.66; acc: 0.81
Batch: 340; loss: 0.5; acc: 0.83
Batch: 360; loss: 0.26; acc: 0.92
Batch: 380; loss: 0.37; acc: 0.84
Batch: 400; loss: 0.63; acc: 0.81
Batch: 420; loss: 0.27; acc: 0.92
Batch: 440; loss: 0.52; acc: 0.86
Batch: 460; loss: 0.33; acc: 0.89
Batch: 480; loss: 0.4; acc: 0.88
Batch: 500; loss: 0.37; acc: 0.92
Batch: 520; loss: 0.58; acc: 0.86
Batch: 540; loss: 0.46; acc: 0.88
Batch: 560; loss: 0.47; acc: 0.84
Batch: 580; loss: 0.5; acc: 0.84
Batch: 600; loss: 0.33; acc: 0.89
Batch: 620; loss: 0.37; acc: 0.89
Batch: 640; loss: 0.55; acc: 0.88
Batch: 660; loss: 0.58; acc: 0.83
Batch: 680; loss: 0.58; acc: 0.78
Batch: 700; loss: 0.3; acc: 0.86
Batch: 720; loss: 0.51; acc: 0.88
Batch: 740; loss: 0.42; acc: 0.88
Batch: 760; loss: 0.41; acc: 0.91
Batch: 780; loss: 0.25; acc: 0.89
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

2.4005821614991874e-05
9.884015526040457e-06
Batch: 0; loss: 0.31; acc: 0.92
Batch: 20; loss: 0.58; acc: 0.8
Batch: 40; loss: 0.13; acc: 0.98
Batch: 60; loss: 0.86; acc: 0.77
Batch: 80; loss: 0.35; acc: 0.92
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.74; acc: 0.78
Batch: 140; loss: 0.19; acc: 0.95
Val Epoch over. val_loss: 0.42254531682486746; val_accuracy: 0.8711186305732485 

The current subspace-distance is: 9.884015526040457e-06 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.34; acc: 0.86
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.48; acc: 0.81
Batch: 60; loss: 0.41; acc: 0.88
Batch: 80; loss: 0.47; acc: 0.83
Batch: 100; loss: 0.52; acc: 0.81
Batch: 120; loss: 0.39; acc: 0.84
Batch: 140; loss: 0.35; acc: 0.88
Batch: 160; loss: 0.55; acc: 0.84
Batch: 180; loss: 0.35; acc: 0.86
Batch: 200; loss: 0.41; acc: 0.88
Batch: 220; loss: 0.41; acc: 0.91
Batch: 240; loss: 0.49; acc: 0.86
Batch: 260; loss: 0.46; acc: 0.84
Batch: 280; loss: 0.7; acc: 0.83
Batch: 300; loss: 0.56; acc: 0.83
Batch: 320; loss: 0.47; acc: 0.83
Batch: 340; loss: 0.3; acc: 0.92
Batch: 360; loss: 0.53; acc: 0.88
Batch: 380; loss: 0.51; acc: 0.84
Batch: 400; loss: 0.58; acc: 0.8
Batch: 420; loss: 0.29; acc: 0.92
Batch: 440; loss: 0.53; acc: 0.88
Batch: 460; loss: 0.51; acc: 0.83
Batch: 480; loss: 0.29; acc: 0.92
Batch: 500; loss: 0.34; acc: 0.92
Batch: 520; loss: 0.39; acc: 0.86
Batch: 540; loss: 0.3; acc: 0.89
Batch: 560; loss: 0.31; acc: 0.91
Batch: 580; loss: 0.2; acc: 0.94
Batch: 600; loss: 0.52; acc: 0.88
Batch: 620; loss: 0.66; acc: 0.88
Batch: 640; loss: 0.66; acc: 0.81
Batch: 660; loss: 0.42; acc: 0.83
Batch: 680; loss: 0.43; acc: 0.86
Batch: 700; loss: 0.6; acc: 0.81
Batch: 720; loss: 0.43; acc: 0.89
Batch: 740; loss: 0.56; acc: 0.78
Batch: 760; loss: 0.47; acc: 0.8
Batch: 780; loss: 0.49; acc: 0.83
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

2.4311229935847223e-05
8.231761057686526e-06
Batch: 0; loss: 0.33; acc: 0.86
Batch: 20; loss: 0.57; acc: 0.83
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.96; acc: 0.72
Batch: 80; loss: 0.41; acc: 0.91
Batch: 100; loss: 0.37; acc: 0.88
Batch: 120; loss: 0.75; acc: 0.8
Batch: 140; loss: 0.16; acc: 0.97
Val Epoch over. val_loss: 0.4450643039812708; val_accuracy: 0.8607683121019108 

The current subspace-distance is: 8.231761057686526e-06 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.72; acc: 0.8
Batch: 20; loss: 0.26; acc: 0.89
Batch: 40; loss: 0.49; acc: 0.86
Batch: 60; loss: 0.57; acc: 0.83
Batch: 80; loss: 0.48; acc: 0.86
Batch: 100; loss: 0.35; acc: 0.84
Batch: 120; loss: 0.45; acc: 0.88
Batch: 140; loss: 0.42; acc: 0.86
Batch: 160; loss: 0.38; acc: 0.86
Batch: 180; loss: 0.58; acc: 0.81
Batch: 200; loss: 0.28; acc: 0.94
Batch: 220; loss: 0.37; acc: 0.88
Batch: 240; loss: 0.27; acc: 0.92
Batch: 260; loss: 0.61; acc: 0.81
Batch: 280; loss: 0.45; acc: 0.84
Batch: 300; loss: 0.33; acc: 0.89
Batch: 320; loss: 0.46; acc: 0.88
Batch: 340; loss: 0.42; acc: 0.84
Batch: 360; loss: 0.24; acc: 0.91
Batch: 380; loss: 0.56; acc: 0.84
Batch: 400; loss: 0.4; acc: 0.84
Batch: 420; loss: 0.33; acc: 0.92
Batch: 440; loss: 0.26; acc: 0.92
Batch: 460; loss: 0.33; acc: 0.86
Batch: 480; loss: 0.66; acc: 0.83
Batch: 500; loss: 0.5; acc: 0.84
Batch: 520; loss: 0.32; acc: 0.91
Batch: 540; loss: 0.37; acc: 0.84
Batch: 560; loss: 0.46; acc: 0.83
Batch: 580; loss: 0.34; acc: 0.89
Batch: 600; loss: 0.23; acc: 0.92
Batch: 620; loss: 0.66; acc: 0.84
Batch: 640; loss: 0.4; acc: 0.86
Batch: 660; loss: 0.58; acc: 0.84
Batch: 680; loss: 0.44; acc: 0.83
Batch: 700; loss: 0.28; acc: 0.92
Batch: 720; loss: 0.38; acc: 0.84
Batch: 740; loss: 0.4; acc: 0.88
Batch: 760; loss: 0.56; acc: 0.81
Batch: 780; loss: 0.65; acc: 0.78
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

2.239692912553437e-05
9.087580110644922e-06
Batch: 0; loss: 0.28; acc: 0.92
Batch: 20; loss: 0.47; acc: 0.84
Batch: 40; loss: 0.12; acc: 0.98
Batch: 60; loss: 0.91; acc: 0.73
Batch: 80; loss: 0.33; acc: 0.92
Batch: 100; loss: 0.27; acc: 0.91
Batch: 120; loss: 0.66; acc: 0.81
Batch: 140; loss: 0.14; acc: 0.95
Val Epoch over. val_loss: 0.38783602857855476; val_accuracy: 0.8831608280254777 

The current subspace-distance is: 9.087580110644922e-06 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.38; acc: 0.92
Batch: 20; loss: 0.34; acc: 0.86
Batch: 40; loss: 0.32; acc: 0.88
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.24; acc: 0.95
Batch: 100; loss: 0.35; acc: 0.88
Batch: 120; loss: 0.62; acc: 0.8
Batch: 140; loss: 0.3; acc: 0.91
Batch: 160; loss: 0.4; acc: 0.91
Batch: 180; loss: 0.27; acc: 0.89
Batch: 200; loss: 0.56; acc: 0.83
Batch: 220; loss: 0.19; acc: 0.95
Batch: 240; loss: 0.29; acc: 0.89
Batch: 260; loss: 0.44; acc: 0.86
Batch: 280; loss: 0.43; acc: 0.88
Batch: 300; loss: 0.61; acc: 0.8
Batch: 320; loss: 0.44; acc: 0.78
Batch: 340; loss: 0.26; acc: 0.88
Batch: 360; loss: 0.31; acc: 0.92
Batch: 380; loss: 0.42; acc: 0.91
Batch: 400; loss: 0.51; acc: 0.86
Batch: 420; loss: 0.44; acc: 0.83
Batch: 440; loss: 0.52; acc: 0.83
Batch: 460; loss: 0.31; acc: 0.89
Batch: 480; loss: 0.32; acc: 0.88
Batch: 500; loss: 0.35; acc: 0.86
Batch: 520; loss: 0.34; acc: 0.91
Batch: 540; loss: 0.43; acc: 0.81
Batch: 560; loss: 0.34; acc: 0.92
Batch: 580; loss: 0.45; acc: 0.88
Batch: 600; loss: 0.39; acc: 0.91
Batch: 620; loss: 0.37; acc: 0.91
Batch: 640; loss: 0.49; acc: 0.84
Batch: 660; loss: 0.37; acc: 0.89
Batch: 680; loss: 0.43; acc: 0.89
Batch: 700; loss: 0.2; acc: 0.91
Batch: 720; loss: 0.6; acc: 0.78
Batch: 740; loss: 0.38; acc: 0.89
Batch: 760; loss: 0.41; acc: 0.84
Batch: 780; loss: 0.31; acc: 0.97
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

2.3441743906005286e-05
9.709334335639141e-06
Batch: 0; loss: 0.34; acc: 0.91
Batch: 20; loss: 0.49; acc: 0.83
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 1.0; acc: 0.72
Batch: 80; loss: 0.34; acc: 0.92
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.73; acc: 0.81
Batch: 140; loss: 0.2; acc: 0.92
Val Epoch over. val_loss: 0.4119327478822629; val_accuracy: 0.8707205414012739 

The current subspace-distance is: 9.709334335639141e-06 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.29; acc: 0.92
Batch: 20; loss: 0.54; acc: 0.88
Batch: 40; loss: 0.55; acc: 0.8
Batch: 60; loss: 0.44; acc: 0.89
Batch: 80; loss: 0.41; acc: 0.92
Batch: 100; loss: 0.39; acc: 0.84
Batch: 120; loss: 0.52; acc: 0.8
Batch: 140; loss: 0.24; acc: 0.94
Batch: 160; loss: 0.39; acc: 0.94
Batch: 180; loss: 0.43; acc: 0.84
Batch: 200; loss: 0.45; acc: 0.84
Batch: 220; loss: 0.26; acc: 0.92
Batch: 240; loss: 0.49; acc: 0.84
Batch: 260; loss: 0.44; acc: 0.81
Batch: 280; loss: 0.31; acc: 0.94
Batch: 300; loss: 0.23; acc: 0.92
Batch: 320; loss: 0.42; acc: 0.89
Batch: 340; loss: 0.48; acc: 0.88
Batch: 360; loss: 0.38; acc: 0.89
Batch: 380; loss: 0.6; acc: 0.84
Batch: 400; loss: 0.5; acc: 0.81
Batch: 420; loss: 0.38; acc: 0.88
Batch: 440; loss: 0.81; acc: 0.8
Batch: 460; loss: 0.43; acc: 0.88
Batch: 480; loss: 0.39; acc: 0.88
Batch: 500; loss: 0.5; acc: 0.84
Batch: 520; loss: 0.58; acc: 0.81
Batch: 540; loss: 0.3; acc: 0.94
Batch: 560; loss: 0.4; acc: 0.88
Batch: 580; loss: 0.46; acc: 0.89
Batch: 600; loss: 0.31; acc: 0.88
Batch: 620; loss: 0.43; acc: 0.88
Batch: 640; loss: 0.38; acc: 0.92
Batch: 660; loss: 0.39; acc: 0.91
Batch: 680; loss: 0.29; acc: 0.89
Batch: 700; loss: 0.3; acc: 0.89
Batch: 720; loss: 0.4; acc: 0.89
Batch: 740; loss: 0.37; acc: 0.88
Batch: 760; loss: 0.3; acc: 0.89
Batch: 780; loss: 0.43; acc: 0.89
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

2.3215008695842698e-05
9.814972145250067e-06
Batch: 0; loss: 0.31; acc: 0.91
Batch: 20; loss: 0.56; acc: 0.8
Batch: 40; loss: 0.12; acc: 0.98
Batch: 60; loss: 0.9; acc: 0.73
Batch: 80; loss: 0.33; acc: 0.92
Batch: 100; loss: 0.27; acc: 0.89
Batch: 120; loss: 0.71; acc: 0.78
Batch: 140; loss: 0.14; acc: 0.97
Val Epoch over. val_loss: 0.4008192634981149; val_accuracy: 0.8784832802547771 

The current subspace-distance is: 9.814972145250067e-06 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.36; acc: 0.94
Batch: 20; loss: 0.4; acc: 0.89
Batch: 40; loss: 0.42; acc: 0.89
Batch: 60; loss: 0.56; acc: 0.81
Batch: 80; loss: 0.36; acc: 0.84
Batch: 100; loss: 0.38; acc: 0.88
Batch: 120; loss: 0.33; acc: 0.89
Batch: 140; loss: 0.44; acc: 0.84
Batch: 160; loss: 0.38; acc: 0.89
Batch: 180; loss: 0.38; acc: 0.86
Batch: 200; loss: 0.26; acc: 0.92
Batch: 220; loss: 0.41; acc: 0.89
Batch: 240; loss: 0.37; acc: 0.92
Batch: 260; loss: 0.3; acc: 0.89
Batch: 280; loss: 0.3; acc: 0.92
Batch: 300; loss: 0.36; acc: 0.84
Batch: 320; loss: 0.26; acc: 0.94
Batch: 340; loss: 0.48; acc: 0.88
Batch: 360; loss: 0.58; acc: 0.84
Batch: 380; loss: 0.45; acc: 0.88
Batch: 400; loss: 0.55; acc: 0.8
Batch: 420; loss: 0.44; acc: 0.88
Batch: 440; loss: 0.38; acc: 0.88
Batch: 460; loss: 0.26; acc: 0.91
Batch: 480; loss: 0.41; acc: 0.89
Batch: 500; loss: 0.28; acc: 0.91
Batch: 520; loss: 0.25; acc: 0.94
Batch: 540; loss: 0.31; acc: 0.92
Batch: 560; loss: 0.3; acc: 0.89
Batch: 580; loss: 0.52; acc: 0.77
Batch: 600; loss: 0.41; acc: 0.84
Batch: 620; loss: 0.29; acc: 0.94
Batch: 640; loss: 0.7; acc: 0.81
Batch: 660; loss: 0.46; acc: 0.88
Batch: 680; loss: 0.63; acc: 0.81
Batch: 700; loss: 0.38; acc: 0.89
Batch: 720; loss: 0.38; acc: 0.86
Batch: 740; loss: 0.28; acc: 0.88
Batch: 760; loss: 0.31; acc: 0.92
Batch: 780; loss: 0.6; acc: 0.8
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

2.3447628336725757e-05
8.622221685072873e-06
Batch: 0; loss: 0.27; acc: 0.92
Batch: 20; loss: 0.42; acc: 0.83
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.91; acc: 0.77
Batch: 80; loss: 0.33; acc: 0.94
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.67; acc: 0.81
Batch: 140; loss: 0.14; acc: 0.95
Val Epoch over. val_loss: 0.3871930653027668; val_accuracy: 0.8832603503184714 

The current subspace-distance is: 8.622221685072873e-06 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.31; acc: 0.89
Batch: 20; loss: 0.47; acc: 0.88
Batch: 40; loss: 0.44; acc: 0.88
Batch: 60; loss: 0.35; acc: 0.89
Batch: 80; loss: 0.47; acc: 0.86
Batch: 100; loss: 0.41; acc: 0.91
Batch: 120; loss: 0.44; acc: 0.81
Batch: 140; loss: 0.26; acc: 0.97
Batch: 160; loss: 0.37; acc: 0.95
Batch: 180; loss: 0.35; acc: 0.86
Batch: 200; loss: 0.37; acc: 0.88
Batch: 220; loss: 0.45; acc: 0.88
Batch: 240; loss: 0.68; acc: 0.83
Batch: 260; loss: 0.25; acc: 0.91
Batch: 280; loss: 0.3; acc: 0.91
Batch: 300; loss: 0.42; acc: 0.83
Batch: 320; loss: 0.28; acc: 0.92
Batch: 340; loss: 0.58; acc: 0.88
Batch: 360; loss: 0.22; acc: 0.97
Batch: 380; loss: 0.57; acc: 0.86
Batch: 400; loss: 0.47; acc: 0.8
Batch: 420; loss: 0.35; acc: 0.84
Batch: 440; loss: 0.45; acc: 0.86
Batch: 460; loss: 0.56; acc: 0.86
Batch: 480; loss: 0.46; acc: 0.84
Batch: 500; loss: 0.43; acc: 0.83
Batch: 520; loss: 0.44; acc: 0.84
Batch: 540; loss: 0.77; acc: 0.84
Batch: 560; loss: 0.22; acc: 0.92
Batch: 580; loss: 0.26; acc: 0.91
Batch: 600; loss: 0.46; acc: 0.86
Batch: 620; loss: 0.39; acc: 0.89
Batch: 640; loss: 0.48; acc: 0.88
Batch: 660; loss: 0.63; acc: 0.83
Batch: 680; loss: 0.46; acc: 0.88
Batch: 700; loss: 0.29; acc: 0.92
Batch: 720; loss: 0.29; acc: 0.89
Batch: 740; loss: 0.33; acc: 0.92
Batch: 760; loss: 0.56; acc: 0.81
Batch: 780; loss: 0.39; acc: 0.86
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

2.6011552108684555e-05
8.974600859801285e-06
Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.42; acc: 0.84
Batch: 40; loss: 0.14; acc: 0.94
Batch: 60; loss: 0.97; acc: 0.77
Batch: 80; loss: 0.31; acc: 0.92
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.7; acc: 0.81
Batch: 140; loss: 0.17; acc: 0.92
Val Epoch over. val_loss: 0.39678425313371; val_accuracy: 0.8767914012738853 

The current subspace-distance is: 8.974600859801285e-06 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.53; acc: 0.84
Batch: 20; loss: 0.51; acc: 0.83
Batch: 40; loss: 0.3; acc: 0.92
Batch: 60; loss: 0.41; acc: 0.86
Batch: 80; loss: 0.6; acc: 0.81
Batch: 100; loss: 0.38; acc: 0.86
Batch: 120; loss: 0.19; acc: 0.94
Batch: 140; loss: 0.56; acc: 0.83
Batch: 160; loss: 0.59; acc: 0.83
Batch: 180; loss: 0.48; acc: 0.83
Batch: 200; loss: 0.56; acc: 0.81
Batch: 220; loss: 0.7; acc: 0.86
Batch: 240; loss: 0.44; acc: 0.86
Batch: 260; loss: 0.41; acc: 0.84
Batch: 280; loss: 0.35; acc: 0.89
Batch: 300; loss: 0.75; acc: 0.83
Batch: 320; loss: 0.41; acc: 0.91
Batch: 340; loss: 0.32; acc: 0.92
Batch: 360; loss: 0.55; acc: 0.81
Batch: 380; loss: 0.48; acc: 0.86
Batch: 400; loss: 0.29; acc: 0.89
Batch: 420; loss: 0.39; acc: 0.86
Batch: 440; loss: 0.36; acc: 0.88
Batch: 460; loss: 0.53; acc: 0.83
Batch: 480; loss: 0.45; acc: 0.88
Batch: 500; loss: 0.33; acc: 0.91
Batch: 520; loss: 0.29; acc: 0.95
Batch: 540; loss: 0.47; acc: 0.86
Batch: 560; loss: 0.68; acc: 0.8
Batch: 580; loss: 0.42; acc: 0.86
Batch: 600; loss: 0.5; acc: 0.86
Batch: 620; loss: 0.49; acc: 0.83
Batch: 640; loss: 0.45; acc: 0.88
Batch: 660; loss: 0.56; acc: 0.86
Batch: 680; loss: 0.35; acc: 0.91
Batch: 700; loss: 0.39; acc: 0.89
Batch: 720; loss: 0.39; acc: 0.88
Batch: 740; loss: 0.27; acc: 0.89
Batch: 760; loss: 0.46; acc: 0.88
Batch: 780; loss: 0.14; acc: 0.97
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

2.396790478087496e-05
9.863003469945397e-06
Batch: 0; loss: 0.32; acc: 0.91
Batch: 20; loss: 0.46; acc: 0.88
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.93; acc: 0.73
Batch: 80; loss: 0.34; acc: 0.94
Batch: 100; loss: 0.32; acc: 0.89
Batch: 120; loss: 0.66; acc: 0.8
Batch: 140; loss: 0.12; acc: 0.98
Val Epoch over. val_loss: 0.3948599855611279; val_accuracy: 0.8780851910828026 

The current subspace-distance is: 9.863003469945397e-06 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.35; acc: 0.89
Batch: 20; loss: 0.36; acc: 0.91
Batch: 40; loss: 0.52; acc: 0.84
Batch: 60; loss: 0.56; acc: 0.81
Batch: 80; loss: 0.44; acc: 0.86
Batch: 100; loss: 0.4; acc: 0.78
Batch: 120; loss: 0.32; acc: 0.89
Batch: 140; loss: 0.4; acc: 0.88
Batch: 160; loss: 0.48; acc: 0.88
Batch: 180; loss: 0.42; acc: 0.86
Batch: 200; loss: 0.42; acc: 0.81
Batch: 220; loss: 0.38; acc: 0.83
Batch: 240; loss: 0.5; acc: 0.89
Batch: 260; loss: 0.3; acc: 0.89
Batch: 280; loss: 0.36; acc: 0.89
Batch: 300; loss: 0.32; acc: 0.91
Batch: 320; loss: 0.45; acc: 0.86
Batch: 340; loss: 0.43; acc: 0.83
Batch: 360; loss: 0.26; acc: 0.92
Batch: 380; loss: 0.39; acc: 0.88
Batch: 400; loss: 0.26; acc: 0.94
Batch: 420; loss: 0.67; acc: 0.89
Batch: 440; loss: 0.2; acc: 0.94
Batch: 460; loss: 0.57; acc: 0.86
Batch: 480; loss: 0.37; acc: 0.89
Batch: 500; loss: 0.48; acc: 0.83
Batch: 520; loss: 0.36; acc: 0.92
Batch: 540; loss: 0.5; acc: 0.92
Batch: 560; loss: 0.42; acc: 0.91
Batch: 580; loss: 0.43; acc: 0.84
Batch: 600; loss: 0.51; acc: 0.83
Batch: 620; loss: 0.48; acc: 0.88
Batch: 640; loss: 0.44; acc: 0.88
Batch: 660; loss: 0.6; acc: 0.86
Batch: 680; loss: 0.53; acc: 0.86
Batch: 700; loss: 0.62; acc: 0.83
Batch: 720; loss: 0.46; acc: 0.84
Batch: 740; loss: 0.49; acc: 0.84
Batch: 760; loss: 0.47; acc: 0.84
Batch: 780; loss: 0.36; acc: 0.86
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

2.266669980599545e-05
9.239041901309974e-06
Batch: 0; loss: 0.28; acc: 0.92
Batch: 20; loss: 0.48; acc: 0.84
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.9; acc: 0.75
Batch: 80; loss: 0.3; acc: 0.94
Batch: 100; loss: 0.34; acc: 0.91
Batch: 120; loss: 0.63; acc: 0.81
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.3919500695292357; val_accuracy: 0.8807722929936306 

The current subspace-distance is: 9.239041901309974e-06 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.34; acc: 0.89
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.48; acc: 0.8
Batch: 80; loss: 0.34; acc: 0.92
Batch: 100; loss: 0.27; acc: 0.88
Batch: 120; loss: 0.41; acc: 0.84
Batch: 140; loss: 0.43; acc: 0.86
Batch: 160; loss: 0.51; acc: 0.88
Batch: 180; loss: 0.41; acc: 0.88
Batch: 200; loss: 0.23; acc: 0.92
Batch: 220; loss: 0.42; acc: 0.88
Batch: 240; loss: 0.36; acc: 0.89
Batch: 260; loss: 0.44; acc: 0.86
Batch: 280; loss: 0.34; acc: 0.84
Batch: 300; loss: 0.76; acc: 0.8
Batch: 320; loss: 0.21; acc: 0.94
Batch: 340; loss: 0.4; acc: 0.89
Batch: 360; loss: 0.46; acc: 0.81
Batch: 380; loss: 0.43; acc: 0.88
Batch: 400; loss: 0.26; acc: 0.89
Batch: 420; loss: 0.62; acc: 0.84
Batch: 440; loss: 0.47; acc: 0.84
Batch: 460; loss: 0.58; acc: 0.83
Batch: 480; loss: 0.46; acc: 0.78
Batch: 500; loss: 0.51; acc: 0.89
Batch: 520; loss: 0.45; acc: 0.88
Batch: 540; loss: 0.55; acc: 0.84
Batch: 560; loss: 0.36; acc: 0.86
Batch: 580; loss: 0.39; acc: 0.88
Batch: 600; loss: 0.36; acc: 0.86
Batch: 620; loss: 0.42; acc: 0.92
Batch: 640; loss: 0.12; acc: 0.98
Batch: 660; loss: 0.71; acc: 0.81
Batch: 680; loss: 0.24; acc: 0.94
Batch: 700; loss: 0.64; acc: 0.84
Batch: 720; loss: 0.29; acc: 0.92
Batch: 740; loss: 0.61; acc: 0.84
Batch: 760; loss: 0.35; acc: 0.89
Batch: 780; loss: 0.84; acc: 0.86
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

2.5534814994898625e-05
8.273213097709231e-06
Batch: 0; loss: 0.3; acc: 0.92
Batch: 20; loss: 0.46; acc: 0.84
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.95; acc: 0.73
Batch: 80; loss: 0.31; acc: 0.94
Batch: 100; loss: 0.31; acc: 0.92
Batch: 120; loss: 0.68; acc: 0.78
Batch: 140; loss: 0.15; acc: 0.94
Val Epoch over. val_loss: 0.39324769244831836; val_accuracy: 0.8808718152866242 

The current subspace-distance is: 8.273213097709231e-06 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.5; acc: 0.84
Batch: 20; loss: 0.33; acc: 0.88
Batch: 40; loss: 0.32; acc: 0.88
Batch: 60; loss: 0.35; acc: 0.91
Batch: 80; loss: 0.28; acc: 0.92
Batch: 100; loss: 0.32; acc: 0.92
Batch: 120; loss: 0.39; acc: 0.88
Batch: 140; loss: 0.47; acc: 0.86
Batch: 160; loss: 0.44; acc: 0.88
Batch: 180; loss: 0.44; acc: 0.84
Batch: 200; loss: 0.31; acc: 0.88
Batch: 220; loss: 0.35; acc: 0.86
Batch: 240; loss: 0.35; acc: 0.88
Batch: 260; loss: 0.77; acc: 0.77
Batch: 280; loss: 0.66; acc: 0.73
Batch: 300; loss: 0.47; acc: 0.88
Batch: 320; loss: 0.31; acc: 0.89
Batch: 340; loss: 0.36; acc: 0.91
Batch: 360; loss: 0.43; acc: 0.88
Batch: 380; loss: 0.41; acc: 0.88
Batch: 400; loss: 0.39; acc: 0.88
Batch: 420; loss: 0.43; acc: 0.83
Batch: 440; loss: 0.41; acc: 0.83
Batch: 460; loss: 0.53; acc: 0.8
Batch: 480; loss: 0.31; acc: 0.91
Batch: 500; loss: 0.21; acc: 0.94
Batch: 520; loss: 0.27; acc: 0.89
Batch: 540; loss: 0.21; acc: 0.92
Batch: 560; loss: 0.44; acc: 0.89
Batch: 580; loss: 0.5; acc: 0.8
Batch: 600; loss: 0.63; acc: 0.78
Batch: 620; loss: 0.52; acc: 0.81
Batch: 640; loss: 0.35; acc: 0.91
Batch: 660; loss: 0.28; acc: 0.91
Batch: 680; loss: 0.54; acc: 0.88
Batch: 700; loss: 0.48; acc: 0.84
Batch: 720; loss: 0.17; acc: 0.95
Batch: 740; loss: 0.29; acc: 0.91
Batch: 760; loss: 0.4; acc: 0.88
Batch: 780; loss: 0.4; acc: 0.81
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

2.358741949137766e-05
9.38092762226006e-06
Batch: 0; loss: 0.31; acc: 0.89
Batch: 20; loss: 0.46; acc: 0.84
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.97; acc: 0.73
Batch: 80; loss: 0.32; acc: 0.92
Batch: 100; loss: 0.3; acc: 0.89
Batch: 120; loss: 0.67; acc: 0.78
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.39421820747339803; val_accuracy: 0.8778861464968153 

The current subspace-distance is: 9.38092762226006e-06 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.45; acc: 0.88
Batch: 20; loss: 0.44; acc: 0.83
Batch: 40; loss: 0.34; acc: 0.92
Batch: 60; loss: 0.43; acc: 0.84
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.41; acc: 0.83
Batch: 120; loss: 0.34; acc: 0.91
Batch: 140; loss: 0.53; acc: 0.83
Batch: 160; loss: 0.54; acc: 0.84
Batch: 180; loss: 0.49; acc: 0.86
Batch: 200; loss: 0.18; acc: 0.97
Batch: 220; loss: 0.48; acc: 0.81
Batch: 240; loss: 0.32; acc: 0.91
Batch: 260; loss: 0.31; acc: 0.83
Batch: 280; loss: 0.32; acc: 0.88
Batch: 300; loss: 0.47; acc: 0.86
Batch: 320; loss: 0.43; acc: 0.84
Batch: 340; loss: 0.24; acc: 0.97
Batch: 360; loss: 0.4; acc: 0.86
Batch: 380; loss: 0.4; acc: 0.86
Batch: 400; loss: 0.32; acc: 0.88
Batch: 420; loss: 0.36; acc: 0.84
Batch: 440; loss: 0.84; acc: 0.78
Batch: 460; loss: 0.35; acc: 0.88
Batch: 480; loss: 0.25; acc: 0.92
Batch: 500; loss: 0.21; acc: 0.92
Batch: 520; loss: 0.41; acc: 0.91
Batch: 540; loss: 0.21; acc: 0.94
Batch: 560; loss: 0.32; acc: 0.89
Batch: 580; loss: 0.59; acc: 0.84
Batch: 600; loss: 0.39; acc: 0.86
Batch: 620; loss: 0.39; acc: 0.88
Batch: 640; loss: 0.54; acc: 0.81
Batch: 660; loss: 0.23; acc: 0.92
Batch: 680; loss: 0.27; acc: 0.92
Batch: 700; loss: 0.51; acc: 0.86
Batch: 720; loss: 0.46; acc: 0.86
Batch: 740; loss: 0.44; acc: 0.88
Batch: 760; loss: 0.36; acc: 0.89
Batch: 780; loss: 0.43; acc: 0.86
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

2.5019602617248893e-05
1.0892281352425925e-05
Batch: 0; loss: 0.25; acc: 0.92
Batch: 20; loss: 0.46; acc: 0.86
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.87; acc: 0.75
Batch: 80; loss: 0.29; acc: 0.94
Batch: 100; loss: 0.3; acc: 0.89
Batch: 120; loss: 0.65; acc: 0.8
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.38272206770007017; val_accuracy: 0.8852507961783439 

The current subspace-distance is: 1.0892281352425925e-05 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.3; acc: 0.89
Batch: 20; loss: 0.51; acc: 0.84
Batch: 40; loss: 0.36; acc: 0.86
Batch: 60; loss: 0.45; acc: 0.88
Batch: 80; loss: 0.53; acc: 0.81
Batch: 100; loss: 0.36; acc: 0.92
Batch: 120; loss: 0.7; acc: 0.8
Batch: 140; loss: 0.77; acc: 0.81
Batch: 160; loss: 0.49; acc: 0.83
Batch: 180; loss: 0.31; acc: 0.86
Batch: 200; loss: 0.46; acc: 0.86
Batch: 220; loss: 0.48; acc: 0.8
Batch: 240; loss: 0.49; acc: 0.83
Batch: 260; loss: 0.35; acc: 0.91
Batch: 280; loss: 0.32; acc: 0.88
Batch: 300; loss: 0.44; acc: 0.86
Batch: 320; loss: 0.36; acc: 0.88
Batch: 340; loss: 0.4; acc: 0.91
Batch: 360; loss: 0.35; acc: 0.94
Batch: 380; loss: 0.16; acc: 0.94
Batch: 400; loss: 0.35; acc: 0.86
Batch: 420; loss: 0.48; acc: 0.83
Batch: 440; loss: 0.37; acc: 0.88
Batch: 460; loss: 0.55; acc: 0.84
Batch: 480; loss: 0.33; acc: 0.89
Batch: 500; loss: 0.3; acc: 0.91
Batch: 520; loss: 0.4; acc: 0.84
Batch: 540; loss: 0.34; acc: 0.91
Batch: 560; loss: 0.55; acc: 0.88
Batch: 580; loss: 0.49; acc: 0.86
Batch: 600; loss: 0.57; acc: 0.8
Batch: 620; loss: 0.23; acc: 0.92
Batch: 640; loss: 0.6; acc: 0.81
Batch: 660; loss: 0.42; acc: 0.86
Batch: 680; loss: 0.16; acc: 0.98
Batch: 700; loss: 0.26; acc: 0.92
Batch: 720; loss: 0.53; acc: 0.88
Batch: 740; loss: 0.46; acc: 0.83
Batch: 760; loss: 0.64; acc: 0.83
Batch: 780; loss: 0.37; acc: 0.89
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

2.321383544767741e-05
9.219475032296032e-06
Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.46; acc: 0.86
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.88; acc: 0.73
Batch: 80; loss: 0.27; acc: 0.94
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.63; acc: 0.81
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.3790943887393186; val_accuracy: 0.8852507961783439 

The current subspace-distance is: 9.219475032296032e-06 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.34; acc: 0.94
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.39; acc: 0.88
Batch: 60; loss: 0.39; acc: 0.88
Batch: 80; loss: 0.51; acc: 0.83
Batch: 100; loss: 0.51; acc: 0.91
Batch: 120; loss: 0.53; acc: 0.84
Batch: 140; loss: 0.6; acc: 0.83
Batch: 160; loss: 0.39; acc: 0.83
Batch: 180; loss: 0.46; acc: 0.84
Batch: 200; loss: 0.48; acc: 0.86
Batch: 220; loss: 0.61; acc: 0.83
Batch: 240; loss: 0.37; acc: 0.86
Batch: 260; loss: 0.29; acc: 0.92
Batch: 280; loss: 0.55; acc: 0.92
Batch: 300; loss: 0.99; acc: 0.78
Batch: 320; loss: 0.25; acc: 0.92
Batch: 340; loss: 0.55; acc: 0.84
Batch: 360; loss: 0.32; acc: 0.91
Batch: 380; loss: 0.34; acc: 0.86
Batch: 400; loss: 0.46; acc: 0.84
Batch: 420; loss: 0.34; acc: 0.94
Batch: 440; loss: 0.47; acc: 0.86
Batch: 460; loss: 0.26; acc: 0.91
Batch: 480; loss: 0.33; acc: 0.91
Batch: 500; loss: 0.5; acc: 0.86
Batch: 520; loss: 0.27; acc: 0.92
Batch: 540; loss: 0.27; acc: 0.91
Batch: 560; loss: 0.32; acc: 0.95
Batch: 580; loss: 0.39; acc: 0.86
Batch: 600; loss: 0.4; acc: 0.84
Batch: 620; loss: 0.93; acc: 0.73
Batch: 640; loss: 0.35; acc: 0.89
Batch: 660; loss: 0.25; acc: 0.94
Batch: 680; loss: 0.41; acc: 0.86
Batch: 700; loss: 0.35; acc: 0.86
Batch: 720; loss: 0.41; acc: 0.84
Batch: 740; loss: 0.24; acc: 0.97
Batch: 760; loss: 0.26; acc: 0.88
Batch: 780; loss: 0.42; acc: 0.84
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

2.392282840446569e-05
8.910516953619663e-06
Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.46; acc: 0.86
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.9; acc: 0.75
Batch: 80; loss: 0.28; acc: 0.92
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.65; acc: 0.78
Batch: 140; loss: 0.12; acc: 0.95
Val Epoch over. val_loss: 0.38079999197440545; val_accuracy: 0.8844546178343949 

The current subspace-distance is: 8.910516953619663e-06 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.33; acc: 0.88
Batch: 20; loss: 0.34; acc: 0.89
Batch: 40; loss: 0.37; acc: 0.84
Batch: 60; loss: 0.31; acc: 0.91
Batch: 80; loss: 0.47; acc: 0.88
Batch: 100; loss: 0.32; acc: 0.88
Batch: 120; loss: 0.36; acc: 0.89
Batch: 140; loss: 0.58; acc: 0.84
Batch: 160; loss: 0.33; acc: 0.92
Batch: 180; loss: 0.45; acc: 0.86
Batch: 200; loss: 0.39; acc: 0.91
Batch: 220; loss: 0.58; acc: 0.86
Batch: 240; loss: 0.57; acc: 0.81
Batch: 260; loss: 0.37; acc: 0.88
Batch: 280; loss: 0.34; acc: 0.88
Batch: 300; loss: 0.53; acc: 0.83
Batch: 320; loss: 0.43; acc: 0.86
Batch: 340; loss: 0.4; acc: 0.89
Batch: 360; loss: 0.33; acc: 0.88
Batch: 380; loss: 0.41; acc: 0.88
Batch: 400; loss: 0.54; acc: 0.81
Batch: 420; loss: 0.51; acc: 0.86
Batch: 440; loss: 0.36; acc: 0.89
Batch: 460; loss: 0.63; acc: 0.89
Batch: 480; loss: 0.37; acc: 0.89
Batch: 500; loss: 0.31; acc: 0.89
Batch: 520; loss: 0.26; acc: 0.94
Batch: 540; loss: 0.3; acc: 0.92
Batch: 560; loss: 0.29; acc: 0.91
Batch: 580; loss: 0.39; acc: 0.91
Batch: 600; loss: 0.36; acc: 0.92
Batch: 620; loss: 0.45; acc: 0.83
Batch: 640; loss: 0.47; acc: 0.89
Batch: 660; loss: 0.47; acc: 0.84
Batch: 680; loss: 0.71; acc: 0.8
Batch: 700; loss: 0.32; acc: 0.89
Batch: 720; loss: 0.59; acc: 0.84
Batch: 740; loss: 0.38; acc: 0.86
Batch: 760; loss: 0.53; acc: 0.83
Batch: 780; loss: 0.57; acc: 0.8
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

2.3573878934257664e-05
1.0006327102018986e-05
Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.45; acc: 0.83
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.87; acc: 0.75
Batch: 80; loss: 0.28; acc: 0.94
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.64; acc: 0.8
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.37782132910315397; val_accuracy: 0.8852507961783439 

The current subspace-distance is: 1.0006327102018986e-05 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.42; acc: 0.89
Batch: 20; loss: 0.59; acc: 0.89
Batch: 40; loss: 0.54; acc: 0.78
Batch: 60; loss: 0.37; acc: 0.84
Batch: 80; loss: 0.34; acc: 0.88
Batch: 100; loss: 0.35; acc: 0.92
Batch: 120; loss: 0.49; acc: 0.83
Batch: 140; loss: 0.55; acc: 0.81
Batch: 160; loss: 0.51; acc: 0.8
Batch: 180; loss: 0.4; acc: 0.88
Batch: 200; loss: 0.4; acc: 0.86
Batch: 220; loss: 0.59; acc: 0.83
Batch: 240; loss: 0.3; acc: 0.88
Batch: 260; loss: 0.29; acc: 0.91
Batch: 280; loss: 0.41; acc: 0.88
Batch: 300; loss: 0.44; acc: 0.86
Batch: 320; loss: 0.39; acc: 0.84
Batch: 340; loss: 0.52; acc: 0.83
Batch: 360; loss: 0.28; acc: 0.92
Batch: 380; loss: 0.27; acc: 0.92
Batch: 400; loss: 0.61; acc: 0.88
Batch: 420; loss: 0.42; acc: 0.91
Batch: 440; loss: 0.46; acc: 0.83
Batch: 460; loss: 0.34; acc: 0.92
Batch: 480; loss: 0.27; acc: 0.89
Batch: 500; loss: 0.37; acc: 0.91
Batch: 520; loss: 0.32; acc: 0.94
Batch: 540; loss: 0.46; acc: 0.89
Batch: 560; loss: 0.46; acc: 0.81
Batch: 580; loss: 0.28; acc: 0.91
Batch: 600; loss: 0.43; acc: 0.84
Batch: 620; loss: 0.31; acc: 0.88
Batch: 640; loss: 0.36; acc: 0.88
Batch: 660; loss: 0.57; acc: 0.83
Batch: 680; loss: 0.53; acc: 0.81
Batch: 700; loss: 0.63; acc: 0.78
Batch: 720; loss: 0.35; acc: 0.91
Batch: 740; loss: 0.49; acc: 0.83
Batch: 760; loss: 0.36; acc: 0.88
Batch: 780; loss: 0.29; acc: 0.91
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

2.4209468392655253e-05
9.175506420433521e-06
Batch: 0; loss: 0.29; acc: 0.92
Batch: 20; loss: 0.43; acc: 0.86
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.94; acc: 0.73
Batch: 80; loss: 0.31; acc: 0.94
Batch: 100; loss: 0.32; acc: 0.91
Batch: 120; loss: 0.66; acc: 0.81
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.38318236679977674; val_accuracy: 0.8835589171974523 

The current subspace-distance is: 9.175506420433521e-06 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.66; acc: 0.88
Batch: 20; loss: 0.35; acc: 0.89
Batch: 40; loss: 0.44; acc: 0.91
Batch: 60; loss: 0.38; acc: 0.83
Batch: 80; loss: 0.41; acc: 0.89
Batch: 100; loss: 0.37; acc: 0.91
Batch: 120; loss: 0.43; acc: 0.89
Batch: 140; loss: 0.35; acc: 0.92
Batch: 160; loss: 0.4; acc: 0.92
Batch: 180; loss: 0.32; acc: 0.89
Batch: 200; loss: 0.41; acc: 0.88
Batch: 220; loss: 0.56; acc: 0.84
Batch: 240; loss: 0.59; acc: 0.81
Batch: 260; loss: 0.51; acc: 0.83
Batch: 280; loss: 0.61; acc: 0.78
Batch: 300; loss: 0.31; acc: 0.91
Batch: 320; loss: 0.45; acc: 0.91
Batch: 340; loss: 0.37; acc: 0.91
Batch: 360; loss: 0.37; acc: 0.84
Batch: 380; loss: 0.25; acc: 0.94
Batch: 400; loss: 0.66; acc: 0.78
Batch: 420; loss: 0.43; acc: 0.88
Batch: 440; loss: 0.64; acc: 0.84
Batch: 460; loss: 0.33; acc: 0.91
Batch: 480; loss: 0.4; acc: 0.89
Batch: 500; loss: 0.26; acc: 0.94
Batch: 520; loss: 0.52; acc: 0.88
Batch: 540; loss: 0.42; acc: 0.86
Batch: 560; loss: 0.32; acc: 0.91
Batch: 580; loss: 0.51; acc: 0.89
Batch: 600; loss: 0.46; acc: 0.89
Batch: 620; loss: 0.36; acc: 0.89
Batch: 640; loss: 0.42; acc: 0.84
Batch: 660; loss: 0.25; acc: 0.91
Batch: 680; loss: 0.47; acc: 0.88
Batch: 700; loss: 0.3; acc: 0.89
Batch: 720; loss: 0.45; acc: 0.88
Batch: 740; loss: 0.48; acc: 0.84
Batch: 760; loss: 0.41; acc: 0.89
Batch: 780; loss: 0.43; acc: 0.84
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

2.178662361984607e-05
8.743730177229736e-06
Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.45; acc: 0.88
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.91; acc: 0.73
Batch: 80; loss: 0.29; acc: 0.94
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.64; acc: 0.78
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.3780907595138641; val_accuracy: 0.8858479299363057 

The current subspace-distance is: 8.743730177229736e-06 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.66; acc: 0.8
Batch: 40; loss: 0.41; acc: 0.86
Batch: 60; loss: 0.4; acc: 0.88
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.38; acc: 0.88
Batch: 120; loss: 0.48; acc: 0.86
Batch: 140; loss: 0.34; acc: 0.86
Batch: 160; loss: 0.34; acc: 0.89
Batch: 180; loss: 0.54; acc: 0.89
Batch: 200; loss: 0.33; acc: 0.92
Batch: 220; loss: 0.47; acc: 0.84
Batch: 240; loss: 0.33; acc: 0.89
Batch: 260; loss: 0.33; acc: 0.89
Batch: 280; loss: 0.68; acc: 0.86
Batch: 300; loss: 0.66; acc: 0.8
Batch: 320; loss: 0.49; acc: 0.8
Batch: 340; loss: 0.44; acc: 0.92
Batch: 360; loss: 0.45; acc: 0.81
Batch: 380; loss: 0.53; acc: 0.8
Batch: 400; loss: 0.19; acc: 0.97
Batch: 420; loss: 0.25; acc: 0.94
Batch: 440; loss: 0.46; acc: 0.88
Batch: 460; loss: 0.34; acc: 0.92
Batch: 480; loss: 0.4; acc: 0.89
Batch: 500; loss: 0.38; acc: 0.92
Batch: 520; loss: 0.34; acc: 0.89
Batch: 540; loss: 0.37; acc: 0.84
Batch: 560; loss: 0.36; acc: 0.86
Batch: 580; loss: 0.69; acc: 0.83
Batch: 600; loss: 0.46; acc: 0.88
Batch: 620; loss: 0.46; acc: 0.86
Batch: 640; loss: 0.78; acc: 0.75
Batch: 660; loss: 0.36; acc: 0.89
Batch: 680; loss: 0.34; acc: 0.86
Batch: 700; loss: 0.21; acc: 0.94
Batch: 720; loss: 0.43; acc: 0.86
Batch: 740; loss: 0.43; acc: 0.84
Batch: 760; loss: 0.43; acc: 0.83
Batch: 780; loss: 0.67; acc: 0.8
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

2.2945067030377686e-05
9.960043826140463e-06
Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.46; acc: 0.83
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.88; acc: 0.77
Batch: 80; loss: 0.28; acc: 0.95
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.67; acc: 0.81
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.38059720658003143; val_accuracy: 0.8845541401273885 

The current subspace-distance is: 9.960043826140463e-06 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.4; acc: 0.91
Batch: 20; loss: 0.58; acc: 0.88
Batch: 40; loss: 0.35; acc: 0.88
Batch: 60; loss: 0.44; acc: 0.86
Batch: 80; loss: 0.18; acc: 0.92
Batch: 100; loss: 0.41; acc: 0.89
Batch: 120; loss: 0.27; acc: 0.92
Batch: 140; loss: 0.24; acc: 0.94
Batch: 160; loss: 0.4; acc: 0.83
Batch: 180; loss: 0.4; acc: 0.89
Batch: 200; loss: 0.51; acc: 0.84
Batch: 220; loss: 0.51; acc: 0.83
Batch: 240; loss: 0.27; acc: 0.94
Batch: 260; loss: 0.41; acc: 0.81
Batch: 280; loss: 0.28; acc: 0.92
Batch: 300; loss: 0.56; acc: 0.86
Batch: 320; loss: 0.56; acc: 0.81
Batch: 340; loss: 0.58; acc: 0.84
Batch: 360; loss: 0.34; acc: 0.89
Batch: 380; loss: 0.29; acc: 0.92
Batch: 400; loss: 0.37; acc: 0.89
Batch: 420; loss: 0.47; acc: 0.89
Batch: 440; loss: 0.31; acc: 0.88
Batch: 460; loss: 0.4; acc: 0.89
Batch: 480; loss: 0.37; acc: 0.94
Batch: 500; loss: 0.3; acc: 0.91
Batch: 520; loss: 0.44; acc: 0.84
Batch: 540; loss: 0.64; acc: 0.83
Batch: 560; loss: 0.36; acc: 0.88
Batch: 580; loss: 0.64; acc: 0.88
Batch: 600; loss: 0.34; acc: 0.89
Batch: 620; loss: 0.33; acc: 0.86
Batch: 640; loss: 0.54; acc: 0.86
Batch: 660; loss: 0.37; acc: 0.88
Batch: 680; loss: 0.39; acc: 0.89
Batch: 700; loss: 0.53; acc: 0.84
Batch: 720; loss: 0.46; acc: 0.86
Batch: 740; loss: 0.4; acc: 0.92
Batch: 760; loss: 0.29; acc: 0.94
Batch: 780; loss: 0.55; acc: 0.8
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

2.4695926185813732e-05
1.0745094186859205e-05
Batch: 0; loss: 0.27; acc: 0.94
Batch: 20; loss: 0.48; acc: 0.86
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.9; acc: 0.75
Batch: 80; loss: 0.29; acc: 0.94
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.64; acc: 0.81
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.3793606460094452; val_accuracy: 0.884952229299363 

The current subspace-distance is: 1.0745094186859205e-05 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.23; acc: 0.92
Batch: 20; loss: 0.45; acc: 0.86
Batch: 40; loss: 0.32; acc: 0.86
Batch: 60; loss: 0.41; acc: 0.92
Batch: 80; loss: 0.26; acc: 0.92
Batch: 100; loss: 0.35; acc: 0.92
Batch: 120; loss: 0.54; acc: 0.88
Batch: 140; loss: 0.6; acc: 0.78
Batch: 160; loss: 0.39; acc: 0.83
Batch: 180; loss: 0.25; acc: 0.89
Batch: 200; loss: 0.37; acc: 0.91
Batch: 220; loss: 0.47; acc: 0.84
Batch: 240; loss: 0.39; acc: 0.89
Batch: 260; loss: 0.41; acc: 0.86
Batch: 280; loss: 0.55; acc: 0.81
Batch: 300; loss: 0.21; acc: 0.92
Batch: 320; loss: 0.39; acc: 0.89
Batch: 340; loss: 0.45; acc: 0.86
Batch: 360; loss: 0.33; acc: 0.88
Batch: 380; loss: 0.32; acc: 0.95
Batch: 400; loss: 0.25; acc: 0.92
Batch: 420; loss: 0.44; acc: 0.86
Batch: 440; loss: 0.44; acc: 0.84
Batch: 460; loss: 0.35; acc: 0.88
Batch: 480; loss: 0.32; acc: 0.92
Batch: 500; loss: 0.24; acc: 0.92
Batch: 520; loss: 0.57; acc: 0.88
Batch: 540; loss: 0.55; acc: 0.86
Batch: 560; loss: 0.46; acc: 0.88
Batch: 580; loss: 0.26; acc: 0.91
Batch: 600; loss: 0.58; acc: 0.84
Batch: 620; loss: 0.39; acc: 0.83
Batch: 640; loss: 0.3; acc: 0.91
Batch: 660; loss: 0.44; acc: 0.84
Batch: 680; loss: 0.25; acc: 0.91
Batch: 700; loss: 0.55; acc: 0.81
Batch: 720; loss: 0.18; acc: 0.94
Batch: 740; loss: 0.22; acc: 0.94
Batch: 760; loss: 0.34; acc: 0.89
Batch: 780; loss: 0.41; acc: 0.88
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

2.3830019927117974e-05
8.609818905824795e-06
Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.47; acc: 0.86
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.9; acc: 0.77
Batch: 80; loss: 0.29; acc: 0.92
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.65; acc: 0.8
Batch: 140; loss: 0.1; acc: 0.98
Val Epoch over. val_loss: 0.38186583034456917; val_accuracy: 0.8839570063694268 

The current subspace-distance is: 8.609818905824795e-06 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.61; acc: 0.83
Batch: 20; loss: 0.69; acc: 0.83
Batch: 40; loss: 0.35; acc: 0.91
Batch: 60; loss: 0.21; acc: 0.97
Batch: 80; loss: 0.51; acc: 0.83
Batch: 100; loss: 0.36; acc: 0.86
Batch: 120; loss: 0.48; acc: 0.84
Batch: 140; loss: 0.42; acc: 0.91
Batch: 160; loss: 0.27; acc: 0.94
Batch: 180; loss: 0.31; acc: 0.86
Batch: 200; loss: 0.46; acc: 0.83
Batch: 220; loss: 0.3; acc: 0.88
Batch: 240; loss: 0.43; acc: 0.86
Batch: 260; loss: 0.64; acc: 0.81
Batch: 280; loss: 0.37; acc: 0.89
Batch: 300; loss: 0.54; acc: 0.75
Batch: 320; loss: 0.44; acc: 0.91
Batch: 340; loss: 0.44; acc: 0.89
Batch: 360; loss: 0.16; acc: 0.98
Batch: 380; loss: 0.35; acc: 0.84
Batch: 400; loss: 0.25; acc: 0.95
Batch: 420; loss: 0.46; acc: 0.88
Batch: 440; loss: 0.11; acc: 0.98
Batch: 460; loss: 0.28; acc: 0.89
Batch: 480; loss: 0.26; acc: 0.89
Batch: 500; loss: 0.37; acc: 0.91
Batch: 520; loss: 0.47; acc: 0.86
Batch: 540; loss: 0.29; acc: 0.92
Batch: 560; loss: 0.59; acc: 0.84
Batch: 580; loss: 0.59; acc: 0.8
Batch: 600; loss: 0.34; acc: 0.92
Batch: 620; loss: 0.53; acc: 0.86
Batch: 640; loss: 0.27; acc: 0.88
Batch: 660; loss: 0.29; acc: 0.88
Batch: 680; loss: 0.37; acc: 0.81
Batch: 700; loss: 0.48; acc: 0.78
Batch: 720; loss: 0.49; acc: 0.89
Batch: 740; loss: 0.47; acc: 0.84
Batch: 760; loss: 0.22; acc: 0.94
Batch: 780; loss: 0.36; acc: 0.88
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

2.2789661670685746e-05
9.421563845535275e-06
Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.46; acc: 0.83
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.91; acc: 0.75
Batch: 80; loss: 0.29; acc: 0.94
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.65; acc: 0.81
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.37789559857860494; val_accuracy: 0.8854498407643312 

The current subspace-distance is: 9.421563845535275e-06 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.33; acc: 0.84
Batch: 20; loss: 0.35; acc: 0.88
Batch: 40; loss: 0.26; acc: 0.91
Batch: 60; loss: 0.62; acc: 0.8
Batch: 80; loss: 0.28; acc: 0.89
Batch: 100; loss: 0.33; acc: 0.91
Batch: 120; loss: 0.3; acc: 0.92
Batch: 140; loss: 0.4; acc: 0.83
Batch: 160; loss: 0.59; acc: 0.83
Batch: 180; loss: 0.4; acc: 0.88
Batch: 200; loss: 0.28; acc: 0.89
Batch: 220; loss: 0.35; acc: 0.91
Batch: 240; loss: 0.44; acc: 0.86
Batch: 260; loss: 0.52; acc: 0.8
Batch: 280; loss: 0.52; acc: 0.78
Batch: 300; loss: 0.5; acc: 0.84
Batch: 320; loss: 0.45; acc: 0.89
Batch: 340; loss: 0.57; acc: 0.83
Batch: 360; loss: 0.32; acc: 0.89
Batch: 380; loss: 0.49; acc: 0.83
Batch: 400; loss: 0.36; acc: 0.88
Batch: 420; loss: 0.39; acc: 0.88
Batch: 440; loss: 0.53; acc: 0.84
Batch: 460; loss: 0.32; acc: 0.91
Batch: 480; loss: 0.37; acc: 0.81
Batch: 500; loss: 0.59; acc: 0.84
Batch: 520; loss: 0.3; acc: 0.92
Batch: 540; loss: 0.26; acc: 0.92
Batch: 560; loss: 0.25; acc: 0.88
Batch: 580; loss: 0.65; acc: 0.8
Batch: 600; loss: 0.44; acc: 0.86
Batch: 620; loss: 0.47; acc: 0.86
Batch: 640; loss: 0.36; acc: 0.89
Batch: 660; loss: 0.33; acc: 0.91
Batch: 680; loss: 0.45; acc: 0.89
Batch: 700; loss: 0.38; acc: 0.88
Batch: 720; loss: 0.38; acc: 0.91
Batch: 740; loss: 0.69; acc: 0.8
Batch: 760; loss: 0.32; acc: 0.86
Batch: 780; loss: 0.49; acc: 0.88
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

2.5601380912121385e-05
1.0122509593202267e-05
Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.44; acc: 0.86
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.93; acc: 0.73
Batch: 80; loss: 0.29; acc: 0.94
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.64; acc: 0.83
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.379349775802178; val_accuracy: 0.8852507961783439 

The current subspace-distance is: 1.0122509593202267e-05 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.52; acc: 0.83
Batch: 20; loss: 0.47; acc: 0.86
Batch: 40; loss: 0.41; acc: 0.84
Batch: 60; loss: 0.42; acc: 0.83
Batch: 80; loss: 0.41; acc: 0.86
Batch: 100; loss: 0.51; acc: 0.84
Batch: 120; loss: 0.41; acc: 0.92
Batch: 140; loss: 0.53; acc: 0.84
Batch: 160; loss: 0.5; acc: 0.83
Batch: 180; loss: 0.62; acc: 0.83
Batch: 200; loss: 0.31; acc: 0.89
Batch: 220; loss: 0.48; acc: 0.88
Batch: 240; loss: 0.5; acc: 0.83
Batch: 260; loss: 0.38; acc: 0.88
Batch: 280; loss: 0.56; acc: 0.89
Batch: 300; loss: 0.43; acc: 0.89
Batch: 320; loss: 0.35; acc: 0.86
Batch: 340; loss: 0.25; acc: 0.97
Batch: 360; loss: 0.66; acc: 0.91
Batch: 380; loss: 0.47; acc: 0.88
Batch: 400; loss: 0.38; acc: 0.91
Batch: 420; loss: 0.36; acc: 0.89
Batch: 440; loss: 0.43; acc: 0.86
Batch: 460; loss: 0.37; acc: 0.88
Batch: 480; loss: 0.21; acc: 0.92
Batch: 500; loss: 0.32; acc: 0.88
Batch: 520; loss: 0.34; acc: 0.89
Batch: 540; loss: 0.22; acc: 0.97
Batch: 560; loss: 0.47; acc: 0.84
Batch: 580; loss: 0.48; acc: 0.86
Batch: 600; loss: 0.45; acc: 0.81
Batch: 620; loss: 0.24; acc: 0.97
Batch: 640; loss: 0.3; acc: 0.94
Batch: 660; loss: 0.53; acc: 0.84
Batch: 680; loss: 0.54; acc: 0.86
Batch: 700; loss: 0.42; acc: 0.91
Batch: 720; loss: 0.64; acc: 0.83
Batch: 740; loss: 0.31; acc: 0.92
Batch: 760; loss: 0.22; acc: 0.95
Batch: 780; loss: 0.24; acc: 0.92
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

2.3603659428772517e-05
8.130882633849978e-06
Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.43; acc: 0.86
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.9; acc: 0.75
Batch: 80; loss: 0.29; acc: 0.95
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.63; acc: 0.83
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.3764671524096826; val_accuracy: 0.8864450636942676 

The current subspace-distance is: 8.130882633849978e-06 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.35; acc: 0.88
Batch: 20; loss: 0.34; acc: 0.88
Batch: 40; loss: 0.48; acc: 0.83
Batch: 60; loss: 0.41; acc: 0.86
Batch: 80; loss: 0.47; acc: 0.91
Batch: 100; loss: 0.61; acc: 0.81
Batch: 120; loss: 0.67; acc: 0.8
Batch: 140; loss: 0.45; acc: 0.89
Batch: 160; loss: 0.42; acc: 0.84
Batch: 180; loss: 0.46; acc: 0.86
Batch: 200; loss: 0.42; acc: 0.89
Batch: 220; loss: 0.4; acc: 0.88
Batch: 240; loss: 0.4; acc: 0.86
Batch: 260; loss: 0.47; acc: 0.88
Batch: 280; loss: 0.42; acc: 0.92
Batch: 300; loss: 0.28; acc: 0.91
Batch: 320; loss: 0.47; acc: 0.83
Batch: 340; loss: 0.29; acc: 0.88
Batch: 360; loss: 0.34; acc: 0.92
Batch: 380; loss: 0.38; acc: 0.91
Batch: 400; loss: 0.44; acc: 0.91
Batch: 420; loss: 0.32; acc: 0.89
Batch: 440; loss: 0.39; acc: 0.81
Batch: 460; loss: 0.36; acc: 0.88
Batch: 480; loss: 0.3; acc: 0.91
Batch: 500; loss: 0.35; acc: 0.91
Batch: 520; loss: 0.54; acc: 0.84
Batch: 540; loss: 0.4; acc: 0.86
Batch: 560; loss: 0.42; acc: 0.88
Batch: 580; loss: 0.59; acc: 0.81
Batch: 600; loss: 0.64; acc: 0.84
Batch: 620; loss: 0.36; acc: 0.89
Batch: 640; loss: 0.3; acc: 0.89
Batch: 660; loss: 0.63; acc: 0.75
Batch: 680; loss: 0.4; acc: 0.88
Batch: 700; loss: 0.3; acc: 0.91
Batch: 720; loss: 0.36; acc: 0.86
Batch: 740; loss: 0.24; acc: 0.91
Batch: 760; loss: 0.27; acc: 0.91
Batch: 780; loss: 0.47; acc: 0.91
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

2.3553497157990932e-05
8.788142622506712e-06
Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.44; acc: 0.88
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.89; acc: 0.73
Batch: 80; loss: 0.27; acc: 0.95
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.62; acc: 0.83
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.3768275327933062; val_accuracy: 0.8846536624203821 

The current subspace-distance is: 8.788142622506712e-06 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.4; acc: 0.88
Batch: 20; loss: 0.56; acc: 0.88
Batch: 40; loss: 0.52; acc: 0.89
Batch: 60; loss: 0.42; acc: 0.86
Batch: 80; loss: 0.34; acc: 0.91
Batch: 100; loss: 0.33; acc: 0.88
Batch: 120; loss: 0.35; acc: 0.86
Batch: 140; loss: 0.32; acc: 0.89
Batch: 160; loss: 0.23; acc: 0.92
Batch: 180; loss: 0.57; acc: 0.8
Batch: 200; loss: 0.35; acc: 0.89
Batch: 220; loss: 0.32; acc: 0.92
Batch: 240; loss: 0.57; acc: 0.83
Batch: 260; loss: 0.47; acc: 0.89
Batch: 280; loss: 0.34; acc: 0.83
Batch: 300; loss: 0.36; acc: 0.86
Batch: 320; loss: 0.42; acc: 0.89
Batch: 340; loss: 0.47; acc: 0.91
Batch: 360; loss: 0.32; acc: 0.86
Batch: 380; loss: 0.32; acc: 0.88
Batch: 400; loss: 0.27; acc: 0.86
Batch: 420; loss: 0.46; acc: 0.89
Batch: 440; loss: 0.23; acc: 0.95
Batch: 460; loss: 0.38; acc: 0.88
Batch: 480; loss: 0.29; acc: 0.89
Batch: 500; loss: 0.45; acc: 0.89
Batch: 520; loss: 0.54; acc: 0.89
Batch: 540; loss: 0.41; acc: 0.84
Batch: 560; loss: 0.26; acc: 0.91
Batch: 580; loss: 0.4; acc: 0.86
Batch: 600; loss: 0.58; acc: 0.86
Batch: 620; loss: 0.31; acc: 0.91
Batch: 640; loss: 0.18; acc: 0.97
Batch: 660; loss: 0.36; acc: 0.88
Batch: 680; loss: 0.44; acc: 0.88
Batch: 700; loss: 0.26; acc: 0.94
Batch: 720; loss: 0.5; acc: 0.86
Batch: 740; loss: 0.41; acc: 0.89
Batch: 760; loss: 0.42; acc: 0.88
Batch: 780; loss: 0.4; acc: 0.88
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

2.3546414013253525e-05
8.776713912084233e-06
Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.45; acc: 0.84
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.89; acc: 0.75
Batch: 80; loss: 0.28; acc: 0.95
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.64; acc: 0.8
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.3771230951188856; val_accuracy: 0.8870421974522293 

The current subspace-distance is: 8.776713912084233e-06 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.4; acc: 0.84
Batch: 20; loss: 0.68; acc: 0.8
Batch: 40; loss: 0.24; acc: 0.91
Batch: 60; loss: 0.71; acc: 0.84
Batch: 80; loss: 0.35; acc: 0.86
Batch: 100; loss: 0.57; acc: 0.84
Batch: 120; loss: 0.31; acc: 0.89
Batch: 140; loss: 0.41; acc: 0.92
Batch: 160; loss: 0.43; acc: 0.91
Batch: 180; loss: 0.45; acc: 0.84
Batch: 200; loss: 0.46; acc: 0.88
Batch: 220; loss: 0.34; acc: 0.91
Batch: 240; loss: 0.69; acc: 0.81
Batch: 260; loss: 0.66; acc: 0.83
Batch: 280; loss: 0.43; acc: 0.84
Batch: 300; loss: 0.37; acc: 0.88
Batch: 320; loss: 0.33; acc: 0.91
Batch: 340; loss: 0.4; acc: 0.83
Batch: 360; loss: 0.39; acc: 0.84
Batch: 380; loss: 0.38; acc: 0.88
Batch: 400; loss: 0.71; acc: 0.77
Batch: 420; loss: 0.48; acc: 0.84
Batch: 440; loss: 0.46; acc: 0.88
Batch: 460; loss: 0.33; acc: 0.89
Batch: 480; loss: 0.57; acc: 0.83
Batch: 500; loss: 0.71; acc: 0.78
Batch: 520; loss: 0.46; acc: 0.84
Batch: 540; loss: 0.51; acc: 0.86
Batch: 560; loss: 0.35; acc: 0.88
Batch: 580; loss: 0.61; acc: 0.83
Batch: 600; loss: 0.45; acc: 0.88
Batch: 620; loss: 0.44; acc: 0.89
Batch: 640; loss: 0.6; acc: 0.75
Batch: 660; loss: 0.59; acc: 0.78
Batch: 680; loss: 0.27; acc: 0.94
Batch: 700; loss: 0.5; acc: 0.83
Batch: 720; loss: 0.35; acc: 0.89
Batch: 740; loss: 0.8; acc: 0.8
Batch: 760; loss: 0.28; acc: 0.89
Batch: 780; loss: 0.43; acc: 0.88
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

2.198136098741088e-05
8.967968824435957e-06
Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.47; acc: 0.84
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.89; acc: 0.73
Batch: 80; loss: 0.28; acc: 0.94
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.62; acc: 0.84
Batch: 140; loss: 0.1; acc: 0.98
Val Epoch over. val_loss: 0.37840034874381534; val_accuracy: 0.8853503184713376 

The current subspace-distance is: 8.967968824435957e-06 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.22; acc: 0.95
Batch: 20; loss: 0.27; acc: 0.89
Batch: 40; loss: 0.39; acc: 0.88
Batch: 60; loss: 0.54; acc: 0.84
Batch: 80; loss: 0.43; acc: 0.88
Batch: 100; loss: 0.42; acc: 0.89
Batch: 120; loss: 0.57; acc: 0.83
Batch: 140; loss: 0.23; acc: 0.95
Batch: 160; loss: 0.22; acc: 0.95
Batch: 180; loss: 0.25; acc: 0.94
Batch: 200; loss: 0.68; acc: 0.86
Batch: 220; loss: 0.29; acc: 0.89
Batch: 240; loss: 0.64; acc: 0.78
Batch: 260; loss: 0.6; acc: 0.84
Batch: 280; loss: 0.83; acc: 0.83
Batch: 300; loss: 0.33; acc: 0.88
Batch: 320; loss: 0.32; acc: 0.88
Batch: 340; loss: 0.31; acc: 0.94
Batch: 360; loss: 0.33; acc: 0.91
Batch: 380; loss: 0.3; acc: 0.84
Batch: 400; loss: 0.41; acc: 0.88
Batch: 420; loss: 0.42; acc: 0.88
Batch: 440; loss: 0.38; acc: 0.88
Batch: 460; loss: 0.39; acc: 0.83
Batch: 480; loss: 0.4; acc: 0.86
Batch: 500; loss: 0.38; acc: 0.92
Batch: 520; loss: 0.26; acc: 0.91
Batch: 540; loss: 0.49; acc: 0.84
Batch: 560; loss: 0.18; acc: 0.94
Batch: 580; loss: 0.33; acc: 0.95
Batch: 600; loss: 0.36; acc: 0.88
Batch: 620; loss: 0.33; acc: 0.88
Batch: 640; loss: 0.32; acc: 0.88
Batch: 660; loss: 0.47; acc: 0.88
Batch: 680; loss: 0.7; acc: 0.84
Batch: 700; loss: 0.41; acc: 0.88
Batch: 720; loss: 0.68; acc: 0.8
Batch: 740; loss: 0.45; acc: 0.83
Batch: 760; loss: 0.53; acc: 0.83
Batch: 780; loss: 0.4; acc: 0.91
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

2.3952539777383208e-05
9.826363566389773e-06
Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.45; acc: 0.84
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.88; acc: 0.75
Batch: 80; loss: 0.28; acc: 0.95
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.63; acc: 0.81
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.37709546611187567; val_accuracy: 0.8853503184713376 

The current subspace-distance is: 9.826363566389773e-06 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.44; acc: 0.88
Batch: 20; loss: 0.38; acc: 0.92
Batch: 40; loss: 0.32; acc: 0.91
Batch: 60; loss: 0.27; acc: 0.91
Batch: 80; loss: 0.5; acc: 0.88
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.49; acc: 0.86
Batch: 140; loss: 0.54; acc: 0.81
Batch: 160; loss: 0.35; acc: 0.91
Batch: 180; loss: 0.23; acc: 0.92
Batch: 200; loss: 0.21; acc: 0.94
Batch: 220; loss: 0.52; acc: 0.89
Batch: 240; loss: 0.38; acc: 0.88
Batch: 260; loss: 0.43; acc: 0.88
Batch: 280; loss: 0.66; acc: 0.8
Batch: 300; loss: 0.54; acc: 0.89
Batch: 320; loss: 0.73; acc: 0.84
Batch: 340; loss: 0.39; acc: 0.81
Batch: 360; loss: 0.38; acc: 0.86
Batch: 380; loss: 0.51; acc: 0.81
Batch: 400; loss: 0.34; acc: 0.91
Batch: 420; loss: 0.53; acc: 0.88
Batch: 440; loss: 0.4; acc: 0.86
Batch: 460; loss: 0.5; acc: 0.88
Batch: 480; loss: 0.38; acc: 0.88
Batch: 500; loss: 0.37; acc: 0.88
Batch: 520; loss: 0.61; acc: 0.83
Batch: 540; loss: 0.77; acc: 0.81
Batch: 560; loss: 0.5; acc: 0.8
Batch: 580; loss: 0.5; acc: 0.83
Batch: 600; loss: 0.31; acc: 0.89
Batch: 620; loss: 0.44; acc: 0.86
Batch: 640; loss: 0.35; acc: 0.89
Batch: 660; loss: 0.43; acc: 0.86
Batch: 680; loss: 0.31; acc: 0.92
Batch: 700; loss: 0.31; acc: 0.91
Batch: 720; loss: 0.37; acc: 0.91
Batch: 740; loss: 0.38; acc: 0.92
Batch: 760; loss: 0.59; acc: 0.86
Batch: 780; loss: 0.49; acc: 0.88
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

2.3327285816776566e-05
1.0125881090061739e-05
Batch: 0; loss: 0.25; acc: 0.92
Batch: 20; loss: 0.46; acc: 0.84
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.89; acc: 0.75
Batch: 80; loss: 0.29; acc: 0.94
Batch: 100; loss: 0.3; acc: 0.89
Batch: 120; loss: 0.63; acc: 0.81
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.37818942926112253; val_accuracy: 0.8845541401273885 

The current subspace-distance is: 1.0125881090061739e-05 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.44; acc: 0.92
Batch: 20; loss: 0.47; acc: 0.89
Batch: 40; loss: 0.39; acc: 0.88
Batch: 60; loss: 0.36; acc: 0.84
Batch: 80; loss: 0.54; acc: 0.86
Batch: 100; loss: 0.7; acc: 0.8
Batch: 120; loss: 0.32; acc: 0.84
Batch: 140; loss: 0.62; acc: 0.83
Batch: 160; loss: 0.48; acc: 0.84
Batch: 180; loss: 0.5; acc: 0.86
Batch: 200; loss: 0.48; acc: 0.86
Batch: 220; loss: 0.3; acc: 0.91
Batch: 240; loss: 0.3; acc: 0.89
Batch: 260; loss: 0.38; acc: 0.84
Batch: 280; loss: 0.22; acc: 0.94
Batch: 300; loss: 0.24; acc: 0.88
Batch: 320; loss: 0.46; acc: 0.89
Batch: 340; loss: 0.45; acc: 0.88
Batch: 360; loss: 0.54; acc: 0.81
Batch: 380; loss: 0.52; acc: 0.89
Batch: 400; loss: 0.35; acc: 0.88
Batch: 420; loss: 0.4; acc: 0.86
Batch: 440; loss: 0.38; acc: 0.86
Batch: 460; loss: 0.43; acc: 0.92
Batch: 480; loss: 0.2; acc: 0.92
Batch: 500; loss: 0.2; acc: 0.95
Batch: 520; loss: 0.28; acc: 0.92
Batch: 540; loss: 0.36; acc: 0.89
Batch: 560; loss: 0.35; acc: 0.91
Batch: 580; loss: 0.27; acc: 0.89
Batch: 600; loss: 0.51; acc: 0.83
Batch: 620; loss: 0.33; acc: 0.91
Batch: 640; loss: 0.3; acc: 0.92
Batch: 660; loss: 0.43; acc: 0.83
Batch: 680; loss: 0.58; acc: 0.83
Batch: 700; loss: 0.54; acc: 0.84
Batch: 720; loss: 0.3; acc: 0.92
Batch: 740; loss: 0.39; acc: 0.92
Batch: 760; loss: 0.6; acc: 0.8
Batch: 780; loss: 0.29; acc: 0.88
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

2.3197440896183252e-05
9.551547009323258e-06
Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.45; acc: 0.84
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.91; acc: 0.75
Batch: 80; loss: 0.29; acc: 0.94
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.66; acc: 0.8
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.3788789988845397; val_accuracy: 0.8858479299363057 

The current subspace-distance is: 9.551547009323258e-06 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.31; acc: 0.92
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.36; acc: 0.91
Batch: 60; loss: 0.54; acc: 0.86
Batch: 80; loss: 0.36; acc: 0.88
Batch: 100; loss: 0.34; acc: 0.84
Batch: 120; loss: 0.46; acc: 0.83
Batch: 140; loss: 0.48; acc: 0.8
Batch: 160; loss: 0.54; acc: 0.83
Batch: 180; loss: 0.34; acc: 0.91
Batch: 200; loss: 0.33; acc: 0.89
Batch: 220; loss: 0.28; acc: 0.94
Batch: 240; loss: 0.15; acc: 0.95
Batch: 260; loss: 0.59; acc: 0.83
Batch: 280; loss: 0.44; acc: 0.88
Batch: 300; loss: 0.51; acc: 0.88
Batch: 320; loss: 0.57; acc: 0.84
Batch: 340; loss: 0.33; acc: 0.91
Batch: 360; loss: 0.47; acc: 0.84
Batch: 380; loss: 0.4; acc: 0.86
Batch: 400; loss: 0.28; acc: 0.89
Batch: 420; loss: 0.39; acc: 0.92
Batch: 440; loss: 0.47; acc: 0.83
Batch: 460; loss: 0.37; acc: 0.89
Batch: 480; loss: 0.56; acc: 0.84
Batch: 500; loss: 0.65; acc: 0.81
Batch: 520; loss: 0.44; acc: 0.83
Batch: 540; loss: 0.78; acc: 0.77
Batch: 560; loss: 0.44; acc: 0.86
Batch: 580; loss: 0.2; acc: 0.95
Batch: 600; loss: 0.49; acc: 0.83
Batch: 620; loss: 0.31; acc: 0.92
Batch: 640; loss: 0.32; acc: 0.91
Batch: 660; loss: 0.28; acc: 0.91
Batch: 680; loss: 0.34; acc: 0.89
Batch: 700; loss: 0.3; acc: 0.91
Batch: 720; loss: 0.3; acc: 0.88
Batch: 740; loss: 0.43; acc: 0.89
Batch: 760; loss: 0.64; acc: 0.83
Batch: 780; loss: 0.3; acc: 0.86
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

2.361777296755463e-05
9.120283721131273e-06
Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.46; acc: 0.84
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.89; acc: 0.75
Batch: 80; loss: 0.27; acc: 0.94
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.63; acc: 0.83
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.3774193436334467; val_accuracy: 0.8865445859872612 

The current subspace-distance is: 9.120283721131273e-06 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.26; acc: 0.92
Batch: 20; loss: 0.49; acc: 0.88
Batch: 40; loss: 0.31; acc: 0.84
Batch: 60; loss: 0.52; acc: 0.91
Batch: 80; loss: 0.43; acc: 0.86
Batch: 100; loss: 0.28; acc: 0.92
Batch: 120; loss: 0.25; acc: 0.92
Batch: 140; loss: 0.57; acc: 0.89
Batch: 160; loss: 0.46; acc: 0.88
Batch: 180; loss: 0.49; acc: 0.89
Batch: 200; loss: 0.39; acc: 0.88
Batch: 220; loss: 0.5; acc: 0.83
Batch: 240; loss: 0.49; acc: 0.84
Batch: 260; loss: 0.36; acc: 0.86
Batch: 280; loss: 0.45; acc: 0.88
Batch: 300; loss: 0.51; acc: 0.86
Batch: 320; loss: 0.28; acc: 0.94
Batch: 340; loss: 0.58; acc: 0.83
Batch: 360; loss: 0.43; acc: 0.81
Batch: 380; loss: 0.5; acc: 0.84
Batch: 400; loss: 0.45; acc: 0.89
Batch: 420; loss: 0.41; acc: 0.89
Batch: 440; loss: 0.28; acc: 0.92
Batch: 460; loss: 0.27; acc: 0.95
Batch: 480; loss: 0.34; acc: 0.84
Batch: 500; loss: 0.39; acc: 0.88
Batch: 520; loss: 0.63; acc: 0.83
Batch: 540; loss: 0.58; acc: 0.84
Batch: 560; loss: 0.4; acc: 0.89
Batch: 580; loss: 0.37; acc: 0.84
Batch: 600; loss: 0.49; acc: 0.89
Batch: 620; loss: 0.32; acc: 0.94
Batch: 640; loss: 0.47; acc: 0.91
Batch: 660; loss: 0.3; acc: 0.92
Batch: 680; loss: 0.49; acc: 0.84
Batch: 700; loss: 0.27; acc: 0.92
Batch: 720; loss: 0.39; acc: 0.84
Batch: 740; loss: 0.28; acc: 0.92
Batch: 760; loss: 0.67; acc: 0.83
Batch: 780; loss: 0.48; acc: 0.88
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

2.3109494577511214e-05
9.364930519950576e-06
Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.45; acc: 0.86
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.89; acc: 0.75
Batch: 80; loss: 0.28; acc: 0.95
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.64; acc: 0.81
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.37742881707040365; val_accuracy: 0.8861464968152867 

The current subspace-distance is: 9.364930519950576e-06 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.32; acc: 0.86
Batch: 20; loss: 0.47; acc: 0.86
Batch: 40; loss: 0.47; acc: 0.92
Batch: 60; loss: 0.47; acc: 0.86
Batch: 80; loss: 0.5; acc: 0.91
Batch: 100; loss: 0.57; acc: 0.8
Batch: 120; loss: 0.38; acc: 0.84
Batch: 140; loss: 0.33; acc: 0.91
Batch: 160; loss: 0.29; acc: 0.92
Batch: 180; loss: 0.34; acc: 0.89
Batch: 200; loss: 0.32; acc: 0.92
Batch: 220; loss: 0.56; acc: 0.83
Batch: 240; loss: 0.5; acc: 0.86
Batch: 260; loss: 0.43; acc: 0.88
Batch: 280; loss: 0.32; acc: 0.89
Batch: 300; loss: 0.44; acc: 0.83
Batch: 320; loss: 0.53; acc: 0.83
Batch: 340; loss: 0.41; acc: 0.8
Batch: 360; loss: 0.39; acc: 0.86
Batch: 380; loss: 0.43; acc: 0.84
Batch: 400; loss: 0.31; acc: 0.94
Batch: 420; loss: 0.53; acc: 0.81
Batch: 440; loss: 0.32; acc: 0.92
Batch: 460; loss: 0.43; acc: 0.92
Batch: 480; loss: 0.45; acc: 0.86
Batch: 500; loss: 0.41; acc: 0.84
Batch: 520; loss: 0.37; acc: 0.88
Batch: 540; loss: 0.37; acc: 0.84
Batch: 560; loss: 0.54; acc: 0.81
Batch: 580; loss: 0.35; acc: 0.89
Batch: 600; loss: 0.36; acc: 0.91
Batch: 620; loss: 0.48; acc: 0.84
Batch: 640; loss: 0.52; acc: 0.89
Batch: 660; loss: 0.25; acc: 0.92
Batch: 680; loss: 0.33; acc: 0.88
Batch: 700; loss: 0.47; acc: 0.86
Batch: 720; loss: 0.32; acc: 0.92
Batch: 740; loss: 0.53; acc: 0.89
Batch: 760; loss: 0.39; acc: 0.91
Batch: 780; loss: 0.55; acc: 0.8
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

2.338229023735039e-05
8.979696758615319e-06
Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.45; acc: 0.88
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.9; acc: 0.73
Batch: 80; loss: 0.28; acc: 0.94
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.63; acc: 0.81
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.37636521411169865; val_accuracy: 0.8867436305732485 

The current subspace-distance is: 8.979696758615319e-06 

plots/subspace_training/reg_lenet_3/2020-01-22 20:51:04/d_dim_120_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
nonzero elements in E: 27653
elements in E: 5848700
fraction nonzero: 0.004728059226836733
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.31; acc: 0.08
Batch: 20; loss: 2.29; acc: 0.03
Batch: 40; loss: 2.3; acc: 0.11
Batch: 60; loss: 2.3; acc: 0.02
Batch: 80; loss: 2.3; acc: 0.06
Batch: 100; loss: 2.3; acc: 0.11
Batch: 120; loss: 2.31; acc: 0.12
Batch: 140; loss: 2.32; acc: 0.08
Batch: 160; loss: 2.3; acc: 0.09
Batch: 180; loss: 2.3; acc: 0.12
Batch: 200; loss: 2.3; acc: 0.14
Batch: 220; loss: 2.31; acc: 0.11
Batch: 240; loss: 2.31; acc: 0.05
Batch: 260; loss: 2.3; acc: 0.08
Batch: 280; loss: 2.29; acc: 0.2
Batch: 300; loss: 2.29; acc: 0.11
Batch: 320; loss: 2.3; acc: 0.12
Batch: 340; loss: 2.29; acc: 0.12
Batch: 360; loss: 2.29; acc: 0.12
Batch: 380; loss: 2.3; acc: 0.16
Batch: 400; loss: 2.3; acc: 0.12
Batch: 420; loss: 2.31; acc: 0.08
Batch: 440; loss: 2.29; acc: 0.19
Batch: 460; loss: 2.3; acc: 0.09
Batch: 480; loss: 2.29; acc: 0.17
Batch: 500; loss: 2.29; acc: 0.16
Batch: 520; loss: 2.28; acc: 0.22
Batch: 540; loss: 2.29; acc: 0.12
Batch: 560; loss: 2.28; acc: 0.19
Batch: 580; loss: 2.28; acc: 0.17
Batch: 600; loss: 2.28; acc: 0.17
Batch: 620; loss: 2.28; acc: 0.2
Batch: 640; loss: 2.28; acc: 0.12
Batch: 660; loss: 2.27; acc: 0.19
Batch: 680; loss: 2.29; acc: 0.16
Batch: 700; loss: 2.29; acc: 0.14
Batch: 720; loss: 2.3; acc: 0.09
Batch: 740; loss: 2.27; acc: 0.22
Batch: 760; loss: 2.28; acc: 0.19
Batch: 780; loss: 2.27; acc: 0.27
Train Epoch over. train_loss: 2.29; train_accuracy: 0.13 

5.436163519334514e-06
8.979341146186925e-07
Batch: 0; loss: 2.27; acc: 0.19
Batch: 20; loss: 2.28; acc: 0.23
Batch: 40; loss: 2.27; acc: 0.23
Batch: 60; loss: 2.27; acc: 0.22
Batch: 80; loss: 2.27; acc: 0.23
Batch: 100; loss: 2.27; acc: 0.3
Batch: 120; loss: 2.28; acc: 0.23
Batch: 140; loss: 2.28; acc: 0.17
Val Epoch over. val_loss: 2.27508746286866; val_accuracy: 0.21924761146496816 

The current subspace-distance is: 8.979341146186925e-07 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 2.28; acc: 0.25
Batch: 20; loss: 2.28; acc: 0.25
Batch: 40; loss: 2.28; acc: 0.11
Batch: 60; loss: 2.25; acc: 0.42
Batch: 80; loss: 2.27; acc: 0.31
Batch: 100; loss: 2.28; acc: 0.25
Batch: 120; loss: 2.26; acc: 0.33
Batch: 140; loss: 2.26; acc: 0.36
Batch: 160; loss: 2.26; acc: 0.28
Batch: 180; loss: 2.27; acc: 0.25
Batch: 200; loss: 2.24; acc: 0.39
Batch: 220; loss: 2.25; acc: 0.3
Batch: 240; loss: 2.22; acc: 0.36
Batch: 260; loss: 2.24; acc: 0.36
Batch: 280; loss: 2.19; acc: 0.41
Batch: 300; loss: 2.21; acc: 0.45
Batch: 320; loss: 2.22; acc: 0.33
Batch: 340; loss: 2.18; acc: 0.41
Batch: 360; loss: 2.11; acc: 0.55
Batch: 380; loss: 2.14; acc: 0.44
Batch: 400; loss: 2.12; acc: 0.39
Batch: 420; loss: 2.08; acc: 0.48
Batch: 440; loss: 2.08; acc: 0.39
Batch: 460; loss: 2.06; acc: 0.38
Batch: 480; loss: 1.92; acc: 0.5
Batch: 500; loss: 1.89; acc: 0.45
Batch: 520; loss: 1.77; acc: 0.52
Batch: 540; loss: 1.64; acc: 0.55
Batch: 560; loss: 1.47; acc: 0.61
Batch: 580; loss: 1.35; acc: 0.58
Batch: 600; loss: 1.33; acc: 0.61
Batch: 620; loss: 1.08; acc: 0.69
Batch: 640; loss: 1.38; acc: 0.56
Batch: 660; loss: 1.2; acc: 0.61
Batch: 680; loss: 1.07; acc: 0.64
Batch: 700; loss: 1.13; acc: 0.59
Batch: 720; loss: 0.96; acc: 0.7
Batch: 740; loss: 0.91; acc: 0.75
Batch: 760; loss: 1.06; acc: 0.67
Batch: 780; loss: 0.76; acc: 0.8
Train Epoch over. train_loss: 1.85; train_accuracy: 0.45 

1.2275126209715381e-05
4.642111434804974e-06
Batch: 0; loss: 0.88; acc: 0.7
Batch: 20; loss: 1.08; acc: 0.59
Batch: 40; loss: 0.57; acc: 0.81
Batch: 60; loss: 0.84; acc: 0.69
Batch: 80; loss: 0.57; acc: 0.75
Batch: 100; loss: 0.54; acc: 0.88
Batch: 120; loss: 0.95; acc: 0.78
Batch: 140; loss: 0.62; acc: 0.83
Val Epoch over. val_loss: 0.8344477472031951; val_accuracy: 0.7353702229299363 

The current subspace-distance is: 4.642111434804974e-06 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.89; acc: 0.66
Batch: 20; loss: 0.76; acc: 0.81
Batch: 40; loss: 0.72; acc: 0.78
Batch: 60; loss: 0.92; acc: 0.77
Batch: 80; loss: 0.96; acc: 0.64
Batch: 100; loss: 0.74; acc: 0.8
Batch: 120; loss: 0.89; acc: 0.72
Batch: 140; loss: 1.03; acc: 0.66
Batch: 160; loss: 0.59; acc: 0.83
Batch: 180; loss: 0.65; acc: 0.84
Batch: 200; loss: 0.67; acc: 0.78
Batch: 220; loss: 0.95; acc: 0.75
Batch: 240; loss: 0.98; acc: 0.72
Batch: 260; loss: 0.8; acc: 0.78
Batch: 280; loss: 0.66; acc: 0.83
Batch: 300; loss: 0.6; acc: 0.83
Batch: 320; loss: 0.65; acc: 0.81
Batch: 340; loss: 0.78; acc: 0.8
Batch: 360; loss: 0.51; acc: 0.83
Batch: 380; loss: 0.72; acc: 0.81
Batch: 400; loss: 0.9; acc: 0.78
Batch: 420; loss: 0.83; acc: 0.73
Batch: 440; loss: 0.58; acc: 0.81
Batch: 460; loss: 0.89; acc: 0.81
Batch: 480; loss: 0.77; acc: 0.77
Batch: 500; loss: 0.56; acc: 0.77
Batch: 520; loss: 0.53; acc: 0.86
Batch: 540; loss: 0.74; acc: 0.8
Batch: 560; loss: 1.01; acc: 0.73
Batch: 580; loss: 0.54; acc: 0.81
Batch: 600; loss: 0.65; acc: 0.84
Batch: 620; loss: 0.86; acc: 0.73
Batch: 640; loss: 0.49; acc: 0.75
Batch: 660; loss: 0.76; acc: 0.81
Batch: 680; loss: 0.51; acc: 0.84
Batch: 700; loss: 0.7; acc: 0.77
Batch: 720; loss: 0.35; acc: 0.86
Batch: 740; loss: 0.76; acc: 0.78
Batch: 760; loss: 0.57; acc: 0.83
Batch: 780; loss: 0.56; acc: 0.81
Train Epoch over. train_loss: 0.72; train_accuracy: 0.78 

2.1194369764998555e-05
7.1417453000321984e-06
Batch: 0; loss: 0.73; acc: 0.73
Batch: 20; loss: 0.73; acc: 0.73
Batch: 40; loss: 0.35; acc: 0.86
Batch: 60; loss: 0.65; acc: 0.77
Batch: 80; loss: 0.33; acc: 0.88
Batch: 100; loss: 0.63; acc: 0.81
Batch: 120; loss: 0.92; acc: 0.73
Batch: 140; loss: 0.55; acc: 0.81
Val Epoch over. val_loss: 0.6697191599827663; val_accuracy: 0.7880175159235668 

The current subspace-distance is: 7.1417453000321984e-06 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.82; acc: 0.7
Batch: 20; loss: 0.7; acc: 0.72
Batch: 40; loss: 0.68; acc: 0.77
Batch: 60; loss: 0.44; acc: 0.8
Batch: 80; loss: 0.48; acc: 0.91
Batch: 100; loss: 0.39; acc: 0.91
Batch: 120; loss: 0.57; acc: 0.8
Batch: 140; loss: 0.47; acc: 0.83
Batch: 160; loss: 0.48; acc: 0.86
Batch: 180; loss: 0.64; acc: 0.81
Batch: 200; loss: 0.55; acc: 0.84
Batch: 220; loss: 0.91; acc: 0.8
Batch: 240; loss: 0.64; acc: 0.83
Batch: 260; loss: 0.54; acc: 0.83
Batch: 280; loss: 0.77; acc: 0.8
Batch: 300; loss: 0.77; acc: 0.78
Batch: 320; loss: 0.73; acc: 0.77
Batch: 340; loss: 0.73; acc: 0.83
Batch: 360; loss: 0.6; acc: 0.8
Batch: 380; loss: 0.53; acc: 0.81
Batch: 400; loss: 0.73; acc: 0.83
Batch: 420; loss: 0.7; acc: 0.84
Batch: 440; loss: 0.42; acc: 0.84
Batch: 460; loss: 0.42; acc: 0.83
Batch: 480; loss: 0.57; acc: 0.83
Batch: 500; loss: 0.4; acc: 0.86
Batch: 520; loss: 0.42; acc: 0.84
Batch: 540; loss: 0.53; acc: 0.8
Batch: 560; loss: 0.64; acc: 0.8
Batch: 580; loss: 0.65; acc: 0.77
Batch: 600; loss: 0.63; acc: 0.81
Batch: 620; loss: 0.65; acc: 0.8
Batch: 640; loss: 0.73; acc: 0.81
Batch: 660; loss: 0.59; acc: 0.77
Batch: 680; loss: 0.57; acc: 0.86
Batch: 700; loss: 0.36; acc: 0.94
Batch: 720; loss: 0.71; acc: 0.73
Batch: 740; loss: 0.43; acc: 0.84
Batch: 760; loss: 0.4; acc: 0.88
Batch: 780; loss: 0.49; acc: 0.83
Train Epoch over. train_loss: 0.6; train_accuracy: 0.82 

2.1687277694582008e-05
8.720738151168916e-06
Batch: 0; loss: 0.78; acc: 0.75
Batch: 20; loss: 0.75; acc: 0.77
Batch: 40; loss: 0.38; acc: 0.89
Batch: 60; loss: 0.67; acc: 0.77
Batch: 80; loss: 0.38; acc: 0.91
Batch: 100; loss: 0.64; acc: 0.8
Batch: 120; loss: 0.85; acc: 0.77
Batch: 140; loss: 0.32; acc: 0.91
Val Epoch over. val_loss: 0.687462203062264; val_accuracy: 0.7939888535031847 

The current subspace-distance is: 8.720738151168916e-06 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.8; acc: 0.73
Batch: 20; loss: 0.64; acc: 0.81
Batch: 40; loss: 0.97; acc: 0.7
Batch: 60; loss: 0.62; acc: 0.83
Batch: 80; loss: 0.53; acc: 0.84
Batch: 100; loss: 0.41; acc: 0.86
Batch: 120; loss: 0.49; acc: 0.89
Batch: 140; loss: 0.66; acc: 0.83
Batch: 160; loss: 0.35; acc: 0.91
Batch: 180; loss: 0.45; acc: 0.86
Batch: 200; loss: 0.28; acc: 0.92
Batch: 220; loss: 0.68; acc: 0.78
Batch: 240; loss: 0.6; acc: 0.81
Batch: 260; loss: 0.48; acc: 0.81
Batch: 280; loss: 0.35; acc: 0.91
Batch: 300; loss: 0.4; acc: 0.89
Batch: 320; loss: 0.33; acc: 0.89
Batch: 340; loss: 0.42; acc: 0.88
Batch: 360; loss: 0.55; acc: 0.81
Batch: 380; loss: 0.3; acc: 0.91
Batch: 400; loss: 0.87; acc: 0.83
Batch: 420; loss: 0.83; acc: 0.69
Batch: 440; loss: 0.4; acc: 0.84
Batch: 460; loss: 0.46; acc: 0.88
Batch: 480; loss: 0.48; acc: 0.8
Batch: 500; loss: 0.64; acc: 0.81
Batch: 520; loss: 0.55; acc: 0.83
Batch: 540; loss: 0.68; acc: 0.83
Batch: 560; loss: 0.7; acc: 0.77
Batch: 580; loss: 0.52; acc: 0.81
Batch: 600; loss: 0.51; acc: 0.81
Batch: 620; loss: 0.54; acc: 0.81
Batch: 640; loss: 0.39; acc: 0.86
Batch: 660; loss: 1.18; acc: 0.7
Batch: 680; loss: 0.44; acc: 0.86
Batch: 700; loss: 0.45; acc: 0.81
Batch: 720; loss: 0.44; acc: 0.84
Batch: 740; loss: 0.47; acc: 0.89
Batch: 760; loss: 0.53; acc: 0.81
Batch: 780; loss: 0.35; acc: 0.89
Train Epoch over. train_loss: 0.56; train_accuracy: 0.83 

2.6155692467000335e-05
8.67561720951926e-06
Batch: 0; loss: 0.49; acc: 0.86
Batch: 20; loss: 0.71; acc: 0.75
Batch: 40; loss: 0.25; acc: 0.91
Batch: 60; loss: 0.57; acc: 0.83
Batch: 80; loss: 0.27; acc: 0.91
Batch: 100; loss: 0.58; acc: 0.84
Batch: 120; loss: 0.88; acc: 0.8
Batch: 140; loss: 0.3; acc: 0.91
Val Epoch over. val_loss: 0.5299138841070946; val_accuracy: 0.8350915605095541 

The current subspace-distance is: 8.67561720951926e-06 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.69; acc: 0.73
Batch: 20; loss: 0.42; acc: 0.88
Batch: 40; loss: 0.77; acc: 0.83
Batch: 60; loss: 0.43; acc: 0.84
Batch: 80; loss: 0.36; acc: 0.88
Batch: 100; loss: 0.35; acc: 0.89
Batch: 120; loss: 0.48; acc: 0.84
Batch: 140; loss: 0.66; acc: 0.8
Batch: 160; loss: 0.88; acc: 0.75
Batch: 180; loss: 0.44; acc: 0.89
Batch: 200; loss: 0.48; acc: 0.86
Batch: 220; loss: 0.42; acc: 0.86
Batch: 240; loss: 0.5; acc: 0.81
Batch: 260; loss: 0.58; acc: 0.83
Batch: 280; loss: 0.43; acc: 0.89
Batch: 300; loss: 0.79; acc: 0.81
Batch: 320; loss: 0.59; acc: 0.78
Batch: 340; loss: 0.45; acc: 0.89
Batch: 360; loss: 0.63; acc: 0.8
Batch: 380; loss: 0.82; acc: 0.83
Batch: 400; loss: 0.4; acc: 0.91
Batch: 420; loss: 0.57; acc: 0.75
Batch: 440; loss: 0.52; acc: 0.86
Batch: 460; loss: 0.57; acc: 0.83
Batch: 480; loss: 0.49; acc: 0.83
Batch: 500; loss: 0.77; acc: 0.83
Batch: 520; loss: 0.48; acc: 0.84
Batch: 540; loss: 0.38; acc: 0.89
Batch: 560; loss: 0.42; acc: 0.86
Batch: 580; loss: 0.45; acc: 0.84
Batch: 600; loss: 0.41; acc: 0.84
Batch: 620; loss: 0.41; acc: 0.91
Batch: 640; loss: 0.48; acc: 0.84
Batch: 660; loss: 0.9; acc: 0.8
Batch: 680; loss: 0.38; acc: 0.84
Batch: 700; loss: 0.44; acc: 0.84
Batch: 720; loss: 0.82; acc: 0.78
Batch: 740; loss: 0.46; acc: 0.83
Batch: 760; loss: 0.5; acc: 0.92
Batch: 780; loss: 0.45; acc: 0.91
Train Epoch over. train_loss: 0.53; train_accuracy: 0.84 

2.3466052880394273e-05
8.490143954986706e-06
Batch: 0; loss: 0.61; acc: 0.86
Batch: 20; loss: 0.72; acc: 0.78
Batch: 40; loss: 0.36; acc: 0.92
Batch: 60; loss: 0.58; acc: 0.8
Batch: 80; loss: 0.36; acc: 0.88
Batch: 100; loss: 0.71; acc: 0.78
Batch: 120; loss: 0.99; acc: 0.78
Batch: 140; loss: 0.25; acc: 0.95
Val Epoch over. val_loss: 0.6936712964989578; val_accuracy: 0.8056329617834395 

The current subspace-distance is: 8.490143954986706e-06 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 1.06; acc: 0.72
Batch: 20; loss: 0.34; acc: 0.86
Batch: 40; loss: 0.56; acc: 0.84
Batch: 60; loss: 0.44; acc: 0.86
Batch: 80; loss: 0.33; acc: 0.92
Batch: 100; loss: 0.42; acc: 0.91
Batch: 120; loss: 0.46; acc: 0.89
Batch: 140; loss: 0.39; acc: 0.91
Batch: 160; loss: 0.65; acc: 0.78
Batch: 180; loss: 0.45; acc: 0.84
Batch: 200; loss: 0.77; acc: 0.78
Batch: 220; loss: 0.79; acc: 0.81
Batch: 240; loss: 0.49; acc: 0.84
Batch: 260; loss: 0.57; acc: 0.81
Batch: 280; loss: 0.44; acc: 0.84
Batch: 300; loss: 0.45; acc: 0.86
Batch: 320; loss: 0.64; acc: 0.77
Batch: 340; loss: 0.56; acc: 0.89
Batch: 360; loss: 0.37; acc: 0.89
Batch: 380; loss: 0.51; acc: 0.86
Batch: 400; loss: 0.49; acc: 0.89
Batch: 420; loss: 0.49; acc: 0.81
Batch: 440; loss: 0.6; acc: 0.88
Batch: 460; loss: 0.27; acc: 0.89
Batch: 480; loss: 0.36; acc: 0.91
Batch: 500; loss: 0.35; acc: 0.88
Batch: 520; loss: 0.29; acc: 0.84
Batch: 540; loss: 0.63; acc: 0.75
Batch: 560; loss: 0.43; acc: 0.89
Batch: 580; loss: 0.41; acc: 0.91
Batch: 600; loss: 0.3; acc: 0.89
Batch: 620; loss: 0.62; acc: 0.77
Batch: 640; loss: 0.59; acc: 0.81
Batch: 660; loss: 0.57; acc: 0.78
Batch: 680; loss: 0.75; acc: 0.8
Batch: 700; loss: 0.5; acc: 0.84
Batch: 720; loss: 0.45; acc: 0.84
Batch: 740; loss: 0.33; acc: 0.92
Batch: 760; loss: 0.34; acc: 0.89
Batch: 780; loss: 0.41; acc: 0.84
Train Epoch over. train_loss: 0.51; train_accuracy: 0.85 

2.477825000823941e-05
8.091719791991636e-06
Batch: 0; loss: 0.51; acc: 0.83
Batch: 20; loss: 0.63; acc: 0.77
Batch: 40; loss: 0.31; acc: 0.92
Batch: 60; loss: 0.67; acc: 0.81
Batch: 80; loss: 0.31; acc: 0.92
Batch: 100; loss: 0.57; acc: 0.84
Batch: 120; loss: 0.8; acc: 0.78
Batch: 140; loss: 0.22; acc: 0.92
Val Epoch over. val_loss: 0.5537602641400258; val_accuracy: 0.8272292993630573 

The current subspace-distance is: 8.091719791991636e-06 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.75; acc: 0.75
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.4; acc: 0.91
Batch: 60; loss: 0.27; acc: 0.91
Batch: 80; loss: 0.55; acc: 0.81
Batch: 100; loss: 0.51; acc: 0.84
Batch: 120; loss: 0.42; acc: 0.88
Batch: 140; loss: 0.53; acc: 0.81
Batch: 160; loss: 0.44; acc: 0.83
Batch: 180; loss: 0.28; acc: 0.94
Batch: 200; loss: 0.3; acc: 0.89
Batch: 220; loss: 0.43; acc: 0.88
Batch: 240; loss: 0.38; acc: 0.81
Batch: 260; loss: 0.36; acc: 0.94
Batch: 280; loss: 0.55; acc: 0.81
Batch: 300; loss: 0.72; acc: 0.75
Batch: 320; loss: 0.59; acc: 0.81
Batch: 340; loss: 0.77; acc: 0.8
Batch: 360; loss: 0.37; acc: 0.86
Batch: 380; loss: 0.31; acc: 0.89
Batch: 400; loss: 0.48; acc: 0.83
Batch: 420; loss: 0.66; acc: 0.78
Batch: 440; loss: 0.68; acc: 0.75
Batch: 460; loss: 0.31; acc: 0.89
Batch: 480; loss: 0.47; acc: 0.86
Batch: 500; loss: 0.67; acc: 0.84
Batch: 520; loss: 0.58; acc: 0.78
Batch: 540; loss: 0.32; acc: 0.88
Batch: 560; loss: 0.24; acc: 0.89
Batch: 580; loss: 0.43; acc: 0.84
Batch: 600; loss: 0.61; acc: 0.81
Batch: 620; loss: 0.61; acc: 0.83
Batch: 640; loss: 0.3; acc: 0.91
Batch: 660; loss: 0.37; acc: 0.89
Batch: 680; loss: 0.4; acc: 0.88
Batch: 700; loss: 0.64; acc: 0.84
Batch: 720; loss: 0.39; acc: 0.88
Batch: 740; loss: 0.55; acc: 0.81
Batch: 760; loss: 0.32; acc: 0.92
Batch: 780; loss: 0.49; acc: 0.83
Train Epoch over. train_loss: 0.49; train_accuracy: 0.85 

2.4891751309041865e-05
9.624162885302212e-06
Batch: 0; loss: 0.52; acc: 0.8
Batch: 20; loss: 0.58; acc: 0.75
Batch: 40; loss: 0.4; acc: 0.92
Batch: 60; loss: 0.78; acc: 0.77
Batch: 80; loss: 0.31; acc: 0.88
Batch: 100; loss: 0.5; acc: 0.83
Batch: 120; loss: 0.91; acc: 0.72
Batch: 140; loss: 0.36; acc: 0.86
Val Epoch over. val_loss: 0.5269621580269686; val_accuracy: 0.8386743630573248 

The current subspace-distance is: 9.624162885302212e-06 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.9; acc: 0.75
Batch: 20; loss: 0.23; acc: 0.94
Batch: 40; loss: 0.23; acc: 0.92
Batch: 60; loss: 0.64; acc: 0.84
Batch: 80; loss: 0.43; acc: 0.89
Batch: 100; loss: 0.39; acc: 0.88
Batch: 120; loss: 0.26; acc: 0.94
Batch: 140; loss: 0.79; acc: 0.72
Batch: 160; loss: 0.43; acc: 0.89
Batch: 180; loss: 0.81; acc: 0.78
Batch: 200; loss: 0.4; acc: 0.83
Batch: 220; loss: 0.46; acc: 0.86
Batch: 240; loss: 0.45; acc: 0.84
Batch: 260; loss: 0.62; acc: 0.84
Batch: 280; loss: 0.35; acc: 0.89
Batch: 300; loss: 0.51; acc: 0.86
Batch: 320; loss: 0.53; acc: 0.88
Batch: 340; loss: 0.58; acc: 0.84
Batch: 360; loss: 0.59; acc: 0.89
Batch: 380; loss: 0.26; acc: 0.94
Batch: 400; loss: 0.31; acc: 0.88
Batch: 420; loss: 0.4; acc: 0.86
Batch: 440; loss: 0.53; acc: 0.84
Batch: 460; loss: 0.31; acc: 0.92
Batch: 480; loss: 0.66; acc: 0.8
Batch: 500; loss: 0.6; acc: 0.83
Batch: 520; loss: 0.44; acc: 0.89
Batch: 540; loss: 0.62; acc: 0.8
Batch: 560; loss: 0.42; acc: 0.88
Batch: 580; loss: 0.61; acc: 0.83
Batch: 600; loss: 0.56; acc: 0.81
Batch: 620; loss: 0.43; acc: 0.88
Batch: 640; loss: 0.53; acc: 0.8
Batch: 660; loss: 0.7; acc: 0.78
Batch: 680; loss: 0.56; acc: 0.86
Batch: 700; loss: 0.43; acc: 0.84
Batch: 720; loss: 0.33; acc: 0.88
Batch: 740; loss: 0.48; acc: 0.81
Batch: 760; loss: 0.51; acc: 0.86
Batch: 780; loss: 0.34; acc: 0.91
Train Epoch over. train_loss: 0.47; train_accuracy: 0.86 

2.4741140805417672e-05
8.911732948035933e-06
Batch: 0; loss: 0.35; acc: 0.86
Batch: 20; loss: 0.5; acc: 0.81
Batch: 40; loss: 0.29; acc: 0.91
Batch: 60; loss: 0.65; acc: 0.83
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.47; acc: 0.86
Batch: 120; loss: 0.74; acc: 0.8
Batch: 140; loss: 0.19; acc: 0.95
Val Epoch over. val_loss: 0.4262110687744845; val_accuracy: 0.8730095541401274 

The current subspace-distance is: 8.911732948035933e-06 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.48; acc: 0.81
Batch: 20; loss: 0.35; acc: 0.89
Batch: 40; loss: 0.5; acc: 0.86
Batch: 60; loss: 0.32; acc: 0.88
Batch: 80; loss: 0.37; acc: 0.92
Batch: 100; loss: 0.47; acc: 0.86
Batch: 120; loss: 0.53; acc: 0.84
Batch: 140; loss: 0.52; acc: 0.86
Batch: 160; loss: 0.27; acc: 0.89
Batch: 180; loss: 0.41; acc: 0.88
Batch: 200; loss: 0.53; acc: 0.84
Batch: 220; loss: 0.88; acc: 0.72
Batch: 240; loss: 0.38; acc: 0.83
Batch: 260; loss: 0.52; acc: 0.86
Batch: 280; loss: 0.55; acc: 0.8
Batch: 300; loss: 0.19; acc: 0.95
Batch: 320; loss: 0.6; acc: 0.84
Batch: 340; loss: 0.47; acc: 0.86
Batch: 360; loss: 0.49; acc: 0.8
Batch: 380; loss: 0.26; acc: 0.94
Batch: 400; loss: 0.53; acc: 0.78
Batch: 420; loss: 0.41; acc: 0.84
Batch: 440; loss: 0.54; acc: 0.88
Batch: 460; loss: 0.24; acc: 0.91
Batch: 480; loss: 0.32; acc: 0.91
Batch: 500; loss: 0.4; acc: 0.91
Batch: 520; loss: 0.56; acc: 0.86
Batch: 540; loss: 0.34; acc: 0.86
Batch: 560; loss: 0.49; acc: 0.84
Batch: 580; loss: 0.58; acc: 0.84
Batch: 600; loss: 0.35; acc: 0.92
Batch: 620; loss: 0.61; acc: 0.78
Batch: 640; loss: 0.51; acc: 0.89
Batch: 660; loss: 0.47; acc: 0.84
Batch: 680; loss: 0.39; acc: 0.91
Batch: 700; loss: 0.43; acc: 0.84
Batch: 720; loss: 0.61; acc: 0.84
Batch: 740; loss: 0.74; acc: 0.83
Batch: 760; loss: 0.26; acc: 0.92
Batch: 780; loss: 0.72; acc: 0.8
Train Epoch over. train_loss: 0.47; train_accuracy: 0.86 

2.473281892889645e-05
8.49579919304233e-06
Batch: 0; loss: 0.66; acc: 0.73
Batch: 20; loss: 0.59; acc: 0.81
Batch: 40; loss: 0.46; acc: 0.89
Batch: 60; loss: 0.86; acc: 0.78
Batch: 80; loss: 0.52; acc: 0.83
Batch: 100; loss: 0.65; acc: 0.81
Batch: 120; loss: 0.91; acc: 0.78
Batch: 140; loss: 0.27; acc: 0.92
Val Epoch over. val_loss: 0.6159109385909548; val_accuracy: 0.8062300955414012 

The current subspace-distance is: 8.49579919304233e-06 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.67; acc: 0.78
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.54; acc: 0.81
Batch: 60; loss: 0.42; acc: 0.89
Batch: 80; loss: 0.42; acc: 0.88
Batch: 100; loss: 0.42; acc: 0.84
Batch: 120; loss: 0.47; acc: 0.83
Batch: 140; loss: 0.49; acc: 0.88
Batch: 160; loss: 0.44; acc: 0.91
Batch: 180; loss: 0.53; acc: 0.84
Batch: 200; loss: 0.54; acc: 0.89
Batch: 220; loss: 0.75; acc: 0.8
Batch: 240; loss: 0.47; acc: 0.88
Batch: 260; loss: 0.36; acc: 0.92
Batch: 280; loss: 0.25; acc: 0.91
Batch: 300; loss: 0.4; acc: 0.86
Batch: 320; loss: 0.35; acc: 0.88
Batch: 340; loss: 0.59; acc: 0.84
Batch: 360; loss: 0.59; acc: 0.88
Batch: 380; loss: 0.46; acc: 0.86
Batch: 400; loss: 0.77; acc: 0.84
Batch: 420; loss: 0.31; acc: 0.92
Batch: 440; loss: 0.31; acc: 0.91
Batch: 460; loss: 0.26; acc: 0.94
Batch: 480; loss: 0.39; acc: 0.89
Batch: 500; loss: 0.33; acc: 0.88
Batch: 520; loss: 0.53; acc: 0.84
Batch: 540; loss: 0.29; acc: 0.92
Batch: 560; loss: 0.48; acc: 0.86
Batch: 580; loss: 0.45; acc: 0.86
Batch: 600; loss: 0.47; acc: 0.83
Batch: 620; loss: 0.45; acc: 0.84
Batch: 640; loss: 0.33; acc: 0.91
Batch: 660; loss: 0.36; acc: 0.91
Batch: 680; loss: 0.43; acc: 0.88
Batch: 700; loss: 0.24; acc: 0.92
Batch: 720; loss: 0.38; acc: 0.91
Batch: 740; loss: 0.37; acc: 0.88
Batch: 760; loss: 0.38; acc: 0.89
Batch: 780; loss: 0.31; acc: 0.91
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

2.5388822905370034e-05
8.267699740827084e-06
Batch: 0; loss: 0.33; acc: 0.89
Batch: 20; loss: 0.43; acc: 0.84
Batch: 40; loss: 0.25; acc: 0.95
Batch: 60; loss: 0.49; acc: 0.86
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.49; acc: 0.89
Batch: 120; loss: 0.81; acc: 0.8
Batch: 140; loss: 0.15; acc: 0.95
Val Epoch over. val_loss: 0.4075965821553188; val_accuracy: 0.8798765923566879 

The current subspace-distance is: 8.267699740827084e-06 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.59; acc: 0.78
Batch: 20; loss: 0.41; acc: 0.88
Batch: 40; loss: 0.61; acc: 0.81
Batch: 60; loss: 0.42; acc: 0.88
Batch: 80; loss: 0.48; acc: 0.84
Batch: 100; loss: 0.45; acc: 0.84
Batch: 120; loss: 0.3; acc: 0.92
Batch: 140; loss: 0.5; acc: 0.88
Batch: 160; loss: 0.31; acc: 0.86
Batch: 180; loss: 0.18; acc: 0.95
Batch: 200; loss: 0.3; acc: 0.91
Batch: 220; loss: 0.49; acc: 0.84
Batch: 240; loss: 0.32; acc: 0.86
Batch: 260; loss: 0.35; acc: 0.88
Batch: 280; loss: 0.43; acc: 0.89
Batch: 300; loss: 0.36; acc: 0.88
Batch: 320; loss: 0.35; acc: 0.89
Batch: 340; loss: 0.25; acc: 0.95
Batch: 360; loss: 0.61; acc: 0.78
Batch: 380; loss: 0.34; acc: 0.89
Batch: 400; loss: 0.39; acc: 0.88
Batch: 420; loss: 0.39; acc: 0.91
Batch: 440; loss: 0.56; acc: 0.89
Batch: 460; loss: 0.48; acc: 0.81
Batch: 480; loss: 0.56; acc: 0.88
Batch: 500; loss: 0.66; acc: 0.8
Batch: 520; loss: 0.43; acc: 0.89
Batch: 540; loss: 0.5; acc: 0.84
Batch: 560; loss: 0.46; acc: 0.91
Batch: 580; loss: 0.34; acc: 0.91
Batch: 600; loss: 0.35; acc: 0.89
Batch: 620; loss: 0.4; acc: 0.89
Batch: 640; loss: 0.34; acc: 0.84
Batch: 660; loss: 0.36; acc: 0.89
Batch: 680; loss: 0.63; acc: 0.86
Batch: 700; loss: 0.33; acc: 0.95
Batch: 720; loss: 0.36; acc: 0.89
Batch: 740; loss: 0.78; acc: 0.81
Batch: 760; loss: 0.71; acc: 0.81
Batch: 780; loss: 0.37; acc: 0.86
Train Epoch over. train_loss: 0.41; train_accuracy: 0.88 

2.5038409148692153e-05
8.39628955873195e-06
Batch: 0; loss: 0.35; acc: 0.89
Batch: 20; loss: 0.42; acc: 0.89
Batch: 40; loss: 0.29; acc: 0.91
Batch: 60; loss: 0.6; acc: 0.83
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.47; acc: 0.89
Batch: 120; loss: 0.8; acc: 0.77
Batch: 140; loss: 0.26; acc: 0.91
Val Epoch over. val_loss: 0.4309760537591709; val_accuracy: 0.8691281847133758 

The current subspace-distance is: 8.39628955873195e-06 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.48; acc: 0.8
Batch: 20; loss: 0.48; acc: 0.84
Batch: 40; loss: 0.34; acc: 0.91
Batch: 60; loss: 0.21; acc: 0.94
Batch: 80; loss: 0.32; acc: 0.91
Batch: 100; loss: 0.31; acc: 0.89
Batch: 120; loss: 0.54; acc: 0.88
Batch: 140; loss: 0.4; acc: 0.88
Batch: 160; loss: 0.53; acc: 0.88
Batch: 180; loss: 0.53; acc: 0.84
Batch: 200; loss: 0.25; acc: 0.95
Batch: 220; loss: 0.33; acc: 0.91
Batch: 240; loss: 0.37; acc: 0.83
Batch: 260; loss: 0.42; acc: 0.86
Batch: 280; loss: 0.36; acc: 0.89
Batch: 300; loss: 0.24; acc: 0.92
Batch: 320; loss: 0.46; acc: 0.89
Batch: 340; loss: 0.34; acc: 0.94
Batch: 360; loss: 0.31; acc: 0.89
Batch: 380; loss: 0.54; acc: 0.81
Batch: 400; loss: 0.29; acc: 0.92
Batch: 420; loss: 0.18; acc: 0.94
Batch: 440; loss: 0.57; acc: 0.77
Batch: 460; loss: 0.44; acc: 0.89
Batch: 480; loss: 0.33; acc: 0.91
Batch: 500; loss: 0.28; acc: 0.94
Batch: 520; loss: 0.37; acc: 0.78
Batch: 540; loss: 0.51; acc: 0.81
Batch: 560; loss: 0.45; acc: 0.91
Batch: 580; loss: 0.5; acc: 0.86
Batch: 600; loss: 0.57; acc: 0.8
Batch: 620; loss: 0.28; acc: 0.92
Batch: 640; loss: 0.36; acc: 0.89
Batch: 660; loss: 0.32; acc: 0.88
Batch: 680; loss: 0.37; acc: 0.91
Batch: 700; loss: 0.72; acc: 0.81
Batch: 720; loss: 0.23; acc: 0.91
Batch: 740; loss: 0.26; acc: 0.92
Batch: 760; loss: 0.41; acc: 0.91
Batch: 780; loss: 0.67; acc: 0.84
Train Epoch over. train_loss: 0.41; train_accuracy: 0.88 

2.5399909645784646e-05
8.362613698409405e-06
Batch: 0; loss: 0.42; acc: 0.86
Batch: 20; loss: 0.58; acc: 0.8
Batch: 40; loss: 0.32; acc: 0.88
Batch: 60; loss: 0.65; acc: 0.8
Batch: 80; loss: 0.26; acc: 0.95
Batch: 100; loss: 0.48; acc: 0.86
Batch: 120; loss: 1.0; acc: 0.69
Batch: 140; loss: 0.37; acc: 0.86
Val Epoch over. val_loss: 0.47095780088833183; val_accuracy: 0.8500199044585988 

The current subspace-distance is: 8.362613698409405e-06 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.4; acc: 0.86
Batch: 40; loss: 0.31; acc: 0.91
Batch: 60; loss: 0.35; acc: 0.89
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.5; acc: 0.84
Batch: 120; loss: 0.31; acc: 0.92
Batch: 140; loss: 0.57; acc: 0.86
Batch: 160; loss: 0.88; acc: 0.73
Batch: 180; loss: 0.39; acc: 0.88
Batch: 200; loss: 0.37; acc: 0.89
Batch: 220; loss: 0.68; acc: 0.81
Batch: 240; loss: 0.32; acc: 0.89
Batch: 260; loss: 0.29; acc: 0.89
Batch: 280; loss: 0.37; acc: 0.89
Batch: 300; loss: 0.53; acc: 0.83
Batch: 320; loss: 0.18; acc: 0.94
Batch: 340; loss: 0.58; acc: 0.86
Batch: 360; loss: 0.8; acc: 0.81
Batch: 380; loss: 0.26; acc: 0.95
Batch: 400; loss: 0.53; acc: 0.81
Batch: 420; loss: 0.37; acc: 0.88
Batch: 440; loss: 0.34; acc: 0.92
Batch: 460; loss: 0.27; acc: 0.94
Batch: 480; loss: 0.46; acc: 0.83
Batch: 500; loss: 0.57; acc: 0.88
Batch: 520; loss: 0.32; acc: 0.89
Batch: 540; loss: 0.36; acc: 0.92
Batch: 560; loss: 0.64; acc: 0.78
Batch: 580; loss: 0.34; acc: 0.89
Batch: 600; loss: 0.44; acc: 0.89
Batch: 620; loss: 0.64; acc: 0.84
Batch: 640; loss: 0.45; acc: 0.83
Batch: 660; loss: 0.29; acc: 0.91
Batch: 680; loss: 0.69; acc: 0.77
Batch: 700; loss: 0.3; acc: 0.88
Batch: 720; loss: 0.48; acc: 0.88
Batch: 740; loss: 0.21; acc: 0.92
Batch: 760; loss: 0.27; acc: 0.91
Batch: 780; loss: 0.47; acc: 0.84
Train Epoch over. train_loss: 0.41; train_accuracy: 0.88 

2.5029874450410716e-05
7.939334864204284e-06
Batch: 0; loss: 0.31; acc: 0.88
Batch: 20; loss: 0.48; acc: 0.84
Batch: 40; loss: 0.29; acc: 0.91
Batch: 60; loss: 0.5; acc: 0.86
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.42; acc: 0.91
Batch: 120; loss: 0.68; acc: 0.83
Batch: 140; loss: 0.14; acc: 0.94
Val Epoch over. val_loss: 0.38770868985136603; val_accuracy: 0.8815684713375797 

The current subspace-distance is: 7.939334864204284e-06 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.31; acc: 0.91
Batch: 20; loss: 0.23; acc: 0.89
Batch: 40; loss: 0.3; acc: 0.88
Batch: 60; loss: 0.27; acc: 0.95
Batch: 80; loss: 0.55; acc: 0.89
Batch: 100; loss: 0.4; acc: 0.86
Batch: 120; loss: 0.41; acc: 0.86
Batch: 140; loss: 0.57; acc: 0.78
Batch: 160; loss: 0.24; acc: 0.92
Batch: 180; loss: 0.46; acc: 0.83
Batch: 200; loss: 0.34; acc: 0.91
Batch: 220; loss: 0.33; acc: 0.89
Batch: 240; loss: 0.5; acc: 0.8
Batch: 260; loss: 0.58; acc: 0.83
Batch: 280; loss: 0.26; acc: 0.91
Batch: 300; loss: 0.6; acc: 0.84
Batch: 320; loss: 0.33; acc: 0.89
Batch: 340; loss: 0.43; acc: 0.91
Batch: 360; loss: 0.41; acc: 0.83
Batch: 380; loss: 0.49; acc: 0.81
Batch: 400; loss: 0.42; acc: 0.84
Batch: 420; loss: 0.58; acc: 0.78
Batch: 440; loss: 0.42; acc: 0.84
Batch: 460; loss: 0.59; acc: 0.86
Batch: 480; loss: 0.35; acc: 0.89
Batch: 500; loss: 0.44; acc: 0.88
Batch: 520; loss: 0.44; acc: 0.89
Batch: 540; loss: 0.22; acc: 0.94
Batch: 560; loss: 0.35; acc: 0.83
Batch: 580; loss: 0.43; acc: 0.78
Batch: 600; loss: 0.28; acc: 0.91
Batch: 620; loss: 0.31; acc: 0.88
Batch: 640; loss: 0.47; acc: 0.89
Batch: 660; loss: 0.45; acc: 0.84
Batch: 680; loss: 0.27; acc: 0.95
Batch: 700; loss: 0.35; acc: 0.89
Batch: 720; loss: 0.44; acc: 0.86
Batch: 740; loss: 0.18; acc: 0.92
Batch: 760; loss: 0.52; acc: 0.88
Batch: 780; loss: 0.28; acc: 0.92
Train Epoch over. train_loss: 0.41; train_accuracy: 0.88 

2.3086216970114037e-05
8.168021849996876e-06
Batch: 0; loss: 0.48; acc: 0.88
Batch: 20; loss: 0.76; acc: 0.77
Batch: 40; loss: 0.28; acc: 0.91
Batch: 60; loss: 0.61; acc: 0.77
Batch: 80; loss: 0.22; acc: 0.95
Batch: 100; loss: 0.55; acc: 0.89
Batch: 120; loss: 1.15; acc: 0.81
Batch: 140; loss: 0.23; acc: 0.91
Val Epoch over. val_loss: 0.5415862582766326; val_accuracy: 0.841859076433121 

The current subspace-distance is: 8.168021849996876e-06 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.62; acc: 0.8
Batch: 20; loss: 0.54; acc: 0.88
Batch: 40; loss: 0.37; acc: 0.84
Batch: 60; loss: 0.33; acc: 0.88
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.44; acc: 0.88
Batch: 120; loss: 0.71; acc: 0.8
Batch: 140; loss: 0.27; acc: 0.92
Batch: 160; loss: 0.36; acc: 0.88
Batch: 180; loss: 0.55; acc: 0.88
Batch: 200; loss: 0.39; acc: 0.88
Batch: 220; loss: 0.6; acc: 0.91
Batch: 240; loss: 0.32; acc: 0.92
Batch: 260; loss: 0.4; acc: 0.83
Batch: 280; loss: 0.62; acc: 0.83
Batch: 300; loss: 0.22; acc: 0.92
Batch: 320; loss: 0.39; acc: 0.91
Batch: 340; loss: 0.47; acc: 0.86
Batch: 360; loss: 0.36; acc: 0.89
Batch: 380; loss: 0.56; acc: 0.86
Batch: 400; loss: 0.61; acc: 0.84
Batch: 420; loss: 0.41; acc: 0.89
Batch: 440; loss: 0.39; acc: 0.88
Batch: 460; loss: 0.45; acc: 0.86
Batch: 480; loss: 0.29; acc: 0.89
Batch: 500; loss: 0.42; acc: 0.86
Batch: 520; loss: 0.17; acc: 0.95
Batch: 540; loss: 0.64; acc: 0.8
Batch: 560; loss: 0.37; acc: 0.86
Batch: 580; loss: 0.4; acc: 0.89
Batch: 600; loss: 0.33; acc: 0.88
Batch: 620; loss: 0.38; acc: 0.89
Batch: 640; loss: 0.43; acc: 0.84
Batch: 660; loss: 0.43; acc: 0.89
Batch: 680; loss: 0.12; acc: 0.98
Batch: 700; loss: 0.44; acc: 0.86
Batch: 720; loss: 0.32; acc: 0.83
Batch: 740; loss: 0.42; acc: 0.84
Batch: 760; loss: 0.39; acc: 0.88
Batch: 780; loss: 0.49; acc: 0.84
Train Epoch over. train_loss: 0.41; train_accuracy: 0.88 

2.557545121817384e-05
9.447160664421972e-06
Batch: 0; loss: 0.33; acc: 0.91
Batch: 20; loss: 0.51; acc: 0.83
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.5; acc: 0.84
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.48; acc: 0.88
Batch: 120; loss: 0.84; acc: 0.75
Batch: 140; loss: 0.26; acc: 0.89
Val Epoch over. val_loss: 0.4006740035619705; val_accuracy: 0.879578025477707 

The current subspace-distance is: 9.447160664421972e-06 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.27; acc: 0.94
Batch: 20; loss: 0.46; acc: 0.83
Batch: 40; loss: 0.51; acc: 0.84
Batch: 60; loss: 0.32; acc: 0.89
Batch: 80; loss: 0.45; acc: 0.88
Batch: 100; loss: 0.55; acc: 0.84
Batch: 120; loss: 0.67; acc: 0.83
Batch: 140; loss: 0.26; acc: 0.89
Batch: 160; loss: 0.58; acc: 0.84
Batch: 180; loss: 0.7; acc: 0.81
Batch: 200; loss: 0.52; acc: 0.81
Batch: 220; loss: 0.38; acc: 0.89
Batch: 240; loss: 0.55; acc: 0.8
Batch: 260; loss: 0.54; acc: 0.84
Batch: 280; loss: 0.34; acc: 0.89
Batch: 300; loss: 0.61; acc: 0.84
Batch: 320; loss: 0.36; acc: 0.86
Batch: 340; loss: 0.34; acc: 0.89
Batch: 360; loss: 0.51; acc: 0.86
Batch: 380; loss: 0.71; acc: 0.8
Batch: 400; loss: 0.68; acc: 0.78
Batch: 420; loss: 0.65; acc: 0.81
Batch: 440; loss: 0.32; acc: 0.83
Batch: 460; loss: 0.35; acc: 0.91
Batch: 480; loss: 0.28; acc: 0.91
Batch: 500; loss: 0.37; acc: 0.89
Batch: 520; loss: 0.63; acc: 0.8
Batch: 540; loss: 0.34; acc: 0.91
Batch: 560; loss: 0.62; acc: 0.8
Batch: 580; loss: 0.4; acc: 0.91
Batch: 600; loss: 0.44; acc: 0.88
Batch: 620; loss: 0.29; acc: 0.94
Batch: 640; loss: 0.37; acc: 0.89
Batch: 660; loss: 0.5; acc: 0.89
Batch: 680; loss: 0.39; acc: 0.91
Batch: 700; loss: 0.29; acc: 0.91
Batch: 720; loss: 0.27; acc: 0.89
Batch: 740; loss: 0.6; acc: 0.86
Batch: 760; loss: 0.38; acc: 0.89
Batch: 780; loss: 0.51; acc: 0.81
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

2.634996417327784e-05
8.40623579279054e-06
Batch: 0; loss: 0.32; acc: 0.88
Batch: 20; loss: 0.47; acc: 0.83
Batch: 40; loss: 0.3; acc: 0.91
Batch: 60; loss: 0.43; acc: 0.86
Batch: 80; loss: 0.15; acc: 0.94
Batch: 100; loss: 0.45; acc: 0.84
Batch: 120; loss: 0.71; acc: 0.81
Batch: 140; loss: 0.13; acc: 0.95
Val Epoch over. val_loss: 0.3826394602181805; val_accuracy: 0.8827627388535032 

The current subspace-distance is: 8.40623579279054e-06 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.59; acc: 0.84
Batch: 20; loss: 0.27; acc: 0.88
Batch: 40; loss: 0.52; acc: 0.88
Batch: 60; loss: 0.37; acc: 0.91
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.67; acc: 0.8
Batch: 120; loss: 0.37; acc: 0.91
Batch: 140; loss: 0.35; acc: 0.89
Batch: 160; loss: 0.39; acc: 0.89
Batch: 180; loss: 0.46; acc: 0.86
Batch: 200; loss: 0.35; acc: 0.89
Batch: 220; loss: 0.15; acc: 0.98
Batch: 240; loss: 0.32; acc: 0.88
Batch: 260; loss: 0.55; acc: 0.81
Batch: 280; loss: 0.46; acc: 0.92
Batch: 300; loss: 0.32; acc: 0.88
Batch: 320; loss: 0.54; acc: 0.81
Batch: 340; loss: 0.53; acc: 0.81
Batch: 360; loss: 0.28; acc: 0.91
Batch: 380; loss: 0.34; acc: 0.84
Batch: 400; loss: 0.28; acc: 0.89
Batch: 420; loss: 0.33; acc: 0.88
Batch: 440; loss: 0.38; acc: 0.91
Batch: 460; loss: 0.54; acc: 0.86
Batch: 480; loss: 0.27; acc: 0.95
Batch: 500; loss: 0.39; acc: 0.86
Batch: 520; loss: 0.27; acc: 0.92
Batch: 540; loss: 0.33; acc: 0.91
Batch: 560; loss: 0.48; acc: 0.86
Batch: 580; loss: 0.26; acc: 0.92
Batch: 600; loss: 0.45; acc: 0.81
Batch: 620; loss: 0.35; acc: 0.92
Batch: 640; loss: 0.52; acc: 0.89
Batch: 660; loss: 0.34; acc: 0.89
Batch: 680; loss: 0.16; acc: 0.97
Batch: 700; loss: 0.43; acc: 0.89
Batch: 720; loss: 0.25; acc: 0.89
Batch: 740; loss: 0.22; acc: 0.92
Batch: 760; loss: 0.29; acc: 0.92
Batch: 780; loss: 0.5; acc: 0.94
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

2.7205756850889884e-05
9.462425623496529e-06
Batch: 0; loss: 0.38; acc: 0.86
Batch: 20; loss: 0.58; acc: 0.81
Batch: 40; loss: 0.25; acc: 0.92
Batch: 60; loss: 0.54; acc: 0.81
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.49; acc: 0.89
Batch: 120; loss: 0.89; acc: 0.83
Batch: 140; loss: 0.15; acc: 0.97
Val Epoch over. val_loss: 0.44184692256200087; val_accuracy: 0.8674363057324841 

The current subspace-distance is: 9.462425623496529e-06 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.54; acc: 0.83
Batch: 20; loss: 0.31; acc: 0.86
Batch: 40; loss: 0.52; acc: 0.83
Batch: 60; loss: 0.47; acc: 0.88
Batch: 80; loss: 0.7; acc: 0.8
Batch: 100; loss: 0.67; acc: 0.84
Batch: 120; loss: 0.23; acc: 0.92
Batch: 140; loss: 0.34; acc: 0.91
Batch: 160; loss: 0.37; acc: 0.89
Batch: 180; loss: 0.43; acc: 0.91
Batch: 200; loss: 0.69; acc: 0.84
Batch: 220; loss: 0.17; acc: 0.95
Batch: 240; loss: 0.49; acc: 0.91
Batch: 260; loss: 0.56; acc: 0.75
Batch: 280; loss: 0.45; acc: 0.86
Batch: 300; loss: 0.56; acc: 0.84
Batch: 320; loss: 0.57; acc: 0.84
Batch: 340; loss: 0.4; acc: 0.84
Batch: 360; loss: 0.29; acc: 0.94
Batch: 380; loss: 0.31; acc: 0.89
Batch: 400; loss: 0.45; acc: 0.84
Batch: 420; loss: 0.38; acc: 0.88
Batch: 440; loss: 0.32; acc: 0.91
Batch: 460; loss: 0.36; acc: 0.91
Batch: 480; loss: 0.51; acc: 0.81
Batch: 500; loss: 0.33; acc: 0.92
Batch: 520; loss: 0.4; acc: 0.89
Batch: 540; loss: 0.36; acc: 0.91
Batch: 560; loss: 0.3; acc: 0.92
Batch: 580; loss: 0.4; acc: 0.89
Batch: 600; loss: 0.2; acc: 0.91
Batch: 620; loss: 0.59; acc: 0.84
Batch: 640; loss: 0.24; acc: 0.92
Batch: 660; loss: 0.21; acc: 0.92
Batch: 680; loss: 0.58; acc: 0.8
Batch: 700; loss: 0.22; acc: 0.94
Batch: 720; loss: 0.39; acc: 0.88
Batch: 740; loss: 0.33; acc: 0.84
Batch: 760; loss: 0.34; acc: 0.88
Batch: 780; loss: 0.49; acc: 0.91
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

2.659522033354733e-05
8.047415576584172e-06
Batch: 0; loss: 0.3; acc: 0.88
Batch: 20; loss: 0.49; acc: 0.77
Batch: 40; loss: 0.23; acc: 0.92
Batch: 60; loss: 0.45; acc: 0.89
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.41; acc: 0.88
Batch: 120; loss: 0.77; acc: 0.77
Batch: 140; loss: 0.19; acc: 0.92
Val Epoch over. val_loss: 0.3783700890886556; val_accuracy: 0.8863455414012739 

The current subspace-distance is: 8.047415576584172e-06 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.19; acc: 0.91
Batch: 20; loss: 0.45; acc: 0.84
Batch: 40; loss: 0.33; acc: 0.94
Batch: 60; loss: 0.29; acc: 0.92
Batch: 80; loss: 0.45; acc: 0.88
Batch: 100; loss: 0.35; acc: 0.92
Batch: 120; loss: 0.26; acc: 0.89
Batch: 140; loss: 0.33; acc: 0.89
Batch: 160; loss: 0.62; acc: 0.75
Batch: 180; loss: 0.3; acc: 0.92
Batch: 200; loss: 0.4; acc: 0.86
Batch: 220; loss: 0.28; acc: 0.88
Batch: 240; loss: 0.41; acc: 0.88
Batch: 260; loss: 0.31; acc: 0.89
Batch: 280; loss: 0.28; acc: 0.94
Batch: 300; loss: 0.32; acc: 0.94
Batch: 320; loss: 0.45; acc: 0.86
Batch: 340; loss: 0.31; acc: 0.91
Batch: 360; loss: 0.27; acc: 0.92
Batch: 380; loss: 0.54; acc: 0.8
Batch: 400; loss: 0.52; acc: 0.86
Batch: 420; loss: 0.4; acc: 0.86
Batch: 440; loss: 0.45; acc: 0.88
Batch: 460; loss: 0.4; acc: 0.83
Batch: 480; loss: 0.37; acc: 0.89
Batch: 500; loss: 0.32; acc: 0.88
Batch: 520; loss: 0.37; acc: 0.89
Batch: 540; loss: 0.31; acc: 0.88
Batch: 560; loss: 0.32; acc: 0.91
Batch: 580; loss: 0.38; acc: 0.84
Batch: 600; loss: 0.33; acc: 0.88
Batch: 620; loss: 0.57; acc: 0.83
Batch: 640; loss: 0.27; acc: 0.92
Batch: 660; loss: 0.39; acc: 0.88
Batch: 680; loss: 0.4; acc: 0.91
Batch: 700; loss: 0.43; acc: 0.84
Batch: 720; loss: 0.6; acc: 0.83
Batch: 740; loss: 0.26; acc: 0.92
Batch: 760; loss: 0.41; acc: 0.89
Batch: 780; loss: 0.31; acc: 0.94
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

2.5707369786687195e-05
8.766997780185193e-06
Batch: 0; loss: 0.41; acc: 0.86
Batch: 20; loss: 0.62; acc: 0.8
Batch: 40; loss: 0.3; acc: 0.91
Batch: 60; loss: 0.55; acc: 0.86
Batch: 80; loss: 0.33; acc: 0.89
Batch: 100; loss: 0.52; acc: 0.88
Batch: 120; loss: 0.81; acc: 0.81
Batch: 140; loss: 0.16; acc: 0.95
Val Epoch over. val_loss: 0.4503561431530175; val_accuracy: 0.8534036624203821 

The current subspace-distance is: 8.766997780185193e-06 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.54; acc: 0.83
Batch: 20; loss: 0.23; acc: 0.94
Batch: 40; loss: 0.5; acc: 0.78
Batch: 60; loss: 0.48; acc: 0.83
Batch: 80; loss: 0.63; acc: 0.88
Batch: 100; loss: 0.28; acc: 0.89
Batch: 120; loss: 0.4; acc: 0.89
Batch: 140; loss: 0.37; acc: 0.88
Batch: 160; loss: 0.54; acc: 0.86
Batch: 180; loss: 0.54; acc: 0.83
Batch: 200; loss: 0.22; acc: 0.95
Batch: 220; loss: 0.37; acc: 0.86
Batch: 240; loss: 0.29; acc: 0.94
Batch: 260; loss: 0.55; acc: 0.8
Batch: 280; loss: 0.38; acc: 0.84
Batch: 300; loss: 0.33; acc: 0.89
Batch: 320; loss: 0.4; acc: 0.88
Batch: 340; loss: 0.37; acc: 0.89
Batch: 360; loss: 0.27; acc: 0.92
Batch: 380; loss: 0.47; acc: 0.92
Batch: 400; loss: 0.44; acc: 0.8
Batch: 420; loss: 0.44; acc: 0.83
Batch: 440; loss: 0.33; acc: 0.91
Batch: 460; loss: 0.26; acc: 0.92
Batch: 480; loss: 0.36; acc: 0.92
Batch: 500; loss: 0.43; acc: 0.83
Batch: 520; loss: 0.2; acc: 0.97
Batch: 540; loss: 0.28; acc: 0.91
Batch: 560; loss: 0.37; acc: 0.89
Batch: 580; loss: 0.28; acc: 0.94
Batch: 600; loss: 0.21; acc: 0.94
Batch: 620; loss: 0.58; acc: 0.84
Batch: 640; loss: 0.36; acc: 0.89
Batch: 660; loss: 0.36; acc: 0.92
Batch: 680; loss: 0.33; acc: 0.89
Batch: 700; loss: 0.4; acc: 0.89
Batch: 720; loss: 0.34; acc: 0.89
Batch: 740; loss: 0.33; acc: 0.91
Batch: 760; loss: 0.53; acc: 0.86
Batch: 780; loss: 0.64; acc: 0.8
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

2.5935281882993877e-05
8.838749636197463e-06
Batch: 0; loss: 0.28; acc: 0.88
Batch: 20; loss: 0.43; acc: 0.8
Batch: 40; loss: 0.22; acc: 0.92
Batch: 60; loss: 0.44; acc: 0.88
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.43; acc: 0.89
Batch: 120; loss: 0.67; acc: 0.83
Batch: 140; loss: 0.13; acc: 0.95
Val Epoch over. val_loss: 0.3624544721689953; val_accuracy: 0.8929140127388535 

The current subspace-distance is: 8.838749636197463e-06 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.4; acc: 0.92
Batch: 20; loss: 0.34; acc: 0.89
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.26; acc: 0.89
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.59; acc: 0.81
Batch: 140; loss: 0.38; acc: 0.91
Batch: 160; loss: 0.43; acc: 0.86
Batch: 180; loss: 0.25; acc: 0.89
Batch: 200; loss: 0.51; acc: 0.81
Batch: 220; loss: 0.25; acc: 0.91
Batch: 240; loss: 0.27; acc: 0.92
Batch: 260; loss: 0.46; acc: 0.89
Batch: 280; loss: 0.25; acc: 0.94
Batch: 300; loss: 0.45; acc: 0.83
Batch: 320; loss: 0.46; acc: 0.89
Batch: 340; loss: 0.33; acc: 0.92
Batch: 360; loss: 0.35; acc: 0.84
Batch: 380; loss: 0.42; acc: 0.81
Batch: 400; loss: 0.22; acc: 0.95
Batch: 420; loss: 0.53; acc: 0.81
Batch: 440; loss: 0.51; acc: 0.88
Batch: 460; loss: 0.51; acc: 0.83
Batch: 480; loss: 0.23; acc: 0.89
Batch: 500; loss: 0.31; acc: 0.91
Batch: 520; loss: 0.41; acc: 0.88
Batch: 540; loss: 0.39; acc: 0.84
Batch: 560; loss: 0.24; acc: 0.94
Batch: 580; loss: 0.19; acc: 0.94
Batch: 600; loss: 0.27; acc: 0.97
Batch: 620; loss: 0.21; acc: 0.89
Batch: 640; loss: 0.39; acc: 0.83
Batch: 660; loss: 0.49; acc: 0.83
Batch: 680; loss: 0.37; acc: 0.84
Batch: 700; loss: 0.25; acc: 0.92
Batch: 720; loss: 0.4; acc: 0.86
Batch: 740; loss: 0.35; acc: 0.88
Batch: 760; loss: 0.24; acc: 0.95
Batch: 780; loss: 0.24; acc: 0.94
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

2.8786120310542174e-05
9.159615729004145e-06
Batch: 0; loss: 0.3; acc: 0.86
Batch: 20; loss: 0.5; acc: 0.77
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.45; acc: 0.91
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.41; acc: 0.92
Batch: 120; loss: 0.79; acc: 0.81
Batch: 140; loss: 0.16; acc: 0.95
Val Epoch over. val_loss: 0.3729030592189093; val_accuracy: 0.8883359872611465 

The current subspace-distance is: 9.159615729004145e-06 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.59; acc: 0.88
Batch: 40; loss: 0.55; acc: 0.78
Batch: 60; loss: 0.4; acc: 0.86
Batch: 80; loss: 0.38; acc: 0.88
Batch: 100; loss: 0.38; acc: 0.86
Batch: 120; loss: 0.66; acc: 0.8
Batch: 140; loss: 0.24; acc: 0.94
Batch: 160; loss: 0.29; acc: 0.89
Batch: 180; loss: 0.41; acc: 0.88
Batch: 200; loss: 0.51; acc: 0.84
Batch: 220; loss: 0.21; acc: 0.92
Batch: 240; loss: 0.55; acc: 0.84
Batch: 260; loss: 0.34; acc: 0.88
Batch: 280; loss: 0.3; acc: 0.92
Batch: 300; loss: 0.33; acc: 0.94
Batch: 320; loss: 0.53; acc: 0.84
Batch: 340; loss: 0.51; acc: 0.89
Batch: 360; loss: 0.41; acc: 0.88
Batch: 380; loss: 0.5; acc: 0.81
Batch: 400; loss: 0.56; acc: 0.81
Batch: 420; loss: 0.4; acc: 0.88
Batch: 440; loss: 0.89; acc: 0.77
Batch: 460; loss: 0.4; acc: 0.81
Batch: 480; loss: 0.24; acc: 0.91
Batch: 500; loss: 0.41; acc: 0.89
Batch: 520; loss: 0.47; acc: 0.86
Batch: 540; loss: 0.36; acc: 0.88
Batch: 560; loss: 0.6; acc: 0.8
Batch: 580; loss: 0.36; acc: 0.97
Batch: 600; loss: 0.38; acc: 0.92
Batch: 620; loss: 0.43; acc: 0.86
Batch: 640; loss: 0.47; acc: 0.86
Batch: 660; loss: 0.26; acc: 0.92
Batch: 680; loss: 0.29; acc: 0.94
Batch: 700; loss: 0.41; acc: 0.91
Batch: 720; loss: 0.35; acc: 0.94
Batch: 740; loss: 0.25; acc: 0.89
Batch: 760; loss: 0.33; acc: 0.88
Batch: 780; loss: 0.27; acc: 0.92
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

2.662611768755596e-05
8.562941729906015e-06
Batch: 0; loss: 0.27; acc: 0.86
Batch: 20; loss: 0.45; acc: 0.83
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.4; acc: 0.91
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.4; acc: 0.94
Batch: 120; loss: 0.7; acc: 0.83
Batch: 140; loss: 0.15; acc: 0.94
Val Epoch over. val_loss: 0.3548806309225453; val_accuracy: 0.8957006369426752 

The current subspace-distance is: 8.562941729906015e-06 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.23; acc: 0.94
Batch: 20; loss: 0.4; acc: 0.91
Batch: 40; loss: 0.48; acc: 0.84
Batch: 60; loss: 0.48; acc: 0.81
Batch: 80; loss: 0.43; acc: 0.86
Batch: 100; loss: 0.34; acc: 0.89
Batch: 120; loss: 0.25; acc: 0.92
Batch: 140; loss: 0.33; acc: 0.88
Batch: 160; loss: 0.31; acc: 0.86
Batch: 180; loss: 0.32; acc: 0.91
Batch: 200; loss: 0.21; acc: 0.95
Batch: 220; loss: 0.7; acc: 0.8
Batch: 240; loss: 0.29; acc: 0.91
Batch: 260; loss: 0.25; acc: 0.92
Batch: 280; loss: 0.55; acc: 0.84
Batch: 300; loss: 0.32; acc: 0.91
Batch: 320; loss: 0.23; acc: 0.91
Batch: 340; loss: 0.34; acc: 0.91
Batch: 360; loss: 0.41; acc: 0.92
Batch: 380; loss: 0.37; acc: 0.88
Batch: 400; loss: 0.44; acc: 0.84
Batch: 420; loss: 0.34; acc: 0.92
Batch: 440; loss: 0.43; acc: 0.89
Batch: 460; loss: 0.35; acc: 0.89
Batch: 480; loss: 0.31; acc: 0.94
Batch: 500; loss: 0.41; acc: 0.86
Batch: 520; loss: 0.34; acc: 0.89
Batch: 540; loss: 0.26; acc: 0.94
Batch: 560; loss: 0.26; acc: 0.89
Batch: 580; loss: 0.44; acc: 0.86
Batch: 600; loss: 0.42; acc: 0.89
Batch: 620; loss: 0.36; acc: 0.86
Batch: 640; loss: 0.64; acc: 0.77
Batch: 660; loss: 0.44; acc: 0.86
Batch: 680; loss: 0.45; acc: 0.83
Batch: 700; loss: 0.25; acc: 0.91
Batch: 720; loss: 0.24; acc: 0.94
Batch: 740; loss: 0.55; acc: 0.88
Batch: 760; loss: 0.3; acc: 0.89
Batch: 780; loss: 0.68; acc: 0.77
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

2.716076051001437e-05
9.595225492375903e-06
Batch: 0; loss: 0.27; acc: 0.89
Batch: 20; loss: 0.42; acc: 0.83
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.44; acc: 0.88
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.4; acc: 0.94
Batch: 120; loss: 0.71; acc: 0.83
Batch: 140; loss: 0.15; acc: 0.94
Val Epoch over. val_loss: 0.35988612560804484; val_accuracy: 0.8939092356687898 

The current subspace-distance is: 9.595225492375903e-06 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.61; acc: 0.81
Batch: 40; loss: 0.5; acc: 0.86
Batch: 60; loss: 0.43; acc: 0.88
Batch: 80; loss: 0.47; acc: 0.8
Batch: 100; loss: 0.39; acc: 0.88
Batch: 120; loss: 0.17; acc: 0.94
Batch: 140; loss: 0.5; acc: 0.91
Batch: 160; loss: 0.44; acc: 0.83
Batch: 180; loss: 0.23; acc: 0.92
Batch: 200; loss: 0.42; acc: 0.88
Batch: 220; loss: 0.31; acc: 0.89
Batch: 240; loss: 0.57; acc: 0.89
Batch: 260; loss: 0.21; acc: 0.91
Batch: 280; loss: 0.21; acc: 0.94
Batch: 300; loss: 0.34; acc: 0.84
Batch: 320; loss: 0.48; acc: 0.81
Batch: 340; loss: 0.36; acc: 0.88
Batch: 360; loss: 0.24; acc: 0.94
Batch: 380; loss: 0.64; acc: 0.88
Batch: 400; loss: 0.29; acc: 0.94
Batch: 420; loss: 0.43; acc: 0.86
Batch: 440; loss: 0.29; acc: 0.88
Batch: 460; loss: 0.57; acc: 0.86
Batch: 480; loss: 0.33; acc: 0.88
Batch: 500; loss: 0.48; acc: 0.86
Batch: 520; loss: 0.35; acc: 0.91
Batch: 540; loss: 0.36; acc: 0.92
Batch: 560; loss: 0.33; acc: 0.94
Batch: 580; loss: 0.27; acc: 0.91
Batch: 600; loss: 0.5; acc: 0.88
Batch: 620; loss: 0.25; acc: 0.91
Batch: 640; loss: 0.3; acc: 0.94
Batch: 660; loss: 0.57; acc: 0.83
Batch: 680; loss: 0.39; acc: 0.92
Batch: 700; loss: 0.2; acc: 0.94
Batch: 720; loss: 0.36; acc: 0.91
Batch: 740; loss: 0.33; acc: 0.84
Batch: 760; loss: 0.52; acc: 0.86
Batch: 780; loss: 0.31; acc: 0.89
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

2.5474793801549822e-05
8.732527021493297e-06
Batch: 0; loss: 0.27; acc: 0.86
Batch: 20; loss: 0.43; acc: 0.81
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.41; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.4; acc: 0.94
Batch: 120; loss: 0.69; acc: 0.83
Batch: 140; loss: 0.13; acc: 0.95
Val Epoch over. val_loss: 0.35740826857887253; val_accuracy: 0.8927149681528662 

The current subspace-distance is: 8.732527021493297e-06 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.3; acc: 0.92
Batch: 20; loss: 0.43; acc: 0.84
Batch: 40; loss: 0.35; acc: 0.89
Batch: 60; loss: 0.28; acc: 0.88
Batch: 80; loss: 0.44; acc: 0.89
Batch: 100; loss: 0.5; acc: 0.84
Batch: 120; loss: 0.17; acc: 0.94
Batch: 140; loss: 0.41; acc: 0.88
Batch: 160; loss: 0.35; acc: 0.89
Batch: 180; loss: 0.28; acc: 0.92
Batch: 200; loss: 0.38; acc: 0.86
Batch: 220; loss: 0.64; acc: 0.81
Batch: 240; loss: 0.27; acc: 0.94
Batch: 260; loss: 0.23; acc: 0.92
Batch: 280; loss: 0.26; acc: 0.92
Batch: 300; loss: 0.53; acc: 0.83
Batch: 320; loss: 0.2; acc: 0.88
Batch: 340; loss: 0.53; acc: 0.77
Batch: 360; loss: 0.36; acc: 0.88
Batch: 380; loss: 0.41; acc: 0.86
Batch: 400; loss: 0.42; acc: 0.86
Batch: 420; loss: 0.42; acc: 0.83
Batch: 440; loss: 0.3; acc: 0.94
Batch: 460; loss: 0.47; acc: 0.88
Batch: 480; loss: 0.37; acc: 0.88
Batch: 500; loss: 0.5; acc: 0.78
Batch: 520; loss: 0.35; acc: 0.89
Batch: 540; loss: 0.44; acc: 0.89
Batch: 560; loss: 0.29; acc: 0.91
Batch: 580; loss: 0.38; acc: 0.88
Batch: 600; loss: 0.35; acc: 0.89
Batch: 620; loss: 0.3; acc: 0.91
Batch: 640; loss: 0.51; acc: 0.78
Batch: 660; loss: 0.5; acc: 0.83
Batch: 680; loss: 0.27; acc: 0.89
Batch: 700; loss: 0.35; acc: 0.84
Batch: 720; loss: 0.38; acc: 0.88
Batch: 740; loss: 0.46; acc: 0.81
Batch: 760; loss: 0.52; acc: 0.89
Batch: 780; loss: 0.2; acc: 0.91
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

2.493205465725623e-05
9.374240107717924e-06
Batch: 0; loss: 0.25; acc: 0.92
Batch: 20; loss: 0.45; acc: 0.8
Batch: 40; loss: 0.21; acc: 0.92
Batch: 60; loss: 0.43; acc: 0.88
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.39; acc: 0.91
Batch: 120; loss: 0.68; acc: 0.81
Batch: 140; loss: 0.16; acc: 0.95
Val Epoch over. val_loss: 0.35420488309898196; val_accuracy: 0.8953025477707006 

The current subspace-distance is: 9.374240107717924e-06 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.35; acc: 0.84
Batch: 20; loss: 0.42; acc: 0.81
Batch: 40; loss: 0.52; acc: 0.84
Batch: 60; loss: 0.54; acc: 0.8
Batch: 80; loss: 0.37; acc: 0.83
Batch: 100; loss: 0.32; acc: 0.91
Batch: 120; loss: 0.24; acc: 0.94
Batch: 140; loss: 0.43; acc: 0.84
Batch: 160; loss: 0.7; acc: 0.84
Batch: 180; loss: 0.39; acc: 0.88
Batch: 200; loss: 0.4; acc: 0.83
Batch: 220; loss: 0.39; acc: 0.84
Batch: 240; loss: 0.26; acc: 0.92
Batch: 260; loss: 0.46; acc: 0.88
Batch: 280; loss: 0.44; acc: 0.81
Batch: 300; loss: 0.32; acc: 0.91
Batch: 320; loss: 0.25; acc: 0.91
Batch: 340; loss: 0.33; acc: 0.92
Batch: 360; loss: 0.24; acc: 0.91
Batch: 380; loss: 0.47; acc: 0.86
Batch: 400; loss: 0.3; acc: 0.89
Batch: 420; loss: 0.64; acc: 0.78
Batch: 440; loss: 0.25; acc: 0.95
Batch: 460; loss: 0.35; acc: 0.88
Batch: 480; loss: 0.27; acc: 0.89
Batch: 500; loss: 0.52; acc: 0.81
Batch: 520; loss: 0.24; acc: 0.94
Batch: 540; loss: 0.23; acc: 0.97
Batch: 560; loss: 0.37; acc: 0.89
Batch: 580; loss: 0.44; acc: 0.88
Batch: 600; loss: 0.34; acc: 0.89
Batch: 620; loss: 0.55; acc: 0.88
Batch: 640; loss: 0.21; acc: 0.89
Batch: 660; loss: 0.38; acc: 0.83
Batch: 680; loss: 0.3; acc: 0.92
Batch: 700; loss: 0.37; acc: 0.84
Batch: 720; loss: 0.42; acc: 0.83
Batch: 740; loss: 0.39; acc: 0.88
Batch: 760; loss: 0.3; acc: 0.94
Batch: 780; loss: 0.3; acc: 0.91
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

2.4880708224372938e-05
8.721585800230969e-06
Batch: 0; loss: 0.29; acc: 0.89
Batch: 20; loss: 0.43; acc: 0.83
Batch: 40; loss: 0.21; acc: 0.92
Batch: 60; loss: 0.39; acc: 0.88
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.43; acc: 0.89
Batch: 120; loss: 0.67; acc: 0.86
Batch: 140; loss: 0.13; acc: 0.95
Val Epoch over. val_loss: 0.3530536628073188; val_accuracy: 0.8954020700636943 

The current subspace-distance is: 8.721585800230969e-06 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.46; acc: 0.84
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.4; acc: 0.92
Batch: 60; loss: 0.55; acc: 0.86
Batch: 80; loss: 0.36; acc: 0.89
Batch: 100; loss: 0.37; acc: 0.92
Batch: 120; loss: 0.23; acc: 0.91
Batch: 140; loss: 0.38; acc: 0.89
Batch: 160; loss: 0.31; acc: 0.89
Batch: 180; loss: 0.4; acc: 0.86
Batch: 200; loss: 0.14; acc: 0.97
Batch: 220; loss: 0.43; acc: 0.86
Batch: 240; loss: 0.45; acc: 0.89
Batch: 260; loss: 0.38; acc: 0.89
Batch: 280; loss: 0.21; acc: 0.94
Batch: 300; loss: 0.42; acc: 0.89
Batch: 320; loss: 0.13; acc: 0.98
Batch: 340; loss: 0.57; acc: 0.91
Batch: 360; loss: 0.42; acc: 0.88
Batch: 380; loss: 0.33; acc: 0.83
Batch: 400; loss: 0.36; acc: 0.89
Batch: 420; loss: 0.47; acc: 0.81
Batch: 440; loss: 0.4; acc: 0.88
Batch: 460; loss: 0.42; acc: 0.84
Batch: 480; loss: 0.43; acc: 0.91
Batch: 500; loss: 0.3; acc: 0.92
Batch: 520; loss: 0.27; acc: 0.88
Batch: 540; loss: 0.6; acc: 0.81
Batch: 560; loss: 0.26; acc: 0.94
Batch: 580; loss: 0.33; acc: 0.89
Batch: 600; loss: 0.27; acc: 0.91
Batch: 620; loss: 0.26; acc: 0.94
Batch: 640; loss: 0.12; acc: 0.97
Batch: 660; loss: 0.37; acc: 0.84
Batch: 680; loss: 0.2; acc: 0.95
Batch: 700; loss: 0.44; acc: 0.89
Batch: 720; loss: 0.28; acc: 0.91
Batch: 740; loss: 0.47; acc: 0.86
Batch: 760; loss: 0.72; acc: 0.78
Batch: 780; loss: 0.48; acc: 0.86
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

2.6235056793666445e-05
7.960678885865491e-06
Batch: 0; loss: 0.26; acc: 0.89
Batch: 20; loss: 0.4; acc: 0.84
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.41; acc: 0.88
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.39; acc: 0.94
Batch: 120; loss: 0.66; acc: 0.83
Batch: 140; loss: 0.16; acc: 0.94
Val Epoch over. val_loss: 0.35419836004448546; val_accuracy: 0.895203025477707 

The current subspace-distance is: 7.960678885865491e-06 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.4; acc: 0.89
Batch: 20; loss: 0.38; acc: 0.89
Batch: 40; loss: 0.26; acc: 0.91
Batch: 60; loss: 0.35; acc: 0.95
Batch: 80; loss: 0.27; acc: 0.94
Batch: 100; loss: 0.3; acc: 0.89
Batch: 120; loss: 0.26; acc: 0.89
Batch: 140; loss: 0.25; acc: 0.91
Batch: 160; loss: 0.37; acc: 0.89
Batch: 180; loss: 0.27; acc: 0.95
Batch: 200; loss: 0.29; acc: 0.88
Batch: 220; loss: 0.43; acc: 0.86
Batch: 240; loss: 0.32; acc: 0.91
Batch: 260; loss: 0.7; acc: 0.78
Batch: 280; loss: 0.55; acc: 0.8
Batch: 300; loss: 0.3; acc: 0.94
Batch: 320; loss: 0.27; acc: 0.91
Batch: 340; loss: 0.38; acc: 0.91
Batch: 360; loss: 0.32; acc: 0.86
Batch: 380; loss: 0.35; acc: 0.88
Batch: 400; loss: 0.37; acc: 0.91
Batch: 420; loss: 0.34; acc: 0.91
Batch: 440; loss: 0.33; acc: 0.89
Batch: 460; loss: 0.38; acc: 0.88
Batch: 480; loss: 0.45; acc: 0.89
Batch: 500; loss: 0.24; acc: 0.91
Batch: 520; loss: 0.25; acc: 0.91
Batch: 540; loss: 0.25; acc: 0.92
Batch: 560; loss: 0.39; acc: 0.84
Batch: 580; loss: 0.42; acc: 0.86
Batch: 600; loss: 0.45; acc: 0.84
Batch: 620; loss: 0.42; acc: 0.88
Batch: 640; loss: 0.29; acc: 0.88
Batch: 660; loss: 0.17; acc: 0.92
Batch: 680; loss: 0.38; acc: 0.86
Batch: 700; loss: 0.3; acc: 0.86
Batch: 720; loss: 0.3; acc: 0.89
Batch: 740; loss: 0.19; acc: 0.97
Batch: 760; loss: 0.27; acc: 0.94
Batch: 780; loss: 0.28; acc: 0.89
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

2.5591274606995285e-05
8.962526408140548e-06
Batch: 0; loss: 0.3; acc: 0.92
Batch: 20; loss: 0.58; acc: 0.78
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.57; acc: 0.83
Batch: 80; loss: 0.22; acc: 0.92
Batch: 100; loss: 0.41; acc: 0.91
Batch: 120; loss: 0.84; acc: 0.73
Batch: 140; loss: 0.2; acc: 0.92
Val Epoch over. val_loss: 0.41322476839184; val_accuracy: 0.8708200636942676 

The current subspace-distance is: 8.962526408140548e-06 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.38; acc: 0.86
Batch: 20; loss: 0.59; acc: 0.81
Batch: 40; loss: 0.3; acc: 0.92
Batch: 60; loss: 0.61; acc: 0.78
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.54; acc: 0.83
Batch: 140; loss: 0.27; acc: 0.94
Batch: 160; loss: 0.41; acc: 0.83
Batch: 180; loss: 0.33; acc: 0.92
Batch: 200; loss: 0.23; acc: 0.92
Batch: 220; loss: 0.44; acc: 0.84
Batch: 240; loss: 0.34; acc: 0.94
Batch: 260; loss: 0.29; acc: 0.92
Batch: 280; loss: 0.29; acc: 0.89
Batch: 300; loss: 0.63; acc: 0.8
Batch: 320; loss: 0.29; acc: 0.91
Batch: 340; loss: 0.23; acc: 0.92
Batch: 360; loss: 0.43; acc: 0.86
Batch: 380; loss: 0.33; acc: 0.84
Batch: 400; loss: 0.52; acc: 0.83
Batch: 420; loss: 0.22; acc: 0.94
Batch: 440; loss: 0.69; acc: 0.88
Batch: 460; loss: 0.39; acc: 0.91
Batch: 480; loss: 0.35; acc: 0.89
Batch: 500; loss: 0.22; acc: 0.92
Batch: 520; loss: 0.5; acc: 0.86
Batch: 540; loss: 0.28; acc: 0.92
Batch: 560; loss: 0.29; acc: 0.92
Batch: 580; loss: 0.42; acc: 0.89
Batch: 600; loss: 0.25; acc: 0.91
Batch: 620; loss: 0.35; acc: 0.89
Batch: 640; loss: 0.47; acc: 0.84
Batch: 660; loss: 0.29; acc: 0.86
Batch: 680; loss: 0.44; acc: 0.8
Batch: 700; loss: 0.39; acc: 0.88
Batch: 720; loss: 0.43; acc: 0.88
Batch: 740; loss: 0.3; acc: 0.89
Batch: 760; loss: 0.28; acc: 0.88
Batch: 780; loss: 0.24; acc: 0.92
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

2.5084780645556748e-05
8.246420293289702e-06
Batch: 0; loss: 0.27; acc: 0.92
Batch: 20; loss: 0.42; acc: 0.84
Batch: 40; loss: 0.21; acc: 0.92
Batch: 60; loss: 0.4; acc: 0.88
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.41; acc: 0.91
Batch: 120; loss: 0.63; acc: 0.83
Batch: 140; loss: 0.16; acc: 0.94
Val Epoch over. val_loss: 0.3538505155949076; val_accuracy: 0.8938097133757962 

The current subspace-distance is: 8.246420293289702e-06 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.33; acc: 0.92
Batch: 20; loss: 0.38; acc: 0.86
Batch: 40; loss: 0.25; acc: 0.92
Batch: 60; loss: 0.32; acc: 0.89
Batch: 80; loss: 0.46; acc: 0.83
Batch: 100; loss: 0.28; acc: 0.94
Batch: 120; loss: 0.6; acc: 0.83
Batch: 140; loss: 0.62; acc: 0.8
Batch: 160; loss: 0.43; acc: 0.88
Batch: 180; loss: 0.31; acc: 0.91
Batch: 200; loss: 0.33; acc: 0.88
Batch: 220; loss: 0.27; acc: 0.92
Batch: 240; loss: 0.43; acc: 0.88
Batch: 260; loss: 0.18; acc: 0.95
Batch: 280; loss: 0.38; acc: 0.89
Batch: 300; loss: 0.33; acc: 0.88
Batch: 320; loss: 0.51; acc: 0.81
Batch: 340; loss: 0.49; acc: 0.86
Batch: 360; loss: 0.2; acc: 0.92
Batch: 380; loss: 0.22; acc: 0.95
Batch: 400; loss: 0.2; acc: 0.94
Batch: 420; loss: 0.51; acc: 0.88
Batch: 440; loss: 0.39; acc: 0.84
Batch: 460; loss: 0.48; acc: 0.86
Batch: 480; loss: 0.27; acc: 0.95
Batch: 500; loss: 0.39; acc: 0.84
Batch: 520; loss: 0.44; acc: 0.88
Batch: 540; loss: 0.34; acc: 0.91
Batch: 560; loss: 0.22; acc: 0.92
Batch: 580; loss: 0.32; acc: 0.91
Batch: 600; loss: 0.62; acc: 0.8
Batch: 620; loss: 0.21; acc: 0.95
Batch: 640; loss: 0.51; acc: 0.84
Batch: 660; loss: 0.4; acc: 0.84
Batch: 680; loss: 0.13; acc: 0.98
Batch: 700; loss: 0.48; acc: 0.86
Batch: 720; loss: 0.39; acc: 0.89
Batch: 740; loss: 0.59; acc: 0.8
Batch: 760; loss: 0.55; acc: 0.77
Batch: 780; loss: 0.42; acc: 0.89
Train Epoch over. train_loss: 0.37; train_accuracy: 0.88 

2.5906983864842914e-05
8.339099622389767e-06
Batch: 0; loss: 0.25; acc: 0.92
Batch: 20; loss: 0.46; acc: 0.81
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.41; acc: 0.89
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.39; acc: 0.94
Batch: 120; loss: 0.69; acc: 0.81
Batch: 140; loss: 0.18; acc: 0.94
Val Epoch over. val_loss: 0.3521247558817742; val_accuracy: 0.8958996815286624 

The current subspace-distance is: 8.339099622389767e-06 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.33; acc: 0.89
Batch: 20; loss: 0.32; acc: 0.91
Batch: 40; loss: 0.34; acc: 0.89
Batch: 60; loss: 0.47; acc: 0.81
Batch: 80; loss: 0.5; acc: 0.86
Batch: 100; loss: 0.47; acc: 0.81
Batch: 120; loss: 0.44; acc: 0.86
Batch: 140; loss: 0.49; acc: 0.84
Batch: 160; loss: 0.29; acc: 0.91
Batch: 180; loss: 0.11; acc: 0.97
Batch: 200; loss: 0.43; acc: 0.86
Batch: 220; loss: 0.54; acc: 0.89
Batch: 240; loss: 0.24; acc: 0.92
Batch: 260; loss: 0.25; acc: 0.91
Batch: 280; loss: 0.6; acc: 0.84
Batch: 300; loss: 0.83; acc: 0.72
Batch: 320; loss: 0.23; acc: 0.94
Batch: 340; loss: 0.35; acc: 0.91
Batch: 360; loss: 0.28; acc: 0.94
Batch: 380; loss: 0.38; acc: 0.89
Batch: 400; loss: 0.37; acc: 0.88
Batch: 420; loss: 0.31; acc: 0.91
Batch: 440; loss: 0.24; acc: 0.95
Batch: 460; loss: 0.35; acc: 0.88
Batch: 480; loss: 0.2; acc: 0.91
Batch: 500; loss: 0.37; acc: 0.83
Batch: 520; loss: 0.46; acc: 0.89
Batch: 540; loss: 0.22; acc: 0.95
Batch: 560; loss: 0.32; acc: 0.94
Batch: 580; loss: 0.36; acc: 0.89
Batch: 600; loss: 0.34; acc: 0.89
Batch: 620; loss: 0.4; acc: 0.84
Batch: 640; loss: 0.21; acc: 0.92
Batch: 660; loss: 0.28; acc: 0.89
Batch: 680; loss: 0.58; acc: 0.83
Batch: 700; loss: 0.28; acc: 0.94
Batch: 720; loss: 0.39; acc: 0.86
Batch: 740; loss: 0.33; acc: 0.88
Batch: 760; loss: 0.27; acc: 0.91
Batch: 780; loss: 0.33; acc: 0.89
Train Epoch over. train_loss: 0.37; train_accuracy: 0.88 

2.70710534095997e-05
8.586569492763374e-06
Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.43; acc: 0.83
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.44; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.4; acc: 0.94
Batch: 120; loss: 0.7; acc: 0.8
Batch: 140; loss: 0.17; acc: 0.94
Val Epoch over. val_loss: 0.3529312987426284; val_accuracy: 0.8964968152866242 

The current subspace-distance is: 8.586569492763374e-06 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.36; acc: 0.86
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.46; acc: 0.86
Batch: 60; loss: 0.25; acc: 0.91
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.34; acc: 0.91
Batch: 120; loss: 0.36; acc: 0.88
Batch: 140; loss: 0.49; acc: 0.84
Batch: 160; loss: 0.19; acc: 0.97
Batch: 180; loss: 0.37; acc: 0.86
Batch: 200; loss: 0.3; acc: 0.92
Batch: 220; loss: 0.38; acc: 0.92
Batch: 240; loss: 0.51; acc: 0.83
Batch: 260; loss: 0.4; acc: 0.86
Batch: 280; loss: 0.37; acc: 0.89
Batch: 300; loss: 0.43; acc: 0.88
Batch: 320; loss: 0.48; acc: 0.86
Batch: 340; loss: 0.31; acc: 0.91
Batch: 360; loss: 0.37; acc: 0.89
Batch: 380; loss: 0.33; acc: 0.84
Batch: 400; loss: 0.38; acc: 0.89
Batch: 420; loss: 0.28; acc: 0.91
Batch: 440; loss: 0.21; acc: 0.95
Batch: 460; loss: 0.35; acc: 0.86
Batch: 480; loss: 0.33; acc: 0.88
Batch: 500; loss: 0.43; acc: 0.86
Batch: 520; loss: 0.24; acc: 0.92
Batch: 540; loss: 0.4; acc: 0.89
Batch: 560; loss: 0.45; acc: 0.84
Batch: 580; loss: 0.5; acc: 0.88
Batch: 600; loss: 0.44; acc: 0.88
Batch: 620; loss: 0.37; acc: 0.89
Batch: 640; loss: 0.53; acc: 0.88
Batch: 660; loss: 0.38; acc: 0.92
Batch: 680; loss: 0.45; acc: 0.88
Batch: 700; loss: 0.4; acc: 0.88
Batch: 720; loss: 0.3; acc: 0.89
Batch: 740; loss: 0.24; acc: 0.91
Batch: 760; loss: 0.41; acc: 0.88
Batch: 780; loss: 0.56; acc: 0.78
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

2.4860673875082284e-05
8.672740477777552e-06
Batch: 0; loss: 0.26; acc: 0.92
Batch: 20; loss: 0.42; acc: 0.84
Batch: 40; loss: 0.19; acc: 0.92
Batch: 60; loss: 0.41; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.4; acc: 0.92
Batch: 120; loss: 0.66; acc: 0.83
Batch: 140; loss: 0.15; acc: 0.94
Val Epoch over. val_loss: 0.34789205494390174; val_accuracy: 0.8961982484076433 

The current subspace-distance is: 8.672740477777552e-06 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.33; acc: 0.91
Batch: 20; loss: 0.46; acc: 0.92
Batch: 40; loss: 0.44; acc: 0.86
Batch: 60; loss: 0.76; acc: 0.78
Batch: 80; loss: 0.33; acc: 0.86
Batch: 100; loss: 0.46; acc: 0.88
Batch: 120; loss: 0.43; acc: 0.88
Batch: 140; loss: 0.27; acc: 0.94
Batch: 160; loss: 0.46; acc: 0.86
Batch: 180; loss: 0.38; acc: 0.84
Batch: 200; loss: 0.5; acc: 0.83
Batch: 220; loss: 0.32; acc: 0.92
Batch: 240; loss: 0.31; acc: 0.88
Batch: 260; loss: 0.32; acc: 0.89
Batch: 280; loss: 0.34; acc: 0.91
Batch: 300; loss: 0.22; acc: 0.94
Batch: 320; loss: 0.49; acc: 0.88
Batch: 340; loss: 0.51; acc: 0.88
Batch: 360; loss: 0.29; acc: 0.89
Batch: 380; loss: 0.14; acc: 0.95
Batch: 400; loss: 0.5; acc: 0.84
Batch: 420; loss: 0.39; acc: 0.86
Batch: 440; loss: 0.45; acc: 0.86
Batch: 460; loss: 0.38; acc: 0.86
Batch: 480; loss: 0.15; acc: 0.97
Batch: 500; loss: 0.25; acc: 0.91
Batch: 520; loss: 0.22; acc: 0.94
Batch: 540; loss: 0.38; acc: 0.86
Batch: 560; loss: 0.38; acc: 0.89
Batch: 580; loss: 0.15; acc: 0.97
Batch: 600; loss: 0.32; acc: 0.91
Batch: 620; loss: 0.36; acc: 0.89
Batch: 640; loss: 0.21; acc: 0.94
Batch: 660; loss: 0.49; acc: 0.84
Batch: 680; loss: 0.34; acc: 0.88
Batch: 700; loss: 0.42; acc: 0.86
Batch: 720; loss: 0.34; acc: 0.89
Batch: 740; loss: 0.42; acc: 0.86
Batch: 760; loss: 0.28; acc: 0.92
Batch: 780; loss: 0.23; acc: 0.89
Train Epoch over. train_loss: 0.37; train_accuracy: 0.88 

2.4774601115495898e-05
8.74085981195094e-06
Batch: 0; loss: 0.26; acc: 0.88
Batch: 20; loss: 0.42; acc: 0.84
Batch: 40; loss: 0.18; acc: 0.92
Batch: 60; loss: 0.44; acc: 0.88
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.4; acc: 0.92
Batch: 120; loss: 0.67; acc: 0.81
Batch: 140; loss: 0.16; acc: 0.94
Val Epoch over. val_loss: 0.3506194943455374; val_accuracy: 0.8973925159235668 

The current subspace-distance is: 8.74085981195094e-06 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.36; acc: 0.86
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.4; acc: 0.89
Batch: 60; loss: 0.47; acc: 0.88
Batch: 80; loss: 0.4; acc: 0.89
Batch: 100; loss: 0.31; acc: 0.92
Batch: 120; loss: 0.56; acc: 0.81
Batch: 140; loss: 0.32; acc: 0.91
Batch: 160; loss: 0.28; acc: 0.89
Batch: 180; loss: 0.22; acc: 0.91
Batch: 200; loss: 0.35; acc: 0.86
Batch: 220; loss: 0.48; acc: 0.83
Batch: 240; loss: 0.39; acc: 0.84
Batch: 260; loss: 0.37; acc: 0.86
Batch: 280; loss: 0.4; acc: 0.88
Batch: 300; loss: 0.28; acc: 0.92
Batch: 320; loss: 0.42; acc: 0.88
Batch: 340; loss: 0.33; acc: 0.92
Batch: 360; loss: 0.57; acc: 0.84
Batch: 380; loss: 0.33; acc: 0.92
Batch: 400; loss: 0.29; acc: 0.91
Batch: 420; loss: 0.51; acc: 0.84
Batch: 440; loss: 0.66; acc: 0.81
Batch: 460; loss: 0.35; acc: 0.91
Batch: 480; loss: 0.32; acc: 0.86
Batch: 500; loss: 0.37; acc: 0.88
Batch: 520; loss: 0.25; acc: 0.89
Batch: 540; loss: 0.47; acc: 0.84
Batch: 560; loss: 0.18; acc: 0.94
Batch: 580; loss: 0.46; acc: 0.88
Batch: 600; loss: 0.34; acc: 0.91
Batch: 620; loss: 0.47; acc: 0.86
Batch: 640; loss: 0.7; acc: 0.78
Batch: 660; loss: 0.45; acc: 0.88
Batch: 680; loss: 0.31; acc: 0.89
Batch: 700; loss: 0.3; acc: 0.89
Batch: 720; loss: 0.42; acc: 0.83
Batch: 740; loss: 0.4; acc: 0.84
Batch: 760; loss: 0.37; acc: 0.88
Batch: 780; loss: 0.5; acc: 0.91
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

2.4618395400466397e-05
9.444729585084133e-06
Batch: 0; loss: 0.25; acc: 0.92
Batch: 20; loss: 0.44; acc: 0.83
Batch: 40; loss: 0.19; acc: 0.92
Batch: 60; loss: 0.44; acc: 0.88
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.39; acc: 0.95
Batch: 120; loss: 0.67; acc: 0.81
Batch: 140; loss: 0.16; acc: 0.95
Val Epoch over. val_loss: 0.3514142266836516; val_accuracy: 0.8979896496815286 

The current subspace-distance is: 9.444729585084133e-06 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.23; acc: 0.94
Batch: 20; loss: 0.46; acc: 0.84
Batch: 40; loss: 0.46; acc: 0.86
Batch: 60; loss: 0.35; acc: 0.91
Batch: 80; loss: 0.34; acc: 0.94
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.47; acc: 0.83
Batch: 140; loss: 0.46; acc: 0.83
Batch: 160; loss: 0.34; acc: 0.89
Batch: 180; loss: 0.52; acc: 0.84
Batch: 200; loss: 0.24; acc: 0.91
Batch: 220; loss: 0.21; acc: 0.92
Batch: 240; loss: 0.32; acc: 0.92
Batch: 260; loss: 0.36; acc: 0.86
Batch: 280; loss: 0.56; acc: 0.86
Batch: 300; loss: 0.45; acc: 0.86
Batch: 320; loss: 0.35; acc: 0.88
Batch: 340; loss: 0.35; acc: 0.88
Batch: 360; loss: 0.22; acc: 0.95
Batch: 380; loss: 0.59; acc: 0.89
Batch: 400; loss: 0.16; acc: 0.98
Batch: 420; loss: 0.37; acc: 0.81
Batch: 440; loss: 0.27; acc: 0.88
Batch: 460; loss: 0.56; acc: 0.88
Batch: 480; loss: 0.57; acc: 0.81
Batch: 500; loss: 0.3; acc: 0.89
Batch: 520; loss: 0.21; acc: 0.91
Batch: 540; loss: 0.34; acc: 0.91
Batch: 560; loss: 0.36; acc: 0.89
Batch: 580; loss: 0.37; acc: 0.86
Batch: 600; loss: 0.55; acc: 0.84
Batch: 620; loss: 0.33; acc: 0.91
Batch: 640; loss: 0.74; acc: 0.81
Batch: 660; loss: 0.45; acc: 0.89
Batch: 680; loss: 0.24; acc: 0.92
Batch: 700; loss: 0.16; acc: 0.97
Batch: 720; loss: 0.41; acc: 0.92
Batch: 740; loss: 0.32; acc: 0.88
Batch: 760; loss: 0.42; acc: 0.89
Batch: 780; loss: 0.45; acc: 0.89
Train Epoch over. train_loss: 0.37; train_accuracy: 0.88 

2.503693031030707e-05
8.18666103441501e-06
Batch: 0; loss: 0.25; acc: 0.92
Batch: 20; loss: 0.43; acc: 0.83
Batch: 40; loss: 0.19; acc: 0.92
Batch: 60; loss: 0.39; acc: 0.88
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.38; acc: 0.95
Batch: 120; loss: 0.66; acc: 0.83
Batch: 140; loss: 0.18; acc: 0.94
Val Epoch over. val_loss: 0.35258492606745406; val_accuracy: 0.8957006369426752 

The current subspace-distance is: 8.18666103441501e-06 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.39; acc: 0.88
Batch: 20; loss: 0.38; acc: 0.89
Batch: 40; loss: 0.36; acc: 0.89
Batch: 60; loss: 0.44; acc: 0.88
Batch: 80; loss: 0.19; acc: 0.92
Batch: 100; loss: 0.51; acc: 0.84
Batch: 120; loss: 0.31; acc: 0.88
Batch: 140; loss: 0.26; acc: 0.94
Batch: 160; loss: 0.38; acc: 0.83
Batch: 180; loss: 0.25; acc: 0.94
Batch: 200; loss: 0.27; acc: 0.89
Batch: 220; loss: 0.5; acc: 0.88
Batch: 240; loss: 0.38; acc: 0.88
Batch: 260; loss: 0.42; acc: 0.84
Batch: 280; loss: 0.31; acc: 0.88
Batch: 300; loss: 0.51; acc: 0.8
Batch: 320; loss: 0.41; acc: 0.91
Batch: 340; loss: 0.67; acc: 0.83
Batch: 360; loss: 0.36; acc: 0.88
Batch: 380; loss: 0.33; acc: 0.89
Batch: 400; loss: 0.31; acc: 0.91
Batch: 420; loss: 0.33; acc: 0.89
Batch: 440; loss: 0.29; acc: 0.91
Batch: 460; loss: 0.51; acc: 0.86
Batch: 480; loss: 0.58; acc: 0.83
Batch: 500; loss: 0.24; acc: 0.95
Batch: 520; loss: 0.33; acc: 0.89
Batch: 540; loss: 0.43; acc: 0.88
Batch: 560; loss: 0.27; acc: 0.91
Batch: 580; loss: 0.61; acc: 0.8
Batch: 600; loss: 0.34; acc: 0.88
Batch: 620; loss: 0.32; acc: 0.88
Batch: 640; loss: 0.47; acc: 0.84
Batch: 660; loss: 0.33; acc: 0.92
Batch: 680; loss: 0.25; acc: 0.94
Batch: 700; loss: 0.53; acc: 0.83
Batch: 720; loss: 0.37; acc: 0.88
Batch: 740; loss: 0.43; acc: 0.92
Batch: 760; loss: 0.38; acc: 0.86
Batch: 780; loss: 0.62; acc: 0.77
Train Epoch over. train_loss: 0.37; train_accuracy: 0.88 

2.4322387616848573e-05
8.570051249989774e-06
Batch: 0; loss: 0.26; acc: 0.89
Batch: 20; loss: 0.43; acc: 0.83
Batch: 40; loss: 0.19; acc: 0.92
Batch: 60; loss: 0.41; acc: 0.89
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.4; acc: 0.92
Batch: 120; loss: 0.65; acc: 0.81
Batch: 140; loss: 0.16; acc: 0.94
Val Epoch over. val_loss: 0.34933618645948966; val_accuracy: 0.8982882165605095 

The current subspace-distance is: 8.570051249989774e-06 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.32; acc: 0.89
Batch: 20; loss: 0.48; acc: 0.86
Batch: 40; loss: 0.38; acc: 0.84
Batch: 60; loss: 0.35; acc: 0.89
Batch: 80; loss: 0.23; acc: 0.91
Batch: 100; loss: 0.36; acc: 0.89
Batch: 120; loss: 0.34; acc: 0.88
Batch: 140; loss: 0.36; acc: 0.88
Batch: 160; loss: 0.38; acc: 0.91
Batch: 180; loss: 0.21; acc: 0.92
Batch: 200; loss: 0.2; acc: 0.91
Batch: 220; loss: 0.59; acc: 0.88
Batch: 240; loss: 0.41; acc: 0.86
Batch: 260; loss: 0.32; acc: 0.89
Batch: 280; loss: 0.43; acc: 0.84
Batch: 300; loss: 0.33; acc: 0.91
Batch: 320; loss: 0.38; acc: 0.88
Batch: 340; loss: 0.53; acc: 0.81
Batch: 360; loss: 0.3; acc: 0.89
Batch: 380; loss: 0.33; acc: 0.88
Batch: 400; loss: 0.22; acc: 0.89
Batch: 420; loss: 0.53; acc: 0.84
Batch: 440; loss: 0.29; acc: 0.92
Batch: 460; loss: 0.48; acc: 0.84
Batch: 480; loss: 0.3; acc: 0.89
Batch: 500; loss: 0.24; acc: 0.91
Batch: 520; loss: 0.34; acc: 0.84
Batch: 540; loss: 0.45; acc: 0.91
Batch: 560; loss: 0.39; acc: 0.86
Batch: 580; loss: 0.21; acc: 0.89
Batch: 600; loss: 0.57; acc: 0.86
Batch: 620; loss: 0.21; acc: 0.95
Batch: 640; loss: 0.36; acc: 0.88
Batch: 660; loss: 0.33; acc: 0.89
Batch: 680; loss: 0.42; acc: 0.86
Batch: 700; loss: 0.38; acc: 0.89
Batch: 720; loss: 0.33; acc: 0.89
Batch: 740; loss: 0.42; acc: 0.88
Batch: 760; loss: 0.2; acc: 0.95
Batch: 780; loss: 0.23; acc: 0.92
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

2.311670505150687e-05
7.935243047541007e-06
Batch: 0; loss: 0.24; acc: 0.91
Batch: 20; loss: 0.45; acc: 0.83
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.42; acc: 0.89
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.38; acc: 0.94
Batch: 120; loss: 0.68; acc: 0.8
Batch: 140; loss: 0.18; acc: 0.94
Val Epoch over. val_loss: 0.35176772102239023; val_accuracy: 0.8971934713375797 

The current subspace-distance is: 7.935243047541007e-06 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.6; acc: 0.83
Batch: 20; loss: 0.36; acc: 0.84
Batch: 40; loss: 0.43; acc: 0.88
Batch: 60; loss: 0.15; acc: 0.97
Batch: 80; loss: 0.34; acc: 0.89
Batch: 100; loss: 0.42; acc: 0.83
Batch: 120; loss: 0.46; acc: 0.83
Batch: 140; loss: 0.33; acc: 0.91
Batch: 160; loss: 0.21; acc: 0.94
Batch: 180; loss: 0.27; acc: 0.91
Batch: 200; loss: 0.37; acc: 0.89
Batch: 220; loss: 0.42; acc: 0.89
Batch: 240; loss: 0.39; acc: 0.83
Batch: 260; loss: 0.57; acc: 0.84
Batch: 280; loss: 0.37; acc: 0.86
Batch: 300; loss: 0.62; acc: 0.83
Batch: 320; loss: 0.4; acc: 0.89
Batch: 340; loss: 0.31; acc: 0.89
Batch: 360; loss: 0.13; acc: 0.94
Batch: 380; loss: 0.38; acc: 0.86
Batch: 400; loss: 0.24; acc: 0.94
Batch: 420; loss: 0.4; acc: 0.84
Batch: 440; loss: 0.21; acc: 0.92
Batch: 460; loss: 0.21; acc: 0.92
Batch: 480; loss: 0.34; acc: 0.91
Batch: 500; loss: 0.37; acc: 0.88
Batch: 520; loss: 0.43; acc: 0.89
Batch: 540; loss: 0.24; acc: 0.92
Batch: 560; loss: 0.51; acc: 0.86
Batch: 580; loss: 0.57; acc: 0.8
Batch: 600; loss: 0.43; acc: 0.86
Batch: 620; loss: 0.27; acc: 0.89
Batch: 640; loss: 0.3; acc: 0.91
Batch: 660; loss: 0.22; acc: 0.95
Batch: 680; loss: 0.38; acc: 0.88
Batch: 700; loss: 0.35; acc: 0.86
Batch: 720; loss: 0.47; acc: 0.88
Batch: 740; loss: 0.46; acc: 0.88
Batch: 760; loss: 0.27; acc: 0.91
Batch: 780; loss: 0.38; acc: 0.88
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

2.8063614081474952e-05
8.24534708954161e-06
Batch: 0; loss: 0.24; acc: 0.92
Batch: 20; loss: 0.44; acc: 0.83
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.42; acc: 0.88
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.38; acc: 0.94
Batch: 120; loss: 0.68; acc: 0.81
Batch: 140; loss: 0.19; acc: 0.94
Val Epoch over. val_loss: 0.3501949707034287; val_accuracy: 0.8982882165605095 

The current subspace-distance is: 8.24534708954161e-06 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.39; acc: 0.91
Batch: 20; loss: 0.27; acc: 0.89
Batch: 40; loss: 0.39; acc: 0.86
Batch: 60; loss: 0.44; acc: 0.86
Batch: 80; loss: 0.31; acc: 0.89
Batch: 100; loss: 0.32; acc: 0.88
Batch: 120; loss: 0.4; acc: 0.86
Batch: 140; loss: 0.27; acc: 0.92
Batch: 160; loss: 0.56; acc: 0.83
Batch: 180; loss: 0.43; acc: 0.86
Batch: 200; loss: 0.3; acc: 0.88
Batch: 220; loss: 0.38; acc: 0.89
Batch: 240; loss: 0.34; acc: 0.89
Batch: 260; loss: 0.39; acc: 0.84
Batch: 280; loss: 0.66; acc: 0.8
Batch: 300; loss: 0.51; acc: 0.83
Batch: 320; loss: 0.32; acc: 0.91
Batch: 340; loss: 0.47; acc: 0.86
Batch: 360; loss: 0.41; acc: 0.88
Batch: 380; loss: 0.47; acc: 0.86
Batch: 400; loss: 0.25; acc: 0.92
Batch: 420; loss: 0.18; acc: 0.97
Batch: 440; loss: 0.33; acc: 0.86
Batch: 460; loss: 0.36; acc: 0.88
Batch: 480; loss: 0.54; acc: 0.83
Batch: 500; loss: 0.49; acc: 0.83
Batch: 520; loss: 0.16; acc: 0.94
Batch: 540; loss: 0.17; acc: 0.97
Batch: 560; loss: 0.3; acc: 0.91
Batch: 580; loss: 0.42; acc: 0.86
Batch: 600; loss: 0.32; acc: 0.94
Batch: 620; loss: 0.36; acc: 0.83
Batch: 640; loss: 0.23; acc: 0.95
Batch: 660; loss: 0.46; acc: 0.88
Batch: 680; loss: 0.47; acc: 0.86
Batch: 700; loss: 0.25; acc: 0.92
Batch: 720; loss: 0.46; acc: 0.86
Batch: 740; loss: 0.43; acc: 0.88
Batch: 760; loss: 0.29; acc: 0.88
Batch: 780; loss: 0.2; acc: 0.94
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

2.7573853003559634e-05
9.02753890841268e-06
Batch: 0; loss: 0.24; acc: 0.92
Batch: 20; loss: 0.42; acc: 0.83
Batch: 40; loss: 0.19; acc: 0.92
Batch: 60; loss: 0.42; acc: 0.88
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.39; acc: 0.92
Batch: 120; loss: 0.67; acc: 0.81
Batch: 140; loss: 0.17; acc: 0.94
Val Epoch over. val_loss: 0.34962743181426814; val_accuracy: 0.8968949044585988 

The current subspace-distance is: 9.02753890841268e-06 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.31; acc: 0.88
Batch: 20; loss: 0.38; acc: 0.86
Batch: 40; loss: 0.39; acc: 0.88
Batch: 60; loss: 0.56; acc: 0.78
Batch: 80; loss: 0.37; acc: 0.81
Batch: 100; loss: 0.5; acc: 0.86
Batch: 120; loss: 0.42; acc: 0.89
Batch: 140; loss: 0.41; acc: 0.86
Batch: 160; loss: 0.21; acc: 0.94
Batch: 180; loss: 0.53; acc: 0.84
Batch: 200; loss: 0.4; acc: 0.91
Batch: 220; loss: 0.46; acc: 0.86
Batch: 240; loss: 0.36; acc: 0.89
Batch: 260; loss: 0.3; acc: 0.92
Batch: 280; loss: 0.46; acc: 0.83
Batch: 300; loss: 0.23; acc: 0.92
Batch: 320; loss: 0.31; acc: 0.94
Batch: 340; loss: 0.21; acc: 0.94
Batch: 360; loss: 0.52; acc: 0.91
Batch: 380; loss: 0.58; acc: 0.86
Batch: 400; loss: 0.38; acc: 0.88
Batch: 420; loss: 0.26; acc: 0.91
Batch: 440; loss: 0.29; acc: 0.88
Batch: 460; loss: 0.4; acc: 0.83
Batch: 480; loss: 0.24; acc: 0.94
Batch: 500; loss: 0.29; acc: 0.89
Batch: 520; loss: 0.37; acc: 0.89
Batch: 540; loss: 0.35; acc: 0.91
Batch: 560; loss: 0.42; acc: 0.92
Batch: 580; loss: 0.36; acc: 0.89
Batch: 600; loss: 0.58; acc: 0.83
Batch: 620; loss: 0.22; acc: 0.94
Batch: 640; loss: 0.3; acc: 0.89
Batch: 660; loss: 0.34; acc: 0.89
Batch: 680; loss: 0.35; acc: 0.92
Batch: 700; loss: 0.3; acc: 0.89
Batch: 720; loss: 0.34; acc: 0.86
Batch: 740; loss: 0.41; acc: 0.83
Batch: 760; loss: 0.21; acc: 0.95
Batch: 780; loss: 0.26; acc: 0.92
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

2.5228775484720245e-05
8.814502507448196e-06
Batch: 0; loss: 0.25; acc: 0.92
Batch: 20; loss: 0.42; acc: 0.84
Batch: 40; loss: 0.19; acc: 0.92
Batch: 60; loss: 0.42; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.4; acc: 0.94
Batch: 120; loss: 0.65; acc: 0.81
Batch: 140; loss: 0.16; acc: 0.94
Val Epoch over. val_loss: 0.34727163681653656; val_accuracy: 0.8981886942675159 

The current subspace-distance is: 8.814502507448196e-06 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.38; acc: 0.89
Batch: 40; loss: 0.33; acc: 0.91
Batch: 60; loss: 0.37; acc: 0.88
Batch: 80; loss: 0.4; acc: 0.84
Batch: 100; loss: 0.35; acc: 0.89
Batch: 120; loss: 0.56; acc: 0.84
Batch: 140; loss: 0.34; acc: 0.91
Batch: 160; loss: 0.3; acc: 0.86
Batch: 180; loss: 0.27; acc: 0.91
Batch: 200; loss: 0.23; acc: 0.94
Batch: 220; loss: 0.34; acc: 0.88
Batch: 240; loss: 0.28; acc: 0.91
Batch: 260; loss: 0.24; acc: 0.92
Batch: 280; loss: 0.33; acc: 0.86
Batch: 300; loss: 0.23; acc: 0.92
Batch: 320; loss: 0.58; acc: 0.81
Batch: 340; loss: 0.19; acc: 0.92
Batch: 360; loss: 0.38; acc: 0.86
Batch: 380; loss: 0.32; acc: 0.91
Batch: 400; loss: 0.39; acc: 0.84
Batch: 420; loss: 0.26; acc: 0.89
Batch: 440; loss: 0.56; acc: 0.81
Batch: 460; loss: 0.18; acc: 0.95
Batch: 480; loss: 0.18; acc: 0.95
Batch: 500; loss: 0.44; acc: 0.95
Batch: 520; loss: 0.36; acc: 0.89
Batch: 540; loss: 0.35; acc: 0.89
Batch: 560; loss: 0.22; acc: 0.92
Batch: 580; loss: 0.3; acc: 0.91
Batch: 600; loss: 0.51; acc: 0.78
Batch: 620; loss: 0.3; acc: 0.91
Batch: 640; loss: 0.22; acc: 0.92
Batch: 660; loss: 0.51; acc: 0.86
Batch: 680; loss: 0.35; acc: 0.89
Batch: 700; loss: 0.39; acc: 0.88
Batch: 720; loss: 0.57; acc: 0.78
Batch: 740; loss: 0.31; acc: 0.89
Batch: 760; loss: 0.26; acc: 0.92
Batch: 780; loss: 0.38; acc: 0.81
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

2.5423059923923574e-05
9.459579814574681e-06
Batch: 0; loss: 0.26; acc: 0.92
Batch: 20; loss: 0.42; acc: 0.84
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.41; acc: 0.88
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.4; acc: 0.92
Batch: 120; loss: 0.64; acc: 0.83
Batch: 140; loss: 0.15; acc: 0.94
Val Epoch over. val_loss: 0.347518269826842; val_accuracy: 0.8976910828025477 

The current subspace-distance is: 9.459579814574681e-06 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.35; acc: 0.89
Batch: 20; loss: 0.46; acc: 0.84
Batch: 40; loss: 0.57; acc: 0.81
Batch: 60; loss: 0.34; acc: 0.84
Batch: 80; loss: 0.12; acc: 0.98
Batch: 100; loss: 0.54; acc: 0.84
Batch: 120; loss: 0.35; acc: 0.86
Batch: 140; loss: 0.37; acc: 0.89
Batch: 160; loss: 0.21; acc: 0.97
Batch: 180; loss: 0.44; acc: 0.78
Batch: 200; loss: 0.3; acc: 0.91
Batch: 220; loss: 0.55; acc: 0.86
Batch: 240; loss: 0.49; acc: 0.83
Batch: 260; loss: 0.4; acc: 0.88
Batch: 280; loss: 0.26; acc: 0.88
Batch: 300; loss: 0.5; acc: 0.86
Batch: 320; loss: 0.31; acc: 0.91
Batch: 340; loss: 0.27; acc: 0.89
Batch: 360; loss: 0.34; acc: 0.94
Batch: 380; loss: 0.36; acc: 0.89
Batch: 400; loss: 0.28; acc: 0.89
Batch: 420; loss: 0.3; acc: 0.88
Batch: 440; loss: 0.26; acc: 0.97
Batch: 460; loss: 0.52; acc: 0.84
Batch: 480; loss: 0.36; acc: 0.92
Batch: 500; loss: 0.4; acc: 0.92
Batch: 520; loss: 0.52; acc: 0.88
Batch: 540; loss: 0.38; acc: 0.86
Batch: 560; loss: 0.34; acc: 0.86
Batch: 580; loss: 0.44; acc: 0.86
Batch: 600; loss: 0.35; acc: 0.88
Batch: 620; loss: 0.39; acc: 0.86
Batch: 640; loss: 0.19; acc: 0.91
Batch: 660; loss: 0.2; acc: 0.94
Batch: 680; loss: 0.36; acc: 0.88
Batch: 700; loss: 0.28; acc: 0.94
Batch: 720; loss: 0.29; acc: 0.91
Batch: 740; loss: 0.55; acc: 0.84
Batch: 760; loss: 0.53; acc: 0.83
Batch: 780; loss: 0.43; acc: 0.92
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

2.581780790933408e-05
8.013907972781453e-06
Batch: 0; loss: 0.24; acc: 0.92
Batch: 20; loss: 0.43; acc: 0.83
Batch: 40; loss: 0.19; acc: 0.92
Batch: 60; loss: 0.42; acc: 0.88
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.38; acc: 0.95
Batch: 120; loss: 0.66; acc: 0.81
Batch: 140; loss: 0.16; acc: 0.94
Val Epoch over. val_loss: 0.34902054847330805; val_accuracy: 0.8980891719745223 

The current subspace-distance is: 8.013907972781453e-06 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.53; acc: 0.86
Batch: 20; loss: 0.36; acc: 0.86
Batch: 40; loss: 0.34; acc: 0.89
Batch: 60; loss: 0.58; acc: 0.88
Batch: 80; loss: 0.34; acc: 0.86
Batch: 100; loss: 0.56; acc: 0.84
Batch: 120; loss: 0.34; acc: 0.88
Batch: 140; loss: 0.51; acc: 0.86
Batch: 160; loss: 0.47; acc: 0.84
Batch: 180; loss: 0.49; acc: 0.81
Batch: 200; loss: 0.3; acc: 0.91
Batch: 220; loss: 0.34; acc: 0.88
Batch: 240; loss: 0.51; acc: 0.84
Batch: 260; loss: 0.41; acc: 0.88
Batch: 280; loss: 0.44; acc: 0.86
Batch: 300; loss: 0.55; acc: 0.83
Batch: 320; loss: 0.53; acc: 0.89
Batch: 340; loss: 0.36; acc: 0.92
Batch: 360; loss: 0.34; acc: 0.88
Batch: 380; loss: 0.36; acc: 0.89
Batch: 400; loss: 0.59; acc: 0.83
Batch: 420; loss: 0.32; acc: 0.86
Batch: 440; loss: 0.43; acc: 0.89
Batch: 460; loss: 0.26; acc: 0.95
Batch: 480; loss: 0.56; acc: 0.81
Batch: 500; loss: 0.5; acc: 0.81
Batch: 520; loss: 0.38; acc: 0.88
Batch: 540; loss: 0.39; acc: 0.84
Batch: 560; loss: 0.35; acc: 0.91
Batch: 580; loss: 0.77; acc: 0.83
Batch: 600; loss: 0.43; acc: 0.83
Batch: 620; loss: 0.45; acc: 0.84
Batch: 640; loss: 0.63; acc: 0.84
Batch: 660; loss: 0.59; acc: 0.86
Batch: 680; loss: 0.35; acc: 0.89
Batch: 700; loss: 0.26; acc: 0.91
Batch: 720; loss: 0.33; acc: 0.91
Batch: 740; loss: 0.55; acc: 0.83
Batch: 760; loss: 0.35; acc: 0.91
Batch: 780; loss: 0.41; acc: 0.89
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

2.6217729100608267e-05
8.843222531140782e-06
Batch: 0; loss: 0.24; acc: 0.91
Batch: 20; loss: 0.43; acc: 0.84
Batch: 40; loss: 0.2; acc: 0.92
Batch: 60; loss: 0.42; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.39; acc: 0.94
Batch: 120; loss: 0.65; acc: 0.81
Batch: 140; loss: 0.16; acc: 0.94
Val Epoch over. val_loss: 0.3474476457970917; val_accuracy: 0.8983877388535032 

The current subspace-distance is: 8.843222531140782e-06 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.3; acc: 0.91
Batch: 20; loss: 0.32; acc: 0.86
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.34; acc: 0.89
Batch: 80; loss: 0.36; acc: 0.91
Batch: 100; loss: 0.37; acc: 0.88
Batch: 120; loss: 0.45; acc: 0.86
Batch: 140; loss: 0.26; acc: 0.95
Batch: 160; loss: 0.34; acc: 0.89
Batch: 180; loss: 0.31; acc: 0.89
Batch: 200; loss: 0.44; acc: 0.84
Batch: 220; loss: 0.16; acc: 0.94
Batch: 240; loss: 0.59; acc: 0.81
Batch: 260; loss: 0.26; acc: 0.94
Batch: 280; loss: 0.54; acc: 0.88
Batch: 300; loss: 0.42; acc: 0.88
Batch: 320; loss: 0.37; acc: 0.88
Batch: 340; loss: 0.12; acc: 0.98
Batch: 360; loss: 0.39; acc: 0.92
Batch: 380; loss: 0.37; acc: 0.91
Batch: 400; loss: 0.31; acc: 0.88
Batch: 420; loss: 0.45; acc: 0.91
Batch: 440; loss: 0.45; acc: 0.84
Batch: 460; loss: 0.28; acc: 0.92
Batch: 480; loss: 0.39; acc: 0.91
Batch: 500; loss: 0.42; acc: 0.89
Batch: 520; loss: 0.2; acc: 0.95
Batch: 540; loss: 0.52; acc: 0.83
Batch: 560; loss: 0.17; acc: 0.95
Batch: 580; loss: 0.37; acc: 0.91
Batch: 600; loss: 0.4; acc: 0.89
Batch: 620; loss: 0.41; acc: 0.83
Batch: 640; loss: 0.29; acc: 0.89
Batch: 660; loss: 0.4; acc: 0.91
Batch: 680; loss: 0.46; acc: 0.89
Batch: 700; loss: 0.42; acc: 0.89
Batch: 720; loss: 0.57; acc: 0.81
Batch: 740; loss: 0.42; acc: 0.84
Batch: 760; loss: 0.31; acc: 0.91
Batch: 780; loss: 0.28; acc: 0.92
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

2.4813674826873466e-05
8.777303264650982e-06
Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.42; acc: 0.84
Batch: 40; loss: 0.19; acc: 0.92
Batch: 60; loss: 0.41; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.39; acc: 0.94
Batch: 120; loss: 0.65; acc: 0.81
Batch: 140; loss: 0.15; acc: 0.94
Val Epoch over. val_loss: 0.3469566665827089; val_accuracy: 0.8981886942675159 

The current subspace-distance is: 8.777303264650982e-06 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.35; acc: 0.88
Batch: 20; loss: 0.45; acc: 0.88
Batch: 40; loss: 0.25; acc: 0.94
Batch: 60; loss: 0.39; acc: 0.89
Batch: 80; loss: 0.39; acc: 0.91
Batch: 100; loss: 0.3; acc: 0.88
Batch: 120; loss: 0.42; acc: 0.89
Batch: 140; loss: 0.51; acc: 0.86
Batch: 160; loss: 0.37; acc: 0.88
Batch: 180; loss: 0.29; acc: 0.89
Batch: 200; loss: 0.3; acc: 0.91
Batch: 220; loss: 0.31; acc: 0.91
Batch: 240; loss: 0.41; acc: 0.84
Batch: 260; loss: 0.25; acc: 0.92
Batch: 280; loss: 0.59; acc: 0.83
Batch: 300; loss: 0.57; acc: 0.88
Batch: 320; loss: 0.57; acc: 0.91
Batch: 340; loss: 0.3; acc: 0.92
Batch: 360; loss: 0.47; acc: 0.88
Batch: 380; loss: 0.59; acc: 0.81
Batch: 400; loss: 0.37; acc: 0.83
Batch: 420; loss: 0.45; acc: 0.84
Batch: 440; loss: 0.32; acc: 0.91
Batch: 460; loss: 0.54; acc: 0.88
Batch: 480; loss: 0.32; acc: 0.92
Batch: 500; loss: 0.24; acc: 0.94
Batch: 520; loss: 0.55; acc: 0.88
Batch: 540; loss: 0.52; acc: 0.88
Batch: 560; loss: 0.3; acc: 0.91
Batch: 580; loss: 0.33; acc: 0.84
Batch: 600; loss: 0.34; acc: 0.92
Batch: 620; loss: 0.62; acc: 0.88
Batch: 640; loss: 0.27; acc: 0.88
Batch: 660; loss: 0.3; acc: 0.89
Batch: 680; loss: 0.24; acc: 0.92
Batch: 700; loss: 0.3; acc: 0.88
Batch: 720; loss: 0.53; acc: 0.84
Batch: 740; loss: 0.4; acc: 0.91
Batch: 760; loss: 0.37; acc: 0.91
Batch: 780; loss: 0.4; acc: 0.89
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

2.6921692551695742e-05
7.728958735242486e-06
Batch: 0; loss: 0.24; acc: 0.91
Batch: 20; loss: 0.43; acc: 0.84
Batch: 40; loss: 0.19; acc: 0.92
Batch: 60; loss: 0.41; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.39; acc: 0.94
Batch: 120; loss: 0.65; acc: 0.83
Batch: 140; loss: 0.16; acc: 0.94
Val Epoch over. val_loss: 0.3477647820143563; val_accuracy: 0.8982882165605095 

The current subspace-distance is: 7.728958735242486e-06 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.36; acc: 0.91
Batch: 20; loss: 0.32; acc: 0.88
Batch: 40; loss: 0.29; acc: 0.94
Batch: 60; loss: 0.43; acc: 0.89
Batch: 80; loss: 0.5; acc: 0.88
Batch: 100; loss: 0.52; acc: 0.86
Batch: 120; loss: 0.34; acc: 0.89
Batch: 140; loss: 0.38; acc: 0.86
Batch: 160; loss: 0.48; acc: 0.89
Batch: 180; loss: 0.3; acc: 0.89
Batch: 200; loss: 0.46; acc: 0.84
Batch: 220; loss: 0.18; acc: 0.92
Batch: 240; loss: 0.19; acc: 0.95
Batch: 260; loss: 0.43; acc: 0.81
Batch: 280; loss: 0.21; acc: 0.95
Batch: 300; loss: 0.27; acc: 0.88
Batch: 320; loss: 0.41; acc: 0.88
Batch: 340; loss: 0.53; acc: 0.83
Batch: 360; loss: 0.33; acc: 0.91
Batch: 380; loss: 0.36; acc: 0.88
Batch: 400; loss: 0.22; acc: 0.92
Batch: 420; loss: 0.41; acc: 0.86
Batch: 440; loss: 0.33; acc: 0.88
Batch: 460; loss: 0.47; acc: 0.86
Batch: 480; loss: 0.31; acc: 0.91
Batch: 500; loss: 0.21; acc: 0.94
Batch: 520; loss: 0.41; acc: 0.89
Batch: 540; loss: 0.43; acc: 0.89
Batch: 560; loss: 0.26; acc: 0.91
Batch: 580; loss: 0.24; acc: 0.94
Batch: 600; loss: 0.39; acc: 0.83
Batch: 620; loss: 0.38; acc: 0.86
Batch: 640; loss: 0.28; acc: 0.91
Batch: 660; loss: 0.35; acc: 0.91
Batch: 680; loss: 0.43; acc: 0.81
Batch: 700; loss: 0.57; acc: 0.88
Batch: 720; loss: 0.42; acc: 0.89
Batch: 740; loss: 0.5; acc: 0.88
Batch: 760; loss: 0.43; acc: 0.81
Batch: 780; loss: 0.45; acc: 0.88
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

2.4405031581409276e-05
9.776767910807393e-06
Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.41; acc: 0.84
Batch: 40; loss: 0.19; acc: 0.92
Batch: 60; loss: 0.42; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.39; acc: 0.94
Batch: 120; loss: 0.64; acc: 0.81
Batch: 140; loss: 0.16; acc: 0.94
Val Epoch over. val_loss: 0.3479010901253694; val_accuracy: 0.8981886942675159 

The current subspace-distance is: 9.776767910807393e-06 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.43; acc: 0.86
Batch: 40; loss: 0.2; acc: 0.92
Batch: 60; loss: 0.51; acc: 0.81
Batch: 80; loss: 0.34; acc: 0.83
Batch: 100; loss: 0.51; acc: 0.86
Batch: 120; loss: 0.28; acc: 0.92
Batch: 140; loss: 0.58; acc: 0.83
Batch: 160; loss: 0.45; acc: 0.91
Batch: 180; loss: 0.27; acc: 0.92
Batch: 200; loss: 0.32; acc: 0.91
Batch: 220; loss: 0.38; acc: 0.88
Batch: 240; loss: 0.2; acc: 0.91
Batch: 260; loss: 0.47; acc: 0.84
Batch: 280; loss: 0.33; acc: 0.91
Batch: 300; loss: 0.26; acc: 0.88
Batch: 320; loss: 0.39; acc: 0.84
Batch: 340; loss: 0.28; acc: 0.89
Batch: 360; loss: 0.38; acc: 0.84
Batch: 380; loss: 0.45; acc: 0.88
Batch: 400; loss: 0.39; acc: 0.86
Batch: 420; loss: 0.28; acc: 0.92
Batch: 440; loss: 0.27; acc: 0.92
Batch: 460; loss: 0.24; acc: 0.91
Batch: 480; loss: 0.63; acc: 0.86
Batch: 500; loss: 0.74; acc: 0.84
Batch: 520; loss: 0.37; acc: 0.88
Batch: 540; loss: 0.68; acc: 0.83
Batch: 560; loss: 0.42; acc: 0.89
Batch: 580; loss: 0.2; acc: 0.94
Batch: 600; loss: 0.41; acc: 0.89
Batch: 620; loss: 0.25; acc: 0.94
Batch: 640; loss: 0.27; acc: 0.95
Batch: 660; loss: 0.34; acc: 0.92
Batch: 680; loss: 0.33; acc: 0.89
Batch: 700; loss: 0.35; acc: 0.89
Batch: 720; loss: 0.38; acc: 0.89
Batch: 740; loss: 0.31; acc: 0.92
Batch: 760; loss: 0.65; acc: 0.8
Batch: 780; loss: 0.45; acc: 0.94
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

2.5063596694963053e-05
1.0105998626386281e-05
Batch: 0; loss: 0.24; acc: 0.91
Batch: 20; loss: 0.44; acc: 0.83
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.42; acc: 0.89
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.38; acc: 0.94
Batch: 120; loss: 0.67; acc: 0.81
Batch: 140; loss: 0.18; acc: 0.94
Val Epoch over. val_loss: 0.3506246639807133; val_accuracy: 0.8986863057324841 

The current subspace-distance is: 1.0105998626386281e-05 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.35; acc: 0.88
Batch: 20; loss: 0.46; acc: 0.94
Batch: 40; loss: 0.33; acc: 0.92
Batch: 60; loss: 0.34; acc: 0.86
Batch: 80; loss: 0.47; acc: 0.86
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.27; acc: 0.92
Batch: 140; loss: 0.36; acc: 0.89
Batch: 160; loss: 0.46; acc: 0.81
Batch: 180; loss: 0.38; acc: 0.91
Batch: 200; loss: 0.47; acc: 0.84
Batch: 220; loss: 0.48; acc: 0.86
Batch: 240; loss: 0.33; acc: 0.83
Batch: 260; loss: 0.29; acc: 0.86
Batch: 280; loss: 0.58; acc: 0.8
Batch: 300; loss: 0.44; acc: 0.86
Batch: 320; loss: 0.26; acc: 0.94
Batch: 340; loss: 0.57; acc: 0.86
Batch: 360; loss: 0.18; acc: 0.95
Batch: 380; loss: 0.26; acc: 0.88
Batch: 400; loss: 0.5; acc: 0.89
Batch: 420; loss: 0.41; acc: 0.88
Batch: 440; loss: 0.28; acc: 0.95
Batch: 460; loss: 0.26; acc: 0.91
Batch: 480; loss: 0.27; acc: 0.91
Batch: 500; loss: 0.5; acc: 0.89
Batch: 520; loss: 0.33; acc: 0.91
Batch: 540; loss: 0.37; acc: 0.88
Batch: 560; loss: 0.45; acc: 0.86
Batch: 580; loss: 0.24; acc: 0.88
Batch: 600; loss: 0.33; acc: 0.91
Batch: 620; loss: 0.2; acc: 0.94
Batch: 640; loss: 0.33; acc: 0.89
Batch: 660; loss: 0.42; acc: 0.89
Batch: 680; loss: 0.29; acc: 0.89
Batch: 700; loss: 0.23; acc: 0.92
Batch: 720; loss: 0.32; acc: 0.88
Batch: 740; loss: 0.23; acc: 0.92
Batch: 760; loss: 0.47; acc: 0.86
Batch: 780; loss: 0.4; acc: 0.86
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

2.466060504957568e-05
8.465272003377322e-06
Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.43; acc: 0.84
Batch: 40; loss: 0.19; acc: 0.92
Batch: 60; loss: 0.41; acc: 0.89
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.39; acc: 0.94
Batch: 120; loss: 0.66; acc: 0.81
Batch: 140; loss: 0.16; acc: 0.94
Val Epoch over. val_loss: 0.34776828568547397; val_accuracy: 0.8996815286624203 

The current subspace-distance is: 8.465272003377322e-06 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.37; acc: 0.91
Batch: 20; loss: 0.41; acc: 0.86
Batch: 40; loss: 0.34; acc: 0.88
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.48; acc: 0.86
Batch: 100; loss: 0.41; acc: 0.91
Batch: 120; loss: 0.28; acc: 0.94
Batch: 140; loss: 0.38; acc: 0.89
Batch: 160; loss: 0.47; acc: 0.83
Batch: 180; loss: 0.27; acc: 0.95
Batch: 200; loss: 0.51; acc: 0.86
Batch: 220; loss: 0.43; acc: 0.83
Batch: 240; loss: 0.42; acc: 0.89
Batch: 260; loss: 0.4; acc: 0.92
Batch: 280; loss: 0.16; acc: 0.95
Batch: 300; loss: 0.3; acc: 0.88
Batch: 320; loss: 0.33; acc: 0.88
Batch: 340; loss: 0.38; acc: 0.91
Batch: 360; loss: 0.36; acc: 0.91
Batch: 380; loss: 0.5; acc: 0.84
Batch: 400; loss: 0.48; acc: 0.83
Batch: 420; loss: 0.34; acc: 0.91
Batch: 440; loss: 0.47; acc: 0.89
Batch: 460; loss: 0.41; acc: 0.89
Batch: 480; loss: 0.51; acc: 0.86
Batch: 500; loss: 0.49; acc: 0.88
Batch: 520; loss: 0.34; acc: 0.86
Batch: 540; loss: 0.34; acc: 0.92
Batch: 560; loss: 0.47; acc: 0.84
Batch: 580; loss: 0.46; acc: 0.88
Batch: 600; loss: 0.44; acc: 0.86
Batch: 620; loss: 0.26; acc: 0.89
Batch: 640; loss: 0.31; acc: 0.89
Batch: 660; loss: 0.22; acc: 0.91
Batch: 680; loss: 0.39; acc: 0.88
Batch: 700; loss: 0.33; acc: 0.88
Batch: 720; loss: 0.16; acc: 0.95
Batch: 740; loss: 0.4; acc: 0.89
Batch: 760; loss: 0.35; acc: 0.91
Batch: 780; loss: 0.38; acc: 0.86
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

2.4364413548028097e-05
9.065543963515665e-06
Batch: 0; loss: 0.24; acc: 0.92
Batch: 20; loss: 0.44; acc: 0.84
Batch: 40; loss: 0.19; acc: 0.92
Batch: 60; loss: 0.43; acc: 0.88
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.39; acc: 0.94
Batch: 120; loss: 0.66; acc: 0.83
Batch: 140; loss: 0.16; acc: 0.94
Val Epoch over. val_loss: 0.34831830759526816; val_accuracy: 0.8987858280254777 

The current subspace-distance is: 9.065543963515665e-06 

plots/subspace_training/reg_lenet_3/2020-01-22 20:51:04/d_dim_130_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
nonzero elements in E: 29653
elements in E: 6298600
fraction nonzero: 0.004707871590512177
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.31; acc: 0.08
Batch: 20; loss: 2.29; acc: 0.05
Batch: 40; loss: 2.3; acc: 0.08
Batch: 60; loss: 2.3; acc: 0.02
Batch: 80; loss: 2.3; acc: 0.08
Batch: 100; loss: 2.3; acc: 0.11
Batch: 120; loss: 2.3; acc: 0.09
Batch: 140; loss: 2.32; acc: 0.08
Batch: 160; loss: 2.3; acc: 0.09
Batch: 180; loss: 2.3; acc: 0.11
Batch: 200; loss: 2.3; acc: 0.14
Batch: 220; loss: 2.31; acc: 0.08
Batch: 240; loss: 2.31; acc: 0.05
Batch: 260; loss: 2.3; acc: 0.11
Batch: 280; loss: 2.29; acc: 0.11
Batch: 300; loss: 2.29; acc: 0.06
Batch: 320; loss: 2.3; acc: 0.09
Batch: 340; loss: 2.29; acc: 0.09
Batch: 360; loss: 2.29; acc: 0.19
Batch: 380; loss: 2.3; acc: 0.12
Batch: 400; loss: 2.3; acc: 0.17
Batch: 420; loss: 2.31; acc: 0.08
Batch: 440; loss: 2.29; acc: 0.17
Batch: 460; loss: 2.3; acc: 0.09
Batch: 480; loss: 2.29; acc: 0.12
Batch: 500; loss: 2.29; acc: 0.11
Batch: 520; loss: 2.27; acc: 0.16
Batch: 540; loss: 2.28; acc: 0.12
Batch: 560; loss: 2.27; acc: 0.22
Batch: 580; loss: 2.27; acc: 0.2
Batch: 600; loss: 2.28; acc: 0.22
Batch: 620; loss: 2.26; acc: 0.2
Batch: 640; loss: 2.27; acc: 0.2
Batch: 660; loss: 2.27; acc: 0.17
Batch: 680; loss: 2.28; acc: 0.16
Batch: 700; loss: 2.27; acc: 0.19
Batch: 720; loss: 2.27; acc: 0.16
Batch: 740; loss: 2.26; acc: 0.3
Batch: 760; loss: 2.27; acc: 0.17
Batch: 780; loss: 2.27; acc: 0.12
Train Epoch over. train_loss: 2.29; train_accuracy: 0.13 

5.929013696004404e-06
1.2681992984653334e-06
Batch: 0; loss: 2.24; acc: 0.28
Batch: 20; loss: 2.25; acc: 0.19
Batch: 40; loss: 2.24; acc: 0.3
Batch: 60; loss: 2.24; acc: 0.27
Batch: 80; loss: 2.24; acc: 0.25
Batch: 100; loss: 2.24; acc: 0.31
Batch: 120; loss: 2.25; acc: 0.19
Batch: 140; loss: 2.26; acc: 0.16
Val Epoch over. val_loss: 2.2533868270315183; val_accuracy: 0.2300955414012739 

The current subspace-distance is: 1.2681992984653334e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 2.27; acc: 0.12
Batch: 20; loss: 2.25; acc: 0.23
Batch: 40; loss: 2.25; acc: 0.17
Batch: 60; loss: 2.22; acc: 0.28
Batch: 80; loss: 2.24; acc: 0.17
Batch: 100; loss: 2.24; acc: 0.16
Batch: 120; loss: 2.19; acc: 0.36
Batch: 140; loss: 2.19; acc: 0.27
Batch: 160; loss: 2.17; acc: 0.36
Batch: 180; loss: 2.15; acc: 0.33
Batch: 200; loss: 2.13; acc: 0.42
Batch: 220; loss: 2.1; acc: 0.41
Batch: 240; loss: 1.95; acc: 0.47
Batch: 260; loss: 1.83; acc: 0.48
Batch: 280; loss: 1.53; acc: 0.58
Batch: 300; loss: 1.27; acc: 0.7
Batch: 320; loss: 1.4; acc: 0.56
Batch: 340; loss: 1.56; acc: 0.53
Batch: 360; loss: 1.07; acc: 0.62
Batch: 380; loss: 1.13; acc: 0.69
Batch: 400; loss: 1.51; acc: 0.52
Batch: 420; loss: 1.26; acc: 0.66
Batch: 440; loss: 1.22; acc: 0.61
Batch: 460; loss: 1.33; acc: 0.55
Batch: 480; loss: 0.73; acc: 0.77
Batch: 500; loss: 0.9; acc: 0.75
Batch: 520; loss: 0.61; acc: 0.84
Batch: 540; loss: 0.64; acc: 0.83
Batch: 560; loss: 0.78; acc: 0.72
Batch: 580; loss: 0.62; acc: 0.77
Batch: 600; loss: 1.04; acc: 0.7
Batch: 620; loss: 0.77; acc: 0.72
Batch: 640; loss: 0.82; acc: 0.7
Batch: 660; loss: 1.25; acc: 0.56
Batch: 680; loss: 0.8; acc: 0.73
Batch: 700; loss: 0.92; acc: 0.69
Batch: 720; loss: 0.82; acc: 0.73
Batch: 740; loss: 0.86; acc: 0.77
Batch: 760; loss: 1.11; acc: 0.69
Batch: 780; loss: 0.85; acc: 0.67
Train Epoch over. train_loss: 1.41; train_accuracy: 0.54 

1.4156014913169201e-05
6.0024722188245505e-06
Batch: 0; loss: 0.73; acc: 0.78
Batch: 20; loss: 0.95; acc: 0.64
Batch: 40; loss: 0.5; acc: 0.8
Batch: 60; loss: 0.94; acc: 0.72
Batch: 80; loss: 0.61; acc: 0.75
Batch: 100; loss: 0.67; acc: 0.81
Batch: 120; loss: 1.18; acc: 0.61
Batch: 140; loss: 0.74; acc: 0.75
Val Epoch over. val_loss: 0.7368615309523928; val_accuracy: 0.7573646496815286 

The current subspace-distance is: 6.0024722188245505e-06 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.88; acc: 0.75
Batch: 20; loss: 0.55; acc: 0.86
Batch: 40; loss: 0.47; acc: 0.84
Batch: 60; loss: 0.81; acc: 0.81
Batch: 80; loss: 0.88; acc: 0.7
Batch: 100; loss: 0.76; acc: 0.78
Batch: 120; loss: 0.63; acc: 0.77
Batch: 140; loss: 0.65; acc: 0.77
Batch: 160; loss: 0.57; acc: 0.88
Batch: 180; loss: 0.5; acc: 0.84
Batch: 200; loss: 0.59; acc: 0.81
Batch: 220; loss: 0.9; acc: 0.72
Batch: 240; loss: 0.78; acc: 0.77
Batch: 260; loss: 0.74; acc: 0.77
Batch: 280; loss: 0.57; acc: 0.84
Batch: 300; loss: 0.49; acc: 0.86
Batch: 320; loss: 0.51; acc: 0.84
Batch: 340; loss: 0.48; acc: 0.89
Batch: 360; loss: 0.54; acc: 0.84
Batch: 380; loss: 0.71; acc: 0.89
Batch: 400; loss: 1.08; acc: 0.73
Batch: 420; loss: 0.52; acc: 0.83
Batch: 440; loss: 0.51; acc: 0.86
Batch: 460; loss: 0.78; acc: 0.78
Batch: 480; loss: 0.71; acc: 0.78
Batch: 500; loss: 0.49; acc: 0.83
Batch: 520; loss: 0.34; acc: 0.89
Batch: 540; loss: 0.61; acc: 0.78
Batch: 560; loss: 0.75; acc: 0.81
Batch: 580; loss: 0.41; acc: 0.88
Batch: 600; loss: 0.32; acc: 0.88
Batch: 620; loss: 0.91; acc: 0.73
Batch: 640; loss: 0.39; acc: 0.84
Batch: 660; loss: 0.54; acc: 0.84
Batch: 680; loss: 0.37; acc: 0.88
Batch: 700; loss: 0.56; acc: 0.83
Batch: 720; loss: 0.29; acc: 0.89
Batch: 740; loss: 0.47; acc: 0.88
Batch: 760; loss: 0.4; acc: 0.83
Batch: 780; loss: 0.57; acc: 0.89
Train Epoch over. train_loss: 0.59; train_accuracy: 0.82 

2.0851677618338726e-05
8.057338163780514e-06
Batch: 0; loss: 0.34; acc: 0.91
Batch: 20; loss: 0.66; acc: 0.81
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.53; acc: 0.8
Batch: 80; loss: 0.29; acc: 0.89
Batch: 100; loss: 0.44; acc: 0.84
Batch: 120; loss: 0.71; acc: 0.75
Batch: 140; loss: 0.43; acc: 0.88
Val Epoch over. val_loss: 0.5104043097442882; val_accuracy: 0.8430533439490446 

The current subspace-distance is: 8.057338163780514e-06 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.58; acc: 0.78
Batch: 20; loss: 0.6; acc: 0.81
Batch: 40; loss: 0.5; acc: 0.81
Batch: 60; loss: 0.35; acc: 0.89
Batch: 80; loss: 0.3; acc: 0.91
Batch: 100; loss: 0.43; acc: 0.84
Batch: 120; loss: 0.46; acc: 0.84
Batch: 140; loss: 0.33; acc: 0.86
Batch: 160; loss: 0.44; acc: 0.86
Batch: 180; loss: 0.57; acc: 0.77
Batch: 200; loss: 0.42; acc: 0.86
Batch: 220; loss: 0.75; acc: 0.81
Batch: 240; loss: 0.61; acc: 0.81
Batch: 260; loss: 0.57; acc: 0.83
Batch: 280; loss: 0.57; acc: 0.84
Batch: 300; loss: 0.73; acc: 0.84
Batch: 320; loss: 0.49; acc: 0.84
Batch: 340; loss: 0.53; acc: 0.86
Batch: 360; loss: 0.46; acc: 0.84
Batch: 380; loss: 0.55; acc: 0.83
Batch: 400; loss: 0.41; acc: 0.88
Batch: 420; loss: 0.58; acc: 0.84
Batch: 440; loss: 0.25; acc: 0.92
Batch: 460; loss: 0.29; acc: 0.94
Batch: 480; loss: 0.49; acc: 0.84
Batch: 500; loss: 0.39; acc: 0.89
Batch: 520; loss: 0.48; acc: 0.81
Batch: 540; loss: 0.47; acc: 0.88
Batch: 560; loss: 0.55; acc: 0.86
Batch: 580; loss: 0.44; acc: 0.81
Batch: 600; loss: 0.44; acc: 0.84
Batch: 620; loss: 0.56; acc: 0.81
Batch: 640; loss: 0.54; acc: 0.81
Batch: 660; loss: 0.61; acc: 0.83
Batch: 680; loss: 0.38; acc: 0.91
Batch: 700; loss: 0.36; acc: 0.92
Batch: 720; loss: 0.65; acc: 0.8
Batch: 740; loss: 0.43; acc: 0.86
Batch: 760; loss: 0.33; acc: 0.89
Batch: 780; loss: 0.4; acc: 0.86
Train Epoch over. train_loss: 0.49; train_accuracy: 0.85 

2.303612563991919e-05
7.958940841490403e-06
Batch: 0; loss: 0.42; acc: 0.83
Batch: 20; loss: 0.72; acc: 0.78
Batch: 40; loss: 0.3; acc: 0.92
Batch: 60; loss: 0.62; acc: 0.8
Batch: 80; loss: 0.36; acc: 0.88
Batch: 100; loss: 0.58; acc: 0.81
Batch: 120; loss: 0.77; acc: 0.77
Batch: 140; loss: 0.39; acc: 0.83
Val Epoch over. val_loss: 0.5579467044704279; val_accuracy: 0.8188694267515924 

The current subspace-distance is: 7.958940841490403e-06 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.64; acc: 0.75
Batch: 20; loss: 0.45; acc: 0.88
Batch: 40; loss: 0.57; acc: 0.8
Batch: 60; loss: 0.63; acc: 0.84
Batch: 80; loss: 0.47; acc: 0.88
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.33; acc: 0.89
Batch: 140; loss: 0.62; acc: 0.78
Batch: 160; loss: 0.35; acc: 0.89
Batch: 180; loss: 0.4; acc: 0.86
Batch: 200; loss: 0.27; acc: 0.91
Batch: 220; loss: 0.76; acc: 0.8
Batch: 240; loss: 0.4; acc: 0.84
Batch: 260; loss: 0.64; acc: 0.8
Batch: 280; loss: 0.44; acc: 0.89
Batch: 300; loss: 0.33; acc: 0.88
Batch: 320; loss: 0.49; acc: 0.84
Batch: 340; loss: 0.44; acc: 0.86
Batch: 360; loss: 0.49; acc: 0.88
Batch: 380; loss: 0.31; acc: 0.94
Batch: 400; loss: 0.6; acc: 0.86
Batch: 420; loss: 0.34; acc: 0.92
Batch: 440; loss: 0.59; acc: 0.75
Batch: 460; loss: 0.36; acc: 0.88
Batch: 480; loss: 0.37; acc: 0.88
Batch: 500; loss: 0.44; acc: 0.81
Batch: 520; loss: 0.4; acc: 0.94
Batch: 540; loss: 0.43; acc: 0.86
Batch: 560; loss: 0.56; acc: 0.84
Batch: 580; loss: 0.5; acc: 0.84
Batch: 600; loss: 0.36; acc: 0.88
Batch: 620; loss: 0.53; acc: 0.81
Batch: 640; loss: 0.38; acc: 0.94
Batch: 660; loss: 0.81; acc: 0.77
Batch: 680; loss: 0.25; acc: 0.92
Batch: 700; loss: 0.33; acc: 0.86
Batch: 720; loss: 0.31; acc: 0.91
Batch: 740; loss: 0.35; acc: 0.88
Batch: 760; loss: 0.5; acc: 0.84
Batch: 780; loss: 0.43; acc: 0.88
Train Epoch over. train_loss: 0.46; train_accuracy: 0.86 

2.1439831471070647e-05
7.734622158750426e-06
Batch: 0; loss: 0.38; acc: 0.91
Batch: 20; loss: 0.52; acc: 0.84
Batch: 40; loss: 0.32; acc: 0.91
Batch: 60; loss: 0.83; acc: 0.78
Batch: 80; loss: 0.28; acc: 0.91
Batch: 100; loss: 0.43; acc: 0.88
Batch: 120; loss: 0.55; acc: 0.83
Batch: 140; loss: 0.28; acc: 0.92
Val Epoch over. val_loss: 0.48410811735566256; val_accuracy: 0.8491242038216561 

The current subspace-distance is: 7.734622158750426e-06 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.51; acc: 0.86
Batch: 20; loss: 0.41; acc: 0.89
Batch: 40; loss: 0.8; acc: 0.78
Batch: 60; loss: 0.29; acc: 0.92
Batch: 80; loss: 0.4; acc: 0.86
Batch: 100; loss: 0.43; acc: 0.91
Batch: 120; loss: 0.56; acc: 0.75
Batch: 140; loss: 0.56; acc: 0.83
Batch: 160; loss: 0.5; acc: 0.83
Batch: 180; loss: 0.44; acc: 0.86
Batch: 200; loss: 0.53; acc: 0.86
Batch: 220; loss: 0.28; acc: 0.91
Batch: 240; loss: 0.43; acc: 0.88
Batch: 260; loss: 0.45; acc: 0.91
Batch: 280; loss: 0.37; acc: 0.88
Batch: 300; loss: 0.57; acc: 0.86
Batch: 320; loss: 0.52; acc: 0.83
Batch: 340; loss: 0.33; acc: 0.92
Batch: 360; loss: 0.64; acc: 0.81
Batch: 380; loss: 0.8; acc: 0.77
Batch: 400; loss: 0.45; acc: 0.84
Batch: 420; loss: 0.42; acc: 0.86
Batch: 440; loss: 0.42; acc: 0.84
Batch: 460; loss: 0.55; acc: 0.86
Batch: 480; loss: 0.57; acc: 0.81
Batch: 500; loss: 0.64; acc: 0.81
Batch: 520; loss: 0.43; acc: 0.89
Batch: 540; loss: 0.38; acc: 0.89
Batch: 560; loss: 0.35; acc: 0.89
Batch: 580; loss: 0.4; acc: 0.86
Batch: 600; loss: 0.53; acc: 0.81
Batch: 620; loss: 0.36; acc: 0.89
Batch: 640; loss: 0.46; acc: 0.89
Batch: 660; loss: 0.69; acc: 0.8
Batch: 680; loss: 0.27; acc: 0.89
Batch: 700; loss: 0.42; acc: 0.86
Batch: 720; loss: 0.74; acc: 0.78
Batch: 740; loss: 0.4; acc: 0.89
Batch: 760; loss: 0.65; acc: 0.86
Batch: 780; loss: 0.35; acc: 0.91
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

2.4098702851915732e-05
8.444345439784229e-06
Batch: 0; loss: 0.56; acc: 0.8
Batch: 20; loss: 0.75; acc: 0.78
Batch: 40; loss: 0.48; acc: 0.86
Batch: 60; loss: 0.68; acc: 0.7
Batch: 80; loss: 0.51; acc: 0.83
Batch: 100; loss: 0.59; acc: 0.84
Batch: 120; loss: 0.77; acc: 0.75
Batch: 140; loss: 0.42; acc: 0.8
Val Epoch over. val_loss: 0.7162581059583433; val_accuracy: 0.775577229299363 

The current subspace-distance is: 8.444345439784229e-06 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 1.11; acc: 0.66
Batch: 20; loss: 0.3; acc: 0.89
Batch: 40; loss: 0.6; acc: 0.81
Batch: 60; loss: 0.33; acc: 0.92
Batch: 80; loss: 0.35; acc: 0.86
Batch: 100; loss: 0.5; acc: 0.84
Batch: 120; loss: 0.38; acc: 0.86
Batch: 140; loss: 0.49; acc: 0.86
Batch: 160; loss: 0.56; acc: 0.81
Batch: 180; loss: 0.4; acc: 0.91
Batch: 200; loss: 0.67; acc: 0.78
Batch: 220; loss: 0.52; acc: 0.89
Batch: 240; loss: 0.3; acc: 0.89
Batch: 260; loss: 0.49; acc: 0.8
Batch: 280; loss: 0.36; acc: 0.88
Batch: 300; loss: 0.31; acc: 0.88
Batch: 320; loss: 0.42; acc: 0.88
Batch: 340; loss: 0.41; acc: 0.86
Batch: 360; loss: 0.46; acc: 0.89
Batch: 380; loss: 0.63; acc: 0.78
Batch: 400; loss: 0.35; acc: 0.86
Batch: 420; loss: 0.53; acc: 0.8
Batch: 440; loss: 0.74; acc: 0.8
Batch: 460; loss: 0.18; acc: 0.95
Batch: 480; loss: 0.64; acc: 0.8
Batch: 500; loss: 0.21; acc: 0.95
Batch: 520; loss: 0.28; acc: 0.89
Batch: 540; loss: 0.27; acc: 0.91
Batch: 560; loss: 0.37; acc: 0.86
Batch: 580; loss: 0.4; acc: 0.94
Batch: 600; loss: 0.15; acc: 0.98
Batch: 620; loss: 0.54; acc: 0.81
Batch: 640; loss: 0.52; acc: 0.86
Batch: 660; loss: 0.43; acc: 0.84
Batch: 680; loss: 0.43; acc: 0.86
Batch: 700; loss: 0.46; acc: 0.88
Batch: 720; loss: 0.4; acc: 0.8
Batch: 740; loss: 0.25; acc: 0.89
Batch: 760; loss: 0.28; acc: 0.92
Batch: 780; loss: 0.34; acc: 0.86
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

2.3871814846643247e-05
8.185826118278783e-06
Batch: 0; loss: 0.33; acc: 0.92
Batch: 20; loss: 0.52; acc: 0.83
Batch: 40; loss: 0.34; acc: 0.86
Batch: 60; loss: 0.79; acc: 0.77
Batch: 80; loss: 0.31; acc: 0.89
Batch: 100; loss: 0.42; acc: 0.91
Batch: 120; loss: 0.45; acc: 0.88
Batch: 140; loss: 0.23; acc: 0.92
Val Epoch over. val_loss: 0.48703961491964426; val_accuracy: 0.8443471337579618 

The current subspace-distance is: 8.185826118278783e-06 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.85; acc: 0.73
Batch: 20; loss: 0.24; acc: 0.91
Batch: 40; loss: 0.36; acc: 0.84
Batch: 60; loss: 0.28; acc: 0.94
Batch: 80; loss: 0.67; acc: 0.81
Batch: 100; loss: 0.36; acc: 0.88
Batch: 120; loss: 0.33; acc: 0.92
Batch: 140; loss: 0.34; acc: 0.91
Batch: 160; loss: 0.51; acc: 0.84
Batch: 180; loss: 0.33; acc: 0.92
Batch: 200; loss: 0.27; acc: 0.92
Batch: 220; loss: 0.55; acc: 0.83
Batch: 240; loss: 0.33; acc: 0.92
Batch: 260; loss: 0.17; acc: 0.94
Batch: 280; loss: 0.59; acc: 0.86
Batch: 300; loss: 0.5; acc: 0.84
Batch: 320; loss: 0.54; acc: 0.84
Batch: 340; loss: 0.46; acc: 0.84
Batch: 360; loss: 0.34; acc: 0.89
Batch: 380; loss: 0.38; acc: 0.89
Batch: 400; loss: 0.41; acc: 0.88
Batch: 420; loss: 0.29; acc: 0.92
Batch: 440; loss: 0.51; acc: 0.88
Batch: 460; loss: 0.41; acc: 0.84
Batch: 480; loss: 0.45; acc: 0.91
Batch: 500; loss: 0.36; acc: 0.86
Batch: 520; loss: 0.59; acc: 0.84
Batch: 540; loss: 0.39; acc: 0.86
Batch: 560; loss: 0.22; acc: 0.91
Batch: 580; loss: 0.57; acc: 0.83
Batch: 600; loss: 0.58; acc: 0.86
Batch: 620; loss: 0.4; acc: 0.86
Batch: 640; loss: 0.27; acc: 0.92
Batch: 660; loss: 0.33; acc: 0.92
Batch: 680; loss: 0.52; acc: 0.86
Batch: 700; loss: 0.62; acc: 0.8
Batch: 720; loss: 0.33; acc: 0.89
Batch: 740; loss: 0.43; acc: 0.88
Batch: 760; loss: 0.29; acc: 0.92
Batch: 780; loss: 0.54; acc: 0.84
Train Epoch over. train_loss: 0.44; train_accuracy: 0.87 

2.3695729396422394e-05
7.982540410012007e-06
Batch: 0; loss: 0.53; acc: 0.75
Batch: 20; loss: 0.8; acc: 0.73
Batch: 40; loss: 0.34; acc: 0.88
Batch: 60; loss: 0.87; acc: 0.77
Batch: 80; loss: 0.44; acc: 0.89
Batch: 100; loss: 0.46; acc: 0.86
Batch: 120; loss: 0.77; acc: 0.77
Batch: 140; loss: 0.35; acc: 0.86
Val Epoch over. val_loss: 0.5818468518317885; val_accuracy: 0.8207603503184714 

The current subspace-distance is: 7.982540410012007e-06 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.69; acc: 0.78
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.33; acc: 0.92
Batch: 60; loss: 0.72; acc: 0.84
Batch: 80; loss: 0.46; acc: 0.83
Batch: 100; loss: 0.45; acc: 0.91
Batch: 120; loss: 0.27; acc: 0.89
Batch: 140; loss: 0.63; acc: 0.8
Batch: 160; loss: 0.48; acc: 0.88
Batch: 180; loss: 0.79; acc: 0.72
Batch: 200; loss: 0.34; acc: 0.95
Batch: 220; loss: 0.39; acc: 0.88
Batch: 240; loss: 0.33; acc: 0.89
Batch: 260; loss: 0.46; acc: 0.88
Batch: 280; loss: 0.61; acc: 0.8
Batch: 300; loss: 0.52; acc: 0.81
Batch: 320; loss: 0.59; acc: 0.81
Batch: 340; loss: 0.51; acc: 0.86
Batch: 360; loss: 0.63; acc: 0.86
Batch: 380; loss: 0.22; acc: 0.92
Batch: 400; loss: 0.51; acc: 0.84
Batch: 420; loss: 0.26; acc: 0.92
Batch: 440; loss: 0.42; acc: 0.83
Batch: 460; loss: 0.26; acc: 0.89
Batch: 480; loss: 0.33; acc: 0.88
Batch: 500; loss: 0.4; acc: 0.91
Batch: 520; loss: 0.38; acc: 0.89
Batch: 540; loss: 0.55; acc: 0.88
Batch: 560; loss: 0.59; acc: 0.8
Batch: 580; loss: 0.56; acc: 0.83
Batch: 600; loss: 0.53; acc: 0.89
Batch: 620; loss: 0.35; acc: 0.88
Batch: 640; loss: 0.69; acc: 0.77
Batch: 660; loss: 0.47; acc: 0.81
Batch: 680; loss: 0.85; acc: 0.81
Batch: 700; loss: 0.66; acc: 0.84
Batch: 720; loss: 0.39; acc: 0.8
Batch: 740; loss: 0.39; acc: 0.83
Batch: 760; loss: 0.36; acc: 0.86
Batch: 780; loss: 0.54; acc: 0.83
Train Epoch over. train_loss: 0.44; train_accuracy: 0.87 

2.3293889171327464e-05
8.570479621994309e-06
Batch: 0; loss: 0.39; acc: 0.91
Batch: 20; loss: 0.53; acc: 0.89
Batch: 40; loss: 0.32; acc: 0.91
Batch: 60; loss: 0.76; acc: 0.73
Batch: 80; loss: 0.26; acc: 0.91
Batch: 100; loss: 0.58; acc: 0.86
Batch: 120; loss: 0.61; acc: 0.83
Batch: 140; loss: 0.19; acc: 0.89
Val Epoch over. val_loss: 0.4934865975645697; val_accuracy: 0.8471337579617835 

The current subspace-distance is: 8.570479621994309e-06 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.75; acc: 0.8
Batch: 20; loss: 0.26; acc: 0.92
Batch: 40; loss: 0.61; acc: 0.73
Batch: 60; loss: 0.48; acc: 0.84
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.52; acc: 0.84
Batch: 120; loss: 0.39; acc: 0.91
Batch: 140; loss: 0.56; acc: 0.78
Batch: 160; loss: 0.35; acc: 0.91
Batch: 180; loss: 0.34; acc: 0.91
Batch: 200; loss: 0.57; acc: 0.84
Batch: 220; loss: 0.73; acc: 0.78
Batch: 240; loss: 0.31; acc: 0.88
Batch: 260; loss: 0.6; acc: 0.83
Batch: 280; loss: 0.32; acc: 0.92
Batch: 300; loss: 0.22; acc: 0.94
Batch: 320; loss: 0.66; acc: 0.83
Batch: 340; loss: 0.34; acc: 0.84
Batch: 360; loss: 0.3; acc: 0.91
Batch: 380; loss: 0.34; acc: 0.88
Batch: 400; loss: 0.48; acc: 0.84
Batch: 420; loss: 0.53; acc: 0.83
Batch: 440; loss: 0.31; acc: 0.92
Batch: 460; loss: 0.28; acc: 0.91
Batch: 480; loss: 0.49; acc: 0.83
Batch: 500; loss: 0.32; acc: 0.89
Batch: 520; loss: 0.4; acc: 0.91
Batch: 540; loss: 0.23; acc: 0.97
Batch: 560; loss: 0.5; acc: 0.88
Batch: 580; loss: 0.42; acc: 0.84
Batch: 600; loss: 0.34; acc: 0.91
Batch: 620; loss: 0.65; acc: 0.81
Batch: 640; loss: 0.48; acc: 0.89
Batch: 660; loss: 0.34; acc: 0.91
Batch: 680; loss: 0.31; acc: 0.91
Batch: 700; loss: 0.35; acc: 0.91
Batch: 720; loss: 0.72; acc: 0.86
Batch: 740; loss: 0.49; acc: 0.86
Batch: 760; loss: 0.25; acc: 0.92
Batch: 780; loss: 0.59; acc: 0.86
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

2.4641258278279565e-05
8.497085218550637e-06
Batch: 0; loss: 0.34; acc: 0.89
Batch: 20; loss: 0.59; acc: 0.84
Batch: 40; loss: 0.26; acc: 0.89
Batch: 60; loss: 0.59; acc: 0.8
Batch: 80; loss: 0.23; acc: 0.91
Batch: 100; loss: 0.51; acc: 0.86
Batch: 120; loss: 0.64; acc: 0.8
Batch: 140; loss: 0.15; acc: 0.94
Val Epoch over. val_loss: 0.44463594172410903; val_accuracy: 0.8644506369426752 

The current subspace-distance is: 8.497085218550637e-06 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.35; acc: 0.89
Batch: 20; loss: 0.35; acc: 0.89
Batch: 40; loss: 0.54; acc: 0.88
Batch: 60; loss: 0.21; acc: 0.95
Batch: 80; loss: 0.32; acc: 0.91
Batch: 100; loss: 0.32; acc: 0.91
Batch: 120; loss: 0.43; acc: 0.91
Batch: 140; loss: 0.28; acc: 0.91
Batch: 160; loss: 0.43; acc: 0.8
Batch: 180; loss: 0.3; acc: 0.92
Batch: 200; loss: 0.59; acc: 0.84
Batch: 220; loss: 0.43; acc: 0.84
Batch: 240; loss: 0.43; acc: 0.86
Batch: 260; loss: 0.4; acc: 0.84
Batch: 280; loss: 0.33; acc: 0.89
Batch: 300; loss: 0.47; acc: 0.88
Batch: 320; loss: 0.47; acc: 0.86
Batch: 340; loss: 0.38; acc: 0.89
Batch: 360; loss: 0.49; acc: 0.88
Batch: 380; loss: 0.42; acc: 0.91
Batch: 400; loss: 0.68; acc: 0.81
Batch: 420; loss: 0.33; acc: 0.89
Batch: 440; loss: 0.29; acc: 0.91
Batch: 460; loss: 0.33; acc: 0.86
Batch: 480; loss: 0.27; acc: 0.91
Batch: 500; loss: 0.31; acc: 0.86
Batch: 520; loss: 0.41; acc: 0.89
Batch: 540; loss: 0.45; acc: 0.91
Batch: 560; loss: 0.52; acc: 0.83
Batch: 580; loss: 0.28; acc: 0.94
Batch: 600; loss: 0.64; acc: 0.88
Batch: 620; loss: 0.4; acc: 0.91
Batch: 640; loss: 0.32; acc: 0.92
Batch: 660; loss: 0.39; acc: 0.91
Batch: 680; loss: 0.44; acc: 0.88
Batch: 700; loss: 0.19; acc: 0.95
Batch: 720; loss: 0.35; acc: 0.88
Batch: 740; loss: 0.24; acc: 0.94
Batch: 760; loss: 0.44; acc: 0.84
Batch: 780; loss: 0.34; acc: 0.88
Train Epoch over. train_loss: 0.39; train_accuracy: 0.89 

2.4093666070257314e-05
7.930912033771165e-06
Batch: 0; loss: 0.34; acc: 0.91
Batch: 20; loss: 0.47; acc: 0.86
Batch: 40; loss: 0.25; acc: 0.91
Batch: 60; loss: 0.75; acc: 0.78
Batch: 80; loss: 0.24; acc: 0.92
Batch: 100; loss: 0.42; acc: 0.91
Batch: 120; loss: 0.52; acc: 0.86
Batch: 140; loss: 0.17; acc: 0.97
Val Epoch over. val_loss: 0.41943612315092876; val_accuracy: 0.87609474522293 

The current subspace-distance is: 7.930912033771165e-06 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.64; acc: 0.8
Batch: 20; loss: 0.35; acc: 0.88
Batch: 40; loss: 0.34; acc: 0.88
Batch: 60; loss: 0.27; acc: 0.91
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.2; acc: 0.95
Batch: 140; loss: 0.38; acc: 0.91
Batch: 160; loss: 0.25; acc: 0.91
Batch: 180; loss: 0.24; acc: 0.91
Batch: 200; loss: 0.39; acc: 0.89
Batch: 220; loss: 0.41; acc: 0.88
Batch: 240; loss: 0.38; acc: 0.89
Batch: 260; loss: 0.21; acc: 0.95
Batch: 280; loss: 0.28; acc: 0.88
Batch: 300; loss: 0.21; acc: 0.91
Batch: 320; loss: 0.26; acc: 0.95
Batch: 340; loss: 0.36; acc: 0.91
Batch: 360; loss: 0.31; acc: 0.88
Batch: 380; loss: 0.57; acc: 0.84
Batch: 400; loss: 0.37; acc: 0.89
Batch: 420; loss: 0.51; acc: 0.86
Batch: 440; loss: 0.44; acc: 0.89
Batch: 460; loss: 0.27; acc: 0.94
Batch: 480; loss: 0.62; acc: 0.81
Batch: 500; loss: 0.62; acc: 0.77
Batch: 520; loss: 0.42; acc: 0.86
Batch: 540; loss: 0.45; acc: 0.84
Batch: 560; loss: 0.34; acc: 0.91
Batch: 580; loss: 0.3; acc: 0.92
Batch: 600; loss: 0.33; acc: 0.92
Batch: 620; loss: 0.32; acc: 0.94
Batch: 640; loss: 0.38; acc: 0.88
Batch: 660; loss: 0.34; acc: 0.92
Batch: 680; loss: 0.59; acc: 0.8
Batch: 700; loss: 0.38; acc: 0.88
Batch: 720; loss: 0.27; acc: 0.92
Batch: 740; loss: 0.48; acc: 0.88
Batch: 760; loss: 0.62; acc: 0.83
Batch: 780; loss: 0.27; acc: 0.89
Train Epoch over. train_loss: 0.38; train_accuracy: 0.89 

2.372715789533686e-05
8.61309945321409e-06
Batch: 0; loss: 0.35; acc: 0.91
Batch: 20; loss: 0.47; acc: 0.81
Batch: 40; loss: 0.3; acc: 0.88
Batch: 60; loss: 0.84; acc: 0.73
Batch: 80; loss: 0.29; acc: 0.91
Batch: 100; loss: 0.38; acc: 0.91
Batch: 120; loss: 0.53; acc: 0.86
Batch: 140; loss: 0.18; acc: 0.94
Val Epoch over. val_loss: 0.4352586768615018; val_accuracy: 0.8681329617834395 

The current subspace-distance is: 8.61309945321409e-06 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.46; acc: 0.84
Batch: 20; loss: 0.74; acc: 0.78
Batch: 40; loss: 0.48; acc: 0.89
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.32; acc: 0.88
Batch: 100; loss: 0.35; acc: 0.89
Batch: 120; loss: 0.31; acc: 0.91
Batch: 140; loss: 0.38; acc: 0.92
Batch: 160; loss: 0.57; acc: 0.84
Batch: 180; loss: 0.35; acc: 0.89
Batch: 200; loss: 0.43; acc: 0.86
Batch: 220; loss: 0.29; acc: 0.92
Batch: 240; loss: 0.21; acc: 0.92
Batch: 260; loss: 0.3; acc: 0.91
Batch: 280; loss: 0.4; acc: 0.89
Batch: 300; loss: 0.46; acc: 0.81
Batch: 320; loss: 0.46; acc: 0.91
Batch: 340; loss: 0.25; acc: 0.92
Batch: 360; loss: 0.31; acc: 0.91
Batch: 380; loss: 0.43; acc: 0.83
Batch: 400; loss: 0.33; acc: 0.94
Batch: 420; loss: 0.26; acc: 0.92
Batch: 440; loss: 0.33; acc: 0.86
Batch: 460; loss: 0.34; acc: 0.89
Batch: 480; loss: 0.29; acc: 0.92
Batch: 500; loss: 0.29; acc: 0.94
Batch: 520; loss: 0.33; acc: 0.88
Batch: 540; loss: 0.43; acc: 0.83
Batch: 560; loss: 0.31; acc: 0.94
Batch: 580; loss: 0.39; acc: 0.86
Batch: 600; loss: 0.42; acc: 0.81
Batch: 620; loss: 0.34; acc: 0.89
Batch: 640; loss: 0.26; acc: 0.91
Batch: 660; loss: 0.49; acc: 0.89
Batch: 680; loss: 0.32; acc: 0.89
Batch: 700; loss: 0.49; acc: 0.81
Batch: 720; loss: 0.24; acc: 0.91
Batch: 740; loss: 0.32; acc: 0.94
Batch: 760; loss: 0.51; acc: 0.86
Batch: 780; loss: 0.55; acc: 0.8
Train Epoch over. train_loss: 0.38; train_accuracy: 0.89 

2.3864771719672717e-05
7.446664312737994e-06
Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.47; acc: 0.86
Batch: 40; loss: 0.19; acc: 0.91
Batch: 60; loss: 0.56; acc: 0.81
Batch: 80; loss: 0.22; acc: 0.92
Batch: 100; loss: 0.33; acc: 0.89
Batch: 120; loss: 0.61; acc: 0.86
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.37051978337157304; val_accuracy: 0.8856488853503185 

The current subspace-distance is: 7.446664312737994e-06 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.38; acc: 0.89
Batch: 20; loss: 0.35; acc: 0.84
Batch: 40; loss: 0.41; acc: 0.89
Batch: 60; loss: 0.47; acc: 0.88
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.3; acc: 0.89
Batch: 120; loss: 0.41; acc: 0.91
Batch: 140; loss: 0.49; acc: 0.86
Batch: 160; loss: 0.32; acc: 0.92
Batch: 180; loss: 0.24; acc: 0.91
Batch: 200; loss: 0.32; acc: 0.92
Batch: 220; loss: 0.52; acc: 0.86
Batch: 240; loss: 0.15; acc: 0.97
Batch: 260; loss: 0.3; acc: 0.91
Batch: 280; loss: 0.41; acc: 0.86
Batch: 300; loss: 0.32; acc: 0.91
Batch: 320; loss: 0.23; acc: 0.94
Batch: 340; loss: 0.36; acc: 0.92
Batch: 360; loss: 0.54; acc: 0.84
Batch: 380; loss: 0.22; acc: 0.92
Batch: 400; loss: 0.55; acc: 0.78
Batch: 420; loss: 0.35; acc: 0.86
Batch: 440; loss: 0.32; acc: 0.88
Batch: 460; loss: 0.34; acc: 0.88
Batch: 480; loss: 0.58; acc: 0.88
Batch: 500; loss: 0.54; acc: 0.84
Batch: 520; loss: 0.29; acc: 0.88
Batch: 540; loss: 0.4; acc: 0.89
Batch: 560; loss: 0.59; acc: 0.84
Batch: 580; loss: 0.48; acc: 0.86
Batch: 600; loss: 0.32; acc: 0.88
Batch: 620; loss: 0.43; acc: 0.83
Batch: 640; loss: 0.45; acc: 0.86
Batch: 660; loss: 0.38; acc: 0.88
Batch: 680; loss: 0.66; acc: 0.84
Batch: 700; loss: 0.2; acc: 0.95
Batch: 720; loss: 0.26; acc: 0.94
Batch: 740; loss: 0.21; acc: 0.92
Batch: 760; loss: 0.26; acc: 0.91
Batch: 780; loss: 0.43; acc: 0.88
Train Epoch over. train_loss: 0.38; train_accuracy: 0.89 

2.4724782633711584e-05
8.251721737906337e-06
Batch: 0; loss: 0.26; acc: 0.95
Batch: 20; loss: 0.38; acc: 0.89
Batch: 40; loss: 0.18; acc: 0.91
Batch: 60; loss: 0.5; acc: 0.83
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.49; acc: 0.88
Batch: 140; loss: 0.09; acc: 0.98
Val Epoch over. val_loss: 0.34678717840249373; val_accuracy: 0.8993829617834395 

The current subspace-distance is: 8.251721737906337e-06 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.33; acc: 0.91
Batch: 20; loss: 0.26; acc: 0.92
Batch: 40; loss: 0.41; acc: 0.89
Batch: 60; loss: 0.41; acc: 0.89
Batch: 80; loss: 0.32; acc: 0.91
Batch: 100; loss: 0.43; acc: 0.81
Batch: 120; loss: 0.42; acc: 0.88
Batch: 140; loss: 0.46; acc: 0.83
Batch: 160; loss: 0.34; acc: 0.86
Batch: 180; loss: 0.52; acc: 0.86
Batch: 200; loss: 0.45; acc: 0.89
Batch: 220; loss: 0.41; acc: 0.84
Batch: 240; loss: 0.58; acc: 0.83
Batch: 260; loss: 0.38; acc: 0.86
Batch: 280; loss: 0.25; acc: 0.94
Batch: 300; loss: 0.78; acc: 0.84
Batch: 320; loss: 0.45; acc: 0.86
Batch: 340; loss: 0.29; acc: 0.88
Batch: 360; loss: 0.43; acc: 0.81
Batch: 380; loss: 0.46; acc: 0.86
Batch: 400; loss: 0.37; acc: 0.88
Batch: 420; loss: 0.36; acc: 0.88
Batch: 440; loss: 0.35; acc: 0.88
Batch: 460; loss: 0.6; acc: 0.86
Batch: 480; loss: 0.25; acc: 0.89
Batch: 500; loss: 0.31; acc: 0.89
Batch: 520; loss: 0.46; acc: 0.89
Batch: 540; loss: 0.19; acc: 0.94
Batch: 560; loss: 0.44; acc: 0.84
Batch: 580; loss: 0.42; acc: 0.89
Batch: 600; loss: 0.18; acc: 0.95
Batch: 620; loss: 0.41; acc: 0.88
Batch: 640; loss: 0.42; acc: 0.88
Batch: 660; loss: 0.34; acc: 0.91
Batch: 680; loss: 0.42; acc: 0.92
Batch: 700; loss: 0.35; acc: 0.91
Batch: 720; loss: 0.46; acc: 0.86
Batch: 740; loss: 0.35; acc: 0.89
Batch: 760; loss: 0.52; acc: 0.84
Batch: 780; loss: 0.25; acc: 0.92
Train Epoch over. train_loss: 0.38; train_accuracy: 0.89 

2.4826169465086423e-05
9.110693099501077e-06
Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.43; acc: 0.88
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.5; acc: 0.86
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.32; acc: 0.89
Batch: 120; loss: 0.55; acc: 0.86
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.34865806821235423; val_accuracy: 0.8982882165605095 

The current subspace-distance is: 9.110693099501077e-06 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.47; acc: 0.83
Batch: 20; loss: 0.45; acc: 0.86
Batch: 40; loss: 0.47; acc: 0.86
Batch: 60; loss: 0.36; acc: 0.92
Batch: 80; loss: 0.44; acc: 0.89
Batch: 100; loss: 0.35; acc: 0.88
Batch: 120; loss: 0.7; acc: 0.8
Batch: 140; loss: 0.29; acc: 0.94
Batch: 160; loss: 0.32; acc: 0.92
Batch: 180; loss: 0.52; acc: 0.84
Batch: 200; loss: 0.26; acc: 0.89
Batch: 220; loss: 0.38; acc: 0.89
Batch: 240; loss: 0.29; acc: 0.89
Batch: 260; loss: 0.34; acc: 0.88
Batch: 280; loss: 0.95; acc: 0.8
Batch: 300; loss: 0.34; acc: 0.88
Batch: 320; loss: 0.4; acc: 0.88
Batch: 340; loss: 0.54; acc: 0.84
Batch: 360; loss: 0.4; acc: 0.86
Batch: 380; loss: 0.4; acc: 0.89
Batch: 400; loss: 0.51; acc: 0.88
Batch: 420; loss: 0.51; acc: 0.89
Batch: 440; loss: 0.33; acc: 0.89
Batch: 460; loss: 0.38; acc: 0.83
Batch: 480; loss: 0.24; acc: 0.92
Batch: 500; loss: 0.48; acc: 0.86
Batch: 520; loss: 0.2; acc: 0.92
Batch: 540; loss: 0.33; acc: 0.84
Batch: 560; loss: 0.48; acc: 0.84
Batch: 580; loss: 0.41; acc: 0.88
Batch: 600; loss: 0.42; acc: 0.86
Batch: 620; loss: 0.32; acc: 0.91
Batch: 640; loss: 0.52; acc: 0.81
Batch: 660; loss: 0.25; acc: 0.92
Batch: 680; loss: 0.19; acc: 0.91
Batch: 700; loss: 0.4; acc: 0.91
Batch: 720; loss: 0.3; acc: 0.92
Batch: 740; loss: 0.37; acc: 0.84
Batch: 760; loss: 0.42; acc: 0.88
Batch: 780; loss: 0.49; acc: 0.83
Train Epoch over. train_loss: 0.38; train_accuracy: 0.89 

2.558934829721693e-05
8.28666816232726e-06
Batch: 0; loss: 0.28; acc: 0.92
Batch: 20; loss: 0.36; acc: 0.86
Batch: 40; loss: 0.22; acc: 0.91
Batch: 60; loss: 0.58; acc: 0.8
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.38; acc: 0.91
Batch: 120; loss: 0.5; acc: 0.84
Batch: 140; loss: 0.12; acc: 0.95
Val Epoch over. val_loss: 0.36774530807498157; val_accuracy: 0.8893312101910829 

The current subspace-distance is: 8.28666816232726e-06 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.46; acc: 0.8
Batch: 40; loss: 0.46; acc: 0.86
Batch: 60; loss: 0.26; acc: 0.89
Batch: 80; loss: 0.44; acc: 0.92
Batch: 100; loss: 0.44; acc: 0.89
Batch: 120; loss: 0.47; acc: 0.81
Batch: 140; loss: 0.23; acc: 0.92
Batch: 160; loss: 0.58; acc: 0.83
Batch: 180; loss: 0.34; acc: 0.86
Batch: 200; loss: 0.56; acc: 0.83
Batch: 220; loss: 0.27; acc: 0.94
Batch: 240; loss: 0.54; acc: 0.81
Batch: 260; loss: 0.32; acc: 0.92
Batch: 280; loss: 0.35; acc: 0.92
Batch: 300; loss: 0.48; acc: 0.83
Batch: 320; loss: 0.28; acc: 0.91
Batch: 340; loss: 0.24; acc: 0.86
Batch: 360; loss: 0.42; acc: 0.84
Batch: 380; loss: 0.64; acc: 0.86
Batch: 400; loss: 0.45; acc: 0.88
Batch: 420; loss: 0.43; acc: 0.89
Batch: 440; loss: 0.21; acc: 0.95
Batch: 460; loss: 0.31; acc: 0.92
Batch: 480; loss: 0.35; acc: 0.89
Batch: 500; loss: 0.35; acc: 0.88
Batch: 520; loss: 0.47; acc: 0.88
Batch: 540; loss: 0.36; acc: 0.91
Batch: 560; loss: 0.56; acc: 0.84
Batch: 580; loss: 0.46; acc: 0.88
Batch: 600; loss: 0.23; acc: 0.91
Batch: 620; loss: 0.33; acc: 0.88
Batch: 640; loss: 0.47; acc: 0.88
Batch: 660; loss: 0.34; acc: 0.89
Batch: 680; loss: 0.42; acc: 0.89
Batch: 700; loss: 0.21; acc: 0.92
Batch: 720; loss: 0.23; acc: 0.94
Batch: 740; loss: 0.47; acc: 0.91
Batch: 760; loss: 0.49; acc: 0.91
Batch: 780; loss: 0.68; acc: 0.8
Train Epoch over. train_loss: 0.38; train_accuracy: 0.89 

2.5529105187160894e-05
8.943248758441769e-06
Batch: 0; loss: 0.25; acc: 0.95
Batch: 20; loss: 0.35; acc: 0.86
Batch: 40; loss: 0.21; acc: 0.89
Batch: 60; loss: 0.55; acc: 0.8
Batch: 80; loss: 0.17; acc: 0.97
Batch: 100; loss: 0.33; acc: 0.92
Batch: 120; loss: 0.48; acc: 0.89
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.34950408999137816; val_accuracy: 0.8964968152866242 

The current subspace-distance is: 8.943248758441769e-06 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.55; acc: 0.86
Batch: 20; loss: 0.43; acc: 0.86
Batch: 40; loss: 0.5; acc: 0.83
Batch: 60; loss: 0.49; acc: 0.84
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.42; acc: 0.88
Batch: 120; loss: 0.41; acc: 0.84
Batch: 140; loss: 0.48; acc: 0.86
Batch: 160; loss: 0.25; acc: 0.95
Batch: 180; loss: 0.43; acc: 0.92
Batch: 200; loss: 0.21; acc: 0.94
Batch: 220; loss: 0.25; acc: 0.92
Batch: 240; loss: 0.36; acc: 0.89
Batch: 260; loss: 0.59; acc: 0.86
Batch: 280; loss: 0.45; acc: 0.91
Batch: 300; loss: 0.45; acc: 0.88
Batch: 320; loss: 0.35; acc: 0.84
Batch: 340; loss: 0.35; acc: 0.92
Batch: 360; loss: 0.2; acc: 0.94
Batch: 380; loss: 0.35; acc: 0.91
Batch: 400; loss: 0.29; acc: 0.89
Batch: 420; loss: 0.25; acc: 0.92
Batch: 440; loss: 0.36; acc: 0.92
Batch: 460; loss: 0.33; acc: 0.86
Batch: 480; loss: 0.26; acc: 0.89
Batch: 500; loss: 0.36; acc: 0.86
Batch: 520; loss: 0.28; acc: 0.92
Batch: 540; loss: 0.27; acc: 0.89
Batch: 560; loss: 0.67; acc: 0.81
Batch: 580; loss: 0.16; acc: 0.94
Batch: 600; loss: 0.47; acc: 0.83
Batch: 620; loss: 0.32; acc: 0.91
Batch: 640; loss: 0.34; acc: 0.92
Batch: 660; loss: 0.14; acc: 0.98
Batch: 680; loss: 0.38; acc: 0.91
Batch: 700; loss: 0.58; acc: 0.84
Batch: 720; loss: 0.32; acc: 0.91
Batch: 740; loss: 0.35; acc: 0.91
Batch: 760; loss: 0.3; acc: 0.89
Batch: 780; loss: 0.4; acc: 0.94
Train Epoch over. train_loss: 0.38; train_accuracy: 0.89 

2.3929083909024484e-05
7.964157703099772e-06
Batch: 0; loss: 0.27; acc: 0.92
Batch: 20; loss: 0.4; acc: 0.8
Batch: 40; loss: 0.27; acc: 0.86
Batch: 60; loss: 0.53; acc: 0.83
Batch: 80; loss: 0.16; acc: 0.98
Batch: 100; loss: 0.35; acc: 0.91
Batch: 120; loss: 0.5; acc: 0.86
Batch: 140; loss: 0.13; acc: 0.97
Val Epoch over. val_loss: 0.3869693190523773; val_accuracy: 0.8867436305732485 

The current subspace-distance is: 7.964157703099772e-06 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.4; acc: 0.83
Batch: 20; loss: 0.43; acc: 0.89
Batch: 40; loss: 0.47; acc: 0.81
Batch: 60; loss: 0.45; acc: 0.89
Batch: 80; loss: 0.61; acc: 0.84
Batch: 100; loss: 0.62; acc: 0.78
Batch: 120; loss: 0.27; acc: 0.86
Batch: 140; loss: 0.33; acc: 0.92
Batch: 160; loss: 0.21; acc: 0.95
Batch: 180; loss: 0.45; acc: 0.91
Batch: 200; loss: 0.58; acc: 0.83
Batch: 220; loss: 0.26; acc: 0.89
Batch: 240; loss: 0.33; acc: 0.91
Batch: 260; loss: 0.55; acc: 0.83
Batch: 280; loss: 0.46; acc: 0.83
Batch: 300; loss: 0.22; acc: 0.94
Batch: 320; loss: 0.47; acc: 0.86
Batch: 340; loss: 0.39; acc: 0.88
Batch: 360; loss: 0.18; acc: 0.97
Batch: 380; loss: 0.38; acc: 0.89
Batch: 400; loss: 0.49; acc: 0.86
Batch: 420; loss: 0.3; acc: 0.91
Batch: 440; loss: 0.33; acc: 0.88
Batch: 460; loss: 0.44; acc: 0.86
Batch: 480; loss: 0.48; acc: 0.89
Batch: 500; loss: 0.37; acc: 0.91
Batch: 520; loss: 0.57; acc: 0.84
Batch: 540; loss: 0.24; acc: 0.91
Batch: 560; loss: 0.23; acc: 0.92
Batch: 580; loss: 0.38; acc: 0.92
Batch: 600; loss: 0.29; acc: 0.91
Batch: 620; loss: 0.51; acc: 0.88
Batch: 640; loss: 0.33; acc: 0.89
Batch: 660; loss: 0.17; acc: 0.94
Batch: 680; loss: 0.67; acc: 0.8
Batch: 700; loss: 0.18; acc: 0.94
Batch: 720; loss: 0.43; acc: 0.88
Batch: 740; loss: 0.2; acc: 0.94
Batch: 760; loss: 0.21; acc: 0.92
Batch: 780; loss: 0.34; acc: 0.89
Train Epoch over. train_loss: 0.38; train_accuracy: 0.89 

2.5526591343805194e-05
8.60270574776223e-06
Batch: 0; loss: 0.29; acc: 0.92
Batch: 20; loss: 0.46; acc: 0.88
Batch: 40; loss: 0.22; acc: 0.89
Batch: 60; loss: 0.51; acc: 0.86
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.38; acc: 0.86
Batch: 120; loss: 0.64; acc: 0.84
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.37180962797942435; val_accuracy: 0.8889331210191083 

The current subspace-distance is: 8.60270574776223e-06 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.22; acc: 0.97
Batch: 20; loss: 0.41; acc: 0.88
Batch: 40; loss: 0.33; acc: 0.94
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.35; acc: 0.88
Batch: 100; loss: 0.3; acc: 0.94
Batch: 120; loss: 0.3; acc: 0.89
Batch: 140; loss: 0.3; acc: 0.91
Batch: 160; loss: 0.35; acc: 0.91
Batch: 180; loss: 0.36; acc: 0.89
Batch: 200; loss: 0.37; acc: 0.89
Batch: 220; loss: 0.27; acc: 0.94
Batch: 240; loss: 0.31; acc: 0.88
Batch: 260; loss: 0.4; acc: 0.84
Batch: 280; loss: 0.39; acc: 0.88
Batch: 300; loss: 0.62; acc: 0.84
Batch: 320; loss: 0.51; acc: 0.89
Batch: 340; loss: 0.29; acc: 0.91
Batch: 360; loss: 0.41; acc: 0.91
Batch: 380; loss: 0.28; acc: 0.94
Batch: 400; loss: 0.46; acc: 0.88
Batch: 420; loss: 0.36; acc: 0.92
Batch: 440; loss: 0.42; acc: 0.88
Batch: 460; loss: 0.31; acc: 0.89
Batch: 480; loss: 0.35; acc: 0.88
Batch: 500; loss: 0.28; acc: 0.89
Batch: 520; loss: 0.47; acc: 0.86
Batch: 540; loss: 0.22; acc: 0.92
Batch: 560; loss: 0.37; acc: 0.84
Batch: 580; loss: 0.21; acc: 0.94
Batch: 600; loss: 0.53; acc: 0.83
Batch: 620; loss: 0.62; acc: 0.8
Batch: 640; loss: 0.32; acc: 0.89
Batch: 660; loss: 0.38; acc: 0.88
Batch: 680; loss: 0.44; acc: 0.88
Batch: 700; loss: 0.62; acc: 0.86
Batch: 720; loss: 0.37; acc: 0.88
Batch: 740; loss: 0.31; acc: 0.91
Batch: 760; loss: 0.34; acc: 0.89
Batch: 780; loss: 0.26; acc: 0.92
Train Epoch over. train_loss: 0.38; train_accuracy: 0.89 

2.49938548222417e-05
8.429773515672423e-06
Batch: 0; loss: 0.24; acc: 0.92
Batch: 20; loss: 0.34; acc: 0.89
Batch: 40; loss: 0.21; acc: 0.89
Batch: 60; loss: 0.47; acc: 0.83
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.38; acc: 0.91
Batch: 120; loss: 0.46; acc: 0.88
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.35131945442052404; val_accuracy: 0.8993829617834395 

The current subspace-distance is: 8.429773515672423e-06 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.68; acc: 0.83
Batch: 20; loss: 0.23; acc: 0.94
Batch: 40; loss: 0.33; acc: 0.92
Batch: 60; loss: 0.34; acc: 0.92
Batch: 80; loss: 0.58; acc: 0.88
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.39; acc: 0.89
Batch: 140; loss: 0.44; acc: 0.86
Batch: 160; loss: 0.43; acc: 0.91
Batch: 180; loss: 0.4; acc: 0.86
Batch: 200; loss: 0.29; acc: 0.92
Batch: 220; loss: 0.45; acc: 0.84
Batch: 240; loss: 0.16; acc: 0.97
Batch: 260; loss: 0.44; acc: 0.84
Batch: 280; loss: 0.19; acc: 0.94
Batch: 300; loss: 0.34; acc: 0.91
Batch: 320; loss: 0.4; acc: 0.86
Batch: 340; loss: 0.24; acc: 0.92
Batch: 360; loss: 0.24; acc: 0.94
Batch: 380; loss: 0.53; acc: 0.83
Batch: 400; loss: 0.3; acc: 0.86
Batch: 420; loss: 0.33; acc: 0.89
Batch: 440; loss: 0.35; acc: 0.88
Batch: 460; loss: 0.22; acc: 0.97
Batch: 480; loss: 0.39; acc: 0.86
Batch: 500; loss: 0.38; acc: 0.88
Batch: 520; loss: 0.28; acc: 0.92
Batch: 540; loss: 0.23; acc: 0.94
Batch: 560; loss: 0.35; acc: 0.84
Batch: 580; loss: 0.33; acc: 0.92
Batch: 600; loss: 0.29; acc: 0.89
Batch: 620; loss: 0.49; acc: 0.84
Batch: 640; loss: 0.41; acc: 0.86
Batch: 660; loss: 0.37; acc: 0.92
Batch: 680; loss: 0.37; acc: 0.91
Batch: 700; loss: 0.18; acc: 0.95
Batch: 720; loss: 0.39; acc: 0.92
Batch: 740; loss: 0.31; acc: 0.88
Batch: 760; loss: 0.27; acc: 0.94
Batch: 780; loss: 0.43; acc: 0.84
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

2.504222356947139e-05
8.418407560384367e-06
Batch: 0; loss: 0.25; acc: 0.94
Batch: 20; loss: 0.34; acc: 0.88
Batch: 40; loss: 0.21; acc: 0.91
Batch: 60; loss: 0.56; acc: 0.81
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.53; acc: 0.88
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.3501737397757305; val_accuracy: 0.8987858280254777 

The current subspace-distance is: 8.418407560384367e-06 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.25; acc: 0.89
Batch: 20; loss: 0.25; acc: 0.91
Batch: 40; loss: 0.2; acc: 0.94
Batch: 60; loss: 0.2; acc: 0.95
Batch: 80; loss: 0.26; acc: 0.91
Batch: 100; loss: 0.2; acc: 0.92
Batch: 120; loss: 0.49; acc: 0.83
Batch: 140; loss: 0.24; acc: 0.89
Batch: 160; loss: 0.39; acc: 0.91
Batch: 180; loss: 0.27; acc: 0.95
Batch: 200; loss: 0.64; acc: 0.83
Batch: 220; loss: 0.11; acc: 0.98
Batch: 240; loss: 0.3; acc: 0.94
Batch: 260; loss: 0.31; acc: 0.91
Batch: 280; loss: 0.35; acc: 0.91
Batch: 300; loss: 0.41; acc: 0.89
Batch: 320; loss: 0.42; acc: 0.91
Batch: 340; loss: 0.31; acc: 0.91
Batch: 360; loss: 0.33; acc: 0.86
Batch: 380; loss: 0.48; acc: 0.84
Batch: 400; loss: 0.35; acc: 0.92
Batch: 420; loss: 0.43; acc: 0.86
Batch: 440; loss: 0.43; acc: 0.83
Batch: 460; loss: 0.39; acc: 0.88
Batch: 480; loss: 0.38; acc: 0.92
Batch: 500; loss: 0.28; acc: 0.89
Batch: 520; loss: 0.38; acc: 0.94
Batch: 540; loss: 0.38; acc: 0.86
Batch: 560; loss: 0.3; acc: 0.89
Batch: 580; loss: 0.28; acc: 0.92
Batch: 600; loss: 0.31; acc: 0.88
Batch: 620; loss: 0.35; acc: 0.88
Batch: 640; loss: 0.26; acc: 0.92
Batch: 660; loss: 0.34; acc: 0.92
Batch: 680; loss: 0.41; acc: 0.89
Batch: 700; loss: 0.27; acc: 0.86
Batch: 720; loss: 0.44; acc: 0.89
Batch: 740; loss: 0.25; acc: 0.89
Batch: 760; loss: 0.42; acc: 0.91
Batch: 780; loss: 0.28; acc: 0.94
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

2.5851089958450757e-05
9.500540727458429e-06
Batch: 0; loss: 0.27; acc: 0.94
Batch: 20; loss: 0.37; acc: 0.86
Batch: 40; loss: 0.19; acc: 0.92
Batch: 60; loss: 0.54; acc: 0.84
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.31; acc: 0.88
Batch: 120; loss: 0.57; acc: 0.88
Batch: 140; loss: 0.11; acc: 0.95
Val Epoch over. val_loss: 0.34681657250899417; val_accuracy: 0.9003781847133758 

The current subspace-distance is: 9.500540727458429e-06 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.29; acc: 0.92
Batch: 20; loss: 0.34; acc: 0.89
Batch: 40; loss: 0.5; acc: 0.86
Batch: 60; loss: 0.35; acc: 0.92
Batch: 80; loss: 0.56; acc: 0.84
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.69; acc: 0.83
Batch: 140; loss: 0.25; acc: 0.94
Batch: 160; loss: 0.45; acc: 0.86
Batch: 180; loss: 0.6; acc: 0.86
Batch: 200; loss: 0.59; acc: 0.81
Batch: 220; loss: 0.24; acc: 0.91
Batch: 240; loss: 0.49; acc: 0.86
Batch: 260; loss: 0.41; acc: 0.89
Batch: 280; loss: 0.25; acc: 0.91
Batch: 300; loss: 0.22; acc: 0.92
Batch: 320; loss: 0.42; acc: 0.91
Batch: 340; loss: 0.28; acc: 0.91
Batch: 360; loss: 0.34; acc: 0.89
Batch: 380; loss: 0.36; acc: 0.88
Batch: 400; loss: 0.44; acc: 0.88
Batch: 420; loss: 0.41; acc: 0.86
Batch: 440; loss: 0.77; acc: 0.73
Batch: 460; loss: 0.43; acc: 0.89
Batch: 480; loss: 0.35; acc: 0.86
Batch: 500; loss: 0.49; acc: 0.88
Batch: 520; loss: 0.64; acc: 0.89
Batch: 540; loss: 0.24; acc: 0.92
Batch: 560; loss: 0.35; acc: 0.86
Batch: 580; loss: 0.37; acc: 0.91
Batch: 600; loss: 0.38; acc: 0.88
Batch: 620; loss: 0.37; acc: 0.89
Batch: 640; loss: 0.47; acc: 0.92
Batch: 660; loss: 0.28; acc: 0.92
Batch: 680; loss: 0.32; acc: 0.88
Batch: 700; loss: 0.17; acc: 0.92
Batch: 720; loss: 0.32; acc: 0.92
Batch: 740; loss: 0.23; acc: 0.94
Batch: 760; loss: 0.25; acc: 0.89
Batch: 780; loss: 0.4; acc: 0.89
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

2.6013538445113227e-05
7.99706958787283e-06
Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.35; acc: 0.88
Batch: 40; loss: 0.2; acc: 0.92
Batch: 60; loss: 0.42; acc: 0.88
Batch: 80; loss: 0.17; acc: 0.97
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.51; acc: 0.88
Batch: 140; loss: 0.12; acc: 0.95
Val Epoch over. val_loss: 0.3391026378057565; val_accuracy: 0.9031648089171974 

The current subspace-distance is: 7.99706958787283e-06 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.29; acc: 0.94
Batch: 20; loss: 0.34; acc: 0.91
Batch: 40; loss: 0.38; acc: 0.88
Batch: 60; loss: 0.49; acc: 0.84
Batch: 80; loss: 0.34; acc: 0.92
Batch: 100; loss: 0.39; acc: 0.91
Batch: 120; loss: 0.17; acc: 0.95
Batch: 140; loss: 0.4; acc: 0.86
Batch: 160; loss: 0.28; acc: 0.91
Batch: 180; loss: 0.32; acc: 0.88
Batch: 200; loss: 0.16; acc: 0.98
Batch: 220; loss: 0.58; acc: 0.86
Batch: 240; loss: 0.35; acc: 0.91
Batch: 260; loss: 0.38; acc: 0.91
Batch: 280; loss: 0.28; acc: 0.92
Batch: 300; loss: 0.36; acc: 0.86
Batch: 320; loss: 0.21; acc: 0.94
Batch: 340; loss: 0.32; acc: 0.94
Batch: 360; loss: 0.38; acc: 0.91
Batch: 380; loss: 0.44; acc: 0.88
Batch: 400; loss: 0.51; acc: 0.86
Batch: 420; loss: 0.45; acc: 0.83
Batch: 440; loss: 0.39; acc: 0.86
Batch: 460; loss: 0.26; acc: 0.89
Batch: 480; loss: 0.36; acc: 0.89
Batch: 500; loss: 0.22; acc: 0.92
Batch: 520; loss: 0.22; acc: 0.94
Batch: 540; loss: 0.36; acc: 0.89
Batch: 560; loss: 0.33; acc: 0.88
Batch: 580; loss: 0.33; acc: 0.88
Batch: 600; loss: 0.37; acc: 0.89
Batch: 620; loss: 0.44; acc: 0.84
Batch: 640; loss: 0.53; acc: 0.83
Batch: 660; loss: 0.35; acc: 0.92
Batch: 680; loss: 0.44; acc: 0.84
Batch: 700; loss: 0.44; acc: 0.91
Batch: 720; loss: 0.31; acc: 0.91
Batch: 740; loss: 0.49; acc: 0.88
Batch: 760; loss: 0.36; acc: 0.86
Batch: 780; loss: 0.49; acc: 0.86
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

2.5847835786407813e-05
8.95489938557148e-06
Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.32; acc: 0.89
Batch: 40; loss: 0.21; acc: 0.91
Batch: 60; loss: 0.5; acc: 0.81
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.32; acc: 0.92
Batch: 120; loss: 0.47; acc: 0.88
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.3401901260208172; val_accuracy: 0.901671974522293 

The current subspace-distance is: 8.95489938557148e-06 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.45; acc: 0.89
Batch: 20; loss: 0.33; acc: 0.91
Batch: 40; loss: 0.3; acc: 0.89
Batch: 60; loss: 0.39; acc: 0.86
Batch: 80; loss: 0.26; acc: 0.91
Batch: 100; loss: 0.37; acc: 0.89
Batch: 120; loss: 0.23; acc: 0.94
Batch: 140; loss: 0.21; acc: 0.91
Batch: 160; loss: 0.34; acc: 0.92
Batch: 180; loss: 0.23; acc: 0.91
Batch: 200; loss: 0.34; acc: 0.89
Batch: 220; loss: 0.56; acc: 0.88
Batch: 240; loss: 0.42; acc: 0.92
Batch: 260; loss: 0.22; acc: 0.94
Batch: 280; loss: 0.32; acc: 0.88
Batch: 300; loss: 0.37; acc: 0.86
Batch: 320; loss: 0.21; acc: 0.92
Batch: 340; loss: 0.22; acc: 0.91
Batch: 360; loss: 0.2; acc: 0.95
Batch: 380; loss: 0.42; acc: 0.88
Batch: 400; loss: 0.26; acc: 0.91
Batch: 420; loss: 0.4; acc: 0.91
Batch: 440; loss: 0.46; acc: 0.86
Batch: 460; loss: 0.6; acc: 0.86
Batch: 480; loss: 0.33; acc: 0.84
Batch: 500; loss: 0.42; acc: 0.92
Batch: 520; loss: 0.23; acc: 0.94
Batch: 540; loss: 0.47; acc: 0.88
Batch: 560; loss: 0.19; acc: 0.92
Batch: 580; loss: 0.26; acc: 0.89
Batch: 600; loss: 0.3; acc: 0.91
Batch: 620; loss: 0.27; acc: 0.92
Batch: 640; loss: 0.43; acc: 0.86
Batch: 660; loss: 0.47; acc: 0.86
Batch: 680; loss: 0.5; acc: 0.86
Batch: 700; loss: 0.17; acc: 0.97
Batch: 720; loss: 0.27; acc: 0.91
Batch: 740; loss: 0.37; acc: 0.92
Batch: 760; loss: 0.46; acc: 0.83
Batch: 780; loss: 0.29; acc: 0.89
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

2.442269578750711e-05
8.384758075408172e-06
Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.35; acc: 0.88
Batch: 40; loss: 0.2; acc: 0.91
Batch: 60; loss: 0.44; acc: 0.84
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.28; acc: 0.92
Batch: 120; loss: 0.49; acc: 0.88
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.3340522622701469; val_accuracy: 0.904359076433121 

The current subspace-distance is: 8.384758075408172e-06 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.39; acc: 0.88
Batch: 20; loss: 0.44; acc: 0.88
Batch: 40; loss: 0.32; acc: 0.91
Batch: 60; loss: 0.2; acc: 0.92
Batch: 80; loss: 0.48; acc: 0.84
Batch: 100; loss: 0.64; acc: 0.83
Batch: 120; loss: 0.18; acc: 0.94
Batch: 140; loss: 0.3; acc: 0.92
Batch: 160; loss: 0.47; acc: 0.89
Batch: 180; loss: 0.41; acc: 0.89
Batch: 200; loss: 0.33; acc: 0.86
Batch: 220; loss: 0.46; acc: 0.84
Batch: 240; loss: 0.17; acc: 0.94
Batch: 260; loss: 0.36; acc: 0.88
Batch: 280; loss: 0.19; acc: 0.92
Batch: 300; loss: 0.55; acc: 0.89
Batch: 320; loss: 0.23; acc: 0.94
Batch: 340; loss: 0.19; acc: 0.95
Batch: 360; loss: 0.41; acc: 0.88
Batch: 380; loss: 0.42; acc: 0.88
Batch: 400; loss: 0.21; acc: 0.92
Batch: 420; loss: 0.28; acc: 0.95
Batch: 440; loss: 0.33; acc: 0.92
Batch: 460; loss: 0.37; acc: 0.86
Batch: 480; loss: 0.37; acc: 0.92
Batch: 500; loss: 0.43; acc: 0.86
Batch: 520; loss: 0.28; acc: 0.95
Batch: 540; loss: 0.3; acc: 0.91
Batch: 560; loss: 0.46; acc: 0.84
Batch: 580; loss: 0.3; acc: 0.94
Batch: 600; loss: 0.32; acc: 0.91
Batch: 620; loss: 0.35; acc: 0.92
Batch: 640; loss: 0.5; acc: 0.88
Batch: 660; loss: 0.4; acc: 0.86
Batch: 680; loss: 0.26; acc: 0.91
Batch: 700; loss: 0.37; acc: 0.88
Batch: 720; loss: 0.34; acc: 0.92
Batch: 740; loss: 0.45; acc: 0.86
Batch: 760; loss: 0.32; acc: 0.91
Batch: 780; loss: 0.18; acc: 0.92
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

2.4976989152492024e-05
8.660589628561866e-06
Batch: 0; loss: 0.26; acc: 0.92
Batch: 20; loss: 0.32; acc: 0.86
Batch: 40; loss: 0.2; acc: 0.91
Batch: 60; loss: 0.43; acc: 0.84
Batch: 80; loss: 0.17; acc: 0.97
Batch: 100; loss: 0.28; acc: 0.92
Batch: 120; loss: 0.5; acc: 0.89
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.3384214403807737; val_accuracy: 0.9004777070063694 

The current subspace-distance is: 8.660589628561866e-06 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.28; acc: 0.92
Batch: 20; loss: 0.34; acc: 0.91
Batch: 40; loss: 0.44; acc: 0.89
Batch: 60; loss: 0.58; acc: 0.83
Batch: 80; loss: 0.35; acc: 0.91
Batch: 100; loss: 0.11; acc: 0.97
Batch: 120; loss: 0.42; acc: 0.88
Batch: 140; loss: 0.42; acc: 0.86
Batch: 160; loss: 0.57; acc: 0.84
Batch: 180; loss: 0.33; acc: 0.91
Batch: 200; loss: 0.32; acc: 0.92
Batch: 220; loss: 0.33; acc: 0.89
Batch: 240; loss: 0.6; acc: 0.91
Batch: 260; loss: 0.32; acc: 0.91
Batch: 280; loss: 0.44; acc: 0.86
Batch: 300; loss: 0.38; acc: 0.92
Batch: 320; loss: 0.36; acc: 0.91
Batch: 340; loss: 0.39; acc: 0.84
Batch: 360; loss: 0.2; acc: 0.92
Batch: 380; loss: 0.6; acc: 0.86
Batch: 400; loss: 0.13; acc: 0.95
Batch: 420; loss: 0.64; acc: 0.86
Batch: 440; loss: 0.23; acc: 0.94
Batch: 460; loss: 0.27; acc: 0.89
Batch: 480; loss: 0.35; acc: 0.89
Batch: 500; loss: 0.44; acc: 0.88
Batch: 520; loss: 0.34; acc: 0.89
Batch: 540; loss: 0.45; acc: 0.88
Batch: 560; loss: 0.43; acc: 0.86
Batch: 580; loss: 0.38; acc: 0.86
Batch: 600; loss: 0.33; acc: 0.88
Batch: 620; loss: 0.51; acc: 0.86
Batch: 640; loss: 0.38; acc: 0.88
Batch: 660; loss: 0.47; acc: 0.88
Batch: 680; loss: 0.7; acc: 0.83
Batch: 700; loss: 0.43; acc: 0.83
Batch: 720; loss: 0.36; acc: 0.86
Batch: 740; loss: 0.53; acc: 0.88
Batch: 760; loss: 0.55; acc: 0.89
Batch: 780; loss: 0.3; acc: 0.94
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

2.5218218070222065e-05
9.015543582790997e-06
Batch: 0; loss: 0.24; acc: 0.92
Batch: 20; loss: 0.36; acc: 0.88
Batch: 40; loss: 0.21; acc: 0.88
Batch: 60; loss: 0.46; acc: 0.86
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.35; acc: 0.91
Batch: 120; loss: 0.51; acc: 0.86
Batch: 140; loss: 0.09; acc: 0.98
Val Epoch over. val_loss: 0.3400661735587819; val_accuracy: 0.9013734076433121 

The current subspace-distance is: 9.015543582790997e-06 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.46; acc: 0.89
Batch: 20; loss: 0.3; acc: 0.94
Batch: 40; loss: 0.26; acc: 0.91
Batch: 60; loss: 0.31; acc: 0.89
Batch: 80; loss: 0.35; acc: 0.92
Batch: 100; loss: 0.45; acc: 0.89
Batch: 120; loss: 0.34; acc: 0.89
Batch: 140; loss: 0.3; acc: 0.94
Batch: 160; loss: 0.33; acc: 0.91
Batch: 180; loss: 0.43; acc: 0.83
Batch: 200; loss: 0.3; acc: 0.92
Batch: 220; loss: 0.46; acc: 0.81
Batch: 240; loss: 0.49; acc: 0.89
Batch: 260; loss: 0.4; acc: 0.89
Batch: 280; loss: 0.27; acc: 0.94
Batch: 300; loss: 0.41; acc: 0.91
Batch: 320; loss: 0.17; acc: 0.94
Batch: 340; loss: 0.35; acc: 0.89
Batch: 360; loss: 0.25; acc: 0.94
Batch: 380; loss: 0.41; acc: 0.89
Batch: 400; loss: 0.34; acc: 0.89
Batch: 420; loss: 0.64; acc: 0.89
Batch: 440; loss: 0.42; acc: 0.86
Batch: 460; loss: 0.37; acc: 0.92
Batch: 480; loss: 0.39; acc: 0.92
Batch: 500; loss: 0.44; acc: 0.91
Batch: 520; loss: 0.4; acc: 0.88
Batch: 540; loss: 0.51; acc: 0.84
Batch: 560; loss: 0.24; acc: 0.91
Batch: 580; loss: 0.35; acc: 0.91
Batch: 600; loss: 0.21; acc: 0.92
Batch: 620; loss: 0.24; acc: 0.95
Batch: 640; loss: 0.08; acc: 0.98
Batch: 660; loss: 0.53; acc: 0.86
Batch: 680; loss: 0.45; acc: 0.86
Batch: 700; loss: 0.28; acc: 0.91
Batch: 720; loss: 0.3; acc: 0.86
Batch: 740; loss: 0.57; acc: 0.84
Batch: 760; loss: 0.55; acc: 0.78
Batch: 780; loss: 0.7; acc: 0.83
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

2.557617517595645e-05
8.381600309803616e-06
Batch: 0; loss: 0.24; acc: 0.92
Batch: 20; loss: 0.32; acc: 0.89
Batch: 40; loss: 0.21; acc: 0.91
Batch: 60; loss: 0.47; acc: 0.83
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.31; acc: 0.92
Batch: 120; loss: 0.5; acc: 0.88
Batch: 140; loss: 0.09; acc: 0.98
Val Epoch over. val_loss: 0.3321313936334507; val_accuracy: 0.9032643312101911 

The current subspace-distance is: 8.381600309803616e-06 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.4; acc: 0.86
Batch: 20; loss: 0.43; acc: 0.84
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.5; acc: 0.86
Batch: 80; loss: 0.29; acc: 0.91
Batch: 100; loss: 0.33; acc: 0.92
Batch: 120; loss: 0.4; acc: 0.84
Batch: 140; loss: 0.41; acc: 0.91
Batch: 160; loss: 0.31; acc: 0.94
Batch: 180; loss: 0.24; acc: 0.97
Batch: 200; loss: 0.31; acc: 0.88
Batch: 220; loss: 0.29; acc: 0.91
Batch: 240; loss: 0.21; acc: 0.92
Batch: 260; loss: 0.82; acc: 0.75
Batch: 280; loss: 0.48; acc: 0.88
Batch: 300; loss: 0.33; acc: 0.92
Batch: 320; loss: 0.27; acc: 0.91
Batch: 340; loss: 0.25; acc: 0.92
Batch: 360; loss: 0.43; acc: 0.84
Batch: 380; loss: 0.3; acc: 0.91
Batch: 400; loss: 0.41; acc: 0.92
Batch: 420; loss: 0.4; acc: 0.83
Batch: 440; loss: 0.43; acc: 0.88
Batch: 460; loss: 0.27; acc: 0.92
Batch: 480; loss: 0.25; acc: 0.91
Batch: 500; loss: 0.28; acc: 0.88
Batch: 520; loss: 0.19; acc: 0.92
Batch: 540; loss: 0.2; acc: 0.94
Batch: 560; loss: 0.38; acc: 0.89
Batch: 580; loss: 0.32; acc: 0.86
Batch: 600; loss: 0.48; acc: 0.83
Batch: 620; loss: 0.32; acc: 0.91
Batch: 640; loss: 0.23; acc: 0.91
Batch: 660; loss: 0.2; acc: 0.95
Batch: 680; loss: 0.38; acc: 0.91
Batch: 700; loss: 0.2; acc: 0.97
Batch: 720; loss: 0.31; acc: 0.91
Batch: 740; loss: 0.31; acc: 0.88
Batch: 760; loss: 0.36; acc: 0.89
Batch: 780; loss: 0.2; acc: 0.95
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

2.415167364233639e-05
8.285283911391161e-06
Batch: 0; loss: 0.26; acc: 0.92
Batch: 20; loss: 0.34; acc: 0.89
Batch: 40; loss: 0.2; acc: 0.92
Batch: 60; loss: 0.46; acc: 0.83
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.28; acc: 0.91
Batch: 120; loss: 0.56; acc: 0.88
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.3409717677600065; val_accuracy: 0.899781050955414 

The current subspace-distance is: 8.285283911391161e-06 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.49; acc: 0.83
Batch: 20; loss: 0.4; acc: 0.91
Batch: 40; loss: 0.37; acc: 0.94
Batch: 60; loss: 0.23; acc: 0.92
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.32; acc: 0.88
Batch: 120; loss: 0.31; acc: 0.91
Batch: 140; loss: 0.25; acc: 0.95
Batch: 160; loss: 0.38; acc: 0.86
Batch: 180; loss: 0.48; acc: 0.88
Batch: 200; loss: 0.19; acc: 0.94
Batch: 220; loss: 0.29; acc: 0.91
Batch: 240; loss: 0.41; acc: 0.86
Batch: 260; loss: 0.32; acc: 0.91
Batch: 280; loss: 0.29; acc: 0.92
Batch: 300; loss: 0.66; acc: 0.81
Batch: 320; loss: 0.33; acc: 0.89
Batch: 340; loss: 0.25; acc: 0.91
Batch: 360; loss: 0.32; acc: 0.94
Batch: 380; loss: 0.27; acc: 0.94
Batch: 400; loss: 0.25; acc: 0.91
Batch: 420; loss: 0.15; acc: 0.94
Batch: 440; loss: 0.86; acc: 0.78
Batch: 460; loss: 0.32; acc: 0.91
Batch: 480; loss: 0.37; acc: 0.89
Batch: 500; loss: 0.23; acc: 0.94
Batch: 520; loss: 0.58; acc: 0.89
Batch: 540; loss: 0.37; acc: 0.88
Batch: 560; loss: 0.26; acc: 0.89
Batch: 580; loss: 0.4; acc: 0.88
Batch: 600; loss: 0.29; acc: 0.94
Batch: 620; loss: 0.43; acc: 0.92
Batch: 640; loss: 0.53; acc: 0.81
Batch: 660; loss: 0.17; acc: 0.94
Batch: 680; loss: 0.31; acc: 0.92
Batch: 700; loss: 0.31; acc: 0.92
Batch: 720; loss: 0.33; acc: 0.88
Batch: 740; loss: 0.38; acc: 0.89
Batch: 760; loss: 0.32; acc: 0.91
Batch: 780; loss: 0.27; acc: 0.95
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

2.5202920369338244e-05
8.348475603270344e-06
Batch: 0; loss: 0.25; acc: 0.94
Batch: 20; loss: 0.32; acc: 0.86
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.42; acc: 0.84
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.28; acc: 0.91
Batch: 120; loss: 0.5; acc: 0.88
Batch: 140; loss: 0.1; acc: 0.95
Val Epoch over. val_loss: 0.33320131276253684; val_accuracy: 0.9055533439490446 

The current subspace-distance is: 8.348475603270344e-06 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.32; acc: 0.94
Batch: 20; loss: 0.49; acc: 0.89
Batch: 40; loss: 0.3; acc: 0.89
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.43; acc: 0.88
Batch: 100; loss: 0.28; acc: 0.92
Batch: 120; loss: 0.38; acc: 0.89
Batch: 140; loss: 0.71; acc: 0.8
Batch: 160; loss: 0.25; acc: 0.89
Batch: 180; loss: 0.37; acc: 0.86
Batch: 200; loss: 0.28; acc: 0.91
Batch: 220; loss: 0.46; acc: 0.89
Batch: 240; loss: 0.38; acc: 0.92
Batch: 260; loss: 0.35; acc: 0.89
Batch: 280; loss: 0.4; acc: 0.89
Batch: 300; loss: 0.49; acc: 0.89
Batch: 320; loss: 0.25; acc: 0.92
Batch: 340; loss: 0.34; acc: 0.91
Batch: 360; loss: 0.36; acc: 0.92
Batch: 380; loss: 0.18; acc: 0.95
Batch: 400; loss: 0.31; acc: 0.94
Batch: 420; loss: 0.5; acc: 0.86
Batch: 440; loss: 0.36; acc: 0.88
Batch: 460; loss: 0.47; acc: 0.89
Batch: 480; loss: 0.37; acc: 0.89
Batch: 500; loss: 0.38; acc: 0.88
Batch: 520; loss: 0.41; acc: 0.88
Batch: 540; loss: 0.35; acc: 0.86
Batch: 560; loss: 0.29; acc: 0.89
Batch: 580; loss: 0.41; acc: 0.91
Batch: 600; loss: 0.5; acc: 0.83
Batch: 620; loss: 0.21; acc: 0.94
Batch: 640; loss: 0.7; acc: 0.83
Batch: 660; loss: 0.37; acc: 0.88
Batch: 680; loss: 0.23; acc: 0.89
Batch: 700; loss: 0.32; acc: 0.89
Batch: 720; loss: 0.42; acc: 0.84
Batch: 740; loss: 0.42; acc: 0.89
Batch: 760; loss: 0.54; acc: 0.88
Batch: 780; loss: 0.35; acc: 0.94
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

2.504450640117284e-05
9.331497494713403e-06
Batch: 0; loss: 0.25; acc: 0.92
Batch: 20; loss: 0.32; acc: 0.88
Batch: 40; loss: 0.19; acc: 0.92
Batch: 60; loss: 0.44; acc: 0.84
Batch: 80; loss: 0.17; acc: 0.97
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.51; acc: 0.89
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.3273090869662868; val_accuracy: 0.9055533439490446 

The current subspace-distance is: 9.331497494713403e-06 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.23; acc: 0.97
Batch: 20; loss: 0.32; acc: 0.92
Batch: 40; loss: 0.19; acc: 0.91
Batch: 60; loss: 0.36; acc: 0.84
Batch: 80; loss: 0.57; acc: 0.84
Batch: 100; loss: 0.37; acc: 0.88
Batch: 120; loss: 0.32; acc: 0.94
Batch: 140; loss: 0.4; acc: 0.91
Batch: 160; loss: 0.35; acc: 0.88
Batch: 180; loss: 0.3; acc: 0.92
Batch: 200; loss: 0.3; acc: 0.92
Batch: 220; loss: 0.43; acc: 0.88
Batch: 240; loss: 0.22; acc: 0.94
Batch: 260; loss: 0.22; acc: 0.94
Batch: 280; loss: 0.63; acc: 0.83
Batch: 300; loss: 1.07; acc: 0.78
Batch: 320; loss: 0.3; acc: 0.88
Batch: 340; loss: 0.59; acc: 0.88
Batch: 360; loss: 0.26; acc: 0.92
Batch: 380; loss: 0.24; acc: 0.92
Batch: 400; loss: 0.27; acc: 0.91
Batch: 420; loss: 0.48; acc: 0.92
Batch: 440; loss: 0.3; acc: 0.91
Batch: 460; loss: 0.37; acc: 0.84
Batch: 480; loss: 0.21; acc: 0.94
Batch: 500; loss: 0.46; acc: 0.84
Batch: 520; loss: 0.41; acc: 0.89
Batch: 540; loss: 0.37; acc: 0.88
Batch: 560; loss: 0.29; acc: 0.94
Batch: 580; loss: 0.36; acc: 0.89
Batch: 600; loss: 0.37; acc: 0.92
Batch: 620; loss: 0.53; acc: 0.84
Batch: 640; loss: 0.19; acc: 0.95
Batch: 660; loss: 0.2; acc: 0.92
Batch: 680; loss: 0.32; acc: 0.89
Batch: 700; loss: 0.27; acc: 0.94
Batch: 720; loss: 0.42; acc: 0.89
Batch: 740; loss: 0.31; acc: 0.94
Batch: 760; loss: 0.39; acc: 0.86
Batch: 780; loss: 0.24; acc: 0.94
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

2.7737462005461566e-05
8.59568808664335e-06
Batch: 0; loss: 0.24; acc: 0.92
Batch: 20; loss: 0.31; acc: 0.88
Batch: 40; loss: 0.19; acc: 0.92
Batch: 60; loss: 0.48; acc: 0.84
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.53; acc: 0.88
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.32903828756634595; val_accuracy: 0.9058519108280255 

The current subspace-distance is: 8.59568808664335e-06 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.25; acc: 0.94
Batch: 20; loss: 0.23; acc: 0.95
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.18; acc: 0.95
Batch: 80; loss: 0.32; acc: 0.89
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.45; acc: 0.86
Batch: 140; loss: 0.37; acc: 0.88
Batch: 160; loss: 0.2; acc: 0.92
Batch: 180; loss: 0.3; acc: 0.89
Batch: 200; loss: 0.45; acc: 0.89
Batch: 220; loss: 0.39; acc: 0.94
Batch: 240; loss: 0.48; acc: 0.84
Batch: 260; loss: 0.32; acc: 0.92
Batch: 280; loss: 0.23; acc: 0.94
Batch: 300; loss: 0.3; acc: 0.91
Batch: 320; loss: 0.43; acc: 0.91
Batch: 340; loss: 0.31; acc: 0.89
Batch: 360; loss: 0.27; acc: 0.92
Batch: 380; loss: 0.37; acc: 0.92
Batch: 400; loss: 0.34; acc: 0.86
Batch: 420; loss: 0.4; acc: 0.84
Batch: 440; loss: 0.23; acc: 0.92
Batch: 460; loss: 0.44; acc: 0.88
Batch: 480; loss: 0.22; acc: 0.89
Batch: 500; loss: 0.29; acc: 0.89
Batch: 520; loss: 0.32; acc: 0.89
Batch: 540; loss: 0.34; acc: 0.91
Batch: 560; loss: 0.31; acc: 0.91
Batch: 580; loss: 0.51; acc: 0.86
Batch: 600; loss: 0.28; acc: 0.92
Batch: 620; loss: 0.45; acc: 0.91
Batch: 640; loss: 0.3; acc: 0.95
Batch: 660; loss: 0.41; acc: 0.88
Batch: 680; loss: 0.6; acc: 0.81
Batch: 700; loss: 0.39; acc: 0.88
Batch: 720; loss: 0.5; acc: 0.91
Batch: 740; loss: 0.31; acc: 0.89
Batch: 760; loss: 0.44; acc: 0.88
Batch: 780; loss: 0.34; acc: 0.92
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

2.4092847525025718e-05
8.974406227935106e-06
Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.32; acc: 0.88
Batch: 40; loss: 0.2; acc: 0.91
Batch: 60; loss: 0.46; acc: 0.84
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.49; acc: 0.88
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.3294622605773294; val_accuracy: 0.9052547770700637 

The current subspace-distance is: 8.974406227935106e-06 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.34; acc: 0.89
Batch: 20; loss: 0.73; acc: 0.84
Batch: 40; loss: 0.34; acc: 0.91
Batch: 60; loss: 0.33; acc: 0.86
Batch: 80; loss: 0.3; acc: 0.91
Batch: 100; loss: 0.47; acc: 0.89
Batch: 120; loss: 0.36; acc: 0.86
Batch: 140; loss: 0.33; acc: 0.91
Batch: 160; loss: 0.31; acc: 0.91
Batch: 180; loss: 0.34; acc: 0.84
Batch: 200; loss: 0.3; acc: 0.91
Batch: 220; loss: 0.38; acc: 0.88
Batch: 240; loss: 0.33; acc: 0.91
Batch: 260; loss: 0.24; acc: 0.88
Batch: 280; loss: 0.27; acc: 0.91
Batch: 300; loss: 0.31; acc: 0.92
Batch: 320; loss: 0.34; acc: 0.86
Batch: 340; loss: 0.5; acc: 0.89
Batch: 360; loss: 0.25; acc: 0.92
Batch: 380; loss: 0.24; acc: 0.94
Batch: 400; loss: 0.38; acc: 0.86
Batch: 420; loss: 0.37; acc: 0.95
Batch: 440; loss: 0.47; acc: 0.88
Batch: 460; loss: 0.31; acc: 0.94
Batch: 480; loss: 0.19; acc: 0.95
Batch: 500; loss: 0.33; acc: 0.88
Batch: 520; loss: 0.33; acc: 0.97
Batch: 540; loss: 0.45; acc: 0.86
Batch: 560; loss: 0.28; acc: 0.89
Batch: 580; loss: 0.17; acc: 0.97
Batch: 600; loss: 0.42; acc: 0.86
Batch: 620; loss: 0.34; acc: 0.92
Batch: 640; loss: 0.3; acc: 0.89
Batch: 660; loss: 0.62; acc: 0.83
Batch: 680; loss: 0.55; acc: 0.84
Batch: 700; loss: 0.63; acc: 0.88
Batch: 720; loss: 0.21; acc: 0.95
Batch: 740; loss: 0.49; acc: 0.84
Batch: 760; loss: 0.36; acc: 0.86
Batch: 780; loss: 0.22; acc: 0.92
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

2.4239710910478607e-05
8.744586011744104e-06
Batch: 0; loss: 0.25; acc: 0.94
Batch: 20; loss: 0.32; acc: 0.86
Batch: 40; loss: 0.2; acc: 0.92
Batch: 60; loss: 0.48; acc: 0.84
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.51; acc: 0.88
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.33134110623104557; val_accuracy: 0.9055533439490446 

The current subspace-distance is: 8.744586011744104e-06 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.62; acc: 0.88
Batch: 20; loss: 0.23; acc: 0.94
Batch: 40; loss: 0.47; acc: 0.88
Batch: 60; loss: 0.4; acc: 0.89
Batch: 80; loss: 0.31; acc: 0.91
Batch: 100; loss: 0.21; acc: 0.92
Batch: 120; loss: 0.43; acc: 0.83
Batch: 140; loss: 0.43; acc: 0.84
Batch: 160; loss: 0.26; acc: 0.88
Batch: 180; loss: 0.18; acc: 0.97
Batch: 200; loss: 0.38; acc: 0.86
Batch: 220; loss: 0.29; acc: 0.94
Batch: 240; loss: 0.38; acc: 0.89
Batch: 260; loss: 0.31; acc: 0.91
Batch: 280; loss: 0.46; acc: 0.88
Batch: 300; loss: 0.31; acc: 0.91
Batch: 320; loss: 0.42; acc: 0.88
Batch: 340; loss: 0.5; acc: 0.92
Batch: 360; loss: 0.49; acc: 0.91
Batch: 380; loss: 0.27; acc: 0.91
Batch: 400; loss: 0.36; acc: 0.88
Batch: 420; loss: 0.33; acc: 0.91
Batch: 440; loss: 0.59; acc: 0.81
Batch: 460; loss: 0.27; acc: 0.92
Batch: 480; loss: 0.47; acc: 0.92
Batch: 500; loss: 0.18; acc: 0.92
Batch: 520; loss: 0.35; acc: 0.89
Batch: 540; loss: 0.61; acc: 0.8
Batch: 560; loss: 0.2; acc: 0.92
Batch: 580; loss: 0.33; acc: 0.92
Batch: 600; loss: 0.39; acc: 0.88
Batch: 620; loss: 0.26; acc: 0.89
Batch: 640; loss: 0.45; acc: 0.83
Batch: 660; loss: 0.34; acc: 0.91
Batch: 680; loss: 0.34; acc: 0.84
Batch: 700; loss: 0.28; acc: 0.88
Batch: 720; loss: 0.39; acc: 0.86
Batch: 740; loss: 0.23; acc: 0.95
Batch: 760; loss: 0.46; acc: 0.89
Batch: 780; loss: 0.4; acc: 0.88
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

3.0168152079568245e-05
9.271347153116949e-06
Batch: 0; loss: 0.24; acc: 0.92
Batch: 20; loss: 0.32; acc: 0.88
Batch: 40; loss: 0.2; acc: 0.92
Batch: 60; loss: 0.46; acc: 0.84
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.28; acc: 0.91
Batch: 120; loss: 0.51; acc: 0.89
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.32678128309120796; val_accuracy: 0.9050557324840764 

The current subspace-distance is: 9.271347153116949e-06 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.2; acc: 0.92
Batch: 20; loss: 0.48; acc: 0.84
Batch: 40; loss: 0.53; acc: 0.83
Batch: 60; loss: 0.43; acc: 0.88
Batch: 80; loss: 0.18; acc: 0.92
Batch: 100; loss: 0.34; acc: 0.94
Batch: 120; loss: 0.34; acc: 0.91
Batch: 140; loss: 0.33; acc: 0.89
Batch: 160; loss: 0.23; acc: 0.95
Batch: 180; loss: 0.61; acc: 0.84
Batch: 200; loss: 0.23; acc: 0.95
Batch: 220; loss: 0.24; acc: 0.94
Batch: 240; loss: 0.35; acc: 0.89
Batch: 260; loss: 0.21; acc: 0.92
Batch: 280; loss: 0.52; acc: 0.84
Batch: 300; loss: 0.55; acc: 0.84
Batch: 320; loss: 0.41; acc: 0.92
Batch: 340; loss: 0.47; acc: 0.88
Batch: 360; loss: 0.33; acc: 0.89
Batch: 380; loss: 0.35; acc: 0.88
Batch: 400; loss: 0.21; acc: 0.91
Batch: 420; loss: 0.32; acc: 0.94
Batch: 440; loss: 0.46; acc: 0.86
Batch: 460; loss: 0.35; acc: 0.88
Batch: 480; loss: 0.5; acc: 0.84
Batch: 500; loss: 0.53; acc: 0.86
Batch: 520; loss: 0.21; acc: 0.92
Batch: 540; loss: 0.45; acc: 0.89
Batch: 560; loss: 0.32; acc: 0.91
Batch: 580; loss: 0.5; acc: 0.83
Batch: 600; loss: 0.31; acc: 0.92
Batch: 620; loss: 0.46; acc: 0.86
Batch: 640; loss: 0.68; acc: 0.8
Batch: 660; loss: 0.48; acc: 0.8
Batch: 680; loss: 0.26; acc: 0.95
Batch: 700; loss: 0.24; acc: 0.94
Batch: 720; loss: 0.21; acc: 0.94
Batch: 740; loss: 0.25; acc: 0.91
Batch: 760; loss: 0.3; acc: 0.89
Batch: 780; loss: 0.43; acc: 0.83
Train Epoch over. train_loss: 0.36; train_accuracy: 0.9 

2.4506596673745662e-05
8.953988071880303e-06
Batch: 0; loss: 0.25; acc: 0.92
Batch: 20; loss: 0.33; acc: 0.88
Batch: 40; loss: 0.2; acc: 0.91
Batch: 60; loss: 0.42; acc: 0.84
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.28; acc: 0.92
Batch: 120; loss: 0.5; acc: 0.88
Batch: 140; loss: 0.1; acc: 0.95
Val Epoch over. val_loss: 0.32940533937542305; val_accuracy: 0.9053542993630573 

The current subspace-distance is: 8.953988071880303e-06 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.45; acc: 0.88
Batch: 20; loss: 0.48; acc: 0.88
Batch: 40; loss: 0.31; acc: 0.89
Batch: 60; loss: 0.4; acc: 0.89
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.4; acc: 0.88
Batch: 120; loss: 0.36; acc: 0.89
Batch: 140; loss: 0.2; acc: 0.91
Batch: 160; loss: 0.41; acc: 0.89
Batch: 180; loss: 0.38; acc: 0.86
Batch: 200; loss: 0.28; acc: 0.92
Batch: 220; loss: 0.47; acc: 0.84
Batch: 240; loss: 0.17; acc: 0.95
Batch: 260; loss: 0.27; acc: 0.89
Batch: 280; loss: 0.17; acc: 0.95
Batch: 300; loss: 0.51; acc: 0.88
Batch: 320; loss: 0.4; acc: 0.89
Batch: 340; loss: 0.46; acc: 0.89
Batch: 360; loss: 0.26; acc: 0.92
Batch: 380; loss: 0.23; acc: 0.89
Batch: 400; loss: 0.34; acc: 0.89
Batch: 420; loss: 0.32; acc: 0.91
Batch: 440; loss: 0.29; acc: 0.92
Batch: 460; loss: 0.49; acc: 0.86
Batch: 480; loss: 0.33; acc: 0.91
Batch: 500; loss: 0.32; acc: 0.92
Batch: 520; loss: 0.29; acc: 0.88
Batch: 540; loss: 0.47; acc: 0.89
Batch: 560; loss: 0.35; acc: 0.89
Batch: 580; loss: 0.71; acc: 0.83
Batch: 600; loss: 0.36; acc: 0.91
Batch: 620; loss: 0.15; acc: 0.97
Batch: 640; loss: 0.52; acc: 0.88
Batch: 660; loss: 0.26; acc: 0.94
Batch: 680; loss: 0.18; acc: 0.97
Batch: 700; loss: 0.3; acc: 0.94
Batch: 720; loss: 0.41; acc: 0.86
Batch: 740; loss: 0.36; acc: 0.91
Batch: 760; loss: 0.23; acc: 0.91
Batch: 780; loss: 0.41; acc: 0.88
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

2.4635142835904844e-05
7.835235919628758e-06
Batch: 0; loss: 0.24; acc: 0.92
Batch: 20; loss: 0.32; acc: 0.89
Batch: 40; loss: 0.2; acc: 0.89
Batch: 60; loss: 0.44; acc: 0.84
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.5; acc: 0.88
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.32853537247439096; val_accuracy: 0.9047571656050956 

The current subspace-distance is: 7.835235919628758e-06 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.17; acc: 0.94
Batch: 20; loss: 0.49; acc: 0.8
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.43; acc: 0.89
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.25; acc: 0.94
Batch: 120; loss: 0.45; acc: 0.86
Batch: 140; loss: 0.7; acc: 0.78
Batch: 160; loss: 0.36; acc: 0.88
Batch: 180; loss: 0.23; acc: 0.94
Batch: 200; loss: 0.33; acc: 0.91
Batch: 220; loss: 0.53; acc: 0.84
Batch: 240; loss: 0.67; acc: 0.77
Batch: 260; loss: 0.31; acc: 0.91
Batch: 280; loss: 0.46; acc: 0.86
Batch: 300; loss: 0.23; acc: 0.94
Batch: 320; loss: 0.3; acc: 0.92
Batch: 340; loss: 0.4; acc: 0.94
Batch: 360; loss: 0.24; acc: 0.94
Batch: 380; loss: 0.24; acc: 0.89
Batch: 400; loss: 0.22; acc: 0.92
Batch: 420; loss: 0.38; acc: 0.89
Batch: 440; loss: 0.45; acc: 0.84
Batch: 460; loss: 0.22; acc: 0.95
Batch: 480; loss: 0.52; acc: 0.84
Batch: 500; loss: 0.19; acc: 0.91
Batch: 520; loss: 0.54; acc: 0.83
Batch: 540; loss: 0.47; acc: 0.89
Batch: 560; loss: 0.47; acc: 0.91
Batch: 580; loss: 0.23; acc: 0.94
Batch: 600; loss: 0.43; acc: 0.86
Batch: 620; loss: 0.18; acc: 0.95
Batch: 640; loss: 0.24; acc: 0.94
Batch: 660; loss: 0.21; acc: 0.94
Batch: 680; loss: 0.48; acc: 0.86
Batch: 700; loss: 0.38; acc: 0.89
Batch: 720; loss: 0.34; acc: 0.89
Batch: 740; loss: 0.5; acc: 0.84
Batch: 760; loss: 0.3; acc: 0.89
Batch: 780; loss: 0.35; acc: 0.91
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

2.4443306756438687e-05
7.910832209745422e-06
Batch: 0; loss: 0.25; acc: 0.92
Batch: 20; loss: 0.34; acc: 0.88
Batch: 40; loss: 0.2; acc: 0.91
Batch: 60; loss: 0.47; acc: 0.84
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.54; acc: 0.88
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.3326889042072235; val_accuracy: 0.9039609872611465 

The current subspace-distance is: 7.910832209745422e-06 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.45; acc: 0.88
Batch: 20; loss: 0.38; acc: 0.91
Batch: 40; loss: 0.21; acc: 0.92
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.63; acc: 0.89
Batch: 100; loss: 0.35; acc: 0.89
Batch: 120; loss: 0.41; acc: 0.88
Batch: 140; loss: 0.41; acc: 0.92
Batch: 160; loss: 0.2; acc: 0.91
Batch: 180; loss: 0.16; acc: 0.97
Batch: 200; loss: 0.27; acc: 0.92
Batch: 220; loss: 0.37; acc: 0.91
Batch: 240; loss: 0.28; acc: 0.89
Batch: 260; loss: 0.38; acc: 0.88
Batch: 280; loss: 0.37; acc: 0.88
Batch: 300; loss: 0.62; acc: 0.83
Batch: 320; loss: 0.34; acc: 0.89
Batch: 340; loss: 0.34; acc: 0.91
Batch: 360; loss: 0.12; acc: 0.98
Batch: 380; loss: 0.25; acc: 0.86
Batch: 400; loss: 0.3; acc: 0.92
Batch: 420; loss: 0.35; acc: 0.88
Batch: 440; loss: 0.18; acc: 0.94
Batch: 460; loss: 0.21; acc: 0.95
Batch: 480; loss: 0.34; acc: 0.86
Batch: 500; loss: 0.28; acc: 0.91
Batch: 520; loss: 0.38; acc: 0.86
Batch: 540; loss: 0.23; acc: 0.95
Batch: 560; loss: 0.35; acc: 0.88
Batch: 580; loss: 0.41; acc: 0.89
Batch: 600; loss: 0.28; acc: 0.92
Batch: 620; loss: 0.22; acc: 0.92
Batch: 640; loss: 0.19; acc: 0.94
Batch: 660; loss: 0.25; acc: 0.92
Batch: 680; loss: 0.22; acc: 0.91
Batch: 700; loss: 0.5; acc: 0.8
Batch: 720; loss: 0.69; acc: 0.83
Batch: 740; loss: 0.33; acc: 0.91
Batch: 760; loss: 0.2; acc: 0.97
Batch: 780; loss: 0.28; acc: 0.92
Train Epoch over. train_loss: 0.36; train_accuracy: 0.9 

2.5267718228860758e-05
8.077468919509556e-06
Batch: 0; loss: 0.26; acc: 0.92
Batch: 20; loss: 0.33; acc: 0.88
Batch: 40; loss: 0.19; acc: 0.91
Batch: 60; loss: 0.45; acc: 0.84
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.28; acc: 0.91
Batch: 120; loss: 0.54; acc: 0.88
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.3303093832389564; val_accuracy: 0.9046576433121019 

The current subspace-distance is: 8.077468919509556e-06 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.21; acc: 0.91
Batch: 20; loss: 0.42; acc: 0.86
Batch: 40; loss: 0.24; acc: 0.92
Batch: 60; loss: 0.34; acc: 0.86
Batch: 80; loss: 0.33; acc: 0.88
Batch: 100; loss: 0.37; acc: 0.92
Batch: 120; loss: 0.28; acc: 0.89
Batch: 140; loss: 0.26; acc: 0.92
Batch: 160; loss: 0.62; acc: 0.77
Batch: 180; loss: 0.25; acc: 0.95
Batch: 200; loss: 0.27; acc: 0.91
Batch: 220; loss: 0.4; acc: 0.89
Batch: 240; loss: 0.37; acc: 0.86
Batch: 260; loss: 0.36; acc: 0.91
Batch: 280; loss: 0.49; acc: 0.83
Batch: 300; loss: 0.52; acc: 0.81
Batch: 320; loss: 0.32; acc: 0.92
Batch: 340; loss: 0.49; acc: 0.86
Batch: 360; loss: 0.37; acc: 0.86
Batch: 380; loss: 0.27; acc: 0.92
Batch: 400; loss: 0.27; acc: 0.91
Batch: 420; loss: 0.3; acc: 0.86
Batch: 440; loss: 0.4; acc: 0.91
Batch: 460; loss: 0.24; acc: 0.94
Batch: 480; loss: 0.19; acc: 0.92
Batch: 500; loss: 0.45; acc: 0.91
Batch: 520; loss: 0.33; acc: 0.88
Batch: 540; loss: 0.19; acc: 0.94
Batch: 560; loss: 0.22; acc: 0.92
Batch: 580; loss: 0.38; acc: 0.88
Batch: 600; loss: 0.32; acc: 0.88
Batch: 620; loss: 0.37; acc: 0.91
Batch: 640; loss: 0.33; acc: 0.92
Batch: 660; loss: 0.39; acc: 0.86
Batch: 680; loss: 0.43; acc: 0.89
Batch: 700; loss: 0.23; acc: 0.95
Batch: 720; loss: 0.3; acc: 0.97
Batch: 740; loss: 0.5; acc: 0.89
Batch: 760; loss: 0.3; acc: 0.92
Batch: 780; loss: 0.39; acc: 0.89
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

2.636450153659098e-05
9.928809049597476e-06
Batch: 0; loss: 0.25; acc: 0.92
Batch: 20; loss: 0.31; acc: 0.89
Batch: 40; loss: 0.2; acc: 0.89
Batch: 60; loss: 0.46; acc: 0.84
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.28; acc: 0.92
Batch: 120; loss: 0.51; acc: 0.88
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.3286721635681049; val_accuracy: 0.9053542993630573 

The current subspace-distance is: 9.928809049597476e-06 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.2; acc: 0.92
Batch: 20; loss: 0.35; acc: 0.88
Batch: 40; loss: 0.23; acc: 0.91
Batch: 60; loss: 0.42; acc: 0.88
Batch: 80; loss: 0.39; acc: 0.89
Batch: 100; loss: 0.38; acc: 0.89
Batch: 120; loss: 0.46; acc: 0.91
Batch: 140; loss: 0.52; acc: 0.83
Batch: 160; loss: 0.27; acc: 0.86
Batch: 180; loss: 0.48; acc: 0.83
Batch: 200; loss: 0.24; acc: 0.92
Batch: 220; loss: 0.55; acc: 0.91
Batch: 240; loss: 0.41; acc: 0.88
Batch: 260; loss: 0.23; acc: 0.94
Batch: 280; loss: 0.47; acc: 0.92
Batch: 300; loss: 0.26; acc: 0.92
Batch: 320; loss: 0.28; acc: 0.91
Batch: 340; loss: 0.22; acc: 0.98
Batch: 360; loss: 0.5; acc: 0.88
Batch: 380; loss: 0.42; acc: 0.88
Batch: 400; loss: 0.23; acc: 0.92
Batch: 420; loss: 0.37; acc: 0.89
Batch: 440; loss: 0.26; acc: 0.94
Batch: 460; loss: 0.47; acc: 0.83
Batch: 480; loss: 0.22; acc: 0.92
Batch: 500; loss: 0.34; acc: 0.92
Batch: 520; loss: 0.37; acc: 0.89
Batch: 540; loss: 0.2; acc: 0.92
Batch: 560; loss: 0.29; acc: 0.94
Batch: 580; loss: 0.4; acc: 0.84
Batch: 600; loss: 0.49; acc: 0.83
Batch: 620; loss: 0.28; acc: 0.92
Batch: 640; loss: 0.28; acc: 0.91
Batch: 660; loss: 0.33; acc: 0.91
Batch: 680; loss: 0.31; acc: 0.89
Batch: 700; loss: 0.34; acc: 0.92
Batch: 720; loss: 0.35; acc: 0.89
Batch: 740; loss: 0.34; acc: 0.94
Batch: 760; loss: 0.25; acc: 0.95
Batch: 780; loss: 0.18; acc: 0.95
Train Epoch over. train_loss: 0.36; train_accuracy: 0.9 

2.6800986233865842e-05
9.044834769156296e-06
Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.31; acc: 0.89
Batch: 40; loss: 0.2; acc: 0.89
Batch: 60; loss: 0.45; acc: 0.84
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.28; acc: 0.92
Batch: 120; loss: 0.5; acc: 0.89
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.32680313132560934; val_accuracy: 0.9067476114649682 

The current subspace-distance is: 9.044834769156296e-06 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.27; acc: 0.92
Batch: 40; loss: 0.46; acc: 0.83
Batch: 60; loss: 0.43; acc: 0.89
Batch: 80; loss: 0.61; acc: 0.89
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.33; acc: 0.89
Batch: 140; loss: 0.35; acc: 0.91
Batch: 160; loss: 0.53; acc: 0.83
Batch: 180; loss: 0.33; acc: 0.86
Batch: 200; loss: 0.37; acc: 0.91
Batch: 220; loss: 0.44; acc: 0.92
Batch: 240; loss: 0.27; acc: 0.91
Batch: 260; loss: 0.32; acc: 0.91
Batch: 280; loss: 0.25; acc: 0.94
Batch: 300; loss: 0.21; acc: 0.92
Batch: 320; loss: 0.44; acc: 0.83
Batch: 340; loss: 0.3; acc: 0.84
Batch: 360; loss: 0.39; acc: 0.89
Batch: 380; loss: 0.28; acc: 0.92
Batch: 400; loss: 0.52; acc: 0.84
Batch: 420; loss: 0.24; acc: 0.89
Batch: 440; loss: 0.4; acc: 0.88
Batch: 460; loss: 0.25; acc: 0.92
Batch: 480; loss: 0.28; acc: 0.95
Batch: 500; loss: 0.29; acc: 0.94
Batch: 520; loss: 0.57; acc: 0.84
Batch: 540; loss: 0.29; acc: 0.89
Batch: 560; loss: 0.18; acc: 0.97
Batch: 580; loss: 0.5; acc: 0.84
Batch: 600; loss: 0.52; acc: 0.84
Batch: 620; loss: 0.3; acc: 0.92
Batch: 640; loss: 0.37; acc: 0.91
Batch: 660; loss: 0.43; acc: 0.89
Batch: 680; loss: 0.37; acc: 0.89
Batch: 700; loss: 0.38; acc: 0.88
Batch: 720; loss: 0.34; acc: 0.91
Batch: 740; loss: 0.15; acc: 0.94
Batch: 760; loss: 0.28; acc: 0.91
Batch: 780; loss: 0.47; acc: 0.88
Train Epoch over. train_loss: 0.36; train_accuracy: 0.9 

2.5065417503356002e-05
9.549515198159497e-06
Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.31; acc: 0.89
Batch: 40; loss: 0.2; acc: 0.91
Batch: 60; loss: 0.45; acc: 0.84
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.28; acc: 0.92
Batch: 120; loss: 0.51; acc: 0.89
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.3271525687283012; val_accuracy: 0.9066480891719745 

The current subspace-distance is: 9.549515198159497e-06 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.41; acc: 0.91
Batch: 20; loss: 0.51; acc: 0.92
Batch: 40; loss: 0.5; acc: 0.86
Batch: 60; loss: 0.35; acc: 0.92
Batch: 80; loss: 0.35; acc: 0.89
Batch: 100; loss: 0.41; acc: 0.86
Batch: 120; loss: 0.37; acc: 0.89
Batch: 140; loss: 0.5; acc: 0.84
Batch: 160; loss: 0.38; acc: 0.91
Batch: 180; loss: 0.56; acc: 0.89
Batch: 200; loss: 0.15; acc: 0.94
Batch: 220; loss: 0.33; acc: 0.89
Batch: 240; loss: 0.43; acc: 0.84
Batch: 260; loss: 0.6; acc: 0.88
Batch: 280; loss: 0.26; acc: 0.92
Batch: 300; loss: 0.47; acc: 0.83
Batch: 320; loss: 0.34; acc: 0.88
Batch: 340; loss: 0.24; acc: 0.91
Batch: 360; loss: 0.22; acc: 0.95
Batch: 380; loss: 0.28; acc: 0.91
Batch: 400; loss: 0.18; acc: 0.94
Batch: 420; loss: 0.31; acc: 0.95
Batch: 440; loss: 0.36; acc: 0.92
Batch: 460; loss: 0.35; acc: 0.88
Batch: 480; loss: 0.3; acc: 0.91
Batch: 500; loss: 0.35; acc: 0.91
Batch: 520; loss: 0.58; acc: 0.91
Batch: 540; loss: 0.33; acc: 0.94
Batch: 560; loss: 0.24; acc: 0.91
Batch: 580; loss: 0.22; acc: 0.97
Batch: 600; loss: 0.39; acc: 0.88
Batch: 620; loss: 0.41; acc: 0.83
Batch: 640; loss: 0.19; acc: 0.94
Batch: 660; loss: 0.23; acc: 0.94
Batch: 680; loss: 0.3; acc: 0.91
Batch: 700; loss: 0.24; acc: 0.95
Batch: 720; loss: 0.47; acc: 0.84
Batch: 740; loss: 0.38; acc: 0.88
Batch: 760; loss: 0.35; acc: 0.88
Batch: 780; loss: 0.21; acc: 0.94
Train Epoch over. train_loss: 0.36; train_accuracy: 0.9 

2.507243334548548e-05
9.792955097509548e-06
Batch: 0; loss: 0.25; acc: 0.92
Batch: 20; loss: 0.31; acc: 0.88
Batch: 40; loss: 0.2; acc: 0.92
Batch: 60; loss: 0.45; acc: 0.84
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.28; acc: 0.91
Batch: 120; loss: 0.52; acc: 0.89
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.3260058875960909; val_accuracy: 0.9065485668789809 

The current subspace-distance is: 9.792955097509548e-06 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.4; acc: 0.81
Batch: 20; loss: 0.48; acc: 0.86
Batch: 40; loss: 0.27; acc: 0.91
Batch: 60; loss: 0.62; acc: 0.83
Batch: 80; loss: 0.36; acc: 0.86
Batch: 100; loss: 0.44; acc: 0.81
Batch: 120; loss: 0.24; acc: 0.91
Batch: 140; loss: 0.53; acc: 0.88
Batch: 160; loss: 0.46; acc: 0.88
Batch: 180; loss: 0.62; acc: 0.83
Batch: 200; loss: 0.17; acc: 0.98
Batch: 220; loss: 0.27; acc: 0.92
Batch: 240; loss: 0.35; acc: 0.86
Batch: 260; loss: 0.55; acc: 0.81
Batch: 280; loss: 0.29; acc: 0.92
Batch: 300; loss: 0.36; acc: 0.89
Batch: 320; loss: 0.37; acc: 0.88
Batch: 340; loss: 0.43; acc: 0.89
Batch: 360; loss: 0.17; acc: 0.95
Batch: 380; loss: 0.26; acc: 0.89
Batch: 400; loss: 0.39; acc: 0.91
Batch: 420; loss: 0.36; acc: 0.89
Batch: 440; loss: 0.42; acc: 0.89
Batch: 460; loss: 0.26; acc: 0.89
Batch: 480; loss: 0.46; acc: 0.84
Batch: 500; loss: 0.7; acc: 0.81
Batch: 520; loss: 0.36; acc: 0.86
Batch: 540; loss: 0.4; acc: 0.86
Batch: 560; loss: 0.36; acc: 0.92
Batch: 580; loss: 0.64; acc: 0.83
Batch: 600; loss: 0.43; acc: 0.89
Batch: 620; loss: 0.29; acc: 0.89
Batch: 640; loss: 0.36; acc: 0.88
Batch: 660; loss: 0.48; acc: 0.84
Batch: 680; loss: 0.37; acc: 0.94
Batch: 700; loss: 0.33; acc: 0.89
Batch: 720; loss: 0.29; acc: 0.92
Batch: 740; loss: 0.53; acc: 0.84
Batch: 760; loss: 0.41; acc: 0.88
Batch: 780; loss: 0.27; acc: 0.92
Train Epoch over. train_loss: 0.36; train_accuracy: 0.9 

2.4373237465624698e-05
8.872622856870294e-06
Batch: 0; loss: 0.24; acc: 0.92
Batch: 20; loss: 0.32; acc: 0.88
Batch: 40; loss: 0.2; acc: 0.91
Batch: 60; loss: 0.44; acc: 0.84
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.27; acc: 0.91
Batch: 120; loss: 0.51; acc: 0.89
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.3267084221551373; val_accuracy: 0.9049562101910829 

The current subspace-distance is: 8.872622856870294e-06 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.17; acc: 0.97
Batch: 40; loss: 0.17; acc: 0.97
Batch: 60; loss: 0.4; acc: 0.91
Batch: 80; loss: 0.23; acc: 0.91
Batch: 100; loss: 0.21; acc: 0.94
Batch: 120; loss: 0.43; acc: 0.88
Batch: 140; loss: 0.14; acc: 0.97
Batch: 160; loss: 0.24; acc: 0.95
Batch: 180; loss: 0.29; acc: 0.92
Batch: 200; loss: 0.33; acc: 0.89
Batch: 220; loss: 0.17; acc: 0.92
Batch: 240; loss: 0.4; acc: 0.89
Batch: 260; loss: 0.33; acc: 0.92
Batch: 280; loss: 0.48; acc: 0.88
Batch: 300; loss: 0.41; acc: 0.89
Batch: 320; loss: 0.43; acc: 0.86
Batch: 340; loss: 0.33; acc: 0.89
Batch: 360; loss: 0.33; acc: 0.92
Batch: 380; loss: 0.23; acc: 0.94
Batch: 400; loss: 0.23; acc: 0.92
Batch: 420; loss: 0.21; acc: 0.92
Batch: 440; loss: 0.36; acc: 0.89
Batch: 460; loss: 0.25; acc: 0.89
Batch: 480; loss: 0.4; acc: 0.89
Batch: 500; loss: 0.26; acc: 0.91
Batch: 520; loss: 0.27; acc: 0.92
Batch: 540; loss: 0.33; acc: 0.88
Batch: 560; loss: 0.13; acc: 0.97
Batch: 580; loss: 0.27; acc: 0.92
Batch: 600; loss: 0.35; acc: 0.88
Batch: 620; loss: 0.43; acc: 0.89
Batch: 640; loss: 0.25; acc: 0.89
Batch: 660; loss: 0.6; acc: 0.89
Batch: 680; loss: 0.55; acc: 0.88
Batch: 700; loss: 0.28; acc: 0.91
Batch: 720; loss: 0.67; acc: 0.84
Batch: 740; loss: 0.37; acc: 0.92
Batch: 760; loss: 0.35; acc: 0.89
Batch: 780; loss: 0.39; acc: 0.88
Train Epoch over. train_loss: 0.36; train_accuracy: 0.9 

2.66814895439893e-05
8.902142326405738e-06
Batch: 0; loss: 0.25; acc: 0.92
Batch: 20; loss: 0.32; acc: 0.89
Batch: 40; loss: 0.2; acc: 0.92
Batch: 60; loss: 0.43; acc: 0.84
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.28; acc: 0.91
Batch: 120; loss: 0.51; acc: 0.88
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.3265219098728174; val_accuracy: 0.90625 

The current subspace-distance is: 8.902142326405738e-06 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.34; acc: 0.91
Batch: 40; loss: 0.32; acc: 0.95
Batch: 60; loss: 0.3; acc: 0.92
Batch: 80; loss: 0.6; acc: 0.81
Batch: 100; loss: 0.25; acc: 0.91
Batch: 120; loss: 0.34; acc: 0.94
Batch: 140; loss: 0.32; acc: 0.89
Batch: 160; loss: 0.38; acc: 0.88
Batch: 180; loss: 0.18; acc: 0.94
Batch: 200; loss: 0.18; acc: 0.95
Batch: 220; loss: 0.42; acc: 0.89
Batch: 240; loss: 0.3; acc: 0.92
Batch: 260; loss: 0.36; acc: 0.86
Batch: 280; loss: 0.56; acc: 0.8
Batch: 300; loss: 0.5; acc: 0.86
Batch: 320; loss: 0.62; acc: 0.84
Batch: 340; loss: 0.23; acc: 0.92
Batch: 360; loss: 0.41; acc: 0.89
Batch: 380; loss: 0.33; acc: 0.89
Batch: 400; loss: 0.28; acc: 0.97
Batch: 420; loss: 0.29; acc: 0.92
Batch: 440; loss: 0.32; acc: 0.86
Batch: 460; loss: 0.35; acc: 0.88
Batch: 480; loss: 0.28; acc: 0.89
Batch: 500; loss: 0.39; acc: 0.92
Batch: 520; loss: 0.47; acc: 0.89
Batch: 540; loss: 0.82; acc: 0.86
Batch: 560; loss: 0.31; acc: 0.92
Batch: 580; loss: 0.35; acc: 0.86
Batch: 600; loss: 0.42; acc: 0.91
Batch: 620; loss: 0.72; acc: 0.84
Batch: 640; loss: 0.32; acc: 0.86
Batch: 660; loss: 0.27; acc: 0.91
Batch: 680; loss: 0.28; acc: 0.95
Batch: 700; loss: 0.2; acc: 0.94
Batch: 720; loss: 0.37; acc: 0.92
Batch: 740; loss: 0.32; acc: 0.91
Batch: 760; loss: 0.37; acc: 0.94
Batch: 780; loss: 0.28; acc: 0.88
Train Epoch over. train_loss: 0.36; train_accuracy: 0.9 

2.4991044483613223e-05
9.214957572112326e-06
Batch: 0; loss: 0.24; acc: 0.92
Batch: 20; loss: 0.32; acc: 0.88
Batch: 40; loss: 0.2; acc: 0.91
Batch: 60; loss: 0.43; acc: 0.84
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.28; acc: 0.92
Batch: 120; loss: 0.51; acc: 0.88
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.3270215130630572; val_accuracy: 0.9058519108280255 

The current subspace-distance is: 9.214957572112326e-06 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.43; acc: 0.86
Batch: 20; loss: 0.32; acc: 0.89
Batch: 40; loss: 0.47; acc: 0.84
Batch: 60; loss: 0.38; acc: 0.86
Batch: 80; loss: 0.41; acc: 0.86
Batch: 100; loss: 0.57; acc: 0.8
Batch: 120; loss: 0.36; acc: 0.88
Batch: 140; loss: 0.56; acc: 0.86
Batch: 160; loss: 0.39; acc: 0.91
Batch: 180; loss: 0.28; acc: 0.94
Batch: 200; loss: 0.44; acc: 0.84
Batch: 220; loss: 0.26; acc: 0.94
Batch: 240; loss: 0.23; acc: 0.95
Batch: 260; loss: 0.35; acc: 0.89
Batch: 280; loss: 0.18; acc: 0.92
Batch: 300; loss: 0.28; acc: 0.89
Batch: 320; loss: 0.45; acc: 0.84
Batch: 340; loss: 0.51; acc: 0.83
Batch: 360; loss: 0.63; acc: 0.83
Batch: 380; loss: 0.28; acc: 0.91
Batch: 400; loss: 0.27; acc: 0.95
Batch: 420; loss: 0.25; acc: 0.92
Batch: 440; loss: 0.3; acc: 0.89
Batch: 460; loss: 0.37; acc: 0.91
Batch: 480; loss: 0.16; acc: 0.95
Batch: 500; loss: 0.15; acc: 0.95
Batch: 520; loss: 0.25; acc: 0.95
Batch: 540; loss: 0.42; acc: 0.83
Batch: 560; loss: 0.15; acc: 0.95
Batch: 580; loss: 0.23; acc: 0.94
Batch: 600; loss: 0.23; acc: 0.94
Batch: 620; loss: 0.3; acc: 0.89
Batch: 640; loss: 0.28; acc: 0.88
Batch: 660; loss: 0.25; acc: 0.94
Batch: 680; loss: 0.4; acc: 0.89
Batch: 700; loss: 0.52; acc: 0.92
Batch: 720; loss: 0.34; acc: 0.89
Batch: 740; loss: 0.31; acc: 0.89
Batch: 760; loss: 0.46; acc: 0.86
Batch: 780; loss: 0.24; acc: 0.94
Train Epoch over. train_loss: 0.35; train_accuracy: 0.9 

2.4166271032299846e-05
9.224025234289002e-06
Batch: 0; loss: 0.25; acc: 0.94
Batch: 20; loss: 0.31; acc: 0.89
Batch: 40; loss: 0.2; acc: 0.91
Batch: 60; loss: 0.45; acc: 0.84
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.28; acc: 0.92
Batch: 120; loss: 0.51; acc: 0.89
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.32662225035345477; val_accuracy: 0.9064490445859873 

The current subspace-distance is: 9.224025234289002e-06 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.26; acc: 0.92
Batch: 20; loss: 0.3; acc: 0.86
Batch: 40; loss: 0.33; acc: 0.89
Batch: 60; loss: 0.32; acc: 0.89
Batch: 80; loss: 0.29; acc: 0.91
Batch: 100; loss: 0.31; acc: 0.89
Batch: 120; loss: 0.34; acc: 0.91
Batch: 140; loss: 0.62; acc: 0.84
Batch: 160; loss: 0.49; acc: 0.88
Batch: 180; loss: 0.46; acc: 0.83
Batch: 200; loss: 0.3; acc: 0.89
Batch: 220; loss: 0.34; acc: 0.88
Batch: 240; loss: 0.22; acc: 0.94
Batch: 260; loss: 0.37; acc: 0.91
Batch: 280; loss: 0.51; acc: 0.91
Batch: 300; loss: 0.34; acc: 0.89
Batch: 320; loss: 0.29; acc: 0.89
Batch: 340; loss: 0.22; acc: 0.92
Batch: 360; loss: 0.3; acc: 0.89
Batch: 380; loss: 0.4; acc: 0.89
Batch: 400; loss: 0.28; acc: 0.89
Batch: 420; loss: 0.44; acc: 0.89
Batch: 440; loss: 0.16; acc: 0.95
Batch: 460; loss: 0.38; acc: 0.89
Batch: 480; loss: 0.3; acc: 0.92
Batch: 500; loss: 0.34; acc: 0.89
Batch: 520; loss: 0.45; acc: 0.83
Batch: 540; loss: 0.7; acc: 0.77
Batch: 560; loss: 0.46; acc: 0.89
Batch: 580; loss: 0.17; acc: 0.95
Batch: 600; loss: 0.48; acc: 0.84
Batch: 620; loss: 0.29; acc: 0.91
Batch: 640; loss: 0.22; acc: 0.91
Batch: 660; loss: 0.19; acc: 0.92
Batch: 680; loss: 0.29; acc: 0.91
Batch: 700; loss: 0.36; acc: 0.89
Batch: 720; loss: 0.32; acc: 0.88
Batch: 740; loss: 0.34; acc: 0.86
Batch: 760; loss: 0.57; acc: 0.83
Batch: 780; loss: 0.27; acc: 0.92
Train Epoch over. train_loss: 0.36; train_accuracy: 0.9 

2.596783269837033e-05
9.317158401245251e-06
Batch: 0; loss: 0.25; acc: 0.92
Batch: 20; loss: 0.31; acc: 0.88
Batch: 40; loss: 0.2; acc: 0.91
Batch: 60; loss: 0.44; acc: 0.84
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.51; acc: 0.89
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.3261648901993302; val_accuracy: 0.90625 

The current subspace-distance is: 9.317158401245251e-06 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.3; acc: 0.91
Batch: 20; loss: 0.26; acc: 0.89
Batch: 40; loss: 0.18; acc: 0.97
Batch: 60; loss: 0.32; acc: 0.89
Batch: 80; loss: 0.41; acc: 0.84
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.2; acc: 0.91
Batch: 140; loss: 0.39; acc: 0.88
Batch: 160; loss: 0.57; acc: 0.78
Batch: 180; loss: 0.35; acc: 0.89
Batch: 200; loss: 0.39; acc: 0.88
Batch: 220; loss: 0.59; acc: 0.81
Batch: 240; loss: 0.43; acc: 0.86
Batch: 260; loss: 0.24; acc: 0.92
Batch: 280; loss: 0.39; acc: 0.88
Batch: 300; loss: 0.31; acc: 0.88
Batch: 320; loss: 0.27; acc: 0.92
Batch: 340; loss: 0.41; acc: 0.84
Batch: 360; loss: 0.34; acc: 0.84
Batch: 380; loss: 0.24; acc: 0.91
Batch: 400; loss: 0.32; acc: 0.94
Batch: 420; loss: 0.45; acc: 0.88
Batch: 440; loss: 0.21; acc: 0.95
Batch: 460; loss: 0.31; acc: 0.89
Batch: 480; loss: 0.28; acc: 0.92
Batch: 500; loss: 0.43; acc: 0.88
Batch: 520; loss: 0.4; acc: 0.89
Batch: 540; loss: 0.32; acc: 0.92
Batch: 560; loss: 0.34; acc: 0.91
Batch: 580; loss: 0.17; acc: 0.95
Batch: 600; loss: 0.32; acc: 0.91
Batch: 620; loss: 0.21; acc: 0.92
Batch: 640; loss: 0.42; acc: 0.88
Batch: 660; loss: 0.18; acc: 0.97
Batch: 680; loss: 0.37; acc: 0.89
Batch: 700; loss: 0.27; acc: 0.91
Batch: 720; loss: 0.3; acc: 0.91
Batch: 740; loss: 0.34; acc: 0.91
Batch: 760; loss: 0.42; acc: 0.89
Batch: 780; loss: 0.39; acc: 0.91
Train Epoch over. train_loss: 0.35; train_accuracy: 0.9 

2.6443885872140527e-05
8.239874659921043e-06
Batch: 0; loss: 0.25; acc: 0.92
Batch: 20; loss: 0.32; acc: 0.88
Batch: 40; loss: 0.2; acc: 0.91
Batch: 60; loss: 0.45; acc: 0.84
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.28; acc: 0.92
Batch: 120; loss: 0.53; acc: 0.88
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.32713808010148393; val_accuracy: 0.9053542993630573 

The current subspace-distance is: 8.239874659921043e-06 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.42; acc: 0.86
Batch: 40; loss: 0.31; acc: 0.94
Batch: 60; loss: 0.24; acc: 0.91
Batch: 80; loss: 0.53; acc: 0.88
Batch: 100; loss: 0.51; acc: 0.84
Batch: 120; loss: 0.25; acc: 0.92
Batch: 140; loss: 0.47; acc: 0.92
Batch: 160; loss: 0.27; acc: 0.89
Batch: 180; loss: 0.17; acc: 0.98
Batch: 200; loss: 0.36; acc: 0.89
Batch: 220; loss: 0.41; acc: 0.88
Batch: 240; loss: 0.36; acc: 0.88
Batch: 260; loss: 0.4; acc: 0.91
Batch: 280; loss: 0.34; acc: 0.92
Batch: 300; loss: 0.32; acc: 0.89
Batch: 320; loss: 0.28; acc: 0.89
Batch: 340; loss: 0.28; acc: 0.91
Batch: 360; loss: 0.38; acc: 0.88
Batch: 380; loss: 0.37; acc: 0.94
Batch: 400; loss: 0.35; acc: 0.91
Batch: 420; loss: 0.4; acc: 0.89
Batch: 440; loss: 0.22; acc: 0.92
Batch: 460; loss: 0.42; acc: 0.92
Batch: 480; loss: 0.38; acc: 0.91
Batch: 500; loss: 0.28; acc: 0.95
Batch: 520; loss: 0.32; acc: 0.89
Batch: 540; loss: 0.31; acc: 0.91
Batch: 560; loss: 0.57; acc: 0.86
Batch: 580; loss: 0.31; acc: 0.91
Batch: 600; loss: 0.46; acc: 0.89
Batch: 620; loss: 0.41; acc: 0.88
Batch: 640; loss: 0.18; acc: 0.97
Batch: 660; loss: 0.43; acc: 0.88
Batch: 680; loss: 0.44; acc: 0.91
Batch: 700; loss: 0.36; acc: 0.88
Batch: 720; loss: 0.27; acc: 0.91
Batch: 740; loss: 0.41; acc: 0.88
Batch: 760; loss: 0.31; acc: 0.89
Batch: 780; loss: 0.46; acc: 0.88
Train Epoch over. train_loss: 0.35; train_accuracy: 0.9 

2.4078932256088592e-05
8.490565960528329e-06
Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.31; acc: 0.89
Batch: 40; loss: 0.2; acc: 0.91
Batch: 60; loss: 0.44; acc: 0.84
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.51; acc: 0.89
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.3258950436950489; val_accuracy: 0.9057523885350318 

The current subspace-distance is: 8.490565960528329e-06 

plots/subspace_training/reg_lenet_3/2020-01-22 20:51:04/d_dim_140_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
nonzero elements in E: 31575
elements in E: 6748500
fraction nonzero: 0.004678817515003334
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.31; acc: 0.08
Batch: 20; loss: 2.29; acc: 0.05
Batch: 40; loss: 2.3; acc: 0.09
Batch: 60; loss: 2.3; acc: 0.02
Batch: 80; loss: 2.3; acc: 0.08
Batch: 100; loss: 2.3; acc: 0.12
Batch: 120; loss: 2.3; acc: 0.11
Batch: 140; loss: 2.31; acc: 0.08
Batch: 160; loss: 2.3; acc: 0.08
Batch: 180; loss: 2.3; acc: 0.11
Batch: 200; loss: 2.29; acc: 0.14
Batch: 220; loss: 2.3; acc: 0.06
Batch: 240; loss: 2.3; acc: 0.05
Batch: 260; loss: 2.3; acc: 0.09
Batch: 280; loss: 2.29; acc: 0.05
Batch: 300; loss: 2.29; acc: 0.05
Batch: 320; loss: 2.3; acc: 0.05
Batch: 340; loss: 2.29; acc: 0.05
Batch: 360; loss: 2.28; acc: 0.16
Batch: 380; loss: 2.29; acc: 0.06
Batch: 400; loss: 2.28; acc: 0.14
Batch: 420; loss: 2.29; acc: 0.05
Batch: 440; loss: 2.27; acc: 0.12
Batch: 460; loss: 2.27; acc: 0.11
Batch: 480; loss: 2.27; acc: 0.06
Batch: 500; loss: 2.27; acc: 0.06
Batch: 520; loss: 2.25; acc: 0.14
Batch: 540; loss: 2.24; acc: 0.11
Batch: 560; loss: 2.23; acc: 0.09
Batch: 580; loss: 2.24; acc: 0.11
Batch: 600; loss: 2.21; acc: 0.17
Batch: 620; loss: 2.19; acc: 0.12
Batch: 640; loss: 2.2; acc: 0.22
Batch: 660; loss: 2.15; acc: 0.16
Batch: 680; loss: 2.19; acc: 0.42
Batch: 700; loss: 2.08; acc: 0.42
Batch: 720; loss: 2.06; acc: 0.44
Batch: 740; loss: 1.92; acc: 0.38
Batch: 760; loss: 1.84; acc: 0.44
Batch: 780; loss: 1.72; acc: 0.33
Train Epoch over. train_loss: 2.23; train_accuracy: 0.15 

7.581393219879828e-06
3.814183173744823e-06
Batch: 0; loss: 1.6; acc: 0.45
Batch: 20; loss: 1.8; acc: 0.28
Batch: 40; loss: 1.47; acc: 0.48
Batch: 60; loss: 1.61; acc: 0.44
Batch: 80; loss: 1.51; acc: 0.48
Batch: 100; loss: 1.73; acc: 0.39
Batch: 120; loss: 1.65; acc: 0.47
Batch: 140; loss: 1.7; acc: 0.45
Val Epoch over. val_loss: 1.6229392981073658; val_accuracy: 0.45222929936305734 

The current subspace-distance is: 3.814183173744823e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 1.63; acc: 0.44
Batch: 20; loss: 1.54; acc: 0.5
Batch: 40; loss: 1.5; acc: 0.42
Batch: 60; loss: 1.26; acc: 0.66
Batch: 80; loss: 1.26; acc: 0.62
Batch: 100; loss: 1.06; acc: 0.69
Batch: 120; loss: 2.05; acc: 0.41
Batch: 140; loss: 1.18; acc: 0.66
Batch: 160; loss: 1.1; acc: 0.61
Batch: 180; loss: 1.04; acc: 0.66
Batch: 200; loss: 0.9; acc: 0.7
Batch: 220; loss: 1.31; acc: 0.59
Batch: 240; loss: 0.81; acc: 0.72
Batch: 260; loss: 1.12; acc: 0.62
Batch: 280; loss: 0.82; acc: 0.77
Batch: 300; loss: 0.76; acc: 0.77
Batch: 320; loss: 0.86; acc: 0.75
Batch: 340; loss: 1.18; acc: 0.62
Batch: 360; loss: 0.64; acc: 0.81
Batch: 380; loss: 0.84; acc: 0.78
Batch: 400; loss: 0.66; acc: 0.83
Batch: 420; loss: 0.8; acc: 0.81
Batch: 440; loss: 0.93; acc: 0.73
Batch: 460; loss: 0.88; acc: 0.73
Batch: 480; loss: 1.04; acc: 0.59
Batch: 500; loss: 0.91; acc: 0.75
Batch: 520; loss: 0.7; acc: 0.77
Batch: 540; loss: 0.61; acc: 0.83
Batch: 560; loss: 0.59; acc: 0.8
Batch: 580; loss: 0.58; acc: 0.84
Batch: 600; loss: 0.83; acc: 0.78
Batch: 620; loss: 0.7; acc: 0.8
Batch: 640; loss: 0.74; acc: 0.8
Batch: 660; loss: 0.82; acc: 0.67
Batch: 680; loss: 0.74; acc: 0.69
Batch: 700; loss: 0.79; acc: 0.75
Batch: 720; loss: 0.68; acc: 0.81
Batch: 740; loss: 0.79; acc: 0.81
Batch: 760; loss: 0.95; acc: 0.77
Batch: 780; loss: 0.9; acc: 0.67
Train Epoch over. train_loss: 0.96; train_accuracy: 0.69 

1.6443505955976434e-05
5.059845079813385e-06
Batch: 0; loss: 0.78; acc: 0.73
Batch: 20; loss: 0.98; acc: 0.72
Batch: 40; loss: 0.29; acc: 0.92
Batch: 60; loss: 0.68; acc: 0.75
Batch: 80; loss: 0.44; acc: 0.83
Batch: 100; loss: 0.53; acc: 0.88
Batch: 120; loss: 0.74; acc: 0.72
Batch: 140; loss: 0.47; acc: 0.86
Val Epoch over. val_loss: 0.6291434857875678; val_accuracy: 0.7967754777070064 

The current subspace-distance is: 5.059845079813385e-06 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.88; acc: 0.73
Batch: 20; loss: 0.41; acc: 0.88
Batch: 40; loss: 0.39; acc: 0.89
Batch: 60; loss: 0.61; acc: 0.78
Batch: 80; loss: 0.65; acc: 0.8
Batch: 100; loss: 0.54; acc: 0.78
Batch: 120; loss: 0.65; acc: 0.8
Batch: 140; loss: 0.52; acc: 0.83
Batch: 160; loss: 0.4; acc: 0.89
Batch: 180; loss: 0.5; acc: 0.86
Batch: 200; loss: 0.42; acc: 0.83
Batch: 220; loss: 0.56; acc: 0.83
Batch: 240; loss: 0.98; acc: 0.69
Batch: 260; loss: 0.67; acc: 0.83
Batch: 280; loss: 0.65; acc: 0.86
Batch: 300; loss: 0.51; acc: 0.8
Batch: 320; loss: 0.57; acc: 0.81
Batch: 340; loss: 0.55; acc: 0.81
Batch: 360; loss: 0.54; acc: 0.84
Batch: 380; loss: 0.57; acc: 0.88
Batch: 400; loss: 0.67; acc: 0.8
Batch: 420; loss: 0.65; acc: 0.83
Batch: 440; loss: 0.46; acc: 0.88
Batch: 460; loss: 0.72; acc: 0.72
Batch: 480; loss: 0.97; acc: 0.69
Batch: 500; loss: 0.99; acc: 0.72
Batch: 520; loss: 0.46; acc: 0.91
Batch: 540; loss: 0.59; acc: 0.75
Batch: 560; loss: 0.47; acc: 0.81
Batch: 580; loss: 0.6; acc: 0.84
Batch: 600; loss: 0.44; acc: 0.91
Batch: 620; loss: 0.91; acc: 0.72
Batch: 640; loss: 0.36; acc: 0.91
Batch: 660; loss: 0.65; acc: 0.83
Batch: 680; loss: 0.58; acc: 0.84
Batch: 700; loss: 0.49; acc: 0.83
Batch: 720; loss: 0.36; acc: 0.84
Batch: 740; loss: 0.38; acc: 0.91
Batch: 760; loss: 0.38; acc: 0.88
Batch: 780; loss: 0.37; acc: 0.89
Train Epoch over. train_loss: 0.57; train_accuracy: 0.82 

2.189660881413147e-05
7.14469069862389e-06
Batch: 0; loss: 0.47; acc: 0.84
Batch: 20; loss: 0.67; acc: 0.72
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.44; acc: 0.84
Batch: 80; loss: 0.24; acc: 0.91
Batch: 100; loss: 0.34; acc: 0.86
Batch: 120; loss: 0.7; acc: 0.75
Batch: 140; loss: 0.29; acc: 0.89
Val Epoch over. val_loss: 0.40569447602625863; val_accuracy: 0.8771894904458599 

The current subspace-distance is: 7.14469069862389e-06 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.37; acc: 0.88
Batch: 20; loss: 0.65; acc: 0.73
Batch: 40; loss: 0.34; acc: 0.86
Batch: 60; loss: 0.54; acc: 0.81
Batch: 80; loss: 0.38; acc: 0.89
Batch: 100; loss: 0.32; acc: 0.88
Batch: 120; loss: 0.39; acc: 0.81
Batch: 140; loss: 0.51; acc: 0.81
Batch: 160; loss: 0.38; acc: 0.84
Batch: 180; loss: 0.5; acc: 0.8
Batch: 200; loss: 0.5; acc: 0.84
Batch: 220; loss: 0.7; acc: 0.78
Batch: 240; loss: 0.56; acc: 0.83
Batch: 260; loss: 0.48; acc: 0.89
Batch: 280; loss: 0.68; acc: 0.83
Batch: 300; loss: 0.72; acc: 0.83
Batch: 320; loss: 0.42; acc: 0.86
Batch: 340; loss: 0.53; acc: 0.89
Batch: 360; loss: 0.4; acc: 0.88
Batch: 380; loss: 0.31; acc: 0.91
Batch: 400; loss: 0.49; acc: 0.86
Batch: 420; loss: 0.74; acc: 0.81
Batch: 440; loss: 0.23; acc: 0.91
Batch: 460; loss: 0.35; acc: 0.89
Batch: 480; loss: 0.55; acc: 0.84
Batch: 500; loss: 0.37; acc: 0.91
Batch: 520; loss: 1.12; acc: 0.69
Batch: 540; loss: 0.39; acc: 0.89
Batch: 560; loss: 0.52; acc: 0.77
Batch: 580; loss: 0.42; acc: 0.88
Batch: 600; loss: 0.43; acc: 0.81
Batch: 620; loss: 0.56; acc: 0.86
Batch: 640; loss: 0.79; acc: 0.8
Batch: 660; loss: 0.62; acc: 0.83
Batch: 680; loss: 0.51; acc: 0.84
Batch: 700; loss: 0.41; acc: 0.83
Batch: 720; loss: 0.49; acc: 0.8
Batch: 740; loss: 0.41; acc: 0.89
Batch: 760; loss: 0.57; acc: 0.81
Batch: 780; loss: 0.39; acc: 0.88
Train Epoch over. train_loss: 0.48; train_accuracy: 0.85 

2.2064674340072088e-05
7.0956039053271525e-06
Batch: 0; loss: 0.62; acc: 0.8
Batch: 20; loss: 0.95; acc: 0.7
Batch: 40; loss: 0.4; acc: 0.91
Batch: 60; loss: 0.77; acc: 0.8
Batch: 80; loss: 0.35; acc: 0.88
Batch: 100; loss: 0.59; acc: 0.8
Batch: 120; loss: 0.72; acc: 0.72
Batch: 140; loss: 0.22; acc: 0.94
Val Epoch over. val_loss: 0.6392924018726227; val_accuracy: 0.8029458598726115 

The current subspace-distance is: 7.0956039053271525e-06 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.67; acc: 0.83
Batch: 20; loss: 0.38; acc: 0.86
Batch: 40; loss: 0.44; acc: 0.86
Batch: 60; loss: 0.49; acc: 0.84
Batch: 80; loss: 0.56; acc: 0.8
Batch: 100; loss: 0.28; acc: 0.91
Batch: 120; loss: 0.39; acc: 0.89
Batch: 140; loss: 0.57; acc: 0.86
Batch: 160; loss: 0.38; acc: 0.88
Batch: 180; loss: 0.29; acc: 0.95
Batch: 200; loss: 0.55; acc: 0.84
Batch: 220; loss: 0.49; acc: 0.84
Batch: 240; loss: 0.36; acc: 0.89
Batch: 260; loss: 0.42; acc: 0.81
Batch: 280; loss: 0.39; acc: 0.91
Batch: 300; loss: 0.82; acc: 0.86
Batch: 320; loss: 0.41; acc: 0.86
Batch: 340; loss: 0.31; acc: 0.89
Batch: 360; loss: 0.49; acc: 0.83
Batch: 380; loss: 0.41; acc: 0.88
Batch: 400; loss: 0.67; acc: 0.84
Batch: 420; loss: 0.51; acc: 0.84
Batch: 440; loss: 0.58; acc: 0.8
Batch: 460; loss: 0.36; acc: 0.91
Batch: 480; loss: 0.4; acc: 0.84
Batch: 500; loss: 0.4; acc: 0.88
Batch: 520; loss: 0.34; acc: 0.89
Batch: 540; loss: 1.2; acc: 0.7
Batch: 560; loss: 0.47; acc: 0.83
Batch: 580; loss: 0.49; acc: 0.89
Batch: 600; loss: 0.35; acc: 0.91
Batch: 620; loss: 0.39; acc: 0.86
Batch: 640; loss: 0.3; acc: 0.88
Batch: 660; loss: 0.75; acc: 0.83
Batch: 680; loss: 0.49; acc: 0.86
Batch: 700; loss: 0.23; acc: 0.95
Batch: 720; loss: 0.31; acc: 0.89
Batch: 740; loss: 0.4; acc: 0.91
Batch: 760; loss: 0.23; acc: 0.92
Batch: 780; loss: 0.35; acc: 0.92
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

2.3818394765839912e-05
6.451075023505837e-06
Batch: 0; loss: 0.49; acc: 0.8
Batch: 20; loss: 0.59; acc: 0.81
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.56; acc: 0.8
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.3; acc: 0.89
Batch: 120; loss: 0.48; acc: 0.81
Batch: 140; loss: 0.2; acc: 0.94
Val Epoch over. val_loss: 0.3765030508018603; val_accuracy: 0.8876393312101911 

The current subspace-distance is: 6.451075023505837e-06 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.47; acc: 0.83
Batch: 20; loss: 0.53; acc: 0.83
Batch: 40; loss: 0.85; acc: 0.72
Batch: 60; loss: 0.38; acc: 0.84
Batch: 80; loss: 0.27; acc: 0.89
Batch: 100; loss: 0.33; acc: 0.84
Batch: 120; loss: 0.49; acc: 0.84
Batch: 140; loss: 0.67; acc: 0.75
Batch: 160; loss: 0.64; acc: 0.83
Batch: 180; loss: 0.33; acc: 0.89
Batch: 200; loss: 0.43; acc: 0.81
Batch: 220; loss: 0.26; acc: 0.94
Batch: 240; loss: 0.43; acc: 0.84
Batch: 260; loss: 0.44; acc: 0.89
Batch: 280; loss: 0.27; acc: 0.88
Batch: 300; loss: 0.45; acc: 0.91
Batch: 320; loss: 0.47; acc: 0.84
Batch: 340; loss: 0.36; acc: 0.89
Batch: 360; loss: 0.67; acc: 0.81
Batch: 380; loss: 0.6; acc: 0.81
Batch: 400; loss: 0.3; acc: 0.92
Batch: 420; loss: 0.4; acc: 0.88
Batch: 440; loss: 0.39; acc: 0.86
Batch: 460; loss: 0.56; acc: 0.84
Batch: 480; loss: 0.29; acc: 0.89
Batch: 500; loss: 0.55; acc: 0.86
Batch: 520; loss: 0.37; acc: 0.84
Batch: 540; loss: 0.37; acc: 0.89
Batch: 560; loss: 0.35; acc: 0.84
Batch: 580; loss: 0.37; acc: 0.88
Batch: 600; loss: 0.35; acc: 0.86
Batch: 620; loss: 0.37; acc: 0.91
Batch: 640; loss: 0.44; acc: 0.88
Batch: 660; loss: 0.92; acc: 0.75
Batch: 680; loss: 0.2; acc: 0.97
Batch: 700; loss: 0.16; acc: 0.94
Batch: 720; loss: 0.79; acc: 0.77
Batch: 740; loss: 0.36; acc: 0.86
Batch: 760; loss: 0.56; acc: 0.86
Batch: 780; loss: 0.27; acc: 0.94
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

2.263363239762839e-05
7.067520073178457e-06
Batch: 0; loss: 0.37; acc: 0.83
Batch: 20; loss: 0.43; acc: 0.81
Batch: 40; loss: 0.22; acc: 0.92
Batch: 60; loss: 0.45; acc: 0.84
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.28; acc: 0.88
Batch: 120; loss: 0.45; acc: 0.8
Batch: 140; loss: 0.13; acc: 0.97
Val Epoch over. val_loss: 0.33632504223448456; val_accuracy: 0.9010748407643312 

The current subspace-distance is: 7.067520073178457e-06 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.65; acc: 0.77
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.47; acc: 0.86
Batch: 60; loss: 0.37; acc: 0.88
Batch: 80; loss: 0.29; acc: 0.89
Batch: 100; loss: 0.42; acc: 0.88
Batch: 120; loss: 0.29; acc: 0.88
Batch: 140; loss: 0.34; acc: 0.88
Batch: 160; loss: 0.56; acc: 0.81
Batch: 180; loss: 0.46; acc: 0.91
Batch: 200; loss: 0.87; acc: 0.77
Batch: 220; loss: 0.54; acc: 0.81
Batch: 240; loss: 0.31; acc: 0.89
Batch: 260; loss: 0.34; acc: 0.91
Batch: 280; loss: 0.39; acc: 0.89
Batch: 300; loss: 0.37; acc: 0.94
Batch: 320; loss: 0.45; acc: 0.88
Batch: 340; loss: 0.32; acc: 0.88
Batch: 360; loss: 0.48; acc: 0.84
Batch: 380; loss: 0.47; acc: 0.84
Batch: 400; loss: 0.31; acc: 0.92
Batch: 420; loss: 0.47; acc: 0.81
Batch: 440; loss: 0.39; acc: 0.88
Batch: 460; loss: 0.13; acc: 0.98
Batch: 480; loss: 0.53; acc: 0.81
Batch: 500; loss: 0.3; acc: 0.91
Batch: 520; loss: 0.23; acc: 0.94
Batch: 540; loss: 0.28; acc: 0.92
Batch: 560; loss: 0.39; acc: 0.88
Batch: 580; loss: 0.46; acc: 0.88
Batch: 600; loss: 0.24; acc: 0.91
Batch: 620; loss: 0.41; acc: 0.86
Batch: 640; loss: 0.83; acc: 0.72
Batch: 660; loss: 0.29; acc: 0.91
Batch: 680; loss: 0.41; acc: 0.91
Batch: 700; loss: 0.28; acc: 0.94
Batch: 720; loss: 0.33; acc: 0.89
Batch: 740; loss: 0.38; acc: 0.89
Batch: 760; loss: 0.33; acc: 0.94
Batch: 780; loss: 0.22; acc: 0.94
Train Epoch over. train_loss: 0.41; train_accuracy: 0.87 

2.493892316124402e-05
7.526205536123598e-06
Batch: 0; loss: 0.74; acc: 0.75
Batch: 20; loss: 0.4; acc: 0.84
Batch: 40; loss: 0.25; acc: 0.92
Batch: 60; loss: 0.71; acc: 0.8
Batch: 80; loss: 0.28; acc: 0.91
Batch: 100; loss: 0.38; acc: 0.84
Batch: 120; loss: 0.43; acc: 0.81
Batch: 140; loss: 0.18; acc: 0.92
Val Epoch over. val_loss: 0.3948769427978309; val_accuracy: 0.8730095541401274 

The current subspace-distance is: 7.526205536123598e-06 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.48; acc: 0.86
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.2; acc: 0.92
Batch: 60; loss: 0.44; acc: 0.86
Batch: 80; loss: 0.45; acc: 0.89
Batch: 100; loss: 0.35; acc: 0.88
Batch: 120; loss: 0.47; acc: 0.83
Batch: 140; loss: 0.41; acc: 0.89
Batch: 160; loss: 0.37; acc: 0.84
Batch: 180; loss: 0.5; acc: 0.83
Batch: 200; loss: 0.35; acc: 0.88
Batch: 220; loss: 0.42; acc: 0.86
Batch: 240; loss: 0.34; acc: 0.88
Batch: 260; loss: 0.25; acc: 0.94
Batch: 280; loss: 0.63; acc: 0.81
Batch: 300; loss: 0.53; acc: 0.78
Batch: 320; loss: 0.29; acc: 0.95
Batch: 340; loss: 0.53; acc: 0.81
Batch: 360; loss: 0.38; acc: 0.88
Batch: 380; loss: 0.23; acc: 0.92
Batch: 400; loss: 0.39; acc: 0.88
Batch: 420; loss: 0.23; acc: 0.94
Batch: 440; loss: 0.63; acc: 0.83
Batch: 460; loss: 0.39; acc: 0.89
Batch: 480; loss: 0.43; acc: 0.86
Batch: 500; loss: 0.33; acc: 0.89
Batch: 520; loss: 0.36; acc: 0.88
Batch: 540; loss: 0.37; acc: 0.92
Batch: 560; loss: 0.37; acc: 0.86
Batch: 580; loss: 0.35; acc: 0.86
Batch: 600; loss: 0.58; acc: 0.81
Batch: 620; loss: 0.38; acc: 0.86
Batch: 640; loss: 0.2; acc: 0.94
Batch: 660; loss: 0.3; acc: 0.92
Batch: 680; loss: 0.36; acc: 0.88
Batch: 700; loss: 0.6; acc: 0.84
Batch: 720; loss: 0.22; acc: 0.94
Batch: 740; loss: 0.47; acc: 0.88
Batch: 760; loss: 0.22; acc: 0.95
Batch: 780; loss: 0.48; acc: 0.86
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

2.3392378352582455e-05
6.394735464709811e-06
Batch: 0; loss: 0.98; acc: 0.67
Batch: 20; loss: 0.91; acc: 0.72
Batch: 40; loss: 0.49; acc: 0.88
Batch: 60; loss: 0.75; acc: 0.77
Batch: 80; loss: 0.59; acc: 0.83
Batch: 100; loss: 0.84; acc: 0.78
Batch: 120; loss: 0.66; acc: 0.72
Batch: 140; loss: 0.26; acc: 0.92
Val Epoch over. val_loss: 0.7071445782662956; val_accuracy: 0.7797571656050956 

The current subspace-distance is: 6.394735464709811e-06 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.76; acc: 0.75
Batch: 20; loss: 0.25; acc: 0.94
Batch: 40; loss: 0.17; acc: 0.97
Batch: 60; loss: 0.6; acc: 0.89
Batch: 80; loss: 0.55; acc: 0.8
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.27; acc: 0.92
Batch: 140; loss: 0.56; acc: 0.83
Batch: 160; loss: 0.42; acc: 0.92
Batch: 180; loss: 0.52; acc: 0.84
Batch: 200; loss: 0.21; acc: 0.91
Batch: 220; loss: 0.34; acc: 0.86
Batch: 240; loss: 0.34; acc: 0.94
Batch: 260; loss: 0.32; acc: 0.88
Batch: 280; loss: 0.41; acc: 0.86
Batch: 300; loss: 0.45; acc: 0.84
Batch: 320; loss: 0.49; acc: 0.86
Batch: 340; loss: 0.41; acc: 0.88
Batch: 360; loss: 0.3; acc: 0.92
Batch: 380; loss: 0.13; acc: 0.97
Batch: 400; loss: 0.42; acc: 0.91
Batch: 420; loss: 0.35; acc: 0.89
Batch: 440; loss: 0.42; acc: 0.88
Batch: 460; loss: 0.19; acc: 0.95
Batch: 480; loss: 0.4; acc: 0.88
Batch: 500; loss: 0.49; acc: 0.89
Batch: 520; loss: 0.32; acc: 0.92
Batch: 540; loss: 0.39; acc: 0.86
Batch: 560; loss: 0.49; acc: 0.86
Batch: 580; loss: 0.6; acc: 0.83
Batch: 600; loss: 0.46; acc: 0.88
Batch: 620; loss: 0.39; acc: 0.86
Batch: 640; loss: 0.44; acc: 0.88
Batch: 660; loss: 0.44; acc: 0.83
Batch: 680; loss: 0.4; acc: 0.86
Batch: 700; loss: 0.46; acc: 0.83
Batch: 720; loss: 0.37; acc: 0.83
Batch: 740; loss: 0.42; acc: 0.84
Batch: 760; loss: 0.18; acc: 0.95
Batch: 780; loss: 0.37; acc: 0.89
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

2.5043016648851335e-05
8.542012437828816e-06
Batch: 0; loss: 0.92; acc: 0.7
Batch: 20; loss: 0.89; acc: 0.78
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.57; acc: 0.84
Batch: 80; loss: 0.32; acc: 0.89
Batch: 100; loss: 0.46; acc: 0.84
Batch: 120; loss: 0.58; acc: 0.73
Batch: 140; loss: 0.26; acc: 0.91
Val Epoch over. val_loss: 0.48280320193167703; val_accuracy: 0.8507165605095541 

The current subspace-distance is: 8.542012437828816e-06 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.6; acc: 0.81
Batch: 20; loss: 0.27; acc: 0.86
Batch: 40; loss: 0.47; acc: 0.84
Batch: 60; loss: 0.38; acc: 0.91
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.37; acc: 0.86
Batch: 120; loss: 0.35; acc: 0.86
Batch: 140; loss: 0.39; acc: 0.89
Batch: 160; loss: 0.12; acc: 0.97
Batch: 180; loss: 0.26; acc: 0.94
Batch: 200; loss: 0.37; acc: 0.91
Batch: 220; loss: 0.71; acc: 0.81
Batch: 240; loss: 0.26; acc: 0.94
Batch: 260; loss: 0.35; acc: 0.86
Batch: 280; loss: 0.26; acc: 0.91
Batch: 300; loss: 0.16; acc: 0.97
Batch: 320; loss: 0.61; acc: 0.86
Batch: 340; loss: 0.42; acc: 0.83
Batch: 360; loss: 0.37; acc: 0.89
Batch: 380; loss: 0.28; acc: 0.94
Batch: 400; loss: 0.31; acc: 0.92
Batch: 420; loss: 0.23; acc: 0.92
Batch: 440; loss: 0.33; acc: 0.88
Batch: 460; loss: 0.14; acc: 0.98
Batch: 480; loss: 0.21; acc: 0.91
Batch: 500; loss: 0.22; acc: 0.94
Batch: 520; loss: 0.26; acc: 0.91
Batch: 540; loss: 0.19; acc: 0.95
Batch: 560; loss: 0.41; acc: 0.89
Batch: 580; loss: 0.35; acc: 0.92
Batch: 600; loss: 0.3; acc: 0.94
Batch: 620; loss: 0.59; acc: 0.86
Batch: 640; loss: 0.41; acc: 0.81
Batch: 660; loss: 0.34; acc: 0.89
Batch: 680; loss: 0.37; acc: 0.92
Batch: 700; loss: 0.39; acc: 0.89
Batch: 720; loss: 0.58; acc: 0.88
Batch: 740; loss: 0.49; acc: 0.88
Batch: 760; loss: 0.21; acc: 0.95
Batch: 780; loss: 0.43; acc: 0.84
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

2.6415742468088865e-05
7.845297659514472e-06
Batch: 0; loss: 0.67; acc: 0.8
Batch: 20; loss: 0.35; acc: 0.84
Batch: 40; loss: 0.19; acc: 0.97
Batch: 60; loss: 0.51; acc: 0.83
Batch: 80; loss: 0.27; acc: 0.91
Batch: 100; loss: 0.39; acc: 0.84
Batch: 120; loss: 0.37; acc: 0.89
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.34164256227623885; val_accuracy: 0.8948049363057324 

The current subspace-distance is: 7.845297659514472e-06 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.4; acc: 0.86
Batch: 20; loss: 0.24; acc: 0.89
Batch: 40; loss: 0.66; acc: 0.88
Batch: 60; loss: 0.28; acc: 0.95
Batch: 80; loss: 0.3; acc: 0.91
Batch: 100; loss: 0.37; acc: 0.89
Batch: 120; loss: 0.26; acc: 0.91
Batch: 140; loss: 0.52; acc: 0.81
Batch: 160; loss: 0.19; acc: 0.95
Batch: 180; loss: 0.24; acc: 0.94
Batch: 200; loss: 0.39; acc: 0.92
Batch: 220; loss: 0.29; acc: 0.89
Batch: 240; loss: 0.42; acc: 0.88
Batch: 260; loss: 0.22; acc: 0.94
Batch: 280; loss: 0.15; acc: 0.98
Batch: 300; loss: 0.26; acc: 0.91
Batch: 320; loss: 0.36; acc: 0.86
Batch: 340; loss: 0.38; acc: 0.94
Batch: 360; loss: 0.34; acc: 0.89
Batch: 380; loss: 0.44; acc: 0.88
Batch: 400; loss: 0.57; acc: 0.84
Batch: 420; loss: 0.22; acc: 0.91
Batch: 440; loss: 0.29; acc: 0.94
Batch: 460; loss: 0.37; acc: 0.86
Batch: 480; loss: 0.29; acc: 0.92
Batch: 500; loss: 0.43; acc: 0.84
Batch: 520; loss: 0.51; acc: 0.86
Batch: 540; loss: 0.53; acc: 0.84
Batch: 560; loss: 0.42; acc: 0.84
Batch: 580; loss: 0.34; acc: 0.94
Batch: 600; loss: 0.33; acc: 0.91
Batch: 620; loss: 0.34; acc: 0.91
Batch: 640; loss: 0.23; acc: 0.94
Batch: 660; loss: 0.37; acc: 0.91
Batch: 680; loss: 0.24; acc: 0.94
Batch: 700; loss: 0.2; acc: 0.92
Batch: 720; loss: 0.42; acc: 0.88
Batch: 740; loss: 0.33; acc: 0.89
Batch: 760; loss: 0.29; acc: 0.92
Batch: 780; loss: 0.36; acc: 0.91
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

2.5097740945057012e-05
6.807960289734183e-06
Batch: 0; loss: 0.6; acc: 0.8
Batch: 20; loss: 0.46; acc: 0.83
Batch: 40; loss: 0.12; acc: 0.98
Batch: 60; loss: 0.42; acc: 0.89
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.33; acc: 0.91
Batch: 120; loss: 0.39; acc: 0.86
Batch: 140; loss: 0.14; acc: 0.95
Val Epoch over. val_loss: 0.3147116966403214; val_accuracy: 0.9003781847133758 

The current subspace-distance is: 6.807960289734183e-06 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.46; acc: 0.88
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.23; acc: 0.92
Batch: 60; loss: 0.48; acc: 0.83
Batch: 80; loss: 0.29; acc: 0.91
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.15; acc: 0.95
Batch: 140; loss: 0.33; acc: 0.91
Batch: 160; loss: 0.32; acc: 0.88
Batch: 180; loss: 0.13; acc: 0.95
Batch: 200; loss: 0.2; acc: 0.92
Batch: 220; loss: 0.23; acc: 0.89
Batch: 240; loss: 0.25; acc: 0.94
Batch: 260; loss: 0.2; acc: 0.95
Batch: 280; loss: 0.22; acc: 0.92
Batch: 300; loss: 0.19; acc: 0.92
Batch: 320; loss: 0.24; acc: 0.92
Batch: 340; loss: 0.32; acc: 0.88
Batch: 360; loss: 0.29; acc: 0.92
Batch: 380; loss: 0.47; acc: 0.86
Batch: 400; loss: 0.18; acc: 0.95
Batch: 420; loss: 0.33; acc: 0.88
Batch: 440; loss: 0.49; acc: 0.86
Batch: 460; loss: 0.4; acc: 0.89
Batch: 480; loss: 0.35; acc: 0.86
Batch: 500; loss: 0.46; acc: 0.86
Batch: 520; loss: 0.32; acc: 0.92
Batch: 540; loss: 0.28; acc: 0.89
Batch: 560; loss: 0.24; acc: 0.97
Batch: 580; loss: 0.29; acc: 0.92
Batch: 600; loss: 0.35; acc: 0.89
Batch: 620; loss: 0.54; acc: 0.88
Batch: 640; loss: 0.43; acc: 0.83
Batch: 660; loss: 0.37; acc: 0.88
Batch: 680; loss: 0.41; acc: 0.86
Batch: 700; loss: 0.32; acc: 0.91
Batch: 720; loss: 0.35; acc: 0.89
Batch: 740; loss: 0.57; acc: 0.84
Batch: 760; loss: 0.52; acc: 0.83
Batch: 780; loss: 0.27; acc: 0.89
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.448690793244168e-05
7.1287995524471626e-06
Batch: 0; loss: 0.74; acc: 0.77
Batch: 20; loss: 0.44; acc: 0.81
Batch: 40; loss: 0.26; acc: 0.92
Batch: 60; loss: 0.64; acc: 0.83
Batch: 80; loss: 0.43; acc: 0.88
Batch: 100; loss: 0.35; acc: 0.86
Batch: 120; loss: 0.43; acc: 0.83
Batch: 140; loss: 0.19; acc: 0.95
Val Epoch over. val_loss: 0.49276515898431184; val_accuracy: 0.8469347133757962 

The current subspace-distance is: 7.1287995524471626e-06 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.46; acc: 0.84
Batch: 20; loss: 0.48; acc: 0.84
Batch: 40; loss: 0.38; acc: 0.88
Batch: 60; loss: 0.36; acc: 0.91
Batch: 80; loss: 0.3; acc: 0.88
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.31; acc: 0.92
Batch: 140; loss: 0.22; acc: 0.95
Batch: 160; loss: 0.57; acc: 0.88
Batch: 180; loss: 0.27; acc: 0.91
Batch: 200; loss: 0.21; acc: 0.95
Batch: 220; loss: 0.24; acc: 0.89
Batch: 240; loss: 0.25; acc: 0.92
Batch: 260; loss: 0.27; acc: 0.92
Batch: 280; loss: 0.42; acc: 0.89
Batch: 300; loss: 0.23; acc: 0.91
Batch: 320; loss: 0.52; acc: 0.81
Batch: 340; loss: 0.23; acc: 0.92
Batch: 360; loss: 0.36; acc: 0.91
Batch: 380; loss: 0.48; acc: 0.81
Batch: 400; loss: 0.23; acc: 0.94
Batch: 420; loss: 0.22; acc: 0.94
Batch: 440; loss: 0.25; acc: 0.88
Batch: 460; loss: 0.31; acc: 0.92
Batch: 480; loss: 0.23; acc: 0.92
Batch: 500; loss: 0.25; acc: 0.92
Batch: 520; loss: 0.18; acc: 0.95
Batch: 540; loss: 0.51; acc: 0.83
Batch: 560; loss: 0.17; acc: 0.95
Batch: 580; loss: 0.25; acc: 0.92
Batch: 600; loss: 0.44; acc: 0.84
Batch: 620; loss: 0.43; acc: 0.89
Batch: 640; loss: 0.24; acc: 0.89
Batch: 660; loss: 0.28; acc: 0.91
Batch: 680; loss: 0.36; acc: 0.89
Batch: 700; loss: 0.47; acc: 0.86
Batch: 720; loss: 0.21; acc: 0.97
Batch: 740; loss: 0.25; acc: 0.92
Batch: 760; loss: 0.29; acc: 0.89
Batch: 780; loss: 0.44; acc: 0.89
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.4079359718598425e-05
8.132356924761552e-06
Batch: 0; loss: 0.47; acc: 0.84
Batch: 20; loss: 0.36; acc: 0.88
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.42; acc: 0.89
Batch: 80; loss: 0.22; acc: 0.92
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.38; acc: 0.86
Batch: 140; loss: 0.13; acc: 0.95
Val Epoch over. val_loss: 0.29856841783424853; val_accuracy: 0.9068471337579618 

The current subspace-distance is: 8.132356924761552e-06 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.19; acc: 0.92
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.24; acc: 0.91
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.25; acc: 0.94
Batch: 140; loss: 0.47; acc: 0.83
Batch: 160; loss: 0.37; acc: 0.89
Batch: 180; loss: 0.17; acc: 0.94
Batch: 200; loss: 0.3; acc: 0.92
Batch: 220; loss: 0.61; acc: 0.81
Batch: 240; loss: 0.26; acc: 0.92
Batch: 260; loss: 0.11; acc: 0.98
Batch: 280; loss: 0.23; acc: 0.92
Batch: 300; loss: 0.32; acc: 0.84
Batch: 320; loss: 0.21; acc: 0.94
Batch: 340; loss: 0.23; acc: 0.95
Batch: 360; loss: 0.47; acc: 0.88
Batch: 380; loss: 0.23; acc: 0.92
Batch: 400; loss: 0.53; acc: 0.81
Batch: 420; loss: 0.26; acc: 0.89
Batch: 440; loss: 0.22; acc: 0.91
Batch: 460; loss: 0.26; acc: 0.92
Batch: 480; loss: 0.32; acc: 0.91
Batch: 500; loss: 0.35; acc: 0.92
Batch: 520; loss: 0.24; acc: 0.94
Batch: 540; loss: 0.19; acc: 0.92
Batch: 560; loss: 0.45; acc: 0.88
Batch: 580; loss: 0.19; acc: 0.95
Batch: 600; loss: 0.39; acc: 0.89
Batch: 620; loss: 0.5; acc: 0.86
Batch: 640; loss: 0.34; acc: 0.91
Batch: 660; loss: 0.18; acc: 0.94
Batch: 680; loss: 0.45; acc: 0.86
Batch: 700; loss: 0.22; acc: 0.94
Batch: 720; loss: 0.2; acc: 0.94
Batch: 740; loss: 0.18; acc: 0.94
Batch: 760; loss: 0.37; acc: 0.86
Batch: 780; loss: 0.36; acc: 0.88
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.450605643389281e-05
8.078438440861646e-06
Batch: 0; loss: 0.54; acc: 0.83
Batch: 20; loss: 0.34; acc: 0.86
Batch: 40; loss: 0.13; acc: 0.98
Batch: 60; loss: 0.48; acc: 0.86
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.27; acc: 0.91
Batch: 120; loss: 0.34; acc: 0.88
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.2851296705045518; val_accuracy: 0.9125199044585988 

The current subspace-distance is: 8.078438440861646e-06 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.32; acc: 0.89
Batch: 20; loss: 0.3; acc: 0.94
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.29; acc: 0.92
Batch: 80; loss: 0.32; acc: 0.92
Batch: 100; loss: 0.25; acc: 0.91
Batch: 120; loss: 0.31; acc: 0.89
Batch: 140; loss: 0.33; acc: 0.94
Batch: 160; loss: 0.31; acc: 0.91
Batch: 180; loss: 0.3; acc: 0.92
Batch: 200; loss: 0.36; acc: 0.89
Batch: 220; loss: 0.31; acc: 0.86
Batch: 240; loss: 0.4; acc: 0.88
Batch: 260; loss: 0.25; acc: 0.88
Batch: 280; loss: 0.23; acc: 0.89
Batch: 300; loss: 0.36; acc: 0.92
Batch: 320; loss: 0.56; acc: 0.83
Batch: 340; loss: 0.36; acc: 0.92
Batch: 360; loss: 0.3; acc: 0.91
Batch: 380; loss: 0.41; acc: 0.88
Batch: 400; loss: 0.27; acc: 0.86
Batch: 420; loss: 0.39; acc: 0.89
Batch: 440; loss: 0.18; acc: 0.95
Batch: 460; loss: 0.42; acc: 0.84
Batch: 480; loss: 0.13; acc: 0.98
Batch: 500; loss: 0.32; acc: 0.88
Batch: 520; loss: 0.25; acc: 0.94
Batch: 540; loss: 0.12; acc: 0.95
Batch: 560; loss: 0.37; acc: 0.86
Batch: 580; loss: 0.4; acc: 0.88
Batch: 600; loss: 0.2; acc: 0.94
Batch: 620; loss: 0.27; acc: 0.92
Batch: 640; loss: 0.33; acc: 0.92
Batch: 660; loss: 0.18; acc: 0.94
Batch: 680; loss: 0.27; acc: 0.88
Batch: 700; loss: 0.27; acc: 0.91
Batch: 720; loss: 0.26; acc: 0.91
Batch: 740; loss: 0.28; acc: 0.89
Batch: 760; loss: 0.5; acc: 0.8
Batch: 780; loss: 0.17; acc: 0.94
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.467745252943132e-05
7.325317710638046e-06
Batch: 0; loss: 0.5; acc: 0.88
Batch: 20; loss: 0.37; acc: 0.88
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.43; acc: 0.88
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.35; acc: 0.86
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.28928358183734737; val_accuracy: 0.9131170382165605 

The current subspace-distance is: 7.325317710638046e-06 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.31; acc: 0.92
Batch: 20; loss: 0.37; acc: 0.91
Batch: 40; loss: 0.29; acc: 0.91
Batch: 60; loss: 0.15; acc: 0.95
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.32; acc: 0.88
Batch: 120; loss: 0.35; acc: 0.92
Batch: 140; loss: 0.3; acc: 0.91
Batch: 160; loss: 0.33; acc: 0.86
Batch: 180; loss: 0.44; acc: 0.89
Batch: 200; loss: 0.32; acc: 0.88
Batch: 220; loss: 0.35; acc: 0.91
Batch: 240; loss: 0.36; acc: 0.86
Batch: 260; loss: 0.37; acc: 0.86
Batch: 280; loss: 0.35; acc: 0.91
Batch: 300; loss: 0.27; acc: 0.91
Batch: 320; loss: 0.33; acc: 0.88
Batch: 340; loss: 0.38; acc: 0.92
Batch: 360; loss: 0.33; acc: 0.91
Batch: 380; loss: 0.4; acc: 0.91
Batch: 400; loss: 0.39; acc: 0.94
Batch: 420; loss: 0.38; acc: 0.88
Batch: 440; loss: 0.65; acc: 0.78
Batch: 460; loss: 0.2; acc: 0.92
Batch: 480; loss: 0.27; acc: 0.95
Batch: 500; loss: 0.54; acc: 0.81
Batch: 520; loss: 0.13; acc: 0.95
Batch: 540; loss: 0.59; acc: 0.8
Batch: 560; loss: 0.46; acc: 0.86
Batch: 580; loss: 0.23; acc: 0.94
Batch: 600; loss: 0.31; acc: 0.91
Batch: 620; loss: 0.33; acc: 0.89
Batch: 640; loss: 0.22; acc: 0.92
Batch: 660; loss: 0.25; acc: 0.91
Batch: 680; loss: 0.14; acc: 0.94
Batch: 700; loss: 0.31; acc: 0.89
Batch: 720; loss: 0.26; acc: 0.91
Batch: 740; loss: 0.51; acc: 0.84
Batch: 760; loss: 0.31; acc: 0.89
Batch: 780; loss: 0.2; acc: 0.92
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.4357990696444176e-05
7.087019639584469e-06
Batch: 0; loss: 0.49; acc: 0.84
Batch: 20; loss: 0.27; acc: 0.91
Batch: 40; loss: 0.12; acc: 0.98
Batch: 60; loss: 0.47; acc: 0.86
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.29; acc: 0.91
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.2715032778348133; val_accuracy: 0.9173964968152867 

The current subspace-distance is: 7.087019639584469e-06 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.23; acc: 0.92
Batch: 20; loss: 0.37; acc: 0.91
Batch: 40; loss: 0.25; acc: 0.95
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.53; acc: 0.89
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.42; acc: 0.86
Batch: 140; loss: 0.25; acc: 0.92
Batch: 160; loss: 0.57; acc: 0.83
Batch: 180; loss: 0.35; acc: 0.89
Batch: 200; loss: 0.28; acc: 0.89
Batch: 220; loss: 0.26; acc: 0.94
Batch: 240; loss: 0.37; acc: 0.88
Batch: 260; loss: 0.31; acc: 0.89
Batch: 280; loss: 0.35; acc: 0.94
Batch: 300; loss: 0.41; acc: 0.88
Batch: 320; loss: 0.29; acc: 0.92
Batch: 340; loss: 0.25; acc: 0.91
Batch: 360; loss: 0.36; acc: 0.84
Batch: 380; loss: 0.41; acc: 0.86
Batch: 400; loss: 0.51; acc: 0.83
Batch: 420; loss: 0.35; acc: 0.91
Batch: 440; loss: 0.29; acc: 0.89
Batch: 460; loss: 0.14; acc: 0.98
Batch: 480; loss: 0.32; acc: 0.92
Batch: 500; loss: 0.19; acc: 0.95
Batch: 520; loss: 0.45; acc: 0.83
Batch: 540; loss: 0.3; acc: 0.89
Batch: 560; loss: 0.48; acc: 0.86
Batch: 580; loss: 0.27; acc: 0.92
Batch: 600; loss: 0.23; acc: 0.92
Batch: 620; loss: 0.18; acc: 0.94
Batch: 640; loss: 0.38; acc: 0.88
Batch: 660; loss: 0.28; acc: 0.92
Batch: 680; loss: 0.22; acc: 0.94
Batch: 700; loss: 0.16; acc: 0.95
Batch: 720; loss: 0.16; acc: 0.95
Batch: 740; loss: 0.53; acc: 0.88
Batch: 760; loss: 0.35; acc: 0.92
Batch: 780; loss: 0.46; acc: 0.88
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.4545621272409335e-05
6.497909453173634e-06
Batch: 0; loss: 0.47; acc: 0.88
Batch: 20; loss: 0.38; acc: 0.86
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.41; acc: 0.88
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.3; acc: 0.91
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.2838210639110796; val_accuracy: 0.9137141719745223 

The current subspace-distance is: 6.497909453173634e-06 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.52; acc: 0.84
Batch: 20; loss: 0.14; acc: 0.97
Batch: 40; loss: 0.32; acc: 0.88
Batch: 60; loss: 0.22; acc: 0.92
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.37; acc: 0.86
Batch: 120; loss: 0.34; acc: 0.88
Batch: 140; loss: 0.38; acc: 0.88
Batch: 160; loss: 0.19; acc: 0.97
Batch: 180; loss: 0.29; acc: 0.89
Batch: 200; loss: 0.38; acc: 0.92
Batch: 220; loss: 0.23; acc: 0.92
Batch: 240; loss: 0.48; acc: 0.88
Batch: 260; loss: 0.44; acc: 0.88
Batch: 280; loss: 0.33; acc: 0.84
Batch: 300; loss: 0.24; acc: 0.92
Batch: 320; loss: 0.27; acc: 0.94
Batch: 340; loss: 0.38; acc: 0.91
Batch: 360; loss: 0.15; acc: 0.95
Batch: 380; loss: 0.12; acc: 0.95
Batch: 400; loss: 0.18; acc: 0.92
Batch: 420; loss: 0.49; acc: 0.84
Batch: 440; loss: 0.32; acc: 0.91
Batch: 460; loss: 0.43; acc: 0.89
Batch: 480; loss: 0.14; acc: 0.94
Batch: 500; loss: 0.22; acc: 0.94
Batch: 520; loss: 0.34; acc: 0.91
Batch: 540; loss: 0.33; acc: 0.91
Batch: 560; loss: 0.31; acc: 0.89
Batch: 580; loss: 0.13; acc: 0.97
Batch: 600; loss: 0.21; acc: 0.95
Batch: 620; loss: 0.28; acc: 0.92
Batch: 640; loss: 0.36; acc: 0.92
Batch: 660; loss: 0.19; acc: 0.94
Batch: 680; loss: 0.21; acc: 0.95
Batch: 700; loss: 0.27; acc: 0.91
Batch: 720; loss: 0.31; acc: 0.91
Batch: 740; loss: 0.44; acc: 0.86
Batch: 760; loss: 0.16; acc: 0.94
Batch: 780; loss: 0.39; acc: 0.91
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.372896415181458e-05
7.703614755882882e-06
Batch: 0; loss: 0.57; acc: 0.81
Batch: 20; loss: 0.39; acc: 0.86
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.4; acc: 0.89
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.34; acc: 0.92
Batch: 120; loss: 0.29; acc: 0.91
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.29346600696919073; val_accuracy: 0.9087380573248408 

The current subspace-distance is: 7.703614755882882e-06 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.49; acc: 0.86
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.33; acc: 0.88
Batch: 60; loss: 0.31; acc: 0.91
Batch: 80; loss: 0.43; acc: 0.91
Batch: 100; loss: 0.53; acc: 0.86
Batch: 120; loss: 0.13; acc: 0.94
Batch: 140; loss: 0.31; acc: 0.92
Batch: 160; loss: 0.34; acc: 0.89
Batch: 180; loss: 0.38; acc: 0.86
Batch: 200; loss: 0.57; acc: 0.86
Batch: 220; loss: 0.38; acc: 0.88
Batch: 240; loss: 0.26; acc: 0.91
Batch: 260; loss: 0.44; acc: 0.86
Batch: 280; loss: 0.34; acc: 0.91
Batch: 300; loss: 0.31; acc: 0.89
Batch: 320; loss: 0.18; acc: 0.94
Batch: 340; loss: 0.49; acc: 0.84
Batch: 360; loss: 0.23; acc: 0.95
Batch: 380; loss: 0.24; acc: 0.91
Batch: 400; loss: 0.23; acc: 0.89
Batch: 420; loss: 0.25; acc: 0.92
Batch: 440; loss: 0.36; acc: 0.91
Batch: 460; loss: 0.22; acc: 0.94
Batch: 480; loss: 0.41; acc: 0.91
Batch: 500; loss: 0.27; acc: 0.92
Batch: 520; loss: 0.41; acc: 0.86
Batch: 540; loss: 0.3; acc: 0.88
Batch: 560; loss: 0.27; acc: 0.89
Batch: 580; loss: 0.23; acc: 0.94
Batch: 600; loss: 0.34; acc: 0.88
Batch: 620; loss: 0.33; acc: 0.88
Batch: 640; loss: 0.4; acc: 0.84
Batch: 660; loss: 0.19; acc: 0.97
Batch: 680; loss: 0.45; acc: 0.91
Batch: 700; loss: 0.28; acc: 0.91
Batch: 720; loss: 0.31; acc: 0.92
Batch: 740; loss: 0.29; acc: 0.95
Batch: 760; loss: 0.33; acc: 0.91
Batch: 780; loss: 0.39; acc: 0.92
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.553584818087984e-05
8.37058814795455e-06
Batch: 0; loss: 0.57; acc: 0.84
Batch: 20; loss: 0.48; acc: 0.86
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.39; acc: 0.89
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.37; acc: 0.91
Batch: 140; loss: 0.16; acc: 0.97
Val Epoch over. val_loss: 0.33515267045634567; val_accuracy: 0.8981886942675159 

The current subspace-distance is: 8.37058814795455e-06 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.24; acc: 0.91
Batch: 20; loss: 0.29; acc: 0.88
Batch: 40; loss: 0.26; acc: 0.89
Batch: 60; loss: 0.27; acc: 0.95
Batch: 80; loss: 0.36; acc: 0.89
Batch: 100; loss: 0.32; acc: 0.91
Batch: 120; loss: 0.28; acc: 0.91
Batch: 140; loss: 0.25; acc: 0.92
Batch: 160; loss: 0.39; acc: 0.83
Batch: 180; loss: 0.26; acc: 0.92
Batch: 200; loss: 0.16; acc: 0.94
Batch: 220; loss: 0.23; acc: 0.92
Batch: 240; loss: 0.26; acc: 0.94
Batch: 260; loss: 0.3; acc: 0.94
Batch: 280; loss: 0.34; acc: 0.91
Batch: 300; loss: 0.37; acc: 0.88
Batch: 320; loss: 0.52; acc: 0.84
Batch: 340; loss: 0.16; acc: 0.92
Batch: 360; loss: 0.28; acc: 0.95
Batch: 380; loss: 0.61; acc: 0.83
Batch: 400; loss: 0.36; acc: 0.88
Batch: 420; loss: 0.24; acc: 0.91
Batch: 440; loss: 0.38; acc: 0.88
Batch: 460; loss: 0.19; acc: 0.94
Batch: 480; loss: 0.43; acc: 0.89
Batch: 500; loss: 0.21; acc: 0.92
Batch: 520; loss: 0.39; acc: 0.84
Batch: 540; loss: 0.13; acc: 0.98
Batch: 560; loss: 0.2; acc: 0.91
Batch: 580; loss: 0.1; acc: 0.98
Batch: 600; loss: 0.33; acc: 0.89
Batch: 620; loss: 0.5; acc: 0.83
Batch: 640; loss: 0.24; acc: 0.89
Batch: 660; loss: 0.25; acc: 0.92
Batch: 680; loss: 0.34; acc: 0.89
Batch: 700; loss: 0.45; acc: 0.86
Batch: 720; loss: 0.43; acc: 0.88
Batch: 740; loss: 0.35; acc: 0.91
Batch: 760; loss: 0.33; acc: 0.89
Batch: 780; loss: 0.3; acc: 0.86
Train Epoch over. train_loss: 0.31; train_accuracy: 0.9 

2.4650693376315758e-05
8.143238119373564e-06
Batch: 0; loss: 0.53; acc: 0.83
Batch: 20; loss: 0.43; acc: 0.81
Batch: 40; loss: 0.17; acc: 0.97
Batch: 60; loss: 0.47; acc: 0.88
Batch: 80; loss: 0.25; acc: 0.91
Batch: 100; loss: 0.34; acc: 0.89
Batch: 120; loss: 0.35; acc: 0.88
Batch: 140; loss: 0.1; acc: 0.98
Val Epoch over. val_loss: 0.3054825394491481; val_accuracy: 0.9055533439490446 

The current subspace-distance is: 8.143238119373564e-06 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.54; acc: 0.84
Batch: 20; loss: 0.13; acc: 0.97
Batch: 40; loss: 0.31; acc: 0.91
Batch: 60; loss: 0.37; acc: 0.89
Batch: 80; loss: 0.45; acc: 0.89
Batch: 100; loss: 0.25; acc: 0.91
Batch: 120; loss: 0.33; acc: 0.91
Batch: 140; loss: 0.41; acc: 0.88
Batch: 160; loss: 0.37; acc: 0.88
Batch: 180; loss: 0.45; acc: 0.88
Batch: 200; loss: 0.2; acc: 0.94
Batch: 220; loss: 0.26; acc: 0.91
Batch: 240; loss: 0.14; acc: 0.95
Batch: 260; loss: 0.32; acc: 0.88
Batch: 280; loss: 0.39; acc: 0.88
Batch: 300; loss: 0.13; acc: 0.97
Batch: 320; loss: 0.28; acc: 0.89
Batch: 340; loss: 0.22; acc: 0.91
Batch: 360; loss: 0.17; acc: 0.94
Batch: 380; loss: 0.53; acc: 0.92
Batch: 400; loss: 0.27; acc: 0.92
Batch: 420; loss: 0.26; acc: 0.94
Batch: 440; loss: 0.21; acc: 0.92
Batch: 460; loss: 0.16; acc: 0.94
Batch: 480; loss: 0.3; acc: 0.91
Batch: 500; loss: 0.29; acc: 0.92
Batch: 520; loss: 0.16; acc: 0.95
Batch: 540; loss: 0.22; acc: 0.94
Batch: 560; loss: 0.18; acc: 0.92
Batch: 580; loss: 0.33; acc: 0.94
Batch: 600; loss: 0.23; acc: 0.94
Batch: 620; loss: 0.35; acc: 0.89
Batch: 640; loss: 0.25; acc: 0.89
Batch: 660; loss: 0.25; acc: 0.89
Batch: 680; loss: 0.27; acc: 0.91
Batch: 700; loss: 0.27; acc: 0.92
Batch: 720; loss: 0.39; acc: 0.89
Batch: 740; loss: 0.3; acc: 0.86
Batch: 760; loss: 0.38; acc: 0.86
Batch: 780; loss: 0.62; acc: 0.84
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.439517993479967e-05
7.273457413248252e-06
Batch: 0; loss: 0.53; acc: 0.83
Batch: 20; loss: 0.33; acc: 0.89
Batch: 40; loss: 0.13; acc: 0.98
Batch: 60; loss: 0.41; acc: 0.91
Batch: 80; loss: 0.23; acc: 0.95
Batch: 100; loss: 0.28; acc: 0.91
Batch: 120; loss: 0.26; acc: 0.94
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2706780256169617; val_accuracy: 0.916202229299363 

The current subspace-distance is: 7.273457413248252e-06 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.17; acc: 0.97
Batch: 20; loss: 0.25; acc: 0.91
Batch: 40; loss: 0.3; acc: 0.92
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.25; acc: 0.91
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.3; acc: 0.92
Batch: 140; loss: 0.24; acc: 0.91
Batch: 160; loss: 0.32; acc: 0.92
Batch: 180; loss: 0.22; acc: 0.94
Batch: 200; loss: 0.41; acc: 0.91
Batch: 220; loss: 0.21; acc: 0.94
Batch: 240; loss: 0.3; acc: 0.89
Batch: 260; loss: 0.3; acc: 0.91
Batch: 280; loss: 0.22; acc: 0.94
Batch: 300; loss: 0.28; acc: 0.92
Batch: 320; loss: 0.48; acc: 0.89
Batch: 340; loss: 0.2; acc: 0.94
Batch: 360; loss: 0.2; acc: 0.94
Batch: 380; loss: 0.31; acc: 0.91
Batch: 400; loss: 0.25; acc: 0.92
Batch: 420; loss: 0.36; acc: 0.91
Batch: 440; loss: 0.51; acc: 0.8
Batch: 460; loss: 0.45; acc: 0.88
Batch: 480; loss: 0.37; acc: 0.89
Batch: 500; loss: 0.24; acc: 0.92
Batch: 520; loss: 0.41; acc: 0.88
Batch: 540; loss: 0.35; acc: 0.88
Batch: 560; loss: 0.19; acc: 0.94
Batch: 580; loss: 0.32; acc: 0.94
Batch: 600; loss: 0.35; acc: 0.89
Batch: 620; loss: 0.3; acc: 0.89
Batch: 640; loss: 0.3; acc: 0.88
Batch: 660; loss: 0.27; acc: 0.94
Batch: 680; loss: 0.2; acc: 0.89
Batch: 700; loss: 0.23; acc: 0.89
Batch: 720; loss: 0.38; acc: 0.84
Batch: 740; loss: 0.29; acc: 0.89
Batch: 760; loss: 0.41; acc: 0.88
Batch: 780; loss: 0.28; acc: 0.94
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.504014082660433e-05
8.230323146563023e-06
Batch: 0; loss: 0.5; acc: 0.81
Batch: 20; loss: 0.39; acc: 0.84
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.38; acc: 0.91
Batch: 80; loss: 0.26; acc: 0.91
Batch: 100; loss: 0.31; acc: 0.89
Batch: 120; loss: 0.3; acc: 0.92
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.2791391813261494; val_accuracy: 0.9121218152866242 

The current subspace-distance is: 8.230323146563023e-06 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.3; acc: 0.89
Batch: 20; loss: 0.36; acc: 0.89
Batch: 40; loss: 0.44; acc: 0.89
Batch: 60; loss: 0.32; acc: 0.89
Batch: 80; loss: 0.49; acc: 0.88
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.57; acc: 0.81
Batch: 140; loss: 0.24; acc: 0.91
Batch: 160; loss: 0.41; acc: 0.88
Batch: 180; loss: 0.2; acc: 0.94
Batch: 200; loss: 0.44; acc: 0.89
Batch: 220; loss: 0.2; acc: 0.95
Batch: 240; loss: 0.47; acc: 0.84
Batch: 260; loss: 0.46; acc: 0.88
Batch: 280; loss: 0.15; acc: 0.94
Batch: 300; loss: 0.19; acc: 0.95
Batch: 320; loss: 0.34; acc: 0.92
Batch: 340; loss: 0.28; acc: 0.92
Batch: 360; loss: 0.43; acc: 0.89
Batch: 380; loss: 0.52; acc: 0.89
Batch: 400; loss: 0.24; acc: 0.92
Batch: 420; loss: 0.29; acc: 0.88
Batch: 440; loss: 0.62; acc: 0.83
Batch: 460; loss: 0.25; acc: 0.94
Batch: 480; loss: 0.26; acc: 0.88
Batch: 500; loss: 0.46; acc: 0.89
Batch: 520; loss: 0.38; acc: 0.89
Batch: 540; loss: 0.27; acc: 0.94
Batch: 560; loss: 0.3; acc: 0.91
Batch: 580; loss: 0.26; acc: 0.94
Batch: 600; loss: 0.25; acc: 0.92
Batch: 620; loss: 0.41; acc: 0.89
Batch: 640; loss: 0.32; acc: 0.91
Batch: 660; loss: 0.24; acc: 0.92
Batch: 680; loss: 0.1; acc: 0.98
Batch: 700; loss: 0.18; acc: 0.94
Batch: 720; loss: 0.26; acc: 0.92
Batch: 740; loss: 0.28; acc: 0.91
Batch: 760; loss: 0.12; acc: 0.97
Batch: 780; loss: 0.32; acc: 0.91
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.3096879885997623e-05
7.092662144714268e-06
Batch: 0; loss: 0.55; acc: 0.84
Batch: 20; loss: 0.36; acc: 0.88
Batch: 40; loss: 0.13; acc: 0.98
Batch: 60; loss: 0.4; acc: 0.89
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.27; acc: 0.91
Batch: 120; loss: 0.28; acc: 0.91
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.27299145998279; val_accuracy: 0.9166003184713376 

The current subspace-distance is: 7.092662144714268e-06 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.35; acc: 0.89
Batch: 20; loss: 0.36; acc: 0.88
Batch: 40; loss: 0.35; acc: 0.89
Batch: 60; loss: 0.3; acc: 0.92
Batch: 80; loss: 0.37; acc: 0.91
Batch: 100; loss: 0.36; acc: 0.88
Batch: 120; loss: 0.28; acc: 0.94
Batch: 140; loss: 0.43; acc: 0.8
Batch: 160; loss: 0.39; acc: 0.83
Batch: 180; loss: 0.25; acc: 0.92
Batch: 200; loss: 0.1; acc: 0.95
Batch: 220; loss: 0.54; acc: 0.86
Batch: 240; loss: 0.34; acc: 0.89
Batch: 260; loss: 0.26; acc: 0.92
Batch: 280; loss: 0.24; acc: 0.92
Batch: 300; loss: 0.3; acc: 0.91
Batch: 320; loss: 0.35; acc: 0.88
Batch: 340; loss: 0.37; acc: 0.89
Batch: 360; loss: 0.34; acc: 0.92
Batch: 380; loss: 0.25; acc: 0.89
Batch: 400; loss: 0.22; acc: 0.94
Batch: 420; loss: 0.36; acc: 0.91
Batch: 440; loss: 0.32; acc: 0.94
Batch: 460; loss: 0.2; acc: 0.95
Batch: 480; loss: 0.42; acc: 0.86
Batch: 500; loss: 0.23; acc: 0.89
Batch: 520; loss: 0.27; acc: 0.95
Batch: 540; loss: 0.35; acc: 0.92
Batch: 560; loss: 0.2; acc: 0.94
Batch: 580; loss: 0.21; acc: 0.91
Batch: 600; loss: 0.33; acc: 0.88
Batch: 620; loss: 0.22; acc: 0.91
Batch: 640; loss: 0.43; acc: 0.86
Batch: 660; loss: 0.26; acc: 0.91
Batch: 680; loss: 0.36; acc: 0.88
Batch: 700; loss: 0.22; acc: 0.94
Batch: 720; loss: 0.2; acc: 0.94
Batch: 740; loss: 0.35; acc: 0.91
Batch: 760; loss: 0.3; acc: 0.91
Batch: 780; loss: 0.53; acc: 0.8
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.659633719304111e-05
8.13090355222812e-06
Batch: 0; loss: 0.51; acc: 0.83
Batch: 20; loss: 0.3; acc: 0.88
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.45; acc: 0.89
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.27; acc: 0.91
Batch: 120; loss: 0.27; acc: 0.92
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.26523314843511886; val_accuracy: 0.9204816878980892 

The current subspace-distance is: 8.13090355222812e-06 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.35; acc: 0.91
Batch: 20; loss: 0.49; acc: 0.91
Batch: 40; loss: 0.48; acc: 0.88
Batch: 60; loss: 0.32; acc: 0.89
Batch: 80; loss: 0.39; acc: 0.81
Batch: 100; loss: 0.31; acc: 0.94
Batch: 120; loss: 0.26; acc: 0.91
Batch: 140; loss: 0.18; acc: 0.95
Batch: 160; loss: 0.36; acc: 0.92
Batch: 180; loss: 0.21; acc: 0.94
Batch: 200; loss: 0.29; acc: 0.94
Batch: 220; loss: 0.37; acc: 0.88
Batch: 240; loss: 0.4; acc: 0.94
Batch: 260; loss: 0.15; acc: 0.97
Batch: 280; loss: 0.24; acc: 0.91
Batch: 300; loss: 0.25; acc: 0.92
Batch: 320; loss: 0.16; acc: 0.97
Batch: 340; loss: 0.37; acc: 0.88
Batch: 360; loss: 0.14; acc: 0.97
Batch: 380; loss: 0.45; acc: 0.91
Batch: 400; loss: 0.27; acc: 0.92
Batch: 420; loss: 0.3; acc: 0.84
Batch: 440; loss: 0.29; acc: 0.89
Batch: 460; loss: 0.47; acc: 0.84
Batch: 480; loss: 0.38; acc: 0.86
Batch: 500; loss: 0.22; acc: 0.91
Batch: 520; loss: 0.25; acc: 0.92
Batch: 540; loss: 0.39; acc: 0.88
Batch: 560; loss: 0.4; acc: 0.88
Batch: 580; loss: 0.15; acc: 0.94
Batch: 600; loss: 0.19; acc: 0.95
Batch: 620; loss: 0.22; acc: 0.95
Batch: 640; loss: 0.25; acc: 0.95
Batch: 660; loss: 0.4; acc: 0.86
Batch: 680; loss: 0.31; acc: 0.89
Batch: 700; loss: 0.12; acc: 0.97
Batch: 720; loss: 0.3; acc: 0.88
Batch: 740; loss: 0.31; acc: 0.94
Batch: 760; loss: 0.51; acc: 0.83
Batch: 780; loss: 0.25; acc: 0.94
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.5021712644957006e-05
8.211767635657452e-06
Batch: 0; loss: 0.49; acc: 0.84
Batch: 20; loss: 0.32; acc: 0.88
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.4; acc: 0.89
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.27; acc: 0.94
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.26245792129427004; val_accuracy: 0.9204816878980892 

The current subspace-distance is: 8.211767635657452e-06 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.29; acc: 0.94
Batch: 20; loss: 0.46; acc: 0.84
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.34; acc: 0.94
Batch: 80; loss: 0.5; acc: 0.89
Batch: 100; loss: 0.36; acc: 0.86
Batch: 120; loss: 0.16; acc: 0.94
Batch: 140; loss: 0.22; acc: 0.95
Batch: 160; loss: 0.31; acc: 0.91
Batch: 180; loss: 0.13; acc: 0.97
Batch: 200; loss: 0.42; acc: 0.88
Batch: 220; loss: 0.31; acc: 0.91
Batch: 240; loss: 0.34; acc: 0.89
Batch: 260; loss: 0.24; acc: 0.89
Batch: 280; loss: 0.41; acc: 0.94
Batch: 300; loss: 0.4; acc: 0.89
Batch: 320; loss: 0.41; acc: 0.88
Batch: 340; loss: 0.32; acc: 0.94
Batch: 360; loss: 0.29; acc: 0.89
Batch: 380; loss: 0.4; acc: 0.89
Batch: 400; loss: 0.3; acc: 0.86
Batch: 420; loss: 0.21; acc: 0.95
Batch: 440; loss: 0.27; acc: 0.91
Batch: 460; loss: 0.25; acc: 0.92
Batch: 480; loss: 0.24; acc: 0.92
Batch: 500; loss: 0.26; acc: 0.91
Batch: 520; loss: 0.23; acc: 0.94
Batch: 540; loss: 0.23; acc: 0.92
Batch: 560; loss: 0.25; acc: 0.92
Batch: 580; loss: 0.18; acc: 0.94
Batch: 600; loss: 0.47; acc: 0.91
Batch: 620; loss: 0.44; acc: 0.83
Batch: 640; loss: 0.31; acc: 0.88
Batch: 660; loss: 0.52; acc: 0.78
Batch: 680; loss: 0.26; acc: 0.92
Batch: 700; loss: 0.32; acc: 0.89
Batch: 720; loss: 0.3; acc: 0.89
Batch: 740; loss: 0.25; acc: 0.92
Batch: 760; loss: 0.38; acc: 0.86
Batch: 780; loss: 0.1; acc: 0.98
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.4810433387756348e-05
8.243032425525598e-06
Batch: 0; loss: 0.52; acc: 0.81
Batch: 20; loss: 0.33; acc: 0.89
Batch: 40; loss: 0.16; acc: 0.97
Batch: 60; loss: 0.44; acc: 0.86
Batch: 80; loss: 0.24; acc: 0.97
Batch: 100; loss: 0.31; acc: 0.89
Batch: 120; loss: 0.29; acc: 0.89
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.279607798595717; val_accuracy: 0.9133160828025477 

The current subspace-distance is: 8.243032425525598e-06 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.16; acc: 0.94
Batch: 40; loss: 0.36; acc: 0.92
Batch: 60; loss: 0.3; acc: 0.92
Batch: 80; loss: 0.35; acc: 0.91
Batch: 100; loss: 0.28; acc: 0.92
Batch: 120; loss: 0.29; acc: 0.89
Batch: 140; loss: 0.29; acc: 0.92
Batch: 160; loss: 0.51; acc: 0.83
Batch: 180; loss: 0.27; acc: 0.91
Batch: 200; loss: 0.2; acc: 0.97
Batch: 220; loss: 0.24; acc: 0.89
Batch: 240; loss: 0.33; acc: 0.91
Batch: 260; loss: 0.29; acc: 0.94
Batch: 280; loss: 0.31; acc: 0.89
Batch: 300; loss: 0.23; acc: 0.92
Batch: 320; loss: 0.21; acc: 0.94
Batch: 340; loss: 0.24; acc: 0.91
Batch: 360; loss: 0.13; acc: 0.94
Batch: 380; loss: 0.45; acc: 0.89
Batch: 400; loss: 0.16; acc: 0.92
Batch: 420; loss: 0.74; acc: 0.81
Batch: 440; loss: 0.13; acc: 0.94
Batch: 460; loss: 0.25; acc: 0.91
Batch: 480; loss: 0.21; acc: 0.91
Batch: 500; loss: 0.23; acc: 0.95
Batch: 520; loss: 0.15; acc: 0.97
Batch: 540; loss: 0.3; acc: 0.92
Batch: 560; loss: 0.32; acc: 0.92
Batch: 580; loss: 0.45; acc: 0.84
Batch: 600; loss: 0.31; acc: 0.92
Batch: 620; loss: 0.45; acc: 0.88
Batch: 640; loss: 0.35; acc: 0.92
Batch: 660; loss: 0.44; acc: 0.91
Batch: 680; loss: 0.31; acc: 0.86
Batch: 700; loss: 0.46; acc: 0.89
Batch: 720; loss: 0.27; acc: 0.97
Batch: 740; loss: 0.28; acc: 0.91
Batch: 760; loss: 0.3; acc: 0.91
Batch: 780; loss: 0.25; acc: 0.91
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.397761636530049e-05
9.017942829814274e-06
Batch: 0; loss: 0.43; acc: 0.88
Batch: 20; loss: 0.35; acc: 0.88
Batch: 40; loss: 0.17; acc: 0.97
Batch: 60; loss: 0.39; acc: 0.88
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.32; acc: 0.89
Batch: 120; loss: 0.3; acc: 0.92
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.2733114254987164; val_accuracy: 0.9169984076433121 

The current subspace-distance is: 9.017942829814274e-06 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.44; acc: 0.89
Batch: 20; loss: 0.27; acc: 0.91
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.44; acc: 0.86
Batch: 80; loss: 0.3; acc: 0.91
Batch: 100; loss: 0.25; acc: 0.94
Batch: 120; loss: 0.21; acc: 0.91
Batch: 140; loss: 0.33; acc: 0.91
Batch: 160; loss: 0.27; acc: 0.89
Batch: 180; loss: 0.35; acc: 0.89
Batch: 200; loss: 0.25; acc: 0.92
Batch: 220; loss: 0.31; acc: 0.91
Batch: 240; loss: 0.37; acc: 0.89
Batch: 260; loss: 0.41; acc: 0.88
Batch: 280; loss: 0.19; acc: 0.94
Batch: 300; loss: 0.62; acc: 0.84
Batch: 320; loss: 0.27; acc: 0.94
Batch: 340; loss: 0.45; acc: 0.86
Batch: 360; loss: 0.31; acc: 0.89
Batch: 380; loss: 0.14; acc: 0.95
Batch: 400; loss: 0.19; acc: 0.92
Batch: 420; loss: 0.5; acc: 0.89
Batch: 440; loss: 0.31; acc: 0.89
Batch: 460; loss: 0.39; acc: 0.86
Batch: 480; loss: 0.39; acc: 0.86
Batch: 500; loss: 0.22; acc: 0.92
Batch: 520; loss: 0.24; acc: 0.94
Batch: 540; loss: 0.29; acc: 0.91
Batch: 560; loss: 0.21; acc: 0.89
Batch: 580; loss: 0.23; acc: 0.92
Batch: 600; loss: 0.26; acc: 0.94
Batch: 620; loss: 0.29; acc: 0.92
Batch: 640; loss: 0.08; acc: 0.98
Batch: 660; loss: 0.44; acc: 0.86
Batch: 680; loss: 0.23; acc: 0.94
Batch: 700; loss: 0.33; acc: 0.91
Batch: 720; loss: 0.33; acc: 0.86
Batch: 740; loss: 0.57; acc: 0.86
Batch: 760; loss: 0.38; acc: 0.86
Batch: 780; loss: 0.44; acc: 0.89
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.6364237783127464e-05
9.39656365517294e-06
Batch: 0; loss: 0.48; acc: 0.81
Batch: 20; loss: 0.33; acc: 0.83
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.41; acc: 0.88
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.26; acc: 0.91
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.26401843671586106; val_accuracy: 0.9183917197452229 

The current subspace-distance is: 9.39656365517294e-06 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.38; acc: 0.89
Batch: 20; loss: 0.27; acc: 0.94
Batch: 40; loss: 0.25; acc: 0.92
Batch: 60; loss: 0.32; acc: 0.92
Batch: 80; loss: 0.38; acc: 0.88
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.29; acc: 0.92
Batch: 140; loss: 0.28; acc: 0.92
Batch: 160; loss: 0.38; acc: 0.88
Batch: 180; loss: 0.42; acc: 0.88
Batch: 200; loss: 0.22; acc: 0.94
Batch: 220; loss: 0.3; acc: 0.88
Batch: 240; loss: 0.2; acc: 0.92
Batch: 260; loss: 0.7; acc: 0.78
Batch: 280; loss: 0.49; acc: 0.88
Batch: 300; loss: 0.34; acc: 0.91
Batch: 320; loss: 0.23; acc: 0.91
Batch: 340; loss: 0.21; acc: 0.91
Batch: 360; loss: 0.22; acc: 0.92
Batch: 380; loss: 0.25; acc: 0.94
Batch: 400; loss: 0.46; acc: 0.88
Batch: 420; loss: 0.37; acc: 0.88
Batch: 440; loss: 0.47; acc: 0.83
Batch: 460; loss: 0.3; acc: 0.92
Batch: 480; loss: 0.21; acc: 0.92
Batch: 500; loss: 0.17; acc: 0.95
Batch: 520; loss: 0.37; acc: 0.86
Batch: 540; loss: 0.22; acc: 0.91
Batch: 560; loss: 0.22; acc: 0.91
Batch: 580; loss: 0.24; acc: 0.94
Batch: 600; loss: 0.38; acc: 0.91
Batch: 620; loss: 0.29; acc: 0.89
Batch: 640; loss: 0.36; acc: 0.89
Batch: 660; loss: 0.21; acc: 0.92
Batch: 680; loss: 0.3; acc: 0.92
Batch: 700; loss: 0.25; acc: 0.92
Batch: 720; loss: 0.2; acc: 0.92
Batch: 740; loss: 0.23; acc: 0.92
Batch: 760; loss: 0.27; acc: 0.92
Batch: 780; loss: 0.2; acc: 0.97
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.3938056983752176e-05
9.224251698469743e-06
Batch: 0; loss: 0.56; acc: 0.8
Batch: 20; loss: 0.37; acc: 0.86
Batch: 40; loss: 0.13; acc: 0.98
Batch: 60; loss: 0.48; acc: 0.89
Batch: 80; loss: 0.26; acc: 0.92
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.32; acc: 0.89
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.281258931110619; val_accuracy: 0.9116242038216561 

The current subspace-distance is: 9.224251698469743e-06 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.21; acc: 0.91
Batch: 20; loss: 0.28; acc: 0.94
Batch: 40; loss: 0.35; acc: 0.92
Batch: 60; loss: 0.43; acc: 0.83
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.35; acc: 0.91
Batch: 120; loss: 0.24; acc: 0.91
Batch: 140; loss: 0.18; acc: 0.95
Batch: 160; loss: 0.39; acc: 0.84
Batch: 180; loss: 0.31; acc: 0.91
Batch: 200; loss: 0.16; acc: 0.94
Batch: 220; loss: 0.44; acc: 0.81
Batch: 240; loss: 0.25; acc: 0.91
Batch: 260; loss: 0.31; acc: 0.91
Batch: 280; loss: 0.22; acc: 0.89
Batch: 300; loss: 0.34; acc: 0.86
Batch: 320; loss: 0.37; acc: 0.84
Batch: 340; loss: 0.12; acc: 0.98
Batch: 360; loss: 0.3; acc: 0.94
Batch: 380; loss: 0.28; acc: 0.91
Batch: 400; loss: 0.34; acc: 0.89
Batch: 420; loss: 0.22; acc: 0.94
Batch: 440; loss: 0.43; acc: 0.88
Batch: 460; loss: 0.39; acc: 0.84
Batch: 480; loss: 0.24; acc: 0.95
Batch: 500; loss: 0.22; acc: 0.94
Batch: 520; loss: 0.32; acc: 0.91
Batch: 540; loss: 0.25; acc: 0.95
Batch: 560; loss: 0.27; acc: 0.91
Batch: 580; loss: 0.36; acc: 0.88
Batch: 600; loss: 0.23; acc: 0.89
Batch: 620; loss: 0.44; acc: 0.88
Batch: 640; loss: 0.42; acc: 0.88
Batch: 660; loss: 0.1; acc: 0.97
Batch: 680; loss: 0.26; acc: 0.94
Batch: 700; loss: 0.18; acc: 0.95
Batch: 720; loss: 0.21; acc: 0.98
Batch: 740; loss: 0.37; acc: 0.91
Batch: 760; loss: 0.24; acc: 0.89
Batch: 780; loss: 0.22; acc: 0.94
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.3643753593205474e-05
7.504903805966023e-06
Batch: 0; loss: 0.47; acc: 0.84
Batch: 20; loss: 0.35; acc: 0.88
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.39; acc: 0.89
Batch: 80; loss: 0.23; acc: 0.94
Batch: 100; loss: 0.31; acc: 0.89
Batch: 120; loss: 0.28; acc: 0.92
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.2651786289302407; val_accuracy: 0.9182921974522293 

The current subspace-distance is: 7.504903805966023e-06 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.34; acc: 0.89
Batch: 40; loss: 0.32; acc: 0.92
Batch: 60; loss: 0.12; acc: 0.97
Batch: 80; loss: 0.24; acc: 0.91
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.36; acc: 0.88
Batch: 140; loss: 0.57; acc: 0.81
Batch: 160; loss: 0.18; acc: 0.92
Batch: 180; loss: 0.3; acc: 0.89
Batch: 200; loss: 0.28; acc: 0.89
Batch: 220; loss: 0.18; acc: 0.95
Batch: 240; loss: 0.27; acc: 0.91
Batch: 260; loss: 0.2; acc: 0.94
Batch: 280; loss: 0.22; acc: 0.89
Batch: 300; loss: 0.38; acc: 0.89
Batch: 320; loss: 0.33; acc: 0.92
Batch: 340; loss: 0.25; acc: 0.89
Batch: 360; loss: 0.21; acc: 0.95
Batch: 380; loss: 0.22; acc: 0.95
Batch: 400; loss: 0.25; acc: 0.94
Batch: 420; loss: 0.3; acc: 0.91
Batch: 440; loss: 0.44; acc: 0.86
Batch: 460; loss: 0.54; acc: 0.88
Batch: 480; loss: 0.23; acc: 0.94
Batch: 500; loss: 0.11; acc: 0.98
Batch: 520; loss: 0.16; acc: 0.94
Batch: 540; loss: 0.19; acc: 0.92
Batch: 560; loss: 0.31; acc: 0.89
Batch: 580; loss: 0.29; acc: 0.95
Batch: 600; loss: 0.54; acc: 0.77
Batch: 620; loss: 0.15; acc: 0.95
Batch: 640; loss: 0.48; acc: 0.83
Batch: 660; loss: 0.35; acc: 0.92
Batch: 680; loss: 0.16; acc: 0.94
Batch: 700; loss: 0.31; acc: 0.91
Batch: 720; loss: 0.37; acc: 0.86
Batch: 740; loss: 0.37; acc: 0.91
Batch: 760; loss: 0.27; acc: 0.89
Batch: 780; loss: 0.28; acc: 0.94
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.544902599765919e-05
8.56897167977877e-06
Batch: 0; loss: 0.48; acc: 0.84
Batch: 20; loss: 0.34; acc: 0.88
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.4; acc: 0.89
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.29; acc: 0.89
Batch: 120; loss: 0.28; acc: 0.89
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.2603074640130541; val_accuracy: 0.9197850318471338 

The current subspace-distance is: 8.56897167977877e-06 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.22; acc: 0.95
Batch: 20; loss: 0.27; acc: 0.94
Batch: 40; loss: 0.23; acc: 0.95
Batch: 60; loss: 0.36; acc: 0.86
Batch: 80; loss: 0.42; acc: 0.89
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.3; acc: 0.86
Batch: 140; loss: 0.55; acc: 0.84
Batch: 160; loss: 0.14; acc: 0.97
Batch: 180; loss: 0.32; acc: 0.95
Batch: 200; loss: 0.37; acc: 0.89
Batch: 220; loss: 0.36; acc: 0.86
Batch: 240; loss: 0.13; acc: 0.97
Batch: 260; loss: 0.2; acc: 0.91
Batch: 280; loss: 0.56; acc: 0.83
Batch: 300; loss: 0.82; acc: 0.77
Batch: 320; loss: 0.22; acc: 0.92
Batch: 340; loss: 0.3; acc: 0.89
Batch: 360; loss: 0.21; acc: 0.94
Batch: 380; loss: 0.25; acc: 0.91
Batch: 400; loss: 0.2; acc: 0.92
Batch: 420; loss: 0.32; acc: 0.92
Batch: 440; loss: 0.31; acc: 0.92
Batch: 460; loss: 0.27; acc: 0.94
Batch: 480; loss: 0.19; acc: 0.92
Batch: 500; loss: 0.48; acc: 0.84
Batch: 520; loss: 0.29; acc: 0.94
Batch: 540; loss: 0.3; acc: 0.92
Batch: 560; loss: 0.3; acc: 0.91
Batch: 580; loss: 0.19; acc: 0.95
Batch: 600; loss: 0.27; acc: 0.91
Batch: 620; loss: 0.41; acc: 0.84
Batch: 640; loss: 0.19; acc: 0.91
Batch: 660; loss: 0.19; acc: 0.94
Batch: 680; loss: 0.28; acc: 0.88
Batch: 700; loss: 0.24; acc: 0.91
Batch: 720; loss: 0.17; acc: 0.92
Batch: 740; loss: 0.25; acc: 0.94
Batch: 760; loss: 0.16; acc: 0.94
Batch: 780; loss: 0.31; acc: 0.91
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.7732397938962094e-05
7.867738531786017e-06
Batch: 0; loss: 0.5; acc: 0.83
Batch: 20; loss: 0.38; acc: 0.83
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.39; acc: 0.89
Batch: 80; loss: 0.24; acc: 0.91
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.3; acc: 0.89
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.2674845251592861; val_accuracy: 0.9165007961783439 

The current subspace-distance is: 7.867738531786017e-06 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.23; acc: 0.92
Batch: 20; loss: 0.32; acc: 0.88
Batch: 40; loss: 0.24; acc: 0.92
Batch: 60; loss: 0.36; acc: 0.91
Batch: 80; loss: 0.16; acc: 0.92
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.26; acc: 0.89
Batch: 140; loss: 0.43; acc: 0.88
Batch: 160; loss: 0.28; acc: 0.92
Batch: 180; loss: 0.27; acc: 0.89
Batch: 200; loss: 0.25; acc: 0.92
Batch: 220; loss: 0.42; acc: 0.89
Batch: 240; loss: 0.31; acc: 0.91
Batch: 260; loss: 0.45; acc: 0.88
Batch: 280; loss: 0.16; acc: 0.97
Batch: 300; loss: 0.39; acc: 0.91
Batch: 320; loss: 0.25; acc: 0.89
Batch: 340; loss: 0.23; acc: 0.94
Batch: 360; loss: 0.21; acc: 0.97
Batch: 380; loss: 0.26; acc: 0.94
Batch: 400; loss: 0.17; acc: 0.95
Batch: 420; loss: 0.27; acc: 0.86
Batch: 440; loss: 0.38; acc: 0.92
Batch: 460; loss: 0.19; acc: 0.94
Batch: 480; loss: 0.29; acc: 0.92
Batch: 500; loss: 0.36; acc: 0.84
Batch: 520; loss: 0.16; acc: 0.97
Batch: 540; loss: 0.19; acc: 0.94
Batch: 560; loss: 0.23; acc: 0.91
Batch: 580; loss: 0.35; acc: 0.89
Batch: 600; loss: 0.34; acc: 0.89
Batch: 620; loss: 0.3; acc: 0.91
Batch: 640; loss: 0.53; acc: 0.84
Batch: 660; loss: 0.12; acc: 0.95
Batch: 680; loss: 0.39; acc: 0.89
Batch: 700; loss: 0.16; acc: 0.95
Batch: 720; loss: 0.37; acc: 0.91
Batch: 740; loss: 0.38; acc: 0.94
Batch: 760; loss: 0.31; acc: 0.89
Batch: 780; loss: 0.3; acc: 0.92
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.298889376106672e-05
7.899860975157935e-06
Batch: 0; loss: 0.47; acc: 0.84
Batch: 20; loss: 0.34; acc: 0.84
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.39; acc: 0.89
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.27; acc: 0.89
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.2603800089401045; val_accuracy: 0.9194864649681529 

The current subspace-distance is: 7.899860975157935e-06 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.31; acc: 0.89
Batch: 20; loss: 0.34; acc: 0.91
Batch: 40; loss: 0.41; acc: 0.86
Batch: 60; loss: 0.33; acc: 0.89
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.33; acc: 0.89
Batch: 120; loss: 0.36; acc: 0.88
Batch: 140; loss: 0.18; acc: 0.91
Batch: 160; loss: 0.29; acc: 0.91
Batch: 180; loss: 0.19; acc: 0.92
Batch: 200; loss: 0.45; acc: 0.88
Batch: 220; loss: 0.32; acc: 0.95
Batch: 240; loss: 0.13; acc: 0.98
Batch: 260; loss: 0.19; acc: 0.95
Batch: 280; loss: 0.14; acc: 0.94
Batch: 300; loss: 0.22; acc: 0.91
Batch: 320; loss: 0.48; acc: 0.86
Batch: 340; loss: 0.29; acc: 0.91
Batch: 360; loss: 0.25; acc: 0.94
Batch: 380; loss: 0.18; acc: 0.95
Batch: 400; loss: 0.34; acc: 0.91
Batch: 420; loss: 0.23; acc: 0.94
Batch: 440; loss: 0.27; acc: 0.88
Batch: 460; loss: 0.26; acc: 0.92
Batch: 480; loss: 0.12; acc: 0.95
Batch: 500; loss: 0.16; acc: 0.92
Batch: 520; loss: 0.11; acc: 0.97
Batch: 540; loss: 0.25; acc: 0.92
Batch: 560; loss: 0.36; acc: 0.89
Batch: 580; loss: 0.14; acc: 0.94
Batch: 600; loss: 0.25; acc: 0.91
Batch: 620; loss: 0.23; acc: 0.95
Batch: 640; loss: 0.13; acc: 0.97
Batch: 660; loss: 0.45; acc: 0.89
Batch: 680; loss: 0.36; acc: 0.86
Batch: 700; loss: 0.53; acc: 0.78
Batch: 720; loss: 0.3; acc: 0.88
Batch: 740; loss: 0.51; acc: 0.89
Batch: 760; loss: 0.21; acc: 0.95
Batch: 780; loss: 0.22; acc: 0.94
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.4462706278427504e-05
7.92387163528474e-06
Batch: 0; loss: 0.47; acc: 0.86
Batch: 20; loss: 0.34; acc: 0.84
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.41; acc: 0.89
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.28; acc: 0.94
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.2606634803733249; val_accuracy: 0.9214769108280255 

The current subspace-distance is: 7.92387163528474e-06 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.53; acc: 0.89
Batch: 20; loss: 0.2; acc: 0.92
Batch: 40; loss: 0.37; acc: 0.91
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.36; acc: 0.91
Batch: 140; loss: 0.17; acc: 0.94
Batch: 160; loss: 0.27; acc: 0.91
Batch: 180; loss: 0.2; acc: 0.94
Batch: 200; loss: 0.34; acc: 0.91
Batch: 220; loss: 0.36; acc: 0.94
Batch: 240; loss: 0.26; acc: 0.91
Batch: 260; loss: 0.41; acc: 0.84
Batch: 280; loss: 0.37; acc: 0.88
Batch: 300; loss: 0.28; acc: 0.89
Batch: 320; loss: 0.31; acc: 0.91
Batch: 340; loss: 0.24; acc: 0.91
Batch: 360; loss: 0.42; acc: 0.88
Batch: 380; loss: 0.22; acc: 0.92
Batch: 400; loss: 0.26; acc: 0.91
Batch: 420; loss: 0.26; acc: 0.91
Batch: 440; loss: 0.46; acc: 0.88
Batch: 460; loss: 0.2; acc: 0.97
Batch: 480; loss: 0.23; acc: 0.92
Batch: 500; loss: 0.23; acc: 0.92
Batch: 520; loss: 0.27; acc: 0.94
Batch: 540; loss: 0.41; acc: 0.86
Batch: 560; loss: 0.19; acc: 0.94
Batch: 580; loss: 0.47; acc: 0.89
Batch: 600; loss: 0.25; acc: 0.92
Batch: 620; loss: 0.23; acc: 0.89
Batch: 640; loss: 0.48; acc: 0.83
Batch: 660; loss: 0.17; acc: 0.94
Batch: 680; loss: 0.29; acc: 0.88
Batch: 700; loss: 0.18; acc: 0.94
Batch: 720; loss: 0.38; acc: 0.89
Batch: 740; loss: 0.35; acc: 0.91
Batch: 760; loss: 0.26; acc: 0.94
Batch: 780; loss: 0.18; acc: 0.97
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.5786102924030274e-05
7.982605893630534e-06
Batch: 0; loss: 0.51; acc: 0.84
Batch: 20; loss: 0.33; acc: 0.88
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.42; acc: 0.88
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.27; acc: 0.89
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.26086740912335693; val_accuracy: 0.919984076433121 

The current subspace-distance is: 7.982605893630534e-06 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.56; acc: 0.8
Batch: 40; loss: 0.37; acc: 0.91
Batch: 60; loss: 0.25; acc: 0.92
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.22; acc: 0.92
Batch: 120; loss: 0.23; acc: 0.92
Batch: 140; loss: 0.21; acc: 0.95
Batch: 160; loss: 0.13; acc: 0.95
Batch: 180; loss: 0.47; acc: 0.86
Batch: 200; loss: 0.13; acc: 0.97
Batch: 220; loss: 0.2; acc: 0.92
Batch: 240; loss: 0.26; acc: 0.89
Batch: 260; loss: 0.33; acc: 0.91
Batch: 280; loss: 0.58; acc: 0.86
Batch: 300; loss: 0.59; acc: 0.84
Batch: 320; loss: 0.29; acc: 0.94
Batch: 340; loss: 0.27; acc: 0.89
Batch: 360; loss: 0.33; acc: 0.89
Batch: 380; loss: 0.24; acc: 0.94
Batch: 400; loss: 0.12; acc: 0.98
Batch: 420; loss: 0.28; acc: 0.86
Batch: 440; loss: 0.2; acc: 0.94
Batch: 460; loss: 0.26; acc: 0.92
Batch: 480; loss: 0.36; acc: 0.91
Batch: 500; loss: 0.25; acc: 0.91
Batch: 520; loss: 0.3; acc: 0.92
Batch: 540; loss: 0.33; acc: 0.88
Batch: 560; loss: 0.2; acc: 0.94
Batch: 580; loss: 0.33; acc: 0.88
Batch: 600; loss: 0.28; acc: 0.94
Batch: 620; loss: 0.4; acc: 0.86
Batch: 640; loss: 0.56; acc: 0.84
Batch: 660; loss: 0.32; acc: 0.89
Batch: 680; loss: 0.21; acc: 0.94
Batch: 700; loss: 0.12; acc: 0.97
Batch: 720; loss: 0.18; acc: 0.97
Batch: 740; loss: 0.31; acc: 0.91
Batch: 760; loss: 0.39; acc: 0.86
Batch: 780; loss: 0.44; acc: 0.89
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.5551316866767593e-05
7.73385454522213e-06
Batch: 0; loss: 0.48; acc: 0.84
Batch: 20; loss: 0.34; acc: 0.86
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.41; acc: 0.89
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.28; acc: 0.91
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.2611081868789758; val_accuracy: 0.9198845541401274 

The current subspace-distance is: 7.73385454522213e-06 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.37; acc: 0.86
Batch: 40; loss: 0.34; acc: 0.86
Batch: 60; loss: 0.29; acc: 0.91
Batch: 80; loss: 0.23; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.97
Batch: 120; loss: 0.27; acc: 0.92
Batch: 140; loss: 0.16; acc: 0.98
Batch: 160; loss: 0.21; acc: 0.92
Batch: 180; loss: 0.21; acc: 0.94
Batch: 200; loss: 0.36; acc: 0.84
Batch: 220; loss: 0.42; acc: 0.88
Batch: 240; loss: 0.28; acc: 0.91
Batch: 260; loss: 0.19; acc: 0.92
Batch: 280; loss: 0.28; acc: 0.92
Batch: 300; loss: 0.42; acc: 0.86
Batch: 320; loss: 0.2; acc: 0.94
Batch: 340; loss: 0.52; acc: 0.84
Batch: 360; loss: 0.17; acc: 0.98
Batch: 380; loss: 0.22; acc: 0.95
Batch: 400; loss: 0.19; acc: 0.92
Batch: 420; loss: 0.17; acc: 0.95
Batch: 440; loss: 0.14; acc: 0.95
Batch: 460; loss: 0.26; acc: 0.89
Batch: 480; loss: 0.29; acc: 0.89
Batch: 500; loss: 0.19; acc: 0.91
Batch: 520; loss: 0.21; acc: 0.89
Batch: 540; loss: 0.38; acc: 0.86
Batch: 560; loss: 0.3; acc: 0.91
Batch: 580; loss: 0.4; acc: 0.89
Batch: 600; loss: 0.3; acc: 0.91
Batch: 620; loss: 0.16; acc: 0.94
Batch: 640; loss: 0.27; acc: 0.94
Batch: 660; loss: 0.23; acc: 0.92
Batch: 680; loss: 0.25; acc: 0.91
Batch: 700; loss: 0.44; acc: 0.89
Batch: 720; loss: 0.33; acc: 0.94
Batch: 740; loss: 0.17; acc: 0.94
Batch: 760; loss: 0.36; acc: 0.92
Batch: 780; loss: 0.38; acc: 0.88
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.4651975763845257e-05
8.200182492146268e-06
Batch: 0; loss: 0.53; acc: 0.8
Batch: 20; loss: 0.37; acc: 0.84
Batch: 40; loss: 0.13; acc: 0.98
Batch: 60; loss: 0.4; acc: 0.91
Batch: 80; loss: 0.24; acc: 0.92
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.28; acc: 0.89
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.26541997307235266; val_accuracy: 0.917296974522293 

The current subspace-distance is: 8.200182492146268e-06 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.21; acc: 0.91
Batch: 40; loss: 0.16; acc: 0.97
Batch: 60; loss: 0.33; acc: 0.89
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.32; acc: 0.95
Batch: 120; loss: 0.52; acc: 0.89
Batch: 140; loss: 0.5; acc: 0.84
Batch: 160; loss: 0.2; acc: 0.95
Batch: 180; loss: 0.24; acc: 0.88
Batch: 200; loss: 0.25; acc: 0.91
Batch: 220; loss: 0.41; acc: 0.86
Batch: 240; loss: 0.38; acc: 0.89
Batch: 260; loss: 0.25; acc: 0.91
Batch: 280; loss: 0.35; acc: 0.88
Batch: 300; loss: 0.28; acc: 0.89
Batch: 320; loss: 0.2; acc: 0.91
Batch: 340; loss: 0.18; acc: 0.95
Batch: 360; loss: 0.28; acc: 0.91
Batch: 380; loss: 0.2; acc: 0.95
Batch: 400; loss: 0.26; acc: 0.92
Batch: 420; loss: 0.3; acc: 0.92
Batch: 440; loss: 0.31; acc: 0.91
Batch: 460; loss: 0.38; acc: 0.94
Batch: 480; loss: 0.22; acc: 0.94
Batch: 500; loss: 0.2; acc: 0.92
Batch: 520; loss: 0.27; acc: 0.94
Batch: 540; loss: 0.4; acc: 0.89
Batch: 560; loss: 0.36; acc: 0.92
Batch: 580; loss: 0.31; acc: 0.88
Batch: 600; loss: 0.68; acc: 0.78
Batch: 620; loss: 0.27; acc: 0.91
Batch: 640; loss: 0.18; acc: 0.94
Batch: 660; loss: 0.18; acc: 0.92
Batch: 680; loss: 0.31; acc: 0.88
Batch: 700; loss: 0.26; acc: 0.91
Batch: 720; loss: 0.23; acc: 0.94
Batch: 740; loss: 0.32; acc: 0.86
Batch: 760; loss: 0.25; acc: 0.95
Batch: 780; loss: 0.34; acc: 0.88
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.6207226255792193e-05
7.676827408431564e-06
Batch: 0; loss: 0.49; acc: 0.84
Batch: 20; loss: 0.33; acc: 0.88
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.4; acc: 0.89
Batch: 80; loss: 0.21; acc: 0.97
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.28; acc: 0.89
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.26027144486926923; val_accuracy: 0.919984076433121 

The current subspace-distance is: 7.676827408431564e-06 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.53; acc: 0.83
Batch: 20; loss: 0.34; acc: 0.88
Batch: 40; loss: 0.25; acc: 0.94
Batch: 60; loss: 0.17; acc: 0.95
Batch: 80; loss: 0.32; acc: 0.95
Batch: 100; loss: 0.36; acc: 0.88
Batch: 120; loss: 0.41; acc: 0.89
Batch: 140; loss: 0.28; acc: 0.89
Batch: 160; loss: 0.3; acc: 0.94
Batch: 180; loss: 0.2; acc: 0.94
Batch: 200; loss: 0.27; acc: 0.89
Batch: 220; loss: 0.26; acc: 0.91
Batch: 240; loss: 0.42; acc: 0.83
Batch: 260; loss: 0.31; acc: 0.92
Batch: 280; loss: 0.21; acc: 0.91
Batch: 300; loss: 0.43; acc: 0.88
Batch: 320; loss: 0.31; acc: 0.94
Batch: 340; loss: 0.22; acc: 0.91
Batch: 360; loss: 0.12; acc: 0.95
Batch: 380; loss: 0.15; acc: 0.97
Batch: 400; loss: 0.26; acc: 0.92
Batch: 420; loss: 0.24; acc: 0.92
Batch: 440; loss: 0.08; acc: 0.98
Batch: 460; loss: 0.17; acc: 0.95
Batch: 480; loss: 0.16; acc: 0.97
Batch: 500; loss: 0.25; acc: 0.94
Batch: 520; loss: 0.43; acc: 0.89
Batch: 540; loss: 0.34; acc: 0.86
Batch: 560; loss: 0.25; acc: 0.94
Batch: 580; loss: 0.46; acc: 0.84
Batch: 600; loss: 0.31; acc: 0.89
Batch: 620; loss: 0.33; acc: 0.89
Batch: 640; loss: 0.28; acc: 0.92
Batch: 660; loss: 0.15; acc: 0.98
Batch: 680; loss: 0.18; acc: 0.92
Batch: 700; loss: 0.43; acc: 0.81
Batch: 720; loss: 0.46; acc: 0.83
Batch: 740; loss: 0.43; acc: 0.88
Batch: 760; loss: 0.15; acc: 0.97
Batch: 780; loss: 0.28; acc: 0.88
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.5879744498524815e-05
7.899937372712884e-06
Batch: 0; loss: 0.5; acc: 0.84
Batch: 20; loss: 0.36; acc: 0.86
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.39; acc: 0.89
Batch: 80; loss: 0.23; acc: 0.94
Batch: 100; loss: 0.31; acc: 0.89
Batch: 120; loss: 0.29; acc: 0.91
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.2634398208776857; val_accuracy: 0.9188893312101911 

The current subspace-distance is: 7.899937372712884e-06 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.29; acc: 0.86
Batch: 60; loss: 0.24; acc: 0.89
Batch: 80; loss: 0.29; acc: 0.92
Batch: 100; loss: 0.32; acc: 0.89
Batch: 120; loss: 0.19; acc: 0.94
Batch: 140; loss: 0.25; acc: 0.88
Batch: 160; loss: 0.57; acc: 0.81
Batch: 180; loss: 0.19; acc: 0.92
Batch: 200; loss: 0.27; acc: 0.89
Batch: 220; loss: 0.26; acc: 0.89
Batch: 240; loss: 0.3; acc: 0.86
Batch: 260; loss: 0.21; acc: 0.92
Batch: 280; loss: 0.43; acc: 0.81
Batch: 300; loss: 0.41; acc: 0.86
Batch: 320; loss: 0.31; acc: 0.89
Batch: 340; loss: 0.35; acc: 0.86
Batch: 360; loss: 0.17; acc: 0.95
Batch: 380; loss: 0.22; acc: 0.94
Batch: 400; loss: 0.22; acc: 0.94
Batch: 420; loss: 0.32; acc: 0.91
Batch: 440; loss: 0.23; acc: 0.91
Batch: 460; loss: 0.25; acc: 0.95
Batch: 480; loss: 0.22; acc: 0.92
Batch: 500; loss: 0.41; acc: 0.91
Batch: 520; loss: 0.14; acc: 0.98
Batch: 540; loss: 0.16; acc: 0.95
Batch: 560; loss: 0.18; acc: 0.94
Batch: 580; loss: 0.24; acc: 0.92
Batch: 600; loss: 0.3; acc: 0.91
Batch: 620; loss: 0.2; acc: 0.95
Batch: 640; loss: 0.16; acc: 0.95
Batch: 660; loss: 0.2; acc: 0.95
Batch: 680; loss: 0.37; acc: 0.89
Batch: 700; loss: 0.24; acc: 0.94
Batch: 720; loss: 0.27; acc: 0.94
Batch: 740; loss: 0.32; acc: 0.86
Batch: 760; loss: 0.23; acc: 0.94
Batch: 780; loss: 0.2; acc: 0.94
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.3996937670744956e-05
7.657038622710388e-06
Batch: 0; loss: 0.52; acc: 0.83
Batch: 20; loss: 0.36; acc: 0.84
Batch: 40; loss: 0.13; acc: 0.98
Batch: 60; loss: 0.39; acc: 0.89
Batch: 80; loss: 0.23; acc: 0.91
Batch: 100; loss: 0.3; acc: 0.89
Batch: 120; loss: 0.29; acc: 0.91
Batch: 140; loss: 0.09; acc: 0.98
Val Epoch over. val_loss: 0.2668373374042997; val_accuracy: 0.918093152866242 

The current subspace-distance is: 7.657038622710388e-06 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.3; acc: 0.88
Batch: 20; loss: 0.24; acc: 0.91
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.27; acc: 0.91
Batch: 100; loss: 0.44; acc: 0.86
Batch: 120; loss: 0.39; acc: 0.92
Batch: 140; loss: 0.32; acc: 0.89
Batch: 160; loss: 0.3; acc: 0.88
Batch: 180; loss: 0.35; acc: 0.91
Batch: 200; loss: 0.19; acc: 0.94
Batch: 220; loss: 0.35; acc: 0.91
Batch: 240; loss: 0.29; acc: 0.89
Batch: 260; loss: 0.17; acc: 0.95
Batch: 280; loss: 0.47; acc: 0.89
Batch: 300; loss: 0.2; acc: 0.94
Batch: 320; loss: 0.32; acc: 0.91
Batch: 340; loss: 0.17; acc: 0.94
Batch: 360; loss: 0.39; acc: 0.92
Batch: 380; loss: 0.53; acc: 0.89
Batch: 400; loss: 0.23; acc: 0.92
Batch: 420; loss: 0.25; acc: 0.92
Batch: 440; loss: 0.19; acc: 0.95
Batch: 460; loss: 0.36; acc: 0.84
Batch: 480; loss: 0.18; acc: 0.92
Batch: 500; loss: 0.07; acc: 1.0
Batch: 520; loss: 0.22; acc: 0.95
Batch: 540; loss: 0.21; acc: 0.94
Batch: 560; loss: 0.3; acc: 0.92
Batch: 580; loss: 0.41; acc: 0.86
Batch: 600; loss: 0.45; acc: 0.88
Batch: 620; loss: 0.21; acc: 0.94
Batch: 640; loss: 0.26; acc: 0.89
Batch: 660; loss: 0.35; acc: 0.92
Batch: 680; loss: 0.32; acc: 0.91
Batch: 700; loss: 0.29; acc: 0.94
Batch: 720; loss: 0.36; acc: 0.92
Batch: 740; loss: 0.17; acc: 0.95
Batch: 760; loss: 0.13; acc: 0.95
Batch: 780; loss: 0.19; acc: 0.94
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.5893119527609088e-05
7.5579255280899815e-06
Batch: 0; loss: 0.46; acc: 0.84
Batch: 20; loss: 0.34; acc: 0.88
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.39; acc: 0.89
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.28; acc: 0.91
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.25947522713690047; val_accuracy: 0.919187898089172 

The current subspace-distance is: 7.5579255280899815e-06 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.33; acc: 0.92
Batch: 60; loss: 0.18; acc: 0.92
Batch: 80; loss: 0.44; acc: 0.86
Batch: 100; loss: 0.19; acc: 0.92
Batch: 120; loss: 0.44; acc: 0.86
Batch: 140; loss: 0.28; acc: 0.92
Batch: 160; loss: 0.42; acc: 0.86
Batch: 180; loss: 0.4; acc: 0.89
Batch: 200; loss: 0.21; acc: 0.94
Batch: 220; loss: 0.24; acc: 0.91
Batch: 240; loss: 0.22; acc: 0.94
Batch: 260; loss: 0.19; acc: 0.94
Batch: 280; loss: 0.21; acc: 0.92
Batch: 300; loss: 0.13; acc: 0.95
Batch: 320; loss: 0.44; acc: 0.88
Batch: 340; loss: 0.16; acc: 0.94
Batch: 360; loss: 0.28; acc: 0.92
Batch: 380; loss: 0.15; acc: 0.95
Batch: 400; loss: 0.33; acc: 0.88
Batch: 420; loss: 0.28; acc: 0.88
Batch: 440; loss: 0.26; acc: 0.91
Batch: 460; loss: 0.26; acc: 0.91
Batch: 480; loss: 0.15; acc: 0.92
Batch: 500; loss: 0.43; acc: 0.88
Batch: 520; loss: 0.3; acc: 0.89
Batch: 540; loss: 0.2; acc: 0.95
Batch: 560; loss: 0.25; acc: 0.92
Batch: 580; loss: 0.4; acc: 0.86
Batch: 600; loss: 0.39; acc: 0.89
Batch: 620; loss: 0.18; acc: 0.95
Batch: 640; loss: 0.24; acc: 0.88
Batch: 660; loss: 0.47; acc: 0.84
Batch: 680; loss: 0.25; acc: 0.91
Batch: 700; loss: 0.25; acc: 0.92
Batch: 720; loss: 0.33; acc: 0.88
Batch: 740; loss: 0.21; acc: 0.92
Batch: 760; loss: 0.14; acc: 0.95
Batch: 780; loss: 0.28; acc: 0.92
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.5205530619132333e-05
7.364474186033476e-06
Batch: 0; loss: 0.47; acc: 0.83
Batch: 20; loss: 0.34; acc: 0.88
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.39; acc: 0.89
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.3; acc: 0.89
Batch: 120; loss: 0.28; acc: 0.91
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.25918192307280885; val_accuracy: 0.9194864649681529 

The current subspace-distance is: 7.364474186033476e-06 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.36; acc: 0.88
Batch: 20; loss: 0.39; acc: 0.94
Batch: 40; loss: 0.27; acc: 0.89
Batch: 60; loss: 0.28; acc: 0.92
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.28; acc: 0.89
Batch: 120; loss: 0.26; acc: 0.92
Batch: 140; loss: 0.16; acc: 0.95
Batch: 160; loss: 0.12; acc: 0.97
Batch: 180; loss: 0.42; acc: 0.91
Batch: 200; loss: 0.17; acc: 0.92
Batch: 220; loss: 0.3; acc: 0.91
Batch: 240; loss: 0.41; acc: 0.86
Batch: 260; loss: 0.37; acc: 0.92
Batch: 280; loss: 0.17; acc: 0.95
Batch: 300; loss: 0.27; acc: 0.89
Batch: 320; loss: 0.18; acc: 0.95
Batch: 340; loss: 0.21; acc: 0.95
Batch: 360; loss: 0.15; acc: 0.95
Batch: 380; loss: 0.33; acc: 0.91
Batch: 400; loss: 0.18; acc: 0.92
Batch: 420; loss: 0.33; acc: 0.89
Batch: 440; loss: 0.2; acc: 0.97
Batch: 460; loss: 0.29; acc: 0.91
Batch: 480; loss: 0.38; acc: 0.89
Batch: 500; loss: 0.26; acc: 0.91
Batch: 520; loss: 0.44; acc: 0.84
Batch: 540; loss: 0.44; acc: 0.84
Batch: 560; loss: 0.23; acc: 0.94
Batch: 580; loss: 0.45; acc: 0.84
Batch: 600; loss: 0.38; acc: 0.92
Batch: 620; loss: 0.22; acc: 0.94
Batch: 640; loss: 0.13; acc: 0.94
Batch: 660; loss: 0.14; acc: 0.95
Batch: 680; loss: 0.28; acc: 0.92
Batch: 700; loss: 0.25; acc: 0.91
Batch: 720; loss: 0.45; acc: 0.91
Batch: 740; loss: 0.44; acc: 0.91
Batch: 760; loss: 0.26; acc: 0.92
Batch: 780; loss: 0.3; acc: 0.86
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.6003765015047975e-05
8.215708476200234e-06
Batch: 0; loss: 0.48; acc: 0.84
Batch: 20; loss: 0.33; acc: 0.88
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.41; acc: 0.89
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.28; acc: 0.89
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.2589465113012654; val_accuracy: 0.9194864649681529 

The current subspace-distance is: 8.215708476200234e-06 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.2; acc: 0.92
Batch: 20; loss: 0.58; acc: 0.81
Batch: 40; loss: 0.1; acc: 0.98
Batch: 60; loss: 0.48; acc: 0.88
Batch: 80; loss: 0.41; acc: 0.89
Batch: 100; loss: 0.54; acc: 0.83
Batch: 120; loss: 0.26; acc: 0.91
Batch: 140; loss: 0.32; acc: 0.88
Batch: 160; loss: 0.37; acc: 0.92
Batch: 180; loss: 0.25; acc: 0.94
Batch: 200; loss: 0.17; acc: 0.94
Batch: 220; loss: 0.39; acc: 0.86
Batch: 240; loss: 0.34; acc: 0.88
Batch: 260; loss: 0.38; acc: 0.86
Batch: 280; loss: 0.36; acc: 0.88
Batch: 300; loss: 0.3; acc: 0.89
Batch: 320; loss: 0.33; acc: 0.91
Batch: 340; loss: 0.29; acc: 0.94
Batch: 360; loss: 0.19; acc: 0.94
Batch: 380; loss: 0.52; acc: 0.89
Batch: 400; loss: 0.49; acc: 0.78
Batch: 420; loss: 0.2; acc: 0.91
Batch: 440; loss: 0.39; acc: 0.92
Batch: 460; loss: 0.19; acc: 0.94
Batch: 480; loss: 0.41; acc: 0.86
Batch: 500; loss: 0.4; acc: 0.95
Batch: 520; loss: 0.24; acc: 0.91
Batch: 540; loss: 0.28; acc: 0.92
Batch: 560; loss: 0.2; acc: 0.95
Batch: 580; loss: 0.43; acc: 0.88
Batch: 600; loss: 0.22; acc: 0.92
Batch: 620; loss: 0.32; acc: 0.89
Batch: 640; loss: 0.41; acc: 0.89
Batch: 660; loss: 0.56; acc: 0.86
Batch: 680; loss: 0.24; acc: 0.92
Batch: 700; loss: 0.19; acc: 0.95
Batch: 720; loss: 0.15; acc: 0.97
Batch: 740; loss: 0.65; acc: 0.86
Batch: 760; loss: 0.27; acc: 0.91
Batch: 780; loss: 0.11; acc: 0.97
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.65432900050655e-05
8.63784589455463e-06
Batch: 0; loss: 0.49; acc: 0.83
Batch: 20; loss: 0.35; acc: 0.86
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.4; acc: 0.89
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.28; acc: 0.91
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.26043151380719654; val_accuracy: 0.9189888535031847 

The current subspace-distance is: 8.63784589455463e-06 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.14; acc: 0.97
Batch: 40; loss: 0.25; acc: 0.92
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.29; acc: 0.92
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.24; acc: 0.97
Batch: 140; loss: 0.24; acc: 0.95
Batch: 160; loss: 0.23; acc: 0.95
Batch: 180; loss: 0.19; acc: 0.94
Batch: 200; loss: 0.2; acc: 0.95
Batch: 220; loss: 0.23; acc: 0.94
Batch: 240; loss: 0.29; acc: 0.92
Batch: 260; loss: 0.25; acc: 0.92
Batch: 280; loss: 0.36; acc: 0.92
Batch: 300; loss: 0.24; acc: 0.92
Batch: 320; loss: 0.24; acc: 0.91
Batch: 340; loss: 0.16; acc: 0.92
Batch: 360; loss: 0.37; acc: 0.92
Batch: 380; loss: 0.24; acc: 0.94
Batch: 400; loss: 0.23; acc: 0.94
Batch: 420; loss: 0.28; acc: 0.94
Batch: 440; loss: 0.36; acc: 0.86
Batch: 460; loss: 0.18; acc: 0.95
Batch: 480; loss: 0.2; acc: 0.92
Batch: 500; loss: 0.15; acc: 0.92
Batch: 520; loss: 0.18; acc: 0.94
Batch: 540; loss: 0.25; acc: 0.98
Batch: 560; loss: 0.13; acc: 0.98
Batch: 580; loss: 0.21; acc: 0.95
Batch: 600; loss: 0.42; acc: 0.88
Batch: 620; loss: 0.21; acc: 0.92
Batch: 640; loss: 0.28; acc: 0.89
Batch: 660; loss: 0.46; acc: 0.88
Batch: 680; loss: 0.42; acc: 0.88
Batch: 700; loss: 0.28; acc: 0.91
Batch: 720; loss: 0.46; acc: 0.86
Batch: 740; loss: 0.44; acc: 0.86
Batch: 760; loss: 0.31; acc: 0.92
Batch: 780; loss: 0.26; acc: 0.92
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.583533751021605e-05
8.292732672998682e-06
Batch: 0; loss: 0.47; acc: 0.83
Batch: 20; loss: 0.35; acc: 0.86
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.39; acc: 0.89
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.3; acc: 0.89
Batch: 120; loss: 0.28; acc: 0.89
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.26002600632465567; val_accuracy: 0.9190883757961783 

The current subspace-distance is: 8.292732672998682e-06 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.22; acc: 0.92
Batch: 20; loss: 0.34; acc: 0.91
Batch: 40; loss: 0.2; acc: 0.91
Batch: 60; loss: 0.3; acc: 0.89
Batch: 80; loss: 0.32; acc: 0.88
Batch: 100; loss: 0.35; acc: 0.84
Batch: 120; loss: 0.3; acc: 0.94
Batch: 140; loss: 0.33; acc: 0.89
Batch: 160; loss: 0.31; acc: 0.86
Batch: 180; loss: 0.26; acc: 0.95
Batch: 200; loss: 0.29; acc: 0.88
Batch: 220; loss: 0.35; acc: 0.91
Batch: 240; loss: 0.13; acc: 0.97
Batch: 260; loss: 0.11; acc: 0.95
Batch: 280; loss: 0.46; acc: 0.89
Batch: 300; loss: 0.32; acc: 0.91
Batch: 320; loss: 0.42; acc: 0.88
Batch: 340; loss: 0.21; acc: 0.91
Batch: 360; loss: 0.34; acc: 0.86
Batch: 380; loss: 0.32; acc: 0.89
Batch: 400; loss: 0.25; acc: 0.91
Batch: 420; loss: 0.33; acc: 0.89
Batch: 440; loss: 0.36; acc: 0.91
Batch: 460; loss: 0.44; acc: 0.91
Batch: 480; loss: 0.54; acc: 0.84
Batch: 500; loss: 0.41; acc: 0.89
Batch: 520; loss: 0.42; acc: 0.89
Batch: 540; loss: 0.43; acc: 0.86
Batch: 560; loss: 0.29; acc: 0.92
Batch: 580; loss: 0.24; acc: 0.94
Batch: 600; loss: 0.17; acc: 0.95
Batch: 620; loss: 0.37; acc: 0.91
Batch: 640; loss: 0.32; acc: 0.86
Batch: 660; loss: 0.22; acc: 0.94
Batch: 680; loss: 0.16; acc: 0.92
Batch: 700; loss: 0.21; acc: 0.91
Batch: 720; loss: 0.31; acc: 0.92
Batch: 740; loss: 0.16; acc: 0.97
Batch: 760; loss: 0.38; acc: 0.91
Batch: 780; loss: 0.22; acc: 0.89
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.666565342224203e-05
7.763167559460271e-06
Batch: 0; loss: 0.47; acc: 0.84
Batch: 20; loss: 0.34; acc: 0.88
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.41; acc: 0.89
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.28; acc: 0.91
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.25967483004187325; val_accuracy: 0.9194864649681529 

The current subspace-distance is: 7.763167559460271e-06 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.23; acc: 0.94
Batch: 40; loss: 0.27; acc: 0.91
Batch: 60; loss: 0.27; acc: 0.94
Batch: 80; loss: 0.38; acc: 0.89
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.28; acc: 0.92
Batch: 140; loss: 0.47; acc: 0.86
Batch: 160; loss: 0.43; acc: 0.91
Batch: 180; loss: 0.34; acc: 0.86
Batch: 200; loss: 0.31; acc: 0.89
Batch: 220; loss: 0.18; acc: 0.97
Batch: 240; loss: 0.2; acc: 0.92
Batch: 260; loss: 0.28; acc: 0.89
Batch: 280; loss: 0.11; acc: 0.97
Batch: 300; loss: 0.24; acc: 0.94
Batch: 320; loss: 0.37; acc: 0.89
Batch: 340; loss: 0.31; acc: 0.89
Batch: 360; loss: 0.33; acc: 0.91
Batch: 380; loss: 0.3; acc: 0.92
Batch: 400; loss: 0.24; acc: 0.91
Batch: 420; loss: 0.28; acc: 0.92
Batch: 440; loss: 0.28; acc: 0.89
Batch: 460; loss: 0.38; acc: 0.88
Batch: 480; loss: 0.32; acc: 0.88
Batch: 500; loss: 0.21; acc: 0.92
Batch: 520; loss: 0.28; acc: 0.92
Batch: 540; loss: 0.28; acc: 0.94
Batch: 560; loss: 0.23; acc: 0.94
Batch: 580; loss: 0.23; acc: 0.94
Batch: 600; loss: 0.3; acc: 0.88
Batch: 620; loss: 0.22; acc: 0.94
Batch: 640; loss: 0.11; acc: 0.98
Batch: 660; loss: 0.22; acc: 0.94
Batch: 680; loss: 0.49; acc: 0.86
Batch: 700; loss: 0.51; acc: 0.91
Batch: 720; loss: 0.33; acc: 0.91
Batch: 740; loss: 0.37; acc: 0.86
Batch: 760; loss: 0.33; acc: 0.89
Batch: 780; loss: 0.2; acc: 0.94
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.4104901967803016e-05
8.094492841337342e-06
Batch: 0; loss: 0.48; acc: 0.84
Batch: 20; loss: 0.34; acc: 0.86
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.39; acc: 0.89
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.29; acc: 0.89
Batch: 120; loss: 0.28; acc: 0.91
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.2594567058477432; val_accuracy: 0.9195859872611465 

The current subspace-distance is: 8.094492841337342e-06 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.28; acc: 0.86
Batch: 40; loss: 0.13; acc: 0.94
Batch: 60; loss: 0.3; acc: 0.91
Batch: 80; loss: 0.37; acc: 0.88
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.23; acc: 0.95
Batch: 140; loss: 0.38; acc: 0.88
Batch: 160; loss: 0.29; acc: 0.91
Batch: 180; loss: 0.22; acc: 0.94
Batch: 200; loss: 0.23; acc: 0.92
Batch: 220; loss: 0.09; acc: 0.97
Batch: 240; loss: 0.24; acc: 0.92
Batch: 260; loss: 0.42; acc: 0.89
Batch: 280; loss: 0.41; acc: 0.88
Batch: 300; loss: 0.29; acc: 0.91
Batch: 320; loss: 0.19; acc: 0.94
Batch: 340; loss: 0.16; acc: 0.94
Batch: 360; loss: 0.29; acc: 0.91
Batch: 380; loss: 0.25; acc: 0.94
Batch: 400; loss: 0.2; acc: 0.94
Batch: 420; loss: 0.26; acc: 0.94
Batch: 440; loss: 0.16; acc: 0.92
Batch: 460; loss: 0.14; acc: 0.97
Batch: 480; loss: 0.41; acc: 0.92
Batch: 500; loss: 0.42; acc: 0.88
Batch: 520; loss: 0.17; acc: 0.95
Batch: 540; loss: 0.49; acc: 0.88
Batch: 560; loss: 0.27; acc: 0.92
Batch: 580; loss: 0.15; acc: 0.94
Batch: 600; loss: 0.3; acc: 0.91
Batch: 620; loss: 0.28; acc: 0.91
Batch: 640; loss: 0.27; acc: 0.95
Batch: 660; loss: 0.12; acc: 0.94
Batch: 680; loss: 0.22; acc: 0.94
Batch: 700; loss: 0.2; acc: 0.92
Batch: 720; loss: 0.3; acc: 0.91
Batch: 740; loss: 0.35; acc: 0.91
Batch: 760; loss: 0.39; acc: 0.86
Batch: 780; loss: 0.19; acc: 0.95
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.5424575142096728e-05
1.0043259862868581e-05
Batch: 0; loss: 0.47; acc: 0.84
Batch: 20; loss: 0.34; acc: 0.88
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.39; acc: 0.89
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.29; acc: 0.89
Batch: 120; loss: 0.28; acc: 0.91
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.26050472325959784; val_accuracy: 0.919187898089172 

The current subspace-distance is: 1.0043259862868581e-05 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.18; acc: 0.92
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.4; acc: 0.86
Batch: 80; loss: 0.37; acc: 0.92
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.18; acc: 0.97
Batch: 140; loss: 0.39; acc: 0.92
Batch: 160; loss: 0.25; acc: 0.91
Batch: 180; loss: 0.3; acc: 0.91
Batch: 200; loss: 0.32; acc: 0.89
Batch: 220; loss: 0.28; acc: 0.91
Batch: 240; loss: 0.09; acc: 0.98
Batch: 260; loss: 0.26; acc: 0.95
Batch: 280; loss: 0.32; acc: 0.91
Batch: 300; loss: 0.22; acc: 0.92
Batch: 320; loss: 0.14; acc: 0.98
Batch: 340; loss: 0.46; acc: 0.88
Batch: 360; loss: 0.35; acc: 0.86
Batch: 380; loss: 0.37; acc: 0.88
Batch: 400; loss: 0.35; acc: 0.94
Batch: 420; loss: 0.21; acc: 0.94
Batch: 440; loss: 0.21; acc: 0.94
Batch: 460; loss: 0.15; acc: 0.95
Batch: 480; loss: 0.27; acc: 0.92
Batch: 500; loss: 0.33; acc: 0.88
Batch: 520; loss: 0.39; acc: 0.91
Batch: 540; loss: 0.32; acc: 0.91
Batch: 560; loss: 0.28; acc: 0.89
Batch: 580; loss: 0.14; acc: 0.95
Batch: 600; loss: 0.28; acc: 0.92
Batch: 620; loss: 0.21; acc: 0.97
Batch: 640; loss: 0.26; acc: 0.94
Batch: 660; loss: 0.18; acc: 0.95
Batch: 680; loss: 0.21; acc: 0.95
Batch: 700; loss: 0.14; acc: 0.95
Batch: 720; loss: 0.3; acc: 0.89
Batch: 740; loss: 0.27; acc: 0.91
Batch: 760; loss: 0.35; acc: 0.89
Batch: 780; loss: 0.46; acc: 0.88
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.4691729777259752e-05
9.048157153301872e-06
Batch: 0; loss: 0.49; acc: 0.83
Batch: 20; loss: 0.36; acc: 0.84
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.39; acc: 0.89
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.29; acc: 0.89
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.2609415850157191; val_accuracy: 0.9184912420382165 

The current subspace-distance is: 9.048157153301872e-06 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.3; acc: 0.92
Batch: 40; loss: 0.42; acc: 0.89
Batch: 60; loss: 0.26; acc: 0.88
Batch: 80; loss: 0.51; acc: 0.89
Batch: 100; loss: 0.37; acc: 0.89
Batch: 120; loss: 0.18; acc: 0.92
Batch: 140; loss: 0.46; acc: 0.89
Batch: 160; loss: 0.21; acc: 0.91
Batch: 180; loss: 0.27; acc: 0.89
Batch: 200; loss: 0.37; acc: 0.89
Batch: 220; loss: 0.2; acc: 0.97
Batch: 240; loss: 0.23; acc: 0.94
Batch: 260; loss: 0.46; acc: 0.86
Batch: 280; loss: 0.27; acc: 0.92
Batch: 300; loss: 0.19; acc: 0.92
Batch: 320; loss: 0.24; acc: 0.91
Batch: 340; loss: 0.25; acc: 0.91
Batch: 360; loss: 0.41; acc: 0.88
Batch: 380; loss: 0.38; acc: 0.91
Batch: 400; loss: 0.32; acc: 0.89
Batch: 420; loss: 0.21; acc: 0.91
Batch: 440; loss: 0.38; acc: 0.89
Batch: 460; loss: 0.19; acc: 0.95
Batch: 480; loss: 0.33; acc: 0.88
Batch: 500; loss: 0.26; acc: 0.94
Batch: 520; loss: 0.26; acc: 0.88
Batch: 540; loss: 0.25; acc: 0.92
Batch: 560; loss: 0.6; acc: 0.83
Batch: 580; loss: 0.4; acc: 0.91
Batch: 600; loss: 0.28; acc: 0.89
Batch: 620; loss: 0.26; acc: 0.92
Batch: 640; loss: 0.25; acc: 0.91
Batch: 660; loss: 0.18; acc: 0.95
Batch: 680; loss: 0.26; acc: 0.94
Batch: 700; loss: 0.4; acc: 0.84
Batch: 720; loss: 0.14; acc: 0.97
Batch: 740; loss: 0.29; acc: 0.91
Batch: 760; loss: 0.2; acc: 0.95
Batch: 780; loss: 0.32; acc: 0.89
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.5281373382313177e-05
8.454227099718992e-06
Batch: 0; loss: 0.48; acc: 0.84
Batch: 20; loss: 0.34; acc: 0.88
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.4; acc: 0.89
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.28; acc: 0.89
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.25878379071594043; val_accuracy: 0.9197850318471338 

The current subspace-distance is: 8.454227099718992e-06 

plots/subspace_training/reg_lenet_3/2020-01-22 20:51:04/d_dim_150_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
nonzero elements in E: 33978
elements in E: 7198400
fraction nonzero: 0.004720215603467437
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.31; acc: 0.08
Batch: 20; loss: 2.29; acc: 0.06
Batch: 40; loss: 2.3; acc: 0.11
Batch: 60; loss: 2.3; acc: 0.02
Batch: 80; loss: 2.3; acc: 0.08
Batch: 100; loss: 2.3; acc: 0.12
Batch: 120; loss: 2.3; acc: 0.11
Batch: 140; loss: 2.31; acc: 0.08
Batch: 160; loss: 2.3; acc: 0.08
Batch: 180; loss: 2.3; acc: 0.11
Batch: 200; loss: 2.29; acc: 0.14
Batch: 220; loss: 2.31; acc: 0.06
Batch: 240; loss: 2.31; acc: 0.05
Batch: 260; loss: 2.3; acc: 0.09
Batch: 280; loss: 2.28; acc: 0.06
Batch: 300; loss: 2.29; acc: 0.05
Batch: 320; loss: 2.3; acc: 0.11
Batch: 340; loss: 2.3; acc: 0.06
Batch: 360; loss: 2.28; acc: 0.16
Batch: 380; loss: 2.3; acc: 0.16
Batch: 400; loss: 2.3; acc: 0.17
Batch: 420; loss: 2.31; acc: 0.08
Batch: 440; loss: 2.29; acc: 0.23
Batch: 460; loss: 2.29; acc: 0.14
Batch: 480; loss: 2.29; acc: 0.11
Batch: 500; loss: 2.28; acc: 0.14
Batch: 520; loss: 2.27; acc: 0.25
Batch: 540; loss: 2.28; acc: 0.16
Batch: 560; loss: 2.27; acc: 0.23
Batch: 580; loss: 2.26; acc: 0.22
Batch: 600; loss: 2.27; acc: 0.23
Batch: 620; loss: 2.25; acc: 0.25
Batch: 640; loss: 2.25; acc: 0.23
Batch: 660; loss: 2.25; acc: 0.17
Batch: 680; loss: 2.28; acc: 0.09
Batch: 700; loss: 2.27; acc: 0.17
Batch: 720; loss: 2.26; acc: 0.17
Batch: 740; loss: 2.23; acc: 0.34
Batch: 760; loss: 2.26; acc: 0.19
Batch: 780; loss: 2.22; acc: 0.19
Train Epoch over. train_loss: 2.28; train_accuracy: 0.14 

6.29631267656805e-06
1.8940903601105674e-06
Batch: 0; loss: 2.21; acc: 0.27
Batch: 20; loss: 2.23; acc: 0.27
Batch: 40; loss: 2.2; acc: 0.31
Batch: 60; loss: 2.22; acc: 0.27
Batch: 80; loss: 2.2; acc: 0.19
Batch: 100; loss: 2.21; acc: 0.33
Batch: 120; loss: 2.23; acc: 0.25
Batch: 140; loss: 2.23; acc: 0.19
Val Epoch over. val_loss: 2.2175360956009786; val_accuracy: 0.24532245222929935 

The current subspace-distance is: 1.8940903601105674e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 2.25; acc: 0.17
Batch: 20; loss: 2.19; acc: 0.33
Batch: 40; loss: 2.2; acc: 0.22
Batch: 60; loss: 2.1; acc: 0.38
Batch: 80; loss: 2.12; acc: 0.36
Batch: 100; loss: 2.15; acc: 0.38
Batch: 120; loss: 2.03; acc: 0.3
Batch: 140; loss: 1.91; acc: 0.42
Batch: 160; loss: 1.8; acc: 0.45
Batch: 180; loss: 1.7; acc: 0.44
Batch: 200; loss: 1.44; acc: 0.53
Batch: 220; loss: 1.42; acc: 0.56
Batch: 240; loss: 1.06; acc: 0.64
Batch: 260; loss: 1.3; acc: 0.55
Batch: 280; loss: 0.99; acc: 0.73
Batch: 300; loss: 0.86; acc: 0.78
Batch: 320; loss: 0.91; acc: 0.77
Batch: 340; loss: 1.31; acc: 0.59
Batch: 360; loss: 0.81; acc: 0.77
Batch: 380; loss: 0.83; acc: 0.72
Batch: 400; loss: 0.77; acc: 0.72
Batch: 420; loss: 0.93; acc: 0.73
Batch: 440; loss: 1.01; acc: 0.64
Batch: 460; loss: 0.7; acc: 0.78
Batch: 480; loss: 0.55; acc: 0.81
Batch: 500; loss: 1.27; acc: 0.66
Batch: 520; loss: 0.64; acc: 0.77
Batch: 540; loss: 0.62; acc: 0.78
Batch: 560; loss: 0.56; acc: 0.8
Batch: 580; loss: 0.61; acc: 0.83
Batch: 600; loss: 0.85; acc: 0.77
Batch: 620; loss: 0.51; acc: 0.86
Batch: 640; loss: 0.79; acc: 0.78
Batch: 660; loss: 0.89; acc: 0.72
Batch: 680; loss: 0.6; acc: 0.8
Batch: 700; loss: 0.85; acc: 0.7
Batch: 720; loss: 0.57; acc: 0.8
Batch: 740; loss: 0.58; acc: 0.89
Batch: 760; loss: 0.87; acc: 0.72
Batch: 780; loss: 0.7; acc: 0.77
Train Epoch over. train_loss: 1.16; train_accuracy: 0.64 

1.5342086044256575e-05
5.519389560504351e-06
Batch: 0; loss: 0.58; acc: 0.77
Batch: 20; loss: 1.15; acc: 0.66
Batch: 40; loss: 0.33; acc: 0.88
Batch: 60; loss: 0.69; acc: 0.75
Batch: 80; loss: 0.55; acc: 0.75
Batch: 100; loss: 0.51; acc: 0.84
Batch: 120; loss: 1.06; acc: 0.72
Batch: 140; loss: 0.66; acc: 0.73
Val Epoch over. val_loss: 0.6471525109877252; val_accuracy: 0.78234474522293 

The current subspace-distance is: 5.519389560504351e-06 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.73; acc: 0.8
Batch: 20; loss: 0.45; acc: 0.88
Batch: 40; loss: 0.45; acc: 0.84
Batch: 60; loss: 0.44; acc: 0.88
Batch: 80; loss: 0.56; acc: 0.81
Batch: 100; loss: 0.63; acc: 0.77
Batch: 120; loss: 0.75; acc: 0.77
Batch: 140; loss: 0.65; acc: 0.78
Batch: 160; loss: 0.5; acc: 0.84
Batch: 180; loss: 0.46; acc: 0.83
Batch: 200; loss: 0.49; acc: 0.84
Batch: 220; loss: 0.61; acc: 0.8
Batch: 240; loss: 0.63; acc: 0.81
Batch: 260; loss: 0.71; acc: 0.81
Batch: 280; loss: 0.78; acc: 0.75
Batch: 300; loss: 0.42; acc: 0.88
Batch: 320; loss: 0.51; acc: 0.83
Batch: 340; loss: 0.59; acc: 0.8
Batch: 360; loss: 0.44; acc: 0.88
Batch: 380; loss: 0.56; acc: 0.84
Batch: 400; loss: 0.65; acc: 0.81
Batch: 420; loss: 0.74; acc: 0.78
Batch: 440; loss: 0.42; acc: 0.86
Batch: 460; loss: 0.85; acc: 0.77
Batch: 480; loss: 0.6; acc: 0.8
Batch: 500; loss: 0.38; acc: 0.86
Batch: 520; loss: 0.33; acc: 0.94
Batch: 540; loss: 0.55; acc: 0.83
Batch: 560; loss: 0.77; acc: 0.73
Batch: 580; loss: 0.39; acc: 0.89
Batch: 600; loss: 0.41; acc: 0.91
Batch: 620; loss: 0.82; acc: 0.75
Batch: 640; loss: 0.35; acc: 0.89
Batch: 660; loss: 0.44; acc: 0.88
Batch: 680; loss: 0.49; acc: 0.83
Batch: 700; loss: 0.59; acc: 0.86
Batch: 720; loss: 0.27; acc: 0.92
Batch: 740; loss: 0.56; acc: 0.88
Batch: 760; loss: 0.6; acc: 0.77
Batch: 780; loss: 0.45; acc: 0.86
Train Epoch over. train_loss: 0.56; train_accuracy: 0.83 

2.0143053916399367e-05
5.8177311075269245e-06
Batch: 0; loss: 0.41; acc: 0.86
Batch: 20; loss: 0.73; acc: 0.78
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.53; acc: 0.84
Batch: 80; loss: 0.36; acc: 0.89
Batch: 100; loss: 0.37; acc: 0.88
Batch: 120; loss: 0.8; acc: 0.77
Batch: 140; loss: 0.41; acc: 0.84
Val Epoch over. val_loss: 0.5325580923610432; val_accuracy: 0.8403662420382165 

The current subspace-distance is: 5.8177311075269245e-06 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.43; acc: 0.88
Batch: 20; loss: 0.44; acc: 0.88
Batch: 40; loss: 0.58; acc: 0.81
Batch: 60; loss: 0.44; acc: 0.84
Batch: 80; loss: 0.37; acc: 0.92
Batch: 100; loss: 0.36; acc: 0.89
Batch: 120; loss: 0.51; acc: 0.84
Batch: 140; loss: 0.42; acc: 0.86
Batch: 160; loss: 0.46; acc: 0.83
Batch: 180; loss: 0.58; acc: 0.8
Batch: 200; loss: 0.3; acc: 0.94
Batch: 220; loss: 0.78; acc: 0.83
Batch: 240; loss: 0.97; acc: 0.77
Batch: 260; loss: 0.33; acc: 0.88
Batch: 280; loss: 0.55; acc: 0.86
Batch: 300; loss: 0.66; acc: 0.8
Batch: 320; loss: 0.48; acc: 0.84
Batch: 340; loss: 0.45; acc: 0.89
Batch: 360; loss: 0.45; acc: 0.89
Batch: 380; loss: 0.3; acc: 0.89
Batch: 400; loss: 0.48; acc: 0.8
Batch: 420; loss: 0.65; acc: 0.83
Batch: 440; loss: 0.18; acc: 0.95
Batch: 460; loss: 0.34; acc: 0.88
Batch: 480; loss: 0.58; acc: 0.8
Batch: 500; loss: 0.38; acc: 0.86
Batch: 520; loss: 0.54; acc: 0.83
Batch: 540; loss: 0.33; acc: 0.92
Batch: 560; loss: 0.51; acc: 0.84
Batch: 580; loss: 0.58; acc: 0.8
Batch: 600; loss: 0.4; acc: 0.91
Batch: 620; loss: 0.49; acc: 0.84
Batch: 640; loss: 0.63; acc: 0.8
Batch: 660; loss: 0.61; acc: 0.81
Batch: 680; loss: 0.55; acc: 0.84
Batch: 700; loss: 0.27; acc: 0.91
Batch: 720; loss: 0.78; acc: 0.78
Batch: 740; loss: 0.54; acc: 0.86
Batch: 760; loss: 0.46; acc: 0.81
Batch: 780; loss: 0.34; acc: 0.92
Train Epoch over. train_loss: 0.49; train_accuracy: 0.85 

2.20261044887593e-05
6.817941084591439e-06
Batch: 0; loss: 0.51; acc: 0.81
Batch: 20; loss: 0.82; acc: 0.72
Batch: 40; loss: 0.31; acc: 0.89
Batch: 60; loss: 0.46; acc: 0.88
Batch: 80; loss: 0.39; acc: 0.88
Batch: 100; loss: 0.66; acc: 0.75
Batch: 120; loss: 0.8; acc: 0.78
Batch: 140; loss: 0.5; acc: 0.75
Val Epoch over. val_loss: 0.6214456022924678; val_accuracy: 0.794984076433121 

The current subspace-distance is: 6.817941084591439e-06 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.74; acc: 0.77
Batch: 20; loss: 0.56; acc: 0.81
Batch: 40; loss: 0.6; acc: 0.83
Batch: 60; loss: 0.49; acc: 0.84
Batch: 80; loss: 0.6; acc: 0.83
Batch: 100; loss: 0.34; acc: 0.89
Batch: 120; loss: 0.4; acc: 0.84
Batch: 140; loss: 0.4; acc: 0.84
Batch: 160; loss: 0.27; acc: 0.89
Batch: 180; loss: 0.35; acc: 0.92
Batch: 200; loss: 0.42; acc: 0.86
Batch: 220; loss: 0.48; acc: 0.83
Batch: 240; loss: 0.4; acc: 0.91
Batch: 260; loss: 0.59; acc: 0.77
Batch: 280; loss: 0.43; acc: 0.89
Batch: 300; loss: 0.29; acc: 0.89
Batch: 320; loss: 0.27; acc: 0.91
Batch: 340; loss: 0.24; acc: 0.92
Batch: 360; loss: 0.53; acc: 0.84
Batch: 380; loss: 0.39; acc: 0.84
Batch: 400; loss: 0.46; acc: 0.86
Batch: 420; loss: 0.66; acc: 0.8
Batch: 440; loss: 0.39; acc: 0.84
Batch: 460; loss: 0.48; acc: 0.8
Batch: 480; loss: 0.6; acc: 0.84
Batch: 500; loss: 0.47; acc: 0.84
Batch: 520; loss: 0.44; acc: 0.89
Batch: 540; loss: 0.36; acc: 0.88
Batch: 560; loss: 0.62; acc: 0.8
Batch: 580; loss: 0.42; acc: 0.89
Batch: 600; loss: 0.31; acc: 0.89
Batch: 620; loss: 0.36; acc: 0.86
Batch: 640; loss: 0.48; acc: 0.83
Batch: 660; loss: 0.94; acc: 0.73
Batch: 680; loss: 0.4; acc: 0.88
Batch: 700; loss: 0.49; acc: 0.78
Batch: 720; loss: 0.41; acc: 0.91
Batch: 740; loss: 0.53; acc: 0.88
Batch: 760; loss: 0.36; acc: 0.86
Batch: 780; loss: 0.35; acc: 0.88
Train Epoch over. train_loss: 0.46; train_accuracy: 0.86 

2.238893102912698e-05
7.04786361893639e-06
Batch: 0; loss: 0.36; acc: 0.88
Batch: 20; loss: 0.6; acc: 0.78
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.52; acc: 0.86
Batch: 80; loss: 0.27; acc: 0.94
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.67; acc: 0.81
Batch: 140; loss: 0.19; acc: 0.95
Val Epoch over. val_loss: 0.4304864856467885; val_accuracy: 0.8703224522292994 

The current subspace-distance is: 7.04786361893639e-06 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.44; acc: 0.86
Batch: 20; loss: 0.42; acc: 0.8
Batch: 40; loss: 0.89; acc: 0.73
Batch: 60; loss: 0.43; acc: 0.89
Batch: 80; loss: 0.23; acc: 0.89
Batch: 100; loss: 0.51; acc: 0.83
Batch: 120; loss: 0.45; acc: 0.88
Batch: 140; loss: 0.47; acc: 0.83
Batch: 160; loss: 0.45; acc: 0.86
Batch: 180; loss: 0.35; acc: 0.84
Batch: 200; loss: 0.4; acc: 0.84
Batch: 220; loss: 0.29; acc: 0.92
Batch: 240; loss: 0.4; acc: 0.89
Batch: 260; loss: 0.54; acc: 0.86
Batch: 280; loss: 0.39; acc: 0.86
Batch: 300; loss: 0.49; acc: 0.81
Batch: 320; loss: 0.31; acc: 0.89
Batch: 340; loss: 0.28; acc: 0.89
Batch: 360; loss: 0.69; acc: 0.77
Batch: 380; loss: 0.96; acc: 0.77
Batch: 400; loss: 0.26; acc: 0.94
Batch: 420; loss: 0.29; acc: 0.92
Batch: 440; loss: 0.51; acc: 0.81
Batch: 460; loss: 0.5; acc: 0.84
Batch: 480; loss: 0.5; acc: 0.83
Batch: 500; loss: 0.51; acc: 0.84
Batch: 520; loss: 0.54; acc: 0.86
Batch: 540; loss: 0.5; acc: 0.86
Batch: 560; loss: 0.42; acc: 0.88
Batch: 580; loss: 0.38; acc: 0.88
Batch: 600; loss: 0.23; acc: 0.94
Batch: 620; loss: 0.37; acc: 0.91
Batch: 640; loss: 0.57; acc: 0.81
Batch: 660; loss: 0.81; acc: 0.77
Batch: 680; loss: 0.29; acc: 0.88
Batch: 700; loss: 0.48; acc: 0.86
Batch: 720; loss: 0.74; acc: 0.8
Batch: 740; loss: 0.45; acc: 0.83
Batch: 760; loss: 0.47; acc: 0.88
Batch: 780; loss: 0.32; acc: 0.95
Train Epoch over. train_loss: 0.44; train_accuracy: 0.87 

2.3407512344419956e-05
7.472270226571709e-06
Batch: 0; loss: 0.36; acc: 0.86
Batch: 20; loss: 0.48; acc: 0.81
Batch: 40; loss: 0.16; acc: 0.98
Batch: 60; loss: 0.39; acc: 0.89
Batch: 80; loss: 0.34; acc: 0.86
Batch: 100; loss: 0.33; acc: 0.89
Batch: 120; loss: 0.51; acc: 0.81
Batch: 140; loss: 0.21; acc: 0.91
Val Epoch over. val_loss: 0.4066953244767371; val_accuracy: 0.8747014331210191 

The current subspace-distance is: 7.472270226571709e-06 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.46; acc: 0.83
Batch: 20; loss: 0.14; acc: 0.98
Batch: 40; loss: 0.52; acc: 0.86
Batch: 60; loss: 0.25; acc: 0.95
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.27; acc: 0.91
Batch: 120; loss: 0.37; acc: 0.89
Batch: 140; loss: 0.5; acc: 0.84
Batch: 160; loss: 0.51; acc: 0.78
Batch: 180; loss: 0.6; acc: 0.8
Batch: 200; loss: 0.65; acc: 0.77
Batch: 220; loss: 0.36; acc: 0.84
Batch: 240; loss: 0.51; acc: 0.88
Batch: 260; loss: 0.48; acc: 0.88
Batch: 280; loss: 0.48; acc: 0.88
Batch: 300; loss: 0.31; acc: 0.92
Batch: 320; loss: 0.33; acc: 0.89
Batch: 340; loss: 0.42; acc: 0.88
Batch: 360; loss: 0.29; acc: 0.88
Batch: 380; loss: 0.49; acc: 0.84
Batch: 400; loss: 0.31; acc: 0.89
Batch: 420; loss: 0.52; acc: 0.83
Batch: 440; loss: 0.51; acc: 0.83
Batch: 460; loss: 0.14; acc: 0.95
Batch: 480; loss: 0.4; acc: 0.88
Batch: 500; loss: 0.22; acc: 0.92
Batch: 520; loss: 0.28; acc: 0.92
Batch: 540; loss: 0.62; acc: 0.8
Batch: 560; loss: 0.35; acc: 0.88
Batch: 580; loss: 0.25; acc: 0.92
Batch: 600; loss: 0.3; acc: 0.89
Batch: 620; loss: 0.28; acc: 0.97
Batch: 640; loss: 0.53; acc: 0.84
Batch: 660; loss: 0.39; acc: 0.88
Batch: 680; loss: 0.54; acc: 0.83
Batch: 700; loss: 0.43; acc: 0.86
Batch: 720; loss: 0.46; acc: 0.84
Batch: 740; loss: 0.18; acc: 0.97
Batch: 760; loss: 0.27; acc: 0.92
Batch: 780; loss: 0.27; acc: 0.91
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

2.411698551441077e-05
7.187423761934042e-06
Batch: 0; loss: 0.39; acc: 0.88
Batch: 20; loss: 0.44; acc: 0.88
Batch: 40; loss: 0.21; acc: 0.92
Batch: 60; loss: 0.53; acc: 0.81
Batch: 80; loss: 0.29; acc: 0.91
Batch: 100; loss: 0.31; acc: 0.94
Batch: 120; loss: 0.56; acc: 0.8
Batch: 140; loss: 0.16; acc: 0.94
Val Epoch over. val_loss: 0.41372226401688944; val_accuracy: 0.8707205414012739 

The current subspace-distance is: 7.187423761934042e-06 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.73; acc: 0.75
Batch: 20; loss: 0.31; acc: 0.88
Batch: 40; loss: 0.28; acc: 0.91
Batch: 60; loss: 0.3; acc: 0.91
Batch: 80; loss: 0.46; acc: 0.91
Batch: 100; loss: 0.35; acc: 0.86
Batch: 120; loss: 0.35; acc: 0.89
Batch: 140; loss: 0.4; acc: 0.83
Batch: 160; loss: 0.33; acc: 0.92
Batch: 180; loss: 0.15; acc: 0.97
Batch: 200; loss: 0.35; acc: 0.89
Batch: 220; loss: 0.53; acc: 0.89
Batch: 240; loss: 0.42; acc: 0.88
Batch: 260; loss: 0.28; acc: 0.94
Batch: 280; loss: 0.51; acc: 0.88
Batch: 300; loss: 0.49; acc: 0.83
Batch: 320; loss: 0.52; acc: 0.8
Batch: 340; loss: 0.41; acc: 0.88
Batch: 360; loss: 0.17; acc: 0.94
Batch: 380; loss: 0.24; acc: 0.95
Batch: 400; loss: 0.43; acc: 0.89
Batch: 420; loss: 0.14; acc: 0.95
Batch: 440; loss: 0.42; acc: 0.88
Batch: 460; loss: 0.25; acc: 0.92
Batch: 480; loss: 0.26; acc: 0.92
Batch: 500; loss: 0.35; acc: 0.88
Batch: 520; loss: 0.28; acc: 0.89
Batch: 540; loss: 0.44; acc: 0.88
Batch: 560; loss: 0.25; acc: 0.91
Batch: 580; loss: 0.32; acc: 0.88
Batch: 600; loss: 0.49; acc: 0.86
Batch: 620; loss: 0.43; acc: 0.83
Batch: 640; loss: 0.24; acc: 0.91
Batch: 660; loss: 0.27; acc: 0.91
Batch: 680; loss: 0.31; acc: 0.88
Batch: 700; loss: 0.68; acc: 0.8
Batch: 720; loss: 0.19; acc: 0.94
Batch: 740; loss: 0.36; acc: 0.86
Batch: 760; loss: 0.12; acc: 0.94
Batch: 780; loss: 0.27; acc: 0.89
Train Epoch over. train_loss: 0.37; train_accuracy: 0.88 

2.6019253709819168e-05
7.293036560440669e-06
Batch: 0; loss: 0.48; acc: 0.81
Batch: 20; loss: 0.75; acc: 0.78
Batch: 40; loss: 0.21; acc: 0.91
Batch: 60; loss: 0.62; acc: 0.81
Batch: 80; loss: 0.5; acc: 0.88
Batch: 100; loss: 0.56; acc: 0.88
Batch: 120; loss: 0.88; acc: 0.81
Batch: 140; loss: 0.18; acc: 0.92
Val Epoch over. val_loss: 0.5610590133887188; val_accuracy: 0.8385748407643312 

The current subspace-distance is: 7.293036560440669e-06 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.76; acc: 0.77
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.24; acc: 0.91
Batch: 60; loss: 0.5; acc: 0.86
Batch: 80; loss: 0.24; acc: 0.95
Batch: 100; loss: 0.21; acc: 0.91
Batch: 120; loss: 0.31; acc: 0.92
Batch: 140; loss: 0.41; acc: 0.89
Batch: 160; loss: 0.36; acc: 0.88
Batch: 180; loss: 0.4; acc: 0.83
Batch: 200; loss: 0.2; acc: 0.95
Batch: 220; loss: 0.52; acc: 0.83
Batch: 240; loss: 0.29; acc: 0.91
Batch: 260; loss: 0.36; acc: 0.86
Batch: 280; loss: 0.5; acc: 0.88
Batch: 300; loss: 0.24; acc: 0.95
Batch: 320; loss: 0.52; acc: 0.81
Batch: 340; loss: 0.33; acc: 0.89
Batch: 360; loss: 0.32; acc: 0.94
Batch: 380; loss: 0.13; acc: 0.97
Batch: 400; loss: 0.43; acc: 0.84
Batch: 420; loss: 0.29; acc: 0.94
Batch: 440; loss: 0.34; acc: 0.92
Batch: 460; loss: 0.27; acc: 0.94
Batch: 480; loss: 0.34; acc: 0.89
Batch: 500; loss: 0.52; acc: 0.84
Batch: 520; loss: 0.24; acc: 0.97
Batch: 540; loss: 0.35; acc: 0.89
Batch: 560; loss: 0.47; acc: 0.84
Batch: 580; loss: 0.51; acc: 0.83
Batch: 600; loss: 0.54; acc: 0.84
Batch: 620; loss: 0.28; acc: 0.91
Batch: 640; loss: 0.44; acc: 0.88
Batch: 660; loss: 0.52; acc: 0.84
Batch: 680; loss: 0.66; acc: 0.86
Batch: 700; loss: 0.43; acc: 0.86
Batch: 720; loss: 0.25; acc: 0.91
Batch: 740; loss: 0.49; acc: 0.86
Batch: 760; loss: 0.37; acc: 0.86
Batch: 780; loss: 0.47; acc: 0.88
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

2.496821434760932e-05
7.587686468468746e-06
Batch: 0; loss: 0.41; acc: 0.86
Batch: 20; loss: 0.48; acc: 0.86
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.43; acc: 0.89
Batch: 80; loss: 0.29; acc: 0.91
Batch: 100; loss: 0.4; acc: 0.91
Batch: 120; loss: 0.66; acc: 0.8
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.36839821346246515; val_accuracy: 0.8889331210191083 

The current subspace-distance is: 7.587686468468746e-06 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.37; acc: 0.89
Batch: 20; loss: 0.32; acc: 0.92
Batch: 40; loss: 0.46; acc: 0.86
Batch: 60; loss: 0.41; acc: 0.86
Batch: 80; loss: 0.38; acc: 0.89
Batch: 100; loss: 0.39; acc: 0.89
Batch: 120; loss: 0.45; acc: 0.83
Batch: 140; loss: 0.44; acc: 0.88
Batch: 160; loss: 0.11; acc: 1.0
Batch: 180; loss: 0.27; acc: 0.91
Batch: 200; loss: 0.37; acc: 0.92
Batch: 220; loss: 0.65; acc: 0.84
Batch: 240; loss: 0.24; acc: 0.94
Batch: 260; loss: 0.41; acc: 0.84
Batch: 280; loss: 0.31; acc: 0.89
Batch: 300; loss: 0.14; acc: 0.97
Batch: 320; loss: 0.46; acc: 0.86
Batch: 340; loss: 0.22; acc: 0.92
Batch: 360; loss: 0.3; acc: 0.89
Batch: 380; loss: 0.29; acc: 0.91
Batch: 400; loss: 0.43; acc: 0.88
Batch: 420; loss: 0.28; acc: 0.92
Batch: 440; loss: 0.34; acc: 0.91
Batch: 460; loss: 0.16; acc: 0.97
Batch: 480; loss: 0.33; acc: 0.88
Batch: 500; loss: 0.16; acc: 0.95
Batch: 520; loss: 0.37; acc: 0.89
Batch: 540; loss: 0.34; acc: 0.92
Batch: 560; loss: 0.45; acc: 0.94
Batch: 580; loss: 0.4; acc: 0.84
Batch: 600; loss: 0.2; acc: 0.94
Batch: 620; loss: 0.59; acc: 0.86
Batch: 640; loss: 0.36; acc: 0.91
Batch: 660; loss: 0.28; acc: 0.92
Batch: 680; loss: 0.14; acc: 0.95
Batch: 700; loss: 0.32; acc: 0.92
Batch: 720; loss: 0.59; acc: 0.8
Batch: 740; loss: 0.51; acc: 0.92
Batch: 760; loss: 0.18; acc: 0.95
Batch: 780; loss: 0.41; acc: 0.89
Train Epoch over. train_loss: 0.35; train_accuracy: 0.9 

2.5358956918353215e-05
7.085273409757065e-06
Batch: 0; loss: 0.63; acc: 0.78
Batch: 20; loss: 0.52; acc: 0.83
Batch: 40; loss: 0.26; acc: 0.91
Batch: 60; loss: 0.54; acc: 0.86
Batch: 80; loss: 0.37; acc: 0.92
Batch: 100; loss: 0.36; acc: 0.89
Batch: 120; loss: 0.72; acc: 0.75
Batch: 140; loss: 0.11; acc: 0.98
Val Epoch over. val_loss: 0.5067258459652305; val_accuracy: 0.845640923566879 

The current subspace-distance is: 7.085273409757065e-06 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.57; acc: 0.83
Batch: 20; loss: 0.34; acc: 0.88
Batch: 40; loss: 0.27; acc: 0.92
Batch: 60; loss: 0.2; acc: 0.94
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.21; acc: 0.94
Batch: 120; loss: 0.25; acc: 0.92
Batch: 140; loss: 0.27; acc: 0.92
Batch: 160; loss: 0.19; acc: 0.95
Batch: 180; loss: 0.26; acc: 0.89
Batch: 200; loss: 0.43; acc: 0.86
Batch: 220; loss: 0.29; acc: 0.91
Batch: 240; loss: 0.26; acc: 0.91
Batch: 260; loss: 0.37; acc: 0.86
Batch: 280; loss: 0.27; acc: 0.92
Batch: 300; loss: 0.19; acc: 0.97
Batch: 320; loss: 0.46; acc: 0.89
Batch: 340; loss: 0.25; acc: 0.92
Batch: 360; loss: 0.42; acc: 0.89
Batch: 380; loss: 0.39; acc: 0.88
Batch: 400; loss: 0.46; acc: 0.88
Batch: 420; loss: 0.17; acc: 0.95
Batch: 440; loss: 0.27; acc: 0.94
Batch: 460; loss: 0.3; acc: 0.91
Batch: 480; loss: 0.29; acc: 0.89
Batch: 500; loss: 0.49; acc: 0.86
Batch: 520; loss: 0.5; acc: 0.89
Batch: 540; loss: 0.39; acc: 0.88
Batch: 560; loss: 0.32; acc: 0.88
Batch: 580; loss: 0.36; acc: 0.89
Batch: 600; loss: 0.13; acc: 0.97
Batch: 620; loss: 0.29; acc: 0.91
Batch: 640; loss: 0.23; acc: 0.89
Batch: 660; loss: 0.4; acc: 0.89
Batch: 680; loss: 0.38; acc: 0.91
Batch: 700; loss: 0.22; acc: 0.92
Batch: 720; loss: 0.21; acc: 0.92
Batch: 740; loss: 0.32; acc: 0.91
Batch: 760; loss: 0.28; acc: 0.92
Batch: 780; loss: 0.26; acc: 0.88
Train Epoch over. train_loss: 0.31; train_accuracy: 0.91 

2.5955627279472537e-05
8.680751307110768e-06
Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.34; acc: 0.91
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.21; acc: 0.92
Batch: 120; loss: 0.48; acc: 0.86
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.2660956179877375; val_accuracy: 0.9210788216560509 

The current subspace-distance is: 8.680751307110768e-06 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.46; acc: 0.88
Batch: 20; loss: 0.34; acc: 0.91
Batch: 40; loss: 0.26; acc: 0.95
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.55; acc: 0.88
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.34; acc: 0.91
Batch: 140; loss: 0.26; acc: 0.95
Batch: 160; loss: 0.24; acc: 0.92
Batch: 180; loss: 0.23; acc: 0.94
Batch: 200; loss: 0.2; acc: 0.94
Batch: 220; loss: 0.17; acc: 0.97
Batch: 240; loss: 0.34; acc: 0.86
Batch: 260; loss: 0.18; acc: 0.92
Batch: 280; loss: 0.14; acc: 0.97
Batch: 300; loss: 0.27; acc: 0.91
Batch: 320; loss: 0.31; acc: 0.94
Batch: 340; loss: 0.35; acc: 0.88
Batch: 360; loss: 0.42; acc: 0.83
Batch: 380; loss: 0.39; acc: 0.88
Batch: 400; loss: 0.14; acc: 0.95
Batch: 420; loss: 0.37; acc: 0.88
Batch: 440; loss: 0.58; acc: 0.84
Batch: 460; loss: 0.44; acc: 0.89
Batch: 480; loss: 0.42; acc: 0.92
Batch: 500; loss: 0.44; acc: 0.83
Batch: 520; loss: 0.17; acc: 0.94
Batch: 540; loss: 0.37; acc: 0.89
Batch: 560; loss: 0.15; acc: 0.95
Batch: 580; loss: 0.19; acc: 0.92
Batch: 600; loss: 0.22; acc: 0.94
Batch: 620; loss: 0.48; acc: 0.89
Batch: 640; loss: 0.32; acc: 0.91
Batch: 660; loss: 0.17; acc: 0.92
Batch: 680; loss: 0.22; acc: 0.91
Batch: 700; loss: 0.27; acc: 0.92
Batch: 720; loss: 0.26; acc: 0.92
Batch: 740; loss: 0.54; acc: 0.83
Batch: 760; loss: 0.53; acc: 0.88
Batch: 780; loss: 0.18; acc: 0.94
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.6313466150895692e-05
7.3504661486367695e-06
Batch: 0; loss: 0.24; acc: 0.91
Batch: 20; loss: 0.36; acc: 0.91
Batch: 40; loss: 0.11; acc: 0.94
Batch: 60; loss: 0.38; acc: 0.88
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.26; acc: 0.94
Batch: 120; loss: 0.47; acc: 0.89
Batch: 140; loss: 0.1; acc: 0.98
Val Epoch over. val_loss: 0.30192476245248395; val_accuracy: 0.910031847133758 

The current subspace-distance is: 7.3504661486367695e-06 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.27; acc: 0.89
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.29; acc: 0.89
Batch: 60; loss: 0.26; acc: 0.89
Batch: 80; loss: 0.34; acc: 0.91
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.29; acc: 0.94
Batch: 140; loss: 0.27; acc: 0.92
Batch: 160; loss: 0.29; acc: 0.94
Batch: 180; loss: 0.19; acc: 0.94
Batch: 200; loss: 0.37; acc: 0.91
Batch: 220; loss: 0.33; acc: 0.92
Batch: 240; loss: 0.36; acc: 0.92
Batch: 260; loss: 0.17; acc: 0.94
Batch: 280; loss: 0.33; acc: 0.92
Batch: 300; loss: 0.3; acc: 0.89
Batch: 320; loss: 0.46; acc: 0.86
Batch: 340; loss: 0.13; acc: 0.97
Batch: 360; loss: 0.21; acc: 0.95
Batch: 380; loss: 0.33; acc: 0.89
Batch: 400; loss: 0.24; acc: 0.89
Batch: 420; loss: 0.2; acc: 0.94
Batch: 440; loss: 0.28; acc: 0.92
Batch: 460; loss: 0.3; acc: 0.91
Batch: 480; loss: 0.25; acc: 0.94
Batch: 500; loss: 0.21; acc: 0.92
Batch: 520; loss: 0.2; acc: 0.92
Batch: 540; loss: 0.45; acc: 0.84
Batch: 560; loss: 0.21; acc: 0.95
Batch: 580; loss: 0.22; acc: 0.94
Batch: 600; loss: 0.21; acc: 0.92
Batch: 620; loss: 0.31; acc: 0.91
Batch: 640; loss: 0.32; acc: 0.89
Batch: 660; loss: 0.33; acc: 0.92
Batch: 680; loss: 0.25; acc: 0.92
Batch: 700; loss: 0.48; acc: 0.86
Batch: 720; loss: 0.2; acc: 0.94
Batch: 740; loss: 0.24; acc: 0.92
Batch: 760; loss: 0.37; acc: 0.86
Batch: 780; loss: 0.34; acc: 0.89
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.530856909288559e-05
7.775178346491884e-06
Batch: 0; loss: 0.19; acc: 0.92
Batch: 20; loss: 0.34; acc: 0.91
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.32; acc: 0.88
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.54; acc: 0.84
Batch: 140; loss: 0.16; acc: 0.95
Val Epoch over. val_loss: 0.275167499140949; val_accuracy: 0.917296974522293 

The current subspace-distance is: 7.775178346491884e-06 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.23; acc: 0.94
Batch: 20; loss: 0.18; acc: 0.91
Batch: 40; loss: 0.19; acc: 0.92
Batch: 60; loss: 0.14; acc: 0.97
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.45; acc: 0.88
Batch: 120; loss: 0.25; acc: 0.92
Batch: 140; loss: 0.41; acc: 0.91
Batch: 160; loss: 0.27; acc: 0.95
Batch: 180; loss: 0.17; acc: 0.94
Batch: 200; loss: 0.22; acc: 0.94
Batch: 220; loss: 0.61; acc: 0.78
Batch: 240; loss: 0.16; acc: 0.97
Batch: 260; loss: 0.17; acc: 0.95
Batch: 280; loss: 0.24; acc: 0.94
Batch: 300; loss: 0.34; acc: 0.88
Batch: 320; loss: 0.12; acc: 0.97
Batch: 340; loss: 0.27; acc: 0.94
Batch: 360; loss: 0.47; acc: 0.86
Batch: 380; loss: 0.23; acc: 0.92
Batch: 400; loss: 0.54; acc: 0.81
Batch: 420; loss: 0.37; acc: 0.88
Batch: 440; loss: 0.21; acc: 0.95
Batch: 460; loss: 0.29; acc: 0.89
Batch: 480; loss: 0.28; acc: 0.91
Batch: 500; loss: 0.52; acc: 0.89
Batch: 520; loss: 0.17; acc: 0.97
Batch: 540; loss: 0.27; acc: 0.92
Batch: 560; loss: 0.4; acc: 0.89
Batch: 580; loss: 0.17; acc: 0.95
Batch: 600; loss: 0.25; acc: 0.91
Batch: 620; loss: 0.27; acc: 0.92
Batch: 640; loss: 0.46; acc: 0.92
Batch: 660; loss: 0.24; acc: 0.94
Batch: 680; loss: 0.5; acc: 0.83
Batch: 700; loss: 0.25; acc: 0.92
Batch: 720; loss: 0.37; acc: 0.89
Batch: 740; loss: 0.07; acc: 0.98
Batch: 760; loss: 0.18; acc: 0.94
Batch: 780; loss: 0.39; acc: 0.91
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.6258547222823836e-05
6.928682523721363e-06
Batch: 0; loss: 0.16; acc: 0.97
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.11; acc: 0.98
Batch: 60; loss: 0.28; acc: 0.92
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.21; acc: 0.94
Batch: 120; loss: 0.45; acc: 0.86
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.2636042375141268; val_accuracy: 0.9220740445859873 

The current subspace-distance is: 6.928682523721363e-06 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.27; acc: 0.95
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.44; acc: 0.83
Batch: 60; loss: 0.31; acc: 0.92
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.27; acc: 0.89
Batch: 120; loss: 0.5; acc: 0.86
Batch: 140; loss: 0.34; acc: 0.89
Batch: 160; loss: 0.16; acc: 0.95
Batch: 180; loss: 0.38; acc: 0.92
Batch: 200; loss: 0.18; acc: 0.92
Batch: 220; loss: 0.3; acc: 0.92
Batch: 240; loss: 0.3; acc: 0.91
Batch: 260; loss: 0.16; acc: 0.94
Batch: 280; loss: 0.25; acc: 0.92
Batch: 300; loss: 0.39; acc: 0.89
Batch: 320; loss: 0.65; acc: 0.86
Batch: 340; loss: 0.29; acc: 0.89
Batch: 360; loss: 0.5; acc: 0.86
Batch: 380; loss: 0.2; acc: 0.95
Batch: 400; loss: 0.31; acc: 0.89
Batch: 420; loss: 0.2; acc: 0.92
Batch: 440; loss: 0.32; acc: 0.95
Batch: 460; loss: 0.42; acc: 0.91
Batch: 480; loss: 0.19; acc: 0.91
Batch: 500; loss: 0.41; acc: 0.89
Batch: 520; loss: 0.41; acc: 0.88
Batch: 540; loss: 0.18; acc: 0.95
Batch: 560; loss: 0.32; acc: 0.89
Batch: 580; loss: 0.3; acc: 0.89
Batch: 600; loss: 0.19; acc: 0.92
Batch: 620; loss: 0.21; acc: 0.95
Batch: 640; loss: 0.19; acc: 0.95
Batch: 660; loss: 0.29; acc: 0.91
Batch: 680; loss: 0.32; acc: 0.92
Batch: 700; loss: 0.28; acc: 0.94
Batch: 720; loss: 0.27; acc: 0.92
Batch: 740; loss: 0.25; acc: 0.92
Batch: 760; loss: 0.58; acc: 0.83
Batch: 780; loss: 0.17; acc: 0.95
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.6754845748655498e-05
7.146766165533336e-06
Batch: 0; loss: 0.19; acc: 0.95
Batch: 20; loss: 0.44; acc: 0.86
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.22; acc: 0.91
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.61; acc: 0.83
Batch: 140; loss: 0.2; acc: 0.92
Val Epoch over. val_loss: 0.294514804058204; val_accuracy: 0.9120222929936306 

The current subspace-distance is: 7.146766165533336e-06 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.36; acc: 0.92
Batch: 20; loss: 0.45; acc: 0.94
Batch: 40; loss: 0.26; acc: 0.91
Batch: 60; loss: 0.17; acc: 0.91
Batch: 80; loss: 0.3; acc: 0.92
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.39; acc: 0.89
Batch: 140; loss: 0.23; acc: 0.94
Batch: 160; loss: 0.34; acc: 0.88
Batch: 180; loss: 0.32; acc: 0.92
Batch: 200; loss: 0.35; acc: 0.91
Batch: 220; loss: 0.23; acc: 0.94
Batch: 240; loss: 0.23; acc: 0.95
Batch: 260; loss: 0.22; acc: 0.92
Batch: 280; loss: 0.43; acc: 0.86
Batch: 300; loss: 0.31; acc: 0.91
Batch: 320; loss: 0.32; acc: 0.89
Batch: 340; loss: 0.53; acc: 0.84
Batch: 360; loss: 0.33; acc: 0.88
Batch: 380; loss: 0.42; acc: 0.89
Batch: 400; loss: 0.47; acc: 0.92
Batch: 420; loss: 0.26; acc: 0.94
Batch: 440; loss: 0.41; acc: 0.89
Batch: 460; loss: 0.26; acc: 0.92
Batch: 480; loss: 0.38; acc: 0.91
Batch: 500; loss: 0.42; acc: 0.88
Batch: 520; loss: 0.07; acc: 1.0
Batch: 540; loss: 0.21; acc: 0.91
Batch: 560; loss: 0.21; acc: 0.92
Batch: 580; loss: 0.17; acc: 0.95
Batch: 600; loss: 0.32; acc: 0.92
Batch: 620; loss: 0.4; acc: 0.88
Batch: 640; loss: 0.35; acc: 0.88
Batch: 660; loss: 0.16; acc: 0.97
Batch: 680; loss: 0.16; acc: 0.97
Batch: 700; loss: 0.32; acc: 0.88
Batch: 720; loss: 0.13; acc: 0.94
Batch: 740; loss: 0.27; acc: 0.88
Batch: 760; loss: 0.3; acc: 0.92
Batch: 780; loss: 0.3; acc: 0.91
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.5740073397173546e-05
7.718150300206617e-06
Batch: 0; loss: 0.2; acc: 0.91
Batch: 20; loss: 0.31; acc: 0.92
Batch: 40; loss: 0.11; acc: 0.98
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.48; acc: 0.84
Batch: 140; loss: 0.15; acc: 0.94
Val Epoch over. val_loss: 0.27666714773246437; val_accuracy: 0.9185907643312102 

The current subspace-distance is: 7.718150300206617e-06 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.33; acc: 0.88
Batch: 40; loss: 0.37; acc: 0.92
Batch: 60; loss: 0.42; acc: 0.89
Batch: 80; loss: 0.41; acc: 0.92
Batch: 100; loss: 0.53; acc: 0.88
Batch: 120; loss: 0.37; acc: 0.94
Batch: 140; loss: 0.3; acc: 0.88
Batch: 160; loss: 0.57; acc: 0.84
Batch: 180; loss: 0.31; acc: 0.91
Batch: 200; loss: 0.48; acc: 0.84
Batch: 220; loss: 0.24; acc: 0.94
Batch: 240; loss: 0.48; acc: 0.84
Batch: 260; loss: 0.17; acc: 0.95
Batch: 280; loss: 0.32; acc: 0.92
Batch: 300; loss: 0.25; acc: 0.89
Batch: 320; loss: 0.18; acc: 0.92
Batch: 340; loss: 0.2; acc: 0.94
Batch: 360; loss: 0.3; acc: 0.91
Batch: 380; loss: 0.46; acc: 0.89
Batch: 400; loss: 0.44; acc: 0.89
Batch: 420; loss: 0.28; acc: 0.88
Batch: 440; loss: 0.23; acc: 0.92
Batch: 460; loss: 0.2; acc: 0.94
Batch: 480; loss: 0.39; acc: 0.86
Batch: 500; loss: 0.31; acc: 0.89
Batch: 520; loss: 0.26; acc: 0.86
Batch: 540; loss: 0.27; acc: 0.92
Batch: 560; loss: 0.58; acc: 0.88
Batch: 580; loss: 0.13; acc: 0.94
Batch: 600; loss: 0.29; acc: 0.88
Batch: 620; loss: 0.31; acc: 0.94
Batch: 640; loss: 0.38; acc: 0.86
Batch: 660; loss: 0.22; acc: 0.92
Batch: 680; loss: 0.36; acc: 0.89
Batch: 700; loss: 0.18; acc: 0.95
Batch: 720; loss: 0.2; acc: 0.94
Batch: 740; loss: 0.41; acc: 0.88
Batch: 760; loss: 0.32; acc: 0.91
Batch: 780; loss: 0.35; acc: 0.83
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.4969654987216927e-05
7.734299288131297e-06
Batch: 0; loss: 0.15; acc: 0.98
Batch: 20; loss: 0.36; acc: 0.89
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.26; acc: 0.94
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.92
Batch: 120; loss: 0.5; acc: 0.83
Batch: 140; loss: 0.12; acc: 0.95
Val Epoch over. val_loss: 0.25632263601395733; val_accuracy: 0.9249601910828026 

The current subspace-distance is: 7.734299288131297e-06 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.47; acc: 0.88
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.57; acc: 0.84
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.34; acc: 0.86
Batch: 140; loss: 0.21; acc: 0.97
Batch: 160; loss: 0.32; acc: 0.92
Batch: 180; loss: 0.31; acc: 0.91
Batch: 200; loss: 0.21; acc: 0.94
Batch: 220; loss: 0.15; acc: 0.94
Batch: 240; loss: 0.19; acc: 0.91
Batch: 260; loss: 0.42; acc: 0.91
Batch: 280; loss: 0.27; acc: 0.91
Batch: 300; loss: 0.35; acc: 0.91
Batch: 320; loss: 0.34; acc: 0.88
Batch: 340; loss: 0.25; acc: 0.91
Batch: 360; loss: 0.23; acc: 0.91
Batch: 380; loss: 0.15; acc: 0.97
Batch: 400; loss: 0.25; acc: 0.91
Batch: 420; loss: 0.22; acc: 0.98
Batch: 440; loss: 0.24; acc: 0.95
Batch: 460; loss: 0.37; acc: 0.86
Batch: 480; loss: 0.21; acc: 0.94
Batch: 500; loss: 0.26; acc: 0.92
Batch: 520; loss: 0.22; acc: 0.92
Batch: 540; loss: 0.27; acc: 0.91
Batch: 560; loss: 0.4; acc: 0.84
Batch: 580; loss: 0.18; acc: 0.95
Batch: 600; loss: 0.37; acc: 0.88
Batch: 620; loss: 0.3; acc: 0.88
Batch: 640; loss: 0.16; acc: 0.92
Batch: 660; loss: 0.14; acc: 0.97
Batch: 680; loss: 0.16; acc: 0.97
Batch: 700; loss: 0.37; acc: 0.95
Batch: 720; loss: 0.28; acc: 0.89
Batch: 740; loss: 0.19; acc: 0.94
Batch: 760; loss: 0.15; acc: 0.95
Batch: 780; loss: 0.31; acc: 0.91
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.6476096536498517e-05
7.641058800800238e-06
Batch: 0; loss: 0.23; acc: 0.91
Batch: 20; loss: 0.47; acc: 0.86
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.22; acc: 0.89
Batch: 100; loss: 0.21; acc: 0.94
Batch: 120; loss: 0.52; acc: 0.86
Batch: 140; loss: 0.2; acc: 0.95
Val Epoch over. val_loss: 0.2879908795047338; val_accuracy: 0.9148089171974523 

The current subspace-distance is: 7.641058800800238e-06 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.26; acc: 0.88
Batch: 20; loss: 0.36; acc: 0.89
Batch: 40; loss: 0.35; acc: 0.88
Batch: 60; loss: 0.38; acc: 0.88
Batch: 80; loss: 0.53; acc: 0.86
Batch: 100; loss: 0.53; acc: 0.89
Batch: 120; loss: 0.13; acc: 0.94
Batch: 140; loss: 0.33; acc: 0.91
Batch: 160; loss: 0.24; acc: 0.94
Batch: 180; loss: 0.23; acc: 0.94
Batch: 200; loss: 0.43; acc: 0.88
Batch: 220; loss: 0.32; acc: 0.92
Batch: 240; loss: 0.17; acc: 0.95
Batch: 260; loss: 0.31; acc: 0.92
Batch: 280; loss: 0.41; acc: 0.89
Batch: 300; loss: 0.54; acc: 0.81
Batch: 320; loss: 0.39; acc: 0.86
Batch: 340; loss: 0.41; acc: 0.88
Batch: 360; loss: 0.24; acc: 0.94
Batch: 380; loss: 0.14; acc: 0.95
Batch: 400; loss: 0.54; acc: 0.78
Batch: 420; loss: 0.2; acc: 0.94
Batch: 440; loss: 0.32; acc: 0.89
Batch: 460; loss: 0.24; acc: 0.91
Batch: 480; loss: 0.46; acc: 0.86
Batch: 500; loss: 0.31; acc: 0.86
Batch: 520; loss: 0.41; acc: 0.91
Batch: 540; loss: 0.23; acc: 0.95
Batch: 560; loss: 0.18; acc: 0.92
Batch: 580; loss: 0.43; acc: 0.89
Batch: 600; loss: 0.18; acc: 0.95
Batch: 620; loss: 0.35; acc: 0.88
Batch: 640; loss: 0.38; acc: 0.92
Batch: 660; loss: 0.21; acc: 0.94
Batch: 680; loss: 0.49; acc: 0.89
Batch: 700; loss: 0.1; acc: 0.97
Batch: 720; loss: 0.43; acc: 0.91
Batch: 740; loss: 0.2; acc: 0.92
Batch: 760; loss: 0.19; acc: 0.94
Batch: 780; loss: 0.41; acc: 0.92
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.4857226890162565e-05
7.305283816094743e-06
Batch: 0; loss: 0.2; acc: 0.92
Batch: 20; loss: 0.4; acc: 0.86
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.28; acc: 0.92
Batch: 80; loss: 0.25; acc: 0.91
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.53; acc: 0.86
Batch: 140; loss: 0.16; acc: 0.95
Val Epoch over. val_loss: 0.270082904844527; val_accuracy: 0.9204816878980892 

The current subspace-distance is: 7.305283816094743e-06 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.22; acc: 0.91
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.25; acc: 0.92
Batch: 80; loss: 0.24; acc: 0.91
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.26; acc: 0.91
Batch: 140; loss: 0.18; acc: 0.94
Batch: 160; loss: 0.23; acc: 0.91
Batch: 180; loss: 0.3; acc: 0.91
Batch: 200; loss: 0.19; acc: 0.94
Batch: 220; loss: 0.22; acc: 0.92
Batch: 240; loss: 0.24; acc: 0.94
Batch: 260; loss: 0.32; acc: 0.89
Batch: 280; loss: 0.25; acc: 0.92
Batch: 300; loss: 0.32; acc: 0.88
Batch: 320; loss: 0.5; acc: 0.89
Batch: 340; loss: 0.17; acc: 0.94
Batch: 360; loss: 0.27; acc: 0.95
Batch: 380; loss: 0.22; acc: 0.95
Batch: 400; loss: 0.32; acc: 0.89
Batch: 420; loss: 0.2; acc: 0.94
Batch: 440; loss: 0.33; acc: 0.89
Batch: 460; loss: 0.21; acc: 0.94
Batch: 480; loss: 0.38; acc: 0.89
Batch: 500; loss: 0.22; acc: 0.94
Batch: 520; loss: 0.46; acc: 0.89
Batch: 540; loss: 0.11; acc: 0.95
Batch: 560; loss: 0.41; acc: 0.86
Batch: 580; loss: 0.11; acc: 0.97
Batch: 600; loss: 0.3; acc: 0.89
Batch: 620; loss: 0.34; acc: 0.89
Batch: 640; loss: 0.22; acc: 0.94
Batch: 660; loss: 0.44; acc: 0.92
Batch: 680; loss: 0.25; acc: 0.89
Batch: 700; loss: 0.38; acc: 0.92
Batch: 720; loss: 0.31; acc: 0.94
Batch: 740; loss: 0.26; acc: 0.91
Batch: 760; loss: 0.25; acc: 0.95
Batch: 780; loss: 0.24; acc: 0.92
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

2.6772384444484487e-05
8.990512469608802e-06
Batch: 0; loss: 0.17; acc: 0.97
Batch: 20; loss: 0.29; acc: 0.89
Batch: 40; loss: 0.12; acc: 0.98
Batch: 60; loss: 0.28; acc: 0.94
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.43; acc: 0.88
Batch: 140; loss: 0.12; acc: 0.95
Val Epoch over. val_loss: 0.2512268508742949; val_accuracy: 0.9254578025477707 

The current subspace-distance is: 8.990512469608802e-06 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.3; acc: 0.88
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.16; acc: 0.97
Batch: 60; loss: 0.47; acc: 0.88
Batch: 80; loss: 0.32; acc: 0.91
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.31; acc: 0.92
Batch: 140; loss: 0.44; acc: 0.88
Batch: 160; loss: 0.17; acc: 0.94
Batch: 180; loss: 0.38; acc: 0.89
Batch: 200; loss: 0.18; acc: 0.94
Batch: 220; loss: 0.14; acc: 0.94
Batch: 240; loss: 0.14; acc: 0.95
Batch: 260; loss: 0.25; acc: 0.92
Batch: 280; loss: 0.22; acc: 0.94
Batch: 300; loss: 0.21; acc: 0.94
Batch: 320; loss: 0.49; acc: 0.89
Batch: 340; loss: 0.26; acc: 0.92
Batch: 360; loss: 0.06; acc: 1.0
Batch: 380; loss: 0.26; acc: 0.94
Batch: 400; loss: 0.26; acc: 0.91
Batch: 420; loss: 0.32; acc: 0.89
Batch: 440; loss: 0.1; acc: 0.97
Batch: 460; loss: 0.1; acc: 0.98
Batch: 480; loss: 0.29; acc: 0.92
Batch: 500; loss: 0.25; acc: 0.92
Batch: 520; loss: 0.18; acc: 0.92
Batch: 540; loss: 0.23; acc: 0.91
Batch: 560; loss: 0.23; acc: 0.89
Batch: 580; loss: 0.27; acc: 0.92
Batch: 600; loss: 0.19; acc: 0.95
Batch: 620; loss: 0.54; acc: 0.89
Batch: 640; loss: 0.18; acc: 0.92
Batch: 660; loss: 0.43; acc: 0.89
Batch: 680; loss: 0.1; acc: 0.95
Batch: 700; loss: 0.14; acc: 0.95
Batch: 720; loss: 0.3; acc: 0.91
Batch: 740; loss: 0.29; acc: 0.94
Batch: 760; loss: 0.4; acc: 0.92
Batch: 780; loss: 0.34; acc: 0.86
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.7254634915152565e-05
7.90032026998233e-06
Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.32; acc: 0.89
Batch: 40; loss: 0.1; acc: 0.98
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.18; acc: 0.92
Batch: 120; loss: 0.41; acc: 0.89
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.24952728621614206; val_accuracy: 0.9284434713375797 

The current subspace-distance is: 7.90032026998233e-06 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.08; acc: 0.98
Batch: 80; loss: 0.22; acc: 0.92
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.36; acc: 0.89
Batch: 140; loss: 0.18; acc: 0.92
Batch: 160; loss: 0.42; acc: 0.89
Batch: 180; loss: 0.13; acc: 0.97
Batch: 200; loss: 0.28; acc: 0.89
Batch: 220; loss: 0.15; acc: 0.97
Batch: 240; loss: 0.22; acc: 0.94
Batch: 260; loss: 0.2; acc: 0.94
Batch: 280; loss: 0.28; acc: 0.92
Batch: 300; loss: 0.33; acc: 0.88
Batch: 320; loss: 0.47; acc: 0.88
Batch: 340; loss: 0.21; acc: 0.94
Batch: 360; loss: 0.2; acc: 0.94
Batch: 380; loss: 0.33; acc: 0.89
Batch: 400; loss: 0.39; acc: 0.91
Batch: 420; loss: 0.32; acc: 0.94
Batch: 440; loss: 0.39; acc: 0.86
Batch: 460; loss: 0.26; acc: 0.91
Batch: 480; loss: 0.2; acc: 0.94
Batch: 500; loss: 0.23; acc: 0.89
Batch: 520; loss: 0.24; acc: 0.94
Batch: 540; loss: 0.55; acc: 0.81
Batch: 560; loss: 0.24; acc: 0.94
Batch: 580; loss: 0.3; acc: 0.94
Batch: 600; loss: 0.26; acc: 0.95
Batch: 620; loss: 0.18; acc: 0.97
Batch: 640; loss: 0.28; acc: 0.91
Batch: 660; loss: 0.5; acc: 0.83
Batch: 680; loss: 0.18; acc: 0.94
Batch: 700; loss: 0.19; acc: 0.94
Batch: 720; loss: 0.21; acc: 0.97
Batch: 740; loss: 0.15; acc: 0.95
Batch: 760; loss: 0.27; acc: 0.89
Batch: 780; loss: 0.22; acc: 0.95
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.503102587070316e-05
8.539032023691107e-06
Batch: 0; loss: 0.21; acc: 0.91
Batch: 20; loss: 0.38; acc: 0.86
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.33; acc: 0.89
Batch: 80; loss: 0.22; acc: 0.89
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.51; acc: 0.88
Batch: 140; loss: 0.21; acc: 0.95
Val Epoch over. val_loss: 0.27428517853663226; val_accuracy: 0.9176950636942676 

The current subspace-distance is: 8.539032023691107e-06 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.32; acc: 0.88
Batch: 20; loss: 0.39; acc: 0.91
Batch: 40; loss: 0.36; acc: 0.83
Batch: 60; loss: 0.3; acc: 0.91
Batch: 80; loss: 0.48; acc: 0.89
Batch: 100; loss: 0.33; acc: 0.92
Batch: 120; loss: 0.35; acc: 0.92
Batch: 140; loss: 0.19; acc: 0.92
Batch: 160; loss: 0.32; acc: 0.89
Batch: 180; loss: 0.28; acc: 0.88
Batch: 200; loss: 0.34; acc: 0.91
Batch: 220; loss: 0.25; acc: 0.94
Batch: 240; loss: 0.26; acc: 0.92
Batch: 260; loss: 0.2; acc: 0.92
Batch: 280; loss: 0.35; acc: 0.91
Batch: 300; loss: 0.09; acc: 0.98
Batch: 320; loss: 0.31; acc: 0.94
Batch: 340; loss: 0.24; acc: 0.94
Batch: 360; loss: 0.26; acc: 0.91
Batch: 380; loss: 0.33; acc: 0.89
Batch: 400; loss: 0.26; acc: 0.94
Batch: 420; loss: 0.19; acc: 0.94
Batch: 440; loss: 0.5; acc: 0.84
Batch: 460; loss: 0.2; acc: 0.92
Batch: 480; loss: 0.36; acc: 0.86
Batch: 500; loss: 0.29; acc: 0.92
Batch: 520; loss: 0.37; acc: 0.92
Batch: 540; loss: 0.19; acc: 0.94
Batch: 560; loss: 0.3; acc: 0.89
Batch: 580; loss: 0.22; acc: 0.97
Batch: 600; loss: 0.19; acc: 0.92
Batch: 620; loss: 0.19; acc: 0.94
Batch: 640; loss: 0.35; acc: 0.89
Batch: 660; loss: 0.17; acc: 0.95
Batch: 680; loss: 0.25; acc: 0.92
Batch: 700; loss: 0.1; acc: 0.95
Batch: 720; loss: 0.2; acc: 0.95
Batch: 740; loss: 0.12; acc: 0.95
Batch: 760; loss: 0.24; acc: 0.92
Batch: 780; loss: 0.19; acc: 0.97
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.5073553842958063e-05
7.13298413757002e-06
Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.3; acc: 0.89
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.26; acc: 0.94
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.42; acc: 0.89
Batch: 140; loss: 0.15; acc: 0.95
Val Epoch over. val_loss: 0.2519376935900017; val_accuracy: 0.9248606687898089 

The current subspace-distance is: 7.13298413757002e-06 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.27; acc: 0.94
Batch: 40; loss: 0.28; acc: 0.89
Batch: 60; loss: 0.53; acc: 0.86
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.35; acc: 0.91
Batch: 120; loss: 0.09; acc: 0.98
Batch: 140; loss: 0.4; acc: 0.86
Batch: 160; loss: 0.3; acc: 0.91
Batch: 180; loss: 0.28; acc: 0.95
Batch: 200; loss: 0.12; acc: 0.95
Batch: 220; loss: 0.35; acc: 0.91
Batch: 240; loss: 0.27; acc: 0.89
Batch: 260; loss: 0.22; acc: 0.91
Batch: 280; loss: 0.26; acc: 0.92
Batch: 300; loss: 0.2; acc: 0.92
Batch: 320; loss: 0.22; acc: 0.92
Batch: 340; loss: 0.23; acc: 0.95
Batch: 360; loss: 0.33; acc: 0.91
Batch: 380; loss: 0.21; acc: 0.95
Batch: 400; loss: 0.3; acc: 0.89
Batch: 420; loss: 0.29; acc: 0.94
Batch: 440; loss: 0.19; acc: 0.94
Batch: 460; loss: 0.27; acc: 0.94
Batch: 480; loss: 0.21; acc: 0.92
Batch: 500; loss: 0.13; acc: 0.95
Batch: 520; loss: 0.1; acc: 0.94
Batch: 540; loss: 0.14; acc: 0.95
Batch: 560; loss: 0.19; acc: 0.94
Batch: 580; loss: 0.48; acc: 0.86
Batch: 600; loss: 0.15; acc: 0.95
Batch: 620; loss: 0.17; acc: 0.94
Batch: 640; loss: 0.33; acc: 0.92
Batch: 660; loss: 0.17; acc: 0.97
Batch: 680; loss: 0.32; acc: 0.89
Batch: 700; loss: 0.32; acc: 0.91
Batch: 720; loss: 0.25; acc: 0.94
Batch: 740; loss: 0.4; acc: 0.86
Batch: 760; loss: 0.23; acc: 0.89
Batch: 780; loss: 0.43; acc: 0.92
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.6976127628586255e-05
7.2360780905000865e-06
Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.28; acc: 0.92
Batch: 40; loss: 0.1; acc: 0.98
Batch: 60; loss: 0.29; acc: 0.92
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.43; acc: 0.88
Batch: 140; loss: 0.14; acc: 0.95
Val Epoch over. val_loss: 0.2457871153998147; val_accuracy: 0.9278463375796179 

The current subspace-distance is: 7.2360780905000865e-06 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.36; acc: 0.94
Batch: 40; loss: 0.33; acc: 0.92
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.28; acc: 0.91
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.22; acc: 0.92
Batch: 140; loss: 0.28; acc: 0.94
Batch: 160; loss: 0.23; acc: 0.94
Batch: 180; loss: 0.22; acc: 0.95
Batch: 200; loss: 0.14; acc: 0.97
Batch: 220; loss: 0.22; acc: 0.91
Batch: 240; loss: 0.34; acc: 0.91
Batch: 260; loss: 0.1; acc: 0.98
Batch: 280; loss: 0.24; acc: 0.91
Batch: 300; loss: 0.24; acc: 0.97
Batch: 320; loss: 0.18; acc: 0.97
Batch: 340; loss: 0.16; acc: 0.92
Batch: 360; loss: 0.19; acc: 0.95
Batch: 380; loss: 0.39; acc: 0.91
Batch: 400; loss: 0.13; acc: 0.97
Batch: 420; loss: 0.19; acc: 0.97
Batch: 440; loss: 0.26; acc: 0.92
Batch: 460; loss: 0.5; acc: 0.88
Batch: 480; loss: 0.28; acc: 0.91
Batch: 500; loss: 0.38; acc: 0.91
Batch: 520; loss: 0.15; acc: 0.95
Batch: 540; loss: 0.36; acc: 0.88
Batch: 560; loss: 0.12; acc: 0.95
Batch: 580; loss: 0.2; acc: 0.94
Batch: 600; loss: 0.2; acc: 0.94
Batch: 620; loss: 0.15; acc: 0.97
Batch: 640; loss: 0.25; acc: 0.92
Batch: 660; loss: 0.3; acc: 0.88
Batch: 680; loss: 0.38; acc: 0.91
Batch: 700; loss: 0.15; acc: 0.95
Batch: 720; loss: 0.19; acc: 0.94
Batch: 740; loss: 0.13; acc: 0.95
Batch: 760; loss: 0.67; acc: 0.84
Batch: 780; loss: 0.13; acc: 0.97
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.5945095330826007e-05
8.57890336192213e-06
Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.1; acc: 0.98
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.16; acc: 0.92
Batch: 120; loss: 0.4; acc: 0.88
Batch: 140; loss: 0.13; acc: 0.95
Val Epoch over. val_loss: 0.2388577802925353; val_accuracy: 0.9295382165605095 

The current subspace-distance is: 8.57890336192213e-06 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.44; acc: 0.86
Batch: 20; loss: 0.32; acc: 0.84
Batch: 40; loss: 0.2; acc: 0.92
Batch: 60; loss: 0.27; acc: 0.88
Batch: 80; loss: 0.4; acc: 0.92
Batch: 100; loss: 0.32; acc: 0.86
Batch: 120; loss: 0.07; acc: 0.98
Batch: 140; loss: 0.19; acc: 0.92
Batch: 160; loss: 0.17; acc: 0.94
Batch: 180; loss: 0.24; acc: 0.92
Batch: 200; loss: 0.33; acc: 0.91
Batch: 220; loss: 0.52; acc: 0.86
Batch: 240; loss: 0.24; acc: 0.92
Batch: 260; loss: 0.16; acc: 0.95
Batch: 280; loss: 0.31; acc: 0.92
Batch: 300; loss: 0.48; acc: 0.84
Batch: 320; loss: 0.19; acc: 0.95
Batch: 340; loss: 0.27; acc: 0.91
Batch: 360; loss: 0.32; acc: 0.91
Batch: 380; loss: 0.2; acc: 0.94
Batch: 400; loss: 0.3; acc: 0.91
Batch: 420; loss: 0.32; acc: 0.92
Batch: 440; loss: 0.27; acc: 0.92
Batch: 460; loss: 0.35; acc: 0.88
Batch: 480; loss: 0.25; acc: 0.95
Batch: 500; loss: 0.34; acc: 0.89
Batch: 520; loss: 0.24; acc: 0.91
Batch: 540; loss: 0.29; acc: 0.92
Batch: 560; loss: 0.19; acc: 0.95
Batch: 580; loss: 0.18; acc: 0.95
Batch: 600; loss: 0.22; acc: 0.92
Batch: 620; loss: 0.28; acc: 0.89
Batch: 640; loss: 0.22; acc: 0.92
Batch: 660; loss: 0.33; acc: 0.91
Batch: 680; loss: 0.2; acc: 0.92
Batch: 700; loss: 0.31; acc: 0.91
Batch: 720; loss: 0.29; acc: 0.91
Batch: 740; loss: 0.34; acc: 0.91
Batch: 760; loss: 0.32; acc: 0.89
Batch: 780; loss: 0.28; acc: 0.94
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.690636938496027e-05
8.126106877170969e-06
Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.31; acc: 0.92
Batch: 40; loss: 0.11; acc: 0.98
Batch: 60; loss: 0.29; acc: 0.91
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.16; acc: 0.94
Batch: 120; loss: 0.37; acc: 0.89
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.2526698248211745; val_accuracy: 0.923765923566879 

The current subspace-distance is: 8.126106877170969e-06 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.27; acc: 0.88
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.26; acc: 0.89
Batch: 60; loss: 0.44; acc: 0.86
Batch: 80; loss: 0.4; acc: 0.89
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.3; acc: 0.92
Batch: 140; loss: 0.27; acc: 0.92
Batch: 160; loss: 0.52; acc: 0.81
Batch: 180; loss: 0.34; acc: 0.89
Batch: 200; loss: 0.18; acc: 0.97
Batch: 220; loss: 0.33; acc: 0.94
Batch: 240; loss: 0.4; acc: 0.92
Batch: 260; loss: 0.25; acc: 0.89
Batch: 280; loss: 0.28; acc: 0.88
Batch: 300; loss: 0.14; acc: 0.94
Batch: 320; loss: 0.33; acc: 0.88
Batch: 340; loss: 0.15; acc: 0.97
Batch: 360; loss: 0.07; acc: 0.98
Batch: 380; loss: 0.39; acc: 0.88
Batch: 400; loss: 0.24; acc: 0.94
Batch: 420; loss: 0.46; acc: 0.91
Batch: 440; loss: 0.15; acc: 0.95
Batch: 460; loss: 0.36; acc: 0.94
Batch: 480; loss: 0.34; acc: 0.95
Batch: 500; loss: 0.27; acc: 0.94
Batch: 520; loss: 0.14; acc: 0.95
Batch: 540; loss: 0.31; acc: 0.92
Batch: 560; loss: 0.26; acc: 0.94
Batch: 580; loss: 0.45; acc: 0.81
Batch: 600; loss: 0.21; acc: 0.97
Batch: 620; loss: 0.4; acc: 0.86
Batch: 640; loss: 0.25; acc: 0.92
Batch: 660; loss: 0.28; acc: 0.89
Batch: 680; loss: 0.24; acc: 0.91
Batch: 700; loss: 0.39; acc: 0.86
Batch: 720; loss: 0.21; acc: 0.92
Batch: 740; loss: 0.2; acc: 0.94
Batch: 760; loss: 0.3; acc: 0.88
Batch: 780; loss: 0.24; acc: 0.94
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.607894202810712e-05
7.54949633119395e-06
Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.32; acc: 0.88
Batch: 40; loss: 0.1; acc: 0.98
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.92
Batch: 120; loss: 0.43; acc: 0.86
Batch: 140; loss: 0.13; acc: 0.95
Val Epoch over. val_loss: 0.24559696035305406; val_accuracy: 0.9276472929936306 

The current subspace-distance is: 7.54949633119395e-06 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.29; acc: 0.92
Batch: 20; loss: 0.29; acc: 0.94
Batch: 40; loss: 0.2; acc: 0.91
Batch: 60; loss: 0.38; acc: 0.86
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.23; acc: 0.92
Batch: 140; loss: 0.23; acc: 0.95
Batch: 160; loss: 0.26; acc: 0.91
Batch: 180; loss: 0.37; acc: 0.89
Batch: 200; loss: 0.08; acc: 0.97
Batch: 220; loss: 0.35; acc: 0.94
Batch: 240; loss: 0.28; acc: 0.95
Batch: 260; loss: 0.19; acc: 0.94
Batch: 280; loss: 0.15; acc: 0.97
Batch: 300; loss: 0.32; acc: 0.91
Batch: 320; loss: 0.23; acc: 0.94
Batch: 340; loss: 0.39; acc: 0.89
Batch: 360; loss: 0.23; acc: 0.94
Batch: 380; loss: 0.27; acc: 0.89
Batch: 400; loss: 0.3; acc: 0.89
Batch: 420; loss: 0.28; acc: 0.92
Batch: 440; loss: 0.33; acc: 0.92
Batch: 460; loss: 0.27; acc: 0.92
Batch: 480; loss: 0.24; acc: 0.95
Batch: 500; loss: 0.39; acc: 0.89
Batch: 520; loss: 0.35; acc: 0.88
Batch: 540; loss: 0.21; acc: 0.92
Batch: 560; loss: 0.29; acc: 0.88
Batch: 580; loss: 0.13; acc: 0.95
Batch: 600; loss: 0.18; acc: 0.95
Batch: 620; loss: 0.09; acc: 0.97
Batch: 640; loss: 0.06; acc: 1.0
Batch: 660; loss: 0.37; acc: 0.88
Batch: 680; loss: 0.23; acc: 0.89
Batch: 700; loss: 0.27; acc: 0.91
Batch: 720; loss: 0.18; acc: 0.94
Batch: 740; loss: 0.26; acc: 0.89
Batch: 760; loss: 0.49; acc: 0.81
Batch: 780; loss: 0.45; acc: 0.89
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.7318492357153445e-05
8.706597327545751e-06
Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.33; acc: 0.89
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.18; acc: 0.92
Batch: 120; loss: 0.43; acc: 0.86
Batch: 140; loss: 0.16; acc: 0.95
Val Epoch over. val_loss: 0.2460934818502824; val_accuracy: 0.9288415605095541 

The current subspace-distance is: 8.706597327545751e-06 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.33; acc: 0.89
Batch: 20; loss: 0.46; acc: 0.89
Batch: 40; loss: 0.14; acc: 0.94
Batch: 60; loss: 0.46; acc: 0.94
Batch: 80; loss: 0.31; acc: 0.92
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.19; acc: 0.97
Batch: 140; loss: 0.46; acc: 0.92
Batch: 160; loss: 0.18; acc: 0.92
Batch: 180; loss: 0.32; acc: 0.89
Batch: 200; loss: 0.27; acc: 0.86
Batch: 220; loss: 0.13; acc: 0.95
Batch: 240; loss: 0.24; acc: 0.92
Batch: 260; loss: 0.66; acc: 0.83
Batch: 280; loss: 0.49; acc: 0.81
Batch: 300; loss: 0.13; acc: 0.97
Batch: 320; loss: 0.26; acc: 0.94
Batch: 340; loss: 0.31; acc: 0.89
Batch: 360; loss: 0.2; acc: 0.94
Batch: 380; loss: 0.35; acc: 0.91
Batch: 400; loss: 0.26; acc: 0.94
Batch: 420; loss: 0.15; acc: 0.95
Batch: 440; loss: 0.34; acc: 0.89
Batch: 460; loss: 0.31; acc: 0.89
Batch: 480; loss: 0.17; acc: 0.97
Batch: 500; loss: 0.14; acc: 0.94
Batch: 520; loss: 0.15; acc: 0.95
Batch: 540; loss: 0.17; acc: 0.95
Batch: 560; loss: 0.17; acc: 0.97
Batch: 580; loss: 0.21; acc: 0.95
Batch: 600; loss: 0.25; acc: 0.97
Batch: 620; loss: 0.23; acc: 0.91
Batch: 640; loss: 0.3; acc: 0.91
Batch: 660; loss: 0.15; acc: 0.95
Batch: 680; loss: 0.33; acc: 0.92
Batch: 700; loss: 0.22; acc: 0.95
Batch: 720; loss: 0.21; acc: 0.92
Batch: 740; loss: 0.12; acc: 0.94
Batch: 760; loss: 0.2; acc: 0.94
Batch: 780; loss: 0.11; acc: 0.97
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.6576904929243028e-05
6.901515462232055e-06
Batch: 0; loss: 0.14; acc: 0.98
Batch: 20; loss: 0.37; acc: 0.88
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.33; acc: 0.94
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.16; acc: 0.94
Batch: 120; loss: 0.45; acc: 0.84
Batch: 140; loss: 0.15; acc: 0.95
Val Epoch over. val_loss: 0.25502751077151603; val_accuracy: 0.9250597133757962 

The current subspace-distance is: 6.901515462232055e-06 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.19; acc: 0.91
Batch: 20; loss: 0.37; acc: 0.89
Batch: 40; loss: 0.12; acc: 0.94
Batch: 60; loss: 0.46; acc: 0.89
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.26; acc: 0.94
Batch: 120; loss: 0.21; acc: 0.94
Batch: 140; loss: 0.21; acc: 0.94
Batch: 160; loss: 0.31; acc: 0.94
Batch: 180; loss: 0.24; acc: 0.91
Batch: 200; loss: 0.14; acc: 0.95
Batch: 220; loss: 0.41; acc: 0.89
Batch: 240; loss: 0.12; acc: 0.97
Batch: 260; loss: 0.19; acc: 0.94
Batch: 280; loss: 0.21; acc: 0.91
Batch: 300; loss: 0.2; acc: 0.89
Batch: 320; loss: 0.27; acc: 0.92
Batch: 340; loss: 0.12; acc: 0.95
Batch: 360; loss: 0.27; acc: 0.91
Batch: 380; loss: 0.28; acc: 0.89
Batch: 400; loss: 0.3; acc: 0.92
Batch: 420; loss: 0.11; acc: 0.94
Batch: 440; loss: 0.36; acc: 0.89
Batch: 460; loss: 0.51; acc: 0.84
Batch: 480; loss: 0.2; acc: 0.94
Batch: 500; loss: 0.22; acc: 0.94
Batch: 520; loss: 0.32; acc: 0.89
Batch: 540; loss: 0.34; acc: 0.91
Batch: 560; loss: 0.26; acc: 0.92
Batch: 580; loss: 0.35; acc: 0.92
Batch: 600; loss: 0.25; acc: 0.92
Batch: 620; loss: 0.28; acc: 0.89
Batch: 640; loss: 0.4; acc: 0.86
Batch: 660; loss: 0.14; acc: 0.98
Batch: 680; loss: 0.18; acc: 0.92
Batch: 700; loss: 0.46; acc: 0.84
Batch: 720; loss: 0.15; acc: 0.94
Batch: 740; loss: 0.3; acc: 0.88
Batch: 760; loss: 0.1; acc: 0.97
Batch: 780; loss: 0.27; acc: 0.94
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.681559453776572e-05
7.698672561673447e-06
Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.28; acc: 0.92
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.16; acc: 0.94
Batch: 120; loss: 0.4; acc: 0.89
Batch: 140; loss: 0.16; acc: 0.95
Val Epoch over. val_loss: 0.24399905011152764; val_accuracy: 0.9288415605095541 

The current subspace-distance is: 7.698672561673447e-06 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.21; acc: 0.95
Batch: 20; loss: 0.41; acc: 0.86
Batch: 40; loss: 0.38; acc: 0.86
Batch: 60; loss: 0.27; acc: 0.91
Batch: 80; loss: 0.32; acc: 0.92
Batch: 100; loss: 0.25; acc: 0.89
Batch: 120; loss: 0.29; acc: 0.91
Batch: 140; loss: 0.76; acc: 0.78
Batch: 160; loss: 0.32; acc: 0.91
Batch: 180; loss: 0.13; acc: 0.95
Batch: 200; loss: 0.28; acc: 0.94
Batch: 220; loss: 0.23; acc: 0.91
Batch: 240; loss: 0.46; acc: 0.84
Batch: 260; loss: 0.14; acc: 0.97
Batch: 280; loss: 0.32; acc: 0.88
Batch: 300; loss: 0.36; acc: 0.91
Batch: 320; loss: 0.2; acc: 0.94
Batch: 340; loss: 0.2; acc: 0.94
Batch: 360; loss: 0.22; acc: 0.95
Batch: 380; loss: 0.14; acc: 0.95
Batch: 400; loss: 0.29; acc: 0.91
Batch: 420; loss: 0.19; acc: 0.91
Batch: 440; loss: 0.32; acc: 0.89
Batch: 460; loss: 0.33; acc: 0.86
Batch: 480; loss: 0.24; acc: 0.94
Batch: 500; loss: 0.16; acc: 0.95
Batch: 520; loss: 0.28; acc: 0.94
Batch: 540; loss: 0.25; acc: 0.92
Batch: 560; loss: 0.2; acc: 0.92
Batch: 580; loss: 0.31; acc: 0.92
Batch: 600; loss: 0.27; acc: 0.89
Batch: 620; loss: 0.13; acc: 0.95
Batch: 640; loss: 0.4; acc: 0.86
Batch: 660; loss: 0.09; acc: 0.98
Batch: 680; loss: 0.11; acc: 0.95
Batch: 700; loss: 0.21; acc: 0.94
Batch: 720; loss: 0.38; acc: 0.89
Batch: 740; loss: 0.37; acc: 0.88
Batch: 760; loss: 0.28; acc: 0.91
Batch: 780; loss: 0.26; acc: 0.92
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.5710656700539403e-05
7.5089924393978436e-06
Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.33; acc: 0.91
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.29; acc: 0.92
Batch: 80; loss: 0.17; acc: 0.92
Batch: 100; loss: 0.16; acc: 0.94
Batch: 120; loss: 0.4; acc: 0.86
Batch: 140; loss: 0.16; acc: 0.95
Val Epoch over. val_loss: 0.2395179295900521; val_accuracy: 0.9303343949044586 

The current subspace-distance is: 7.5089924393978436e-06 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.25; acc: 0.94
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.25; acc: 0.91
Batch: 80; loss: 0.37; acc: 0.84
Batch: 100; loss: 0.24; acc: 0.89
Batch: 120; loss: 0.27; acc: 0.94
Batch: 140; loss: 0.63; acc: 0.84
Batch: 160; loss: 0.12; acc: 0.97
Batch: 180; loss: 0.13; acc: 0.98
Batch: 200; loss: 0.29; acc: 0.92
Batch: 220; loss: 0.27; acc: 0.91
Batch: 240; loss: 0.14; acc: 0.97
Batch: 260; loss: 0.19; acc: 0.92
Batch: 280; loss: 0.6; acc: 0.86
Batch: 300; loss: 0.69; acc: 0.86
Batch: 320; loss: 0.26; acc: 0.91
Batch: 340; loss: 0.28; acc: 0.94
Batch: 360; loss: 0.23; acc: 0.95
Batch: 380; loss: 0.15; acc: 0.95
Batch: 400; loss: 0.38; acc: 0.89
Batch: 420; loss: 0.29; acc: 0.92
Batch: 440; loss: 0.19; acc: 0.94
Batch: 460; loss: 0.21; acc: 0.94
Batch: 480; loss: 0.09; acc: 0.97
Batch: 500; loss: 0.47; acc: 0.86
Batch: 520; loss: 0.32; acc: 0.94
Batch: 540; loss: 0.28; acc: 0.89
Batch: 560; loss: 0.23; acc: 0.97
Batch: 580; loss: 0.31; acc: 0.92
Batch: 600; loss: 0.17; acc: 0.94
Batch: 620; loss: 0.42; acc: 0.84
Batch: 640; loss: 0.16; acc: 0.95
Batch: 660; loss: 0.12; acc: 0.97
Batch: 680; loss: 0.3; acc: 0.91
Batch: 700; loss: 0.19; acc: 0.95
Batch: 720; loss: 0.25; acc: 0.94
Batch: 740; loss: 0.22; acc: 0.97
Batch: 760; loss: 0.15; acc: 0.95
Batch: 780; loss: 0.19; acc: 0.94
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.5899349566316232e-05
7.751123121124692e-06
Batch: 0; loss: 0.16; acc: 0.97
Batch: 20; loss: 0.33; acc: 0.91
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.28; acc: 0.92
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.4; acc: 0.86
Batch: 140; loss: 0.16; acc: 0.95
Val Epoch over. val_loss: 0.23947180874028784; val_accuracy: 0.931031050955414 

The current subspace-distance is: 7.751123121124692e-06 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.23; acc: 0.91
Batch: 40; loss: 0.23; acc: 0.92
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.16; acc: 0.92
Batch: 100; loss: 0.14; acc: 0.98
Batch: 120; loss: 0.15; acc: 0.94
Batch: 140; loss: 0.34; acc: 0.89
Batch: 160; loss: 0.27; acc: 0.91
Batch: 180; loss: 0.18; acc: 0.94
Batch: 200; loss: 0.18; acc: 0.91
Batch: 220; loss: 0.42; acc: 0.92
Batch: 240; loss: 0.66; acc: 0.88
Batch: 260; loss: 0.28; acc: 0.91
Batch: 280; loss: 0.16; acc: 0.94
Batch: 300; loss: 0.31; acc: 0.89
Batch: 320; loss: 0.22; acc: 0.92
Batch: 340; loss: 0.19; acc: 0.94
Batch: 360; loss: 0.15; acc: 0.94
Batch: 380; loss: 0.17; acc: 0.98
Batch: 400; loss: 0.16; acc: 0.95
Batch: 420; loss: 0.28; acc: 0.89
Batch: 440; loss: 0.21; acc: 0.95
Batch: 460; loss: 0.21; acc: 0.91
Batch: 480; loss: 0.21; acc: 0.95
Batch: 500; loss: 0.23; acc: 0.91
Batch: 520; loss: 0.14; acc: 0.94
Batch: 540; loss: 0.16; acc: 0.95
Batch: 560; loss: 0.22; acc: 0.92
Batch: 580; loss: 0.31; acc: 0.92
Batch: 600; loss: 0.34; acc: 0.92
Batch: 620; loss: 0.45; acc: 0.86
Batch: 640; loss: 0.21; acc: 0.94
Batch: 660; loss: 0.14; acc: 0.95
Batch: 680; loss: 0.38; acc: 0.89
Batch: 700; loss: 0.18; acc: 0.94
Batch: 720; loss: 0.25; acc: 0.95
Batch: 740; loss: 0.18; acc: 0.95
Batch: 760; loss: 0.38; acc: 0.88
Batch: 780; loss: 0.26; acc: 0.89
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.6778589017339982e-05
8.839268048177473e-06
Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.28; acc: 0.92
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.15; acc: 0.94
Batch: 120; loss: 0.37; acc: 0.88
Batch: 140; loss: 0.15; acc: 0.95
Val Epoch over. val_loss: 0.23690467771546098; val_accuracy: 0.9316281847133758 

The current subspace-distance is: 8.839268048177473e-06 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.32; acc: 0.89
Batch: 20; loss: 0.48; acc: 0.92
Batch: 40; loss: 0.27; acc: 0.91
Batch: 60; loss: 0.41; acc: 0.84
Batch: 80; loss: 0.17; acc: 0.92
Batch: 100; loss: 0.44; acc: 0.88
Batch: 120; loss: 0.29; acc: 0.92
Batch: 140; loss: 0.21; acc: 0.97
Batch: 160; loss: 0.24; acc: 0.92
Batch: 180; loss: 0.15; acc: 0.97
Batch: 200; loss: 0.45; acc: 0.92
Batch: 220; loss: 0.18; acc: 0.94
Batch: 240; loss: 0.06; acc: 1.0
Batch: 260; loss: 0.15; acc: 0.95
Batch: 280; loss: 0.15; acc: 0.95
Batch: 300; loss: 0.18; acc: 0.92
Batch: 320; loss: 0.39; acc: 0.88
Batch: 340; loss: 0.24; acc: 0.92
Batch: 360; loss: 0.17; acc: 0.97
Batch: 380; loss: 0.07; acc: 0.98
Batch: 400; loss: 0.4; acc: 0.91
Batch: 420; loss: 0.14; acc: 0.95
Batch: 440; loss: 0.28; acc: 0.91
Batch: 460; loss: 0.14; acc: 0.98
Batch: 480; loss: 0.19; acc: 0.94
Batch: 500; loss: 0.21; acc: 0.94
Batch: 520; loss: 0.27; acc: 0.95
Batch: 540; loss: 0.27; acc: 0.91
Batch: 560; loss: 0.14; acc: 0.95
Batch: 580; loss: 0.15; acc: 0.94
Batch: 600; loss: 0.2; acc: 0.97
Batch: 620; loss: 0.34; acc: 0.94
Batch: 640; loss: 0.11; acc: 0.95
Batch: 660; loss: 0.58; acc: 0.89
Batch: 680; loss: 0.32; acc: 0.91
Batch: 700; loss: 0.36; acc: 0.89
Batch: 720; loss: 0.18; acc: 0.94
Batch: 740; loss: 0.34; acc: 0.88
Batch: 760; loss: 0.38; acc: 0.86
Batch: 780; loss: 0.15; acc: 0.95
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.7794463676400483e-05
7.71668965171557e-06
Batch: 0; loss: 0.15; acc: 0.94
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.29; acc: 0.92
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.38; acc: 0.86
Batch: 140; loss: 0.15; acc: 0.95
Val Epoch over. val_loss: 0.23879959123434535; val_accuracy: 0.9306329617834395 

The current subspace-distance is: 7.71668965171557e-06 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.56; acc: 0.89
Batch: 20; loss: 0.24; acc: 0.95
Batch: 40; loss: 0.48; acc: 0.89
Batch: 60; loss: 0.28; acc: 0.91
Batch: 80; loss: 0.28; acc: 0.92
Batch: 100; loss: 0.25; acc: 0.94
Batch: 120; loss: 0.43; acc: 0.89
Batch: 140; loss: 0.25; acc: 0.92
Batch: 160; loss: 0.41; acc: 0.86
Batch: 180; loss: 0.31; acc: 0.92
Batch: 200; loss: 0.27; acc: 0.92
Batch: 220; loss: 0.23; acc: 0.92
Batch: 240; loss: 0.25; acc: 0.89
Batch: 260; loss: 0.37; acc: 0.88
Batch: 280; loss: 0.39; acc: 0.89
Batch: 300; loss: 0.17; acc: 0.95
Batch: 320; loss: 0.23; acc: 0.94
Batch: 340; loss: 0.19; acc: 0.95
Batch: 360; loss: 0.36; acc: 0.89
Batch: 380; loss: 0.21; acc: 0.92
Batch: 400; loss: 0.26; acc: 0.89
Batch: 420; loss: 0.28; acc: 0.89
Batch: 440; loss: 0.26; acc: 0.91
Batch: 460; loss: 0.14; acc: 0.95
Batch: 480; loss: 0.18; acc: 0.95
Batch: 500; loss: 0.22; acc: 0.91
Batch: 520; loss: 0.37; acc: 0.91
Batch: 540; loss: 0.24; acc: 0.94
Batch: 560; loss: 0.11; acc: 0.97
Batch: 580; loss: 0.36; acc: 0.89
Batch: 600; loss: 0.37; acc: 0.92
Batch: 620; loss: 0.15; acc: 0.97
Batch: 640; loss: 0.3; acc: 0.91
Batch: 660; loss: 0.24; acc: 0.95
Batch: 680; loss: 0.23; acc: 0.94
Batch: 700; loss: 0.16; acc: 0.95
Batch: 720; loss: 0.25; acc: 0.92
Batch: 740; loss: 0.29; acc: 0.91
Batch: 760; loss: 0.24; acc: 0.94
Batch: 780; loss: 0.27; acc: 0.94
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.628961010486819e-05
7.988294782990124e-06
Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.31; acc: 0.89
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.29; acc: 0.94
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.35; acc: 0.88
Batch: 140; loss: 0.14; acc: 0.95
Val Epoch over. val_loss: 0.23597382194107505; val_accuracy: 0.9298367834394905 

The current subspace-distance is: 7.988294782990124e-06 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.37; acc: 0.84
Batch: 40; loss: 0.4; acc: 0.88
Batch: 60; loss: 0.31; acc: 0.92
Batch: 80; loss: 0.14; acc: 0.94
Batch: 100; loss: 0.22; acc: 0.92
Batch: 120; loss: 0.34; acc: 0.92
Batch: 140; loss: 0.29; acc: 0.91
Batch: 160; loss: 0.15; acc: 0.97
Batch: 180; loss: 0.32; acc: 0.88
Batch: 200; loss: 0.29; acc: 0.91
Batch: 220; loss: 0.29; acc: 0.89
Batch: 240; loss: 0.3; acc: 0.88
Batch: 260; loss: 0.25; acc: 0.91
Batch: 280; loss: 0.72; acc: 0.84
Batch: 300; loss: 0.47; acc: 0.86
Batch: 320; loss: 0.44; acc: 0.91
Batch: 340; loss: 0.26; acc: 0.94
Batch: 360; loss: 0.26; acc: 0.92
Batch: 380; loss: 0.22; acc: 0.94
Batch: 400; loss: 0.1; acc: 1.0
Batch: 420; loss: 0.2; acc: 0.92
Batch: 440; loss: 0.29; acc: 0.95
Batch: 460; loss: 0.31; acc: 0.95
Batch: 480; loss: 0.32; acc: 0.92
Batch: 500; loss: 0.23; acc: 0.92
Batch: 520; loss: 0.25; acc: 0.92
Batch: 540; loss: 0.26; acc: 0.92
Batch: 560; loss: 0.25; acc: 0.89
Batch: 580; loss: 0.49; acc: 0.81
Batch: 600; loss: 0.24; acc: 0.97
Batch: 620; loss: 0.4; acc: 0.88
Batch: 640; loss: 0.53; acc: 0.84
Batch: 660; loss: 0.3; acc: 0.92
Batch: 680; loss: 0.22; acc: 0.95
Batch: 700; loss: 0.15; acc: 0.95
Batch: 720; loss: 0.33; acc: 0.91
Batch: 740; loss: 0.28; acc: 0.92
Batch: 760; loss: 0.19; acc: 0.94
Batch: 780; loss: 0.27; acc: 0.92
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.8028953238390386e-05
7.988383913470898e-06
Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.32; acc: 0.91
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.32; acc: 0.92
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.16; acc: 0.97
Batch: 120; loss: 0.38; acc: 0.88
Batch: 140; loss: 0.17; acc: 0.95
Val Epoch over. val_loss: 0.24502564938205063; val_accuracy: 0.9281449044585988 

The current subspace-distance is: 7.988383913470898e-06 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.17; acc: 0.94
Batch: 40; loss: 0.22; acc: 0.92
Batch: 60; loss: 0.15; acc: 0.98
Batch: 80; loss: 0.22; acc: 0.92
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.3; acc: 0.91
Batch: 140; loss: 0.08; acc: 1.0
Batch: 160; loss: 0.27; acc: 0.89
Batch: 180; loss: 0.18; acc: 0.95
Batch: 200; loss: 0.26; acc: 0.89
Batch: 220; loss: 0.21; acc: 0.92
Batch: 240; loss: 0.2; acc: 0.95
Batch: 260; loss: 0.22; acc: 0.91
Batch: 280; loss: 0.11; acc: 0.98
Batch: 300; loss: 0.37; acc: 0.84
Batch: 320; loss: 0.21; acc: 0.92
Batch: 340; loss: 0.47; acc: 0.84
Batch: 360; loss: 0.23; acc: 0.95
Batch: 380; loss: 0.32; acc: 0.95
Batch: 400; loss: 0.18; acc: 0.94
Batch: 420; loss: 0.23; acc: 0.97
Batch: 440; loss: 0.16; acc: 0.97
Batch: 460; loss: 0.17; acc: 0.95
Batch: 480; loss: 0.2; acc: 0.94
Batch: 500; loss: 0.15; acc: 0.95
Batch: 520; loss: 0.18; acc: 0.92
Batch: 540; loss: 0.51; acc: 0.89
Batch: 560; loss: 0.21; acc: 0.94
Batch: 580; loss: 0.37; acc: 0.94
Batch: 600; loss: 0.29; acc: 0.92
Batch: 620; loss: 0.24; acc: 0.92
Batch: 640; loss: 0.29; acc: 0.95
Batch: 660; loss: 0.14; acc: 0.95
Batch: 680; loss: 0.27; acc: 0.92
Batch: 700; loss: 0.37; acc: 0.89
Batch: 720; loss: 0.19; acc: 0.94
Batch: 740; loss: 0.37; acc: 0.91
Batch: 760; loss: 0.43; acc: 0.92
Batch: 780; loss: 0.34; acc: 0.91
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.709981163206976e-05
7.5652314990293235e-06
Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.32; acc: 0.89
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.29; acc: 0.94
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.36; acc: 0.86
Batch: 140; loss: 0.14; acc: 0.95
Val Epoch over. val_loss: 0.2340905357650511; val_accuracy: 0.9322253184713376 

The current subspace-distance is: 7.5652314990293235e-06 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.4; acc: 0.91
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.32; acc: 0.94
Batch: 80; loss: 0.32; acc: 0.91
Batch: 100; loss: 0.33; acc: 0.94
Batch: 120; loss: 0.3; acc: 0.95
Batch: 140; loss: 0.33; acc: 0.92
Batch: 160; loss: 0.35; acc: 0.86
Batch: 180; loss: 0.13; acc: 0.97
Batch: 200; loss: 0.24; acc: 0.92
Batch: 220; loss: 0.15; acc: 0.98
Batch: 240; loss: 0.28; acc: 0.92
Batch: 260; loss: 0.19; acc: 0.92
Batch: 280; loss: 0.27; acc: 0.92
Batch: 300; loss: 0.31; acc: 0.92
Batch: 320; loss: 0.2; acc: 0.91
Batch: 340; loss: 0.27; acc: 0.88
Batch: 360; loss: 0.34; acc: 0.92
Batch: 380; loss: 0.27; acc: 0.92
Batch: 400; loss: 0.19; acc: 0.95
Batch: 420; loss: 0.44; acc: 0.91
Batch: 440; loss: 0.24; acc: 0.94
Batch: 460; loss: 0.21; acc: 0.91
Batch: 480; loss: 0.23; acc: 0.95
Batch: 500; loss: 0.07; acc: 0.98
Batch: 520; loss: 0.34; acc: 0.94
Batch: 540; loss: 0.19; acc: 0.92
Batch: 560; loss: 0.43; acc: 0.88
Batch: 580; loss: 0.2; acc: 0.97
Batch: 600; loss: 0.37; acc: 0.88
Batch: 620; loss: 0.24; acc: 0.89
Batch: 640; loss: 0.22; acc: 0.92
Batch: 660; loss: 0.24; acc: 0.94
Batch: 680; loss: 0.28; acc: 0.92
Batch: 700; loss: 0.44; acc: 0.92
Batch: 720; loss: 0.2; acc: 0.94
Batch: 740; loss: 0.33; acc: 0.92
Batch: 760; loss: 0.18; acc: 0.95
Batch: 780; loss: 0.33; acc: 0.91
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.6987170713255182e-05
7.960418770380784e-06
Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.3; acc: 0.94
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.36; acc: 0.88
Batch: 140; loss: 0.15; acc: 0.95
Val Epoch over. val_loss: 0.23703678051947027; val_accuracy: 0.9309315286624203 

The current subspace-distance is: 7.960418770380784e-06 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.28; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.08; acc: 0.98
Batch: 80; loss: 0.55; acc: 0.86
Batch: 100; loss: 0.24; acc: 0.91
Batch: 120; loss: 0.34; acc: 0.89
Batch: 140; loss: 0.17; acc: 0.95
Batch: 160; loss: 0.16; acc: 0.94
Batch: 180; loss: 0.09; acc: 0.97
Batch: 200; loss: 0.27; acc: 0.92
Batch: 220; loss: 0.2; acc: 0.94
Batch: 240; loss: 0.44; acc: 0.84
Batch: 260; loss: 0.29; acc: 0.92
Batch: 280; loss: 0.19; acc: 0.92
Batch: 300; loss: 0.52; acc: 0.84
Batch: 320; loss: 0.33; acc: 0.89
Batch: 340; loss: 0.24; acc: 0.92
Batch: 360; loss: 0.11; acc: 0.97
Batch: 380; loss: 0.09; acc: 0.97
Batch: 400; loss: 0.17; acc: 0.97
Batch: 420; loss: 0.39; acc: 0.86
Batch: 440; loss: 0.18; acc: 0.91
Batch: 460; loss: 0.15; acc: 0.94
Batch: 480; loss: 0.23; acc: 0.94
Batch: 500; loss: 0.27; acc: 0.94
Batch: 520; loss: 0.33; acc: 0.91
Batch: 540; loss: 0.2; acc: 0.92
Batch: 560; loss: 0.42; acc: 0.89
Batch: 580; loss: 0.4; acc: 0.88
Batch: 600; loss: 0.21; acc: 0.95
Batch: 620; loss: 0.36; acc: 0.89
Batch: 640; loss: 0.18; acc: 0.94
Batch: 660; loss: 0.22; acc: 0.94
Batch: 680; loss: 0.2; acc: 0.92
Batch: 700; loss: 0.32; acc: 0.89
Batch: 720; loss: 0.31; acc: 0.92
Batch: 740; loss: 0.46; acc: 0.84
Batch: 760; loss: 0.33; acc: 0.92
Batch: 780; loss: 0.22; acc: 0.95
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.7278067136649042e-05
9.111332474276423e-06
Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.34; acc: 0.91
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.29; acc: 0.91
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.39; acc: 0.88
Batch: 140; loss: 0.17; acc: 0.95
Val Epoch over. val_loss: 0.2428738488608105; val_accuracy: 0.9290406050955414 

The current subspace-distance is: 9.111332474276423e-06 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.4; acc: 0.88
Batch: 20; loss: 0.39; acc: 0.88
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.23; acc: 0.92
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.27; acc: 0.92
Batch: 140; loss: 0.22; acc: 0.94
Batch: 160; loss: 0.49; acc: 0.83
Batch: 180; loss: 0.27; acc: 0.89
Batch: 200; loss: 0.19; acc: 0.91
Batch: 220; loss: 0.25; acc: 0.89
Batch: 240; loss: 0.21; acc: 0.92
Batch: 260; loss: 0.25; acc: 0.92
Batch: 280; loss: 0.4; acc: 0.88
Batch: 300; loss: 0.33; acc: 0.88
Batch: 320; loss: 0.18; acc: 0.95
Batch: 340; loss: 0.45; acc: 0.86
Batch: 360; loss: 0.16; acc: 0.97
Batch: 380; loss: 0.26; acc: 0.89
Batch: 400; loss: 0.15; acc: 0.95
Batch: 420; loss: 0.14; acc: 0.95
Batch: 440; loss: 0.32; acc: 0.89
Batch: 460; loss: 0.29; acc: 0.91
Batch: 480; loss: 0.22; acc: 0.89
Batch: 500; loss: 0.36; acc: 0.89
Batch: 520; loss: 0.1; acc: 0.97
Batch: 540; loss: 0.07; acc: 0.97
Batch: 560; loss: 0.06; acc: 0.98
Batch: 580; loss: 0.43; acc: 0.92
Batch: 600; loss: 0.16; acc: 0.97
Batch: 620; loss: 0.24; acc: 0.94
Batch: 640; loss: 0.18; acc: 0.94
Batch: 660; loss: 0.26; acc: 0.94
Batch: 680; loss: 0.26; acc: 0.91
Batch: 700; loss: 0.28; acc: 0.92
Batch: 720; loss: 0.27; acc: 0.92
Batch: 740; loss: 0.5; acc: 0.88
Batch: 760; loss: 0.27; acc: 0.92
Batch: 780; loss: 0.32; acc: 0.95
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.7697426048689522e-05
8.642616194265429e-06
Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.31; acc: 0.89
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.31; acc: 0.92
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.14; acc: 0.97
Batch: 120; loss: 0.36; acc: 0.91
Batch: 140; loss: 0.16; acc: 0.95
Val Epoch over. val_loss: 0.23935623421885405; val_accuracy: 0.930234872611465 

The current subspace-distance is: 8.642616194265429e-06 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.32; acc: 0.91
Batch: 40; loss: 0.25; acc: 0.94
Batch: 60; loss: 0.2; acc: 0.92
Batch: 80; loss: 0.22; acc: 0.95
Batch: 100; loss: 0.21; acc: 0.95
Batch: 120; loss: 0.4; acc: 0.89
Batch: 140; loss: 0.27; acc: 0.89
Batch: 160; loss: 0.31; acc: 0.91
Batch: 180; loss: 0.27; acc: 0.92
Batch: 200; loss: 0.18; acc: 0.94
Batch: 220; loss: 0.33; acc: 0.91
Batch: 240; loss: 0.31; acc: 0.92
Batch: 260; loss: 0.27; acc: 0.91
Batch: 280; loss: 0.45; acc: 0.89
Batch: 300; loss: 0.25; acc: 0.94
Batch: 320; loss: 0.26; acc: 0.94
Batch: 340; loss: 0.15; acc: 0.95
Batch: 360; loss: 0.45; acc: 0.88
Batch: 380; loss: 0.42; acc: 0.88
Batch: 400; loss: 0.18; acc: 0.94
Batch: 420; loss: 0.22; acc: 0.89
Batch: 440; loss: 0.2; acc: 0.95
Batch: 460; loss: 0.27; acc: 0.91
Batch: 480; loss: 0.09; acc: 0.97
Batch: 500; loss: 0.1; acc: 0.98
Batch: 520; loss: 0.15; acc: 0.97
Batch: 540; loss: 0.15; acc: 0.95
Batch: 560; loss: 0.43; acc: 0.86
Batch: 580; loss: 0.26; acc: 0.91
Batch: 600; loss: 0.3; acc: 0.89
Batch: 620; loss: 0.18; acc: 0.95
Batch: 640; loss: 0.2; acc: 0.91
Batch: 660; loss: 0.22; acc: 0.92
Batch: 680; loss: 0.11; acc: 0.98
Batch: 700; loss: 0.31; acc: 0.89
Batch: 720; loss: 0.36; acc: 0.91
Batch: 740; loss: 0.12; acc: 0.98
Batch: 760; loss: 0.09; acc: 0.97
Batch: 780; loss: 0.19; acc: 0.94
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.619048609631136e-05
7.281292255356675e-06
Batch: 0; loss: 0.16; acc: 0.97
Batch: 20; loss: 0.32; acc: 0.91
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.28; acc: 0.92
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.15; acc: 0.94
Batch: 120; loss: 0.37; acc: 0.86
Batch: 140; loss: 0.15; acc: 0.95
Val Epoch over. val_loss: 0.2349295675944371; val_accuracy: 0.9314291401273885 

The current subspace-distance is: 7.281292255356675e-06 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.33; acc: 0.94
Batch: 40; loss: 0.28; acc: 0.91
Batch: 60; loss: 0.18; acc: 0.92
Batch: 80; loss: 0.27; acc: 0.94
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.44; acc: 0.84
Batch: 140; loss: 0.26; acc: 0.89
Batch: 160; loss: 0.39; acc: 0.91
Batch: 180; loss: 0.22; acc: 0.92
Batch: 200; loss: 0.43; acc: 0.95
Batch: 220; loss: 0.1; acc: 0.97
Batch: 240; loss: 0.1; acc: 0.97
Batch: 260; loss: 0.13; acc: 0.98
Batch: 280; loss: 0.18; acc: 0.95
Batch: 300; loss: 0.32; acc: 0.86
Batch: 320; loss: 0.3; acc: 0.92
Batch: 340; loss: 0.11; acc: 0.97
Batch: 360; loss: 0.29; acc: 0.91
Batch: 380; loss: 0.15; acc: 0.95
Batch: 400; loss: 0.36; acc: 0.91
Batch: 420; loss: 0.16; acc: 0.92
Batch: 440; loss: 0.15; acc: 0.95
Batch: 460; loss: 0.16; acc: 0.95
Batch: 480; loss: 0.18; acc: 0.92
Batch: 500; loss: 0.16; acc: 0.92
Batch: 520; loss: 0.25; acc: 0.92
Batch: 540; loss: 0.35; acc: 0.89
Batch: 560; loss: 0.23; acc: 0.92
Batch: 580; loss: 0.29; acc: 0.94
Batch: 600; loss: 0.29; acc: 0.95
Batch: 620; loss: 0.17; acc: 0.94
Batch: 640; loss: 0.14; acc: 0.98
Batch: 660; loss: 0.27; acc: 0.89
Batch: 680; loss: 0.17; acc: 0.92
Batch: 700; loss: 0.25; acc: 0.92
Batch: 720; loss: 0.26; acc: 0.94
Batch: 740; loss: 0.24; acc: 0.91
Batch: 760; loss: 0.26; acc: 0.95
Batch: 780; loss: 0.21; acc: 0.94
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.9444960091495886e-05
7.229569291666849e-06
Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.32; acc: 0.91
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.28; acc: 0.92
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.38; acc: 0.86
Batch: 140; loss: 0.15; acc: 0.95
Val Epoch over. val_loss: 0.23529134826010958; val_accuracy: 0.9314291401273885 

The current subspace-distance is: 7.229569291666849e-06 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.3; acc: 0.94
Batch: 20; loss: 0.51; acc: 0.91
Batch: 40; loss: 0.33; acc: 0.92
Batch: 60; loss: 0.22; acc: 0.92
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.15; acc: 0.92
Batch: 120; loss: 0.28; acc: 0.92
Batch: 140; loss: 0.13; acc: 0.95
Batch: 160; loss: 0.16; acc: 0.95
Batch: 180; loss: 0.33; acc: 0.91
Batch: 200; loss: 0.24; acc: 0.94
Batch: 220; loss: 0.12; acc: 0.97
Batch: 240; loss: 0.48; acc: 0.91
Batch: 260; loss: 0.31; acc: 0.94
Batch: 280; loss: 0.24; acc: 0.91
Batch: 300; loss: 0.25; acc: 0.92
Batch: 320; loss: 0.14; acc: 0.97
Batch: 340; loss: 0.1; acc: 0.95
Batch: 360; loss: 0.21; acc: 0.94
Batch: 380; loss: 0.32; acc: 0.89
Batch: 400; loss: 0.15; acc: 0.95
Batch: 420; loss: 0.19; acc: 0.97
Batch: 440; loss: 0.07; acc: 1.0
Batch: 460; loss: 0.17; acc: 0.92
Batch: 480; loss: 0.34; acc: 0.91
Batch: 500; loss: 0.25; acc: 0.91
Batch: 520; loss: 0.49; acc: 0.86
Batch: 540; loss: 0.29; acc: 0.89
Batch: 560; loss: 0.22; acc: 0.94
Batch: 580; loss: 0.39; acc: 0.86
Batch: 600; loss: 0.2; acc: 0.94
Batch: 620; loss: 0.29; acc: 0.89
Batch: 640; loss: 0.11; acc: 0.97
Batch: 660; loss: 0.13; acc: 0.94
Batch: 680; loss: 0.26; acc: 0.92
Batch: 700; loss: 0.27; acc: 0.94
Batch: 720; loss: 0.21; acc: 0.92
Batch: 740; loss: 0.4; acc: 0.91
Batch: 760; loss: 0.23; acc: 0.92
Batch: 780; loss: 0.1; acc: 0.98
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.6038424039143138e-05
6.715301879012259e-06
Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.32; acc: 0.91
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.29; acc: 0.94
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.37; acc: 0.89
Batch: 140; loss: 0.15; acc: 0.95
Val Epoch over. val_loss: 0.2350451228250364; val_accuracy: 0.931031050955414 

The current subspace-distance is: 6.715301879012259e-06 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.32; acc: 0.88
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.39; acc: 0.91
Batch: 80; loss: 0.28; acc: 0.91
Batch: 100; loss: 0.47; acc: 0.86
Batch: 120; loss: 0.24; acc: 0.89
Batch: 140; loss: 0.54; acc: 0.89
Batch: 160; loss: 0.39; acc: 0.83
Batch: 180; loss: 0.33; acc: 0.89
Batch: 200; loss: 0.31; acc: 0.91
Batch: 220; loss: 0.27; acc: 0.94
Batch: 240; loss: 0.4; acc: 0.91
Batch: 260; loss: 0.31; acc: 0.89
Batch: 280; loss: 0.31; acc: 0.89
Batch: 300; loss: 0.11; acc: 0.97
Batch: 320; loss: 0.27; acc: 0.91
Batch: 340; loss: 0.37; acc: 0.92
Batch: 360; loss: 0.25; acc: 0.91
Batch: 380; loss: 0.24; acc: 0.92
Batch: 400; loss: 0.4; acc: 0.89
Batch: 420; loss: 0.19; acc: 0.97
Batch: 440; loss: 0.25; acc: 0.91
Batch: 460; loss: 0.26; acc: 0.92
Batch: 480; loss: 0.44; acc: 0.91
Batch: 500; loss: 0.49; acc: 0.89
Batch: 520; loss: 0.31; acc: 0.91
Batch: 540; loss: 0.18; acc: 0.95
Batch: 560; loss: 0.2; acc: 0.92
Batch: 580; loss: 0.35; acc: 0.92
Batch: 600; loss: 0.31; acc: 0.89
Batch: 620; loss: 0.28; acc: 0.92
Batch: 640; loss: 0.3; acc: 0.89
Batch: 660; loss: 0.41; acc: 0.88
Batch: 680; loss: 0.16; acc: 0.98
Batch: 700; loss: 0.24; acc: 0.91
Batch: 720; loss: 0.25; acc: 0.94
Batch: 740; loss: 0.32; acc: 0.94
Batch: 760; loss: 0.3; acc: 0.88
Batch: 780; loss: 0.11; acc: 0.97
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.7212452550884336e-05
7.700316018599551e-06
Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.32; acc: 0.89
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.29; acc: 0.92
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.36; acc: 0.89
Batch: 140; loss: 0.14; acc: 0.95
Val Epoch over. val_loss: 0.23429400049102533; val_accuracy: 0.9309315286624203 

The current subspace-distance is: 7.700316018599551e-06 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.09; acc: 0.98
Batch: 40; loss: 0.26; acc: 0.92
Batch: 60; loss: 0.3; acc: 0.94
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.24; acc: 0.88
Batch: 140; loss: 0.12; acc: 0.97
Batch: 160; loss: 0.17; acc: 0.94
Batch: 180; loss: 0.09; acc: 0.97
Batch: 200; loss: 0.24; acc: 0.94
Batch: 220; loss: 0.13; acc: 0.95
Batch: 240; loss: 0.42; acc: 0.91
Batch: 260; loss: 0.24; acc: 0.95
Batch: 280; loss: 0.24; acc: 0.95
Batch: 300; loss: 0.25; acc: 0.94
Batch: 320; loss: 0.24; acc: 0.94
Batch: 340; loss: 0.08; acc: 0.98
Batch: 360; loss: 0.18; acc: 0.94
Batch: 380; loss: 0.28; acc: 0.92
Batch: 400; loss: 0.27; acc: 0.92
Batch: 420; loss: 0.31; acc: 0.91
Batch: 440; loss: 0.36; acc: 0.89
Batch: 460; loss: 0.25; acc: 0.92
Batch: 480; loss: 0.25; acc: 0.92
Batch: 500; loss: 0.1; acc: 0.97
Batch: 520; loss: 0.14; acc: 0.94
Batch: 540; loss: 0.16; acc: 0.94
Batch: 560; loss: 0.07; acc: 0.98
Batch: 580; loss: 0.15; acc: 0.92
Batch: 600; loss: 0.31; acc: 0.91
Batch: 620; loss: 0.22; acc: 0.92
Batch: 640; loss: 0.3; acc: 0.86
Batch: 660; loss: 0.22; acc: 0.89
Batch: 680; loss: 0.26; acc: 0.95
Batch: 700; loss: 0.19; acc: 0.91
Batch: 720; loss: 0.39; acc: 0.88
Batch: 740; loss: 0.35; acc: 0.91
Batch: 760; loss: 0.35; acc: 0.94
Batch: 780; loss: 0.29; acc: 0.86
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.589803443697747e-05
8.401095328736119e-06
Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.31; acc: 0.89
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.29; acc: 0.92
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.14; acc: 0.97
Batch: 120; loss: 0.36; acc: 0.88
Batch: 140; loss: 0.14; acc: 0.95
Val Epoch over. val_loss: 0.23373627883328754; val_accuracy: 0.9312300955414012 

The current subspace-distance is: 8.401095328736119e-06 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.17; acc: 0.97
Batch: 20; loss: 0.31; acc: 0.88
Batch: 40; loss: 0.24; acc: 0.94
Batch: 60; loss: 0.48; acc: 0.91
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.34; acc: 0.81
Batch: 120; loss: 0.38; acc: 0.91
Batch: 140; loss: 0.28; acc: 0.91
Batch: 160; loss: 0.23; acc: 0.91
Batch: 180; loss: 0.18; acc: 0.92
Batch: 200; loss: 0.25; acc: 0.92
Batch: 220; loss: 0.23; acc: 0.94
Batch: 240; loss: 0.14; acc: 0.95
Batch: 260; loss: 0.21; acc: 0.94
Batch: 280; loss: 0.32; acc: 0.91
Batch: 300; loss: 0.37; acc: 0.89
Batch: 320; loss: 0.41; acc: 0.92
Batch: 340; loss: 0.24; acc: 0.92
Batch: 360; loss: 0.42; acc: 0.86
Batch: 380; loss: 0.49; acc: 0.88
Batch: 400; loss: 0.3; acc: 0.92
Batch: 420; loss: 0.28; acc: 0.92
Batch: 440; loss: 0.17; acc: 0.94
Batch: 460; loss: 0.28; acc: 0.94
Batch: 480; loss: 0.29; acc: 0.88
Batch: 500; loss: 0.22; acc: 0.95
Batch: 520; loss: 0.27; acc: 0.91
Batch: 540; loss: 0.64; acc: 0.84
Batch: 560; loss: 0.27; acc: 0.91
Batch: 580; loss: 0.31; acc: 0.89
Batch: 600; loss: 0.17; acc: 0.97
Batch: 620; loss: 0.44; acc: 0.86
Batch: 640; loss: 0.17; acc: 0.95
Batch: 660; loss: 0.2; acc: 0.94
Batch: 680; loss: 0.21; acc: 0.95
Batch: 700; loss: 0.29; acc: 0.92
Batch: 720; loss: 0.24; acc: 0.92
Batch: 740; loss: 0.14; acc: 0.95
Batch: 760; loss: 0.34; acc: 0.92
Batch: 780; loss: 0.38; acc: 0.88
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.6112174964509904e-05
7.78492812969489e-06
Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.32; acc: 0.89
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.28; acc: 0.92
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.36; acc: 0.86
Batch: 140; loss: 0.14; acc: 0.95
Val Epoch over. val_loss: 0.2341522859160308; val_accuracy: 0.931827229299363 

The current subspace-distance is: 7.78492812969489e-06 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.29; acc: 0.88
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.2; acc: 0.95
Batch: 80; loss: 0.26; acc: 0.95
Batch: 100; loss: 0.45; acc: 0.86
Batch: 120; loss: 0.3; acc: 0.88
Batch: 140; loss: 0.34; acc: 0.88
Batch: 160; loss: 0.32; acc: 0.92
Batch: 180; loss: 0.34; acc: 0.92
Batch: 200; loss: 0.21; acc: 0.91
Batch: 220; loss: 0.17; acc: 0.94
Batch: 240; loss: 0.15; acc: 0.95
Batch: 260; loss: 0.24; acc: 0.95
Batch: 280; loss: 0.16; acc: 0.95
Batch: 300; loss: 0.15; acc: 0.95
Batch: 320; loss: 0.42; acc: 0.89
Batch: 340; loss: 0.43; acc: 0.91
Batch: 360; loss: 0.3; acc: 0.92
Batch: 380; loss: 0.22; acc: 0.94
Batch: 400; loss: 0.15; acc: 0.95
Batch: 420; loss: 0.2; acc: 0.91
Batch: 440; loss: 0.19; acc: 0.94
Batch: 460; loss: 0.2; acc: 0.91
Batch: 480; loss: 0.1; acc: 0.98
Batch: 500; loss: 0.12; acc: 0.97
Batch: 520; loss: 0.14; acc: 0.98
Batch: 540; loss: 0.49; acc: 0.89
Batch: 560; loss: 0.15; acc: 0.94
Batch: 580; loss: 0.38; acc: 0.91
Batch: 600; loss: 0.26; acc: 0.92
Batch: 620; loss: 0.15; acc: 0.95
Batch: 640; loss: 0.25; acc: 0.91
Batch: 660; loss: 0.16; acc: 0.95
Batch: 680; loss: 0.37; acc: 0.88
Batch: 700; loss: 0.36; acc: 0.91
Batch: 720; loss: 0.23; acc: 0.86
Batch: 740; loss: 0.36; acc: 0.89
Batch: 760; loss: 0.34; acc: 0.89
Batch: 780; loss: 0.26; acc: 0.97
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.605049667181447e-05
8.432187314610928e-06
Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.31; acc: 0.89
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.29; acc: 0.92
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.36; acc: 0.89
Batch: 140; loss: 0.15; acc: 0.95
Val Epoch over. val_loss: 0.2344761800709044; val_accuracy: 0.9315286624203821 

The current subspace-distance is: 8.432187314610928e-06 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.25; acc: 0.94
Batch: 20; loss: 0.23; acc: 0.91
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.32; acc: 0.92
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.23; acc: 0.94
Batch: 140; loss: 0.5; acc: 0.89
Batch: 160; loss: 0.21; acc: 0.94
Batch: 180; loss: 0.18; acc: 0.97
Batch: 200; loss: 0.21; acc: 0.94
Batch: 220; loss: 0.15; acc: 0.97
Batch: 240; loss: 0.17; acc: 0.97
Batch: 260; loss: 0.26; acc: 0.94
Batch: 280; loss: 0.35; acc: 0.92
Batch: 300; loss: 0.26; acc: 0.94
Batch: 320; loss: 0.27; acc: 0.92
Batch: 340; loss: 0.17; acc: 0.91
Batch: 360; loss: 0.3; acc: 0.91
Batch: 380; loss: 0.25; acc: 0.92
Batch: 400; loss: 0.14; acc: 0.95
Batch: 420; loss: 0.26; acc: 0.92
Batch: 440; loss: 0.14; acc: 0.97
Batch: 460; loss: 0.22; acc: 0.94
Batch: 480; loss: 0.32; acc: 0.92
Batch: 500; loss: 0.45; acc: 0.84
Batch: 520; loss: 0.15; acc: 0.95
Batch: 540; loss: 0.45; acc: 0.83
Batch: 560; loss: 0.37; acc: 0.89
Batch: 580; loss: 0.13; acc: 0.97
Batch: 600; loss: 0.44; acc: 0.92
Batch: 620; loss: 0.19; acc: 0.95
Batch: 640; loss: 0.24; acc: 0.94
Batch: 660; loss: 0.22; acc: 0.95
Batch: 680; loss: 0.24; acc: 0.88
Batch: 700; loss: 0.23; acc: 0.92
Batch: 720; loss: 0.21; acc: 0.95
Batch: 740; loss: 0.3; acc: 0.92
Batch: 760; loss: 0.44; acc: 0.81
Batch: 780; loss: 0.22; acc: 0.92
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.7050573407905176e-05
7.720971552771516e-06
Batch: 0; loss: 0.16; acc: 0.97
Batch: 20; loss: 0.32; acc: 0.91
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.3; acc: 0.91
Batch: 80; loss: 0.15; acc: 0.94
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.36; acc: 0.89
Batch: 140; loss: 0.16; acc: 0.95
Val Epoch over. val_loss: 0.23619187741902223; val_accuracy: 0.931031050955414 

The current subspace-distance is: 7.720971552771516e-06 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.17; acc: 0.97
Batch: 20; loss: 0.33; acc: 0.89
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.32; acc: 0.92
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.24; acc: 0.94
Batch: 140; loss: 0.23; acc: 0.95
Batch: 160; loss: 0.28; acc: 0.91
Batch: 180; loss: 0.22; acc: 0.89
Batch: 200; loss: 0.17; acc: 0.94
Batch: 220; loss: 0.25; acc: 0.95
Batch: 240; loss: 0.14; acc: 0.98
Batch: 260; loss: 0.12; acc: 0.97
Batch: 280; loss: 0.43; acc: 0.92
Batch: 300; loss: 0.26; acc: 0.91
Batch: 320; loss: 0.17; acc: 0.95
Batch: 340; loss: 0.19; acc: 0.94
Batch: 360; loss: 0.14; acc: 0.95
Batch: 380; loss: 0.16; acc: 0.94
Batch: 400; loss: 0.33; acc: 0.91
Batch: 420; loss: 0.17; acc: 0.95
Batch: 440; loss: 0.2; acc: 0.92
Batch: 460; loss: 0.17; acc: 0.95
Batch: 480; loss: 0.36; acc: 0.89
Batch: 500; loss: 0.18; acc: 0.91
Batch: 520; loss: 0.35; acc: 0.94
Batch: 540; loss: 0.27; acc: 0.92
Batch: 560; loss: 0.32; acc: 0.89
Batch: 580; loss: 0.22; acc: 0.94
Batch: 600; loss: 0.16; acc: 0.95
Batch: 620; loss: 0.12; acc: 0.95
Batch: 640; loss: 0.32; acc: 0.88
Batch: 660; loss: 0.16; acc: 0.95
Batch: 680; loss: 0.18; acc: 0.95
Batch: 700; loss: 0.11; acc: 0.98
Batch: 720; loss: 0.26; acc: 0.91
Batch: 740; loss: 0.27; acc: 0.92
Batch: 760; loss: 0.32; acc: 0.91
Batch: 780; loss: 0.22; acc: 0.91
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.7304155082674697e-05
7.177294719440397e-06
Batch: 0; loss: 0.16; acc: 0.97
Batch: 20; loss: 0.33; acc: 0.89
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.29; acc: 0.92
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.36; acc: 0.89
Batch: 140; loss: 0.15; acc: 0.95
Val Epoch over. val_loss: 0.23496576412847847; val_accuracy: 0.931031050955414 

The current subspace-distance is: 7.177294719440397e-06 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.29; acc: 0.88
Batch: 40; loss: 0.25; acc: 0.95
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.46; acc: 0.88
Batch: 100; loss: 0.37; acc: 0.92
Batch: 120; loss: 0.15; acc: 0.94
Batch: 140; loss: 0.3; acc: 0.94
Batch: 160; loss: 0.27; acc: 0.92
Batch: 180; loss: 0.23; acc: 0.94
Batch: 200; loss: 0.47; acc: 0.89
Batch: 220; loss: 0.32; acc: 0.89
Batch: 240; loss: 0.15; acc: 0.97
Batch: 260; loss: 0.3; acc: 0.94
Batch: 280; loss: 0.16; acc: 0.94
Batch: 300; loss: 0.23; acc: 0.92
Batch: 320; loss: 0.06; acc: 1.0
Batch: 340; loss: 0.17; acc: 0.95
Batch: 360; loss: 0.32; acc: 0.91
Batch: 380; loss: 0.33; acc: 0.89
Batch: 400; loss: 0.3; acc: 0.92
Batch: 420; loss: 0.24; acc: 0.92
Batch: 440; loss: 0.15; acc: 0.95
Batch: 460; loss: 0.29; acc: 0.92
Batch: 480; loss: 0.44; acc: 0.91
Batch: 500; loss: 0.21; acc: 0.91
Batch: 520; loss: 0.27; acc: 0.92
Batch: 540; loss: 0.32; acc: 0.86
Batch: 560; loss: 0.45; acc: 0.88
Batch: 580; loss: 0.39; acc: 0.92
Batch: 600; loss: 0.27; acc: 0.94
Batch: 620; loss: 0.31; acc: 0.94
Batch: 640; loss: 0.14; acc: 0.98
Batch: 660; loss: 0.19; acc: 0.94
Batch: 680; loss: 0.31; acc: 0.88
Batch: 700; loss: 0.38; acc: 0.89
Batch: 720; loss: 0.28; acc: 0.95
Batch: 740; loss: 0.32; acc: 0.89
Batch: 760; loss: 0.2; acc: 0.91
Batch: 780; loss: 0.22; acc: 0.94
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.739107731031254e-05
6.985654636082472e-06
Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.32; acc: 0.89
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.3; acc: 0.92
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.35; acc: 0.89
Batch: 140; loss: 0.14; acc: 0.95
Val Epoch over. val_loss: 0.23363196337298983; val_accuracy: 0.9322253184713376 

The current subspace-distance is: 6.985654636082472e-06 

plots/subspace_training/reg_lenet_3/2020-01-22 20:51:04/d_dim_160_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
nonzero elements in E: 35951
elements in E: 7648300
fraction nonzero: 0.004700521684557353
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.31; acc: 0.08
Batch: 20; loss: 2.29; acc: 0.05
Batch: 40; loss: 2.3; acc: 0.11
Batch: 60; loss: 2.3; acc: 0.02
Batch: 80; loss: 2.3; acc: 0.06
Batch: 100; loss: 2.3; acc: 0.09
Batch: 120; loss: 2.3; acc: 0.05
Batch: 140; loss: 2.32; acc: 0.06
Batch: 160; loss: 2.3; acc: 0.06
Batch: 180; loss: 2.3; acc: 0.09
Batch: 200; loss: 2.3; acc: 0.08
Batch: 220; loss: 2.31; acc: 0.06
Batch: 240; loss: 2.31; acc: 0.06
Batch: 260; loss: 2.3; acc: 0.08
Batch: 280; loss: 2.29; acc: 0.12
Batch: 300; loss: 2.29; acc: 0.05
Batch: 320; loss: 2.3; acc: 0.08
Batch: 340; loss: 2.29; acc: 0.17
Batch: 360; loss: 2.29; acc: 0.05
Batch: 380; loss: 2.3; acc: 0.16
Batch: 400; loss: 2.3; acc: 0.08
Batch: 420; loss: 2.31; acc: 0.06
Batch: 440; loss: 2.29; acc: 0.12
Batch: 460; loss: 2.3; acc: 0.09
Batch: 480; loss: 2.29; acc: 0.11
Batch: 500; loss: 2.29; acc: 0.11
Batch: 520; loss: 2.27; acc: 0.17
Batch: 540; loss: 2.28; acc: 0.08
Batch: 560; loss: 2.28; acc: 0.19
Batch: 580; loss: 2.27; acc: 0.17
Batch: 600; loss: 2.29; acc: 0.19
Batch: 620; loss: 2.27; acc: 0.16
Batch: 640; loss: 2.27; acc: 0.12
Batch: 660; loss: 2.27; acc: 0.23
Batch: 680; loss: 2.29; acc: 0.11
Batch: 700; loss: 2.29; acc: 0.2
Batch: 720; loss: 2.29; acc: 0.16
Batch: 740; loss: 2.27; acc: 0.22
Batch: 760; loss: 2.28; acc: 0.27
Batch: 780; loss: 2.28; acc: 0.12
Train Epoch over. train_loss: 2.29; train_accuracy: 0.12 

6.073567874409491e-06
1.0073493967865943e-06
Batch: 0; loss: 2.26; acc: 0.27
Batch: 20; loss: 2.27; acc: 0.23
Batch: 40; loss: 2.27; acc: 0.3
Batch: 60; loss: 2.26; acc: 0.28
Batch: 80; loss: 2.25; acc: 0.28
Batch: 100; loss: 2.27; acc: 0.27
Batch: 120; loss: 2.27; acc: 0.2
Batch: 140; loss: 2.28; acc: 0.17
Val Epoch over. val_loss: 2.268754978848111; val_accuracy: 0.2291998407643312 

The current subspace-distance is: 1.0073493967865943e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 2.28; acc: 0.17
Batch: 20; loss: 2.28; acc: 0.22
Batch: 40; loss: 2.27; acc: 0.16
Batch: 60; loss: 2.24; acc: 0.25
Batch: 80; loss: 2.25; acc: 0.16
Batch: 100; loss: 2.27; acc: 0.11
Batch: 120; loss: 2.23; acc: 0.27
Batch: 140; loss: 2.25; acc: 0.17
Batch: 160; loss: 2.24; acc: 0.2
Batch: 180; loss: 2.25; acc: 0.09
Batch: 200; loss: 2.21; acc: 0.14
Batch: 220; loss: 2.22; acc: 0.11
Batch: 240; loss: 2.17; acc: 0.27
Batch: 260; loss: 2.18; acc: 0.28
Batch: 280; loss: 2.11; acc: 0.23
Batch: 300; loss: 2.13; acc: 0.3
Batch: 320; loss: 2.12; acc: 0.31
Batch: 340; loss: 2.04; acc: 0.28
Batch: 360; loss: 1.83; acc: 0.56
Batch: 380; loss: 1.72; acc: 0.55
Batch: 400; loss: 1.57; acc: 0.58
Batch: 420; loss: 1.38; acc: 0.48
Batch: 440; loss: 1.35; acc: 0.55
Batch: 460; loss: 1.43; acc: 0.58
Batch: 480; loss: 0.82; acc: 0.8
Batch: 500; loss: 1.39; acc: 0.45
Batch: 520; loss: 1.08; acc: 0.73
Batch: 540; loss: 0.87; acc: 0.72
Batch: 560; loss: 0.85; acc: 0.66
Batch: 580; loss: 0.81; acc: 0.8
Batch: 600; loss: 0.88; acc: 0.73
Batch: 620; loss: 0.66; acc: 0.75
Batch: 640; loss: 1.04; acc: 0.61
Batch: 660; loss: 1.11; acc: 0.66
Batch: 680; loss: 1.03; acc: 0.64
Batch: 700; loss: 0.74; acc: 0.77
Batch: 720; loss: 0.72; acc: 0.75
Batch: 740; loss: 0.85; acc: 0.81
Batch: 760; loss: 0.81; acc: 0.73
Batch: 780; loss: 1.61; acc: 0.64
Train Epoch over. train_loss: 1.57; train_accuracy: 0.46 

1.3280316125019453e-05
5.071555278846063e-06
Batch: 0; loss: 1.02; acc: 0.66
Batch: 20; loss: 1.09; acc: 0.61
Batch: 40; loss: 0.83; acc: 0.69
Batch: 60; loss: 1.16; acc: 0.67
Batch: 80; loss: 0.59; acc: 0.81
Batch: 100; loss: 0.81; acc: 0.73
Batch: 120; loss: 1.09; acc: 0.62
Batch: 140; loss: 1.11; acc: 0.69
Val Epoch over. val_loss: 0.9779541260877233; val_accuracy: 0.6905851910828026 

The current subspace-distance is: 5.071555278846063e-06 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 1.18; acc: 0.66
Batch: 20; loss: 0.65; acc: 0.8
Batch: 40; loss: 0.48; acc: 0.81
Batch: 60; loss: 0.6; acc: 0.78
Batch: 80; loss: 0.75; acc: 0.73
Batch: 100; loss: 0.64; acc: 0.8
Batch: 120; loss: 0.67; acc: 0.81
Batch: 140; loss: 0.61; acc: 0.75
Batch: 160; loss: 0.61; acc: 0.88
Batch: 180; loss: 0.33; acc: 0.95
Batch: 200; loss: 0.64; acc: 0.86
Batch: 220; loss: 0.76; acc: 0.77
Batch: 240; loss: 0.97; acc: 0.67
Batch: 260; loss: 0.65; acc: 0.81
Batch: 280; loss: 0.58; acc: 0.84
Batch: 300; loss: 0.46; acc: 0.86
Batch: 320; loss: 0.41; acc: 0.86
Batch: 340; loss: 0.6; acc: 0.84
Batch: 360; loss: 0.57; acc: 0.83
Batch: 380; loss: 0.46; acc: 0.88
Batch: 400; loss: 0.77; acc: 0.8
Batch: 420; loss: 0.74; acc: 0.8
Batch: 440; loss: 0.53; acc: 0.84
Batch: 460; loss: 0.59; acc: 0.8
Batch: 480; loss: 0.77; acc: 0.75
Batch: 500; loss: 0.75; acc: 0.75
Batch: 520; loss: 0.49; acc: 0.84
Batch: 540; loss: 0.54; acc: 0.86
Batch: 560; loss: 0.5; acc: 0.86
Batch: 580; loss: 0.63; acc: 0.78
Batch: 600; loss: 0.48; acc: 0.81
Batch: 620; loss: 0.88; acc: 0.7
Batch: 640; loss: 0.44; acc: 0.86
Batch: 660; loss: 0.49; acc: 0.89
Batch: 680; loss: 0.62; acc: 0.83
Batch: 700; loss: 0.52; acc: 0.86
Batch: 720; loss: 0.22; acc: 0.94
Batch: 740; loss: 0.44; acc: 0.86
Batch: 760; loss: 0.51; acc: 0.86
Batch: 780; loss: 0.45; acc: 0.91
Train Epoch over. train_loss: 0.58; train_accuracy: 0.82 

2.1357966033974662e-05
6.916669462952996e-06
Batch: 0; loss: 0.41; acc: 0.88
Batch: 20; loss: 0.53; acc: 0.78
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.5; acc: 0.89
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.37; acc: 0.91
Batch: 120; loss: 0.67; acc: 0.78
Batch: 140; loss: 0.27; acc: 0.95
Val Epoch over. val_loss: 0.45196947132705884; val_accuracy: 0.8660429936305732 

The current subspace-distance is: 6.916669462952996e-06 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.39; acc: 0.89
Batch: 20; loss: 0.59; acc: 0.8
Batch: 40; loss: 0.46; acc: 0.81
Batch: 60; loss: 0.45; acc: 0.86
Batch: 80; loss: 0.33; acc: 0.89
Batch: 100; loss: 0.33; acc: 0.89
Batch: 120; loss: 0.48; acc: 0.84
Batch: 140; loss: 0.41; acc: 0.89
Batch: 160; loss: 0.42; acc: 0.86
Batch: 180; loss: 0.5; acc: 0.8
Batch: 200; loss: 0.51; acc: 0.88
Batch: 220; loss: 0.78; acc: 0.86
Batch: 240; loss: 0.7; acc: 0.8
Batch: 260; loss: 0.49; acc: 0.84
Batch: 280; loss: 0.58; acc: 0.88
Batch: 300; loss: 0.44; acc: 0.86
Batch: 320; loss: 0.51; acc: 0.84
Batch: 340; loss: 0.58; acc: 0.83
Batch: 360; loss: 0.6; acc: 0.78
Batch: 380; loss: 0.57; acc: 0.81
Batch: 400; loss: 0.33; acc: 0.91
Batch: 420; loss: 0.67; acc: 0.8
Batch: 440; loss: 0.24; acc: 0.91
Batch: 460; loss: 0.35; acc: 0.92
Batch: 480; loss: 0.5; acc: 0.83
Batch: 500; loss: 0.28; acc: 0.92
Batch: 520; loss: 0.47; acc: 0.84
Batch: 540; loss: 0.66; acc: 0.73
Batch: 560; loss: 0.53; acc: 0.8
Batch: 580; loss: 0.61; acc: 0.78
Batch: 600; loss: 0.43; acc: 0.84
Batch: 620; loss: 0.54; acc: 0.83
Batch: 640; loss: 0.54; acc: 0.84
Batch: 660; loss: 0.64; acc: 0.8
Batch: 680; loss: 0.44; acc: 0.88
Batch: 700; loss: 0.37; acc: 0.91
Batch: 720; loss: 0.68; acc: 0.78
Batch: 740; loss: 0.5; acc: 0.84
Batch: 760; loss: 0.39; acc: 0.89
Batch: 780; loss: 0.36; acc: 0.86
Train Epoch over. train_loss: 0.48; train_accuracy: 0.85 

2.20409801841015e-05
7.234903478092747e-06
Batch: 0; loss: 0.47; acc: 0.78
Batch: 20; loss: 0.68; acc: 0.75
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.5; acc: 0.83
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.57; acc: 0.83
Batch: 120; loss: 0.74; acc: 0.73
Batch: 140; loss: 0.28; acc: 0.91
Val Epoch over. val_loss: 0.5156195193149482; val_accuracy: 0.8461385350318471 

The current subspace-distance is: 7.234903478092747e-06 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.51; acc: 0.84
Batch: 20; loss: 0.48; acc: 0.84
Batch: 40; loss: 0.48; acc: 0.86
Batch: 60; loss: 0.43; acc: 0.84
Batch: 80; loss: 0.55; acc: 0.84
Batch: 100; loss: 0.28; acc: 0.92
Batch: 120; loss: 0.38; acc: 0.84
Batch: 140; loss: 0.43; acc: 0.86
Batch: 160; loss: 0.31; acc: 0.88
Batch: 180; loss: 0.25; acc: 0.89
Batch: 200; loss: 0.33; acc: 0.89
Batch: 220; loss: 0.61; acc: 0.8
Batch: 240; loss: 0.36; acc: 0.91
Batch: 260; loss: 0.61; acc: 0.8
Batch: 280; loss: 0.31; acc: 0.89
Batch: 300; loss: 0.28; acc: 0.91
Batch: 320; loss: 0.34; acc: 0.88
Batch: 340; loss: 0.29; acc: 0.91
Batch: 360; loss: 0.56; acc: 0.83
Batch: 380; loss: 0.27; acc: 0.95
Batch: 400; loss: 0.67; acc: 0.81
Batch: 420; loss: 0.45; acc: 0.84
Batch: 440; loss: 0.62; acc: 0.75
Batch: 460; loss: 0.47; acc: 0.86
Batch: 480; loss: 0.47; acc: 0.86
Batch: 500; loss: 0.33; acc: 0.88
Batch: 520; loss: 0.28; acc: 0.88
Batch: 540; loss: 0.28; acc: 0.94
Batch: 560; loss: 0.57; acc: 0.81
Batch: 580; loss: 0.44; acc: 0.86
Batch: 600; loss: 0.4; acc: 0.88
Batch: 620; loss: 0.3; acc: 0.91
Batch: 640; loss: 0.36; acc: 0.91
Batch: 660; loss: 0.86; acc: 0.78
Batch: 680; loss: 0.78; acc: 0.75
Batch: 700; loss: 0.35; acc: 0.89
Batch: 720; loss: 0.26; acc: 0.89
Batch: 740; loss: 0.33; acc: 0.91
Batch: 760; loss: 0.3; acc: 0.88
Batch: 780; loss: 0.42; acc: 0.86
Train Epoch over. train_loss: 0.44; train_accuracy: 0.86 

2.505014890630264e-05
7.4382146522111725e-06
Batch: 0; loss: 0.36; acc: 0.86
Batch: 20; loss: 0.55; acc: 0.8
Batch: 40; loss: 0.24; acc: 0.92
Batch: 60; loss: 0.45; acc: 0.83
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.45; acc: 0.89
Batch: 120; loss: 0.54; acc: 0.89
Batch: 140; loss: 0.13; acc: 0.95
Val Epoch over. val_loss: 0.41031599215641146; val_accuracy: 0.877687101910828 

The current subspace-distance is: 7.4382146522111725e-06 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.45; acc: 0.86
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.59; acc: 0.81
Batch: 60; loss: 0.27; acc: 0.95
Batch: 80; loss: 0.25; acc: 0.89
Batch: 100; loss: 0.38; acc: 0.84
Batch: 120; loss: 0.24; acc: 0.92
Batch: 140; loss: 0.6; acc: 0.86
Batch: 160; loss: 0.44; acc: 0.84
Batch: 180; loss: 0.26; acc: 0.92
Batch: 200; loss: 0.44; acc: 0.86
Batch: 220; loss: 0.29; acc: 0.94
Batch: 240; loss: 0.44; acc: 0.86
Batch: 260; loss: 0.39; acc: 0.94
Batch: 280; loss: 0.32; acc: 0.89
Batch: 300; loss: 0.47; acc: 0.88
Batch: 320; loss: 0.4; acc: 0.88
Batch: 340; loss: 0.38; acc: 0.88
Batch: 360; loss: 0.56; acc: 0.88
Batch: 380; loss: 0.63; acc: 0.84
Batch: 400; loss: 0.33; acc: 0.91
Batch: 420; loss: 0.32; acc: 0.91
Batch: 440; loss: 0.53; acc: 0.84
Batch: 460; loss: 0.6; acc: 0.89
Batch: 480; loss: 0.44; acc: 0.84
Batch: 500; loss: 0.71; acc: 0.8
Batch: 520; loss: 0.44; acc: 0.86
Batch: 540; loss: 0.21; acc: 0.95
Batch: 560; loss: 0.34; acc: 0.91
Batch: 580; loss: 0.38; acc: 0.88
Batch: 600; loss: 0.26; acc: 0.91
Batch: 620; loss: 0.34; acc: 0.88
Batch: 640; loss: 0.43; acc: 0.88
Batch: 660; loss: 0.81; acc: 0.75
Batch: 680; loss: 0.25; acc: 0.88
Batch: 700; loss: 0.2; acc: 0.94
Batch: 720; loss: 0.78; acc: 0.81
Batch: 740; loss: 0.4; acc: 0.89
Batch: 760; loss: 0.46; acc: 0.84
Batch: 780; loss: 0.33; acc: 0.88
Train Epoch over. train_loss: 0.41; train_accuracy: 0.88 

2.6334055291954428e-05
8.956512829172425e-06
Batch: 0; loss: 0.49; acc: 0.86
Batch: 20; loss: 0.55; acc: 0.8
Batch: 40; loss: 0.42; acc: 0.84
Batch: 60; loss: 0.47; acc: 0.86
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.42; acc: 0.89
Batch: 120; loss: 0.5; acc: 0.81
Batch: 140; loss: 0.28; acc: 0.91
Val Epoch over. val_loss: 0.512573086721882; val_accuracy: 0.8402667197452229 

The current subspace-distance is: 8.956512829172425e-06 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.87; acc: 0.75
Batch: 20; loss: 0.36; acc: 0.89
Batch: 40; loss: 0.31; acc: 0.92
Batch: 60; loss: 0.47; acc: 0.88
Batch: 80; loss: 0.33; acc: 0.91
Batch: 100; loss: 0.36; acc: 0.94
Batch: 120; loss: 0.25; acc: 0.91
Batch: 140; loss: 0.36; acc: 0.88
Batch: 160; loss: 0.54; acc: 0.81
Batch: 180; loss: 0.51; acc: 0.84
Batch: 200; loss: 0.83; acc: 0.8
Batch: 220; loss: 0.33; acc: 0.88
Batch: 240; loss: 0.4; acc: 0.89
Batch: 260; loss: 0.5; acc: 0.83
Batch: 280; loss: 0.33; acc: 0.89
Batch: 300; loss: 0.43; acc: 0.89
Batch: 320; loss: 0.36; acc: 0.94
Batch: 340; loss: 0.35; acc: 0.89
Batch: 360; loss: 0.33; acc: 0.92
Batch: 380; loss: 0.25; acc: 0.97
Batch: 400; loss: 0.37; acc: 0.88
Batch: 420; loss: 0.51; acc: 0.88
Batch: 440; loss: 0.55; acc: 0.8
Batch: 460; loss: 0.26; acc: 0.91
Batch: 480; loss: 0.41; acc: 0.81
Batch: 500; loss: 0.23; acc: 0.92
Batch: 520; loss: 0.19; acc: 0.95
Batch: 540; loss: 0.19; acc: 0.92
Batch: 560; loss: 0.2; acc: 0.92
Batch: 580; loss: 0.49; acc: 0.88
Batch: 600; loss: 0.23; acc: 0.92
Batch: 620; loss: 0.44; acc: 0.86
Batch: 640; loss: 0.58; acc: 0.83
Batch: 660; loss: 0.48; acc: 0.84
Batch: 680; loss: 0.37; acc: 0.88
Batch: 700; loss: 0.4; acc: 0.91
Batch: 720; loss: 0.31; acc: 0.88
Batch: 740; loss: 0.32; acc: 0.91
Batch: 760; loss: 0.24; acc: 0.95
Batch: 780; loss: 0.21; acc: 0.94
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

2.5952302166842856e-05
8.947536116465926e-06
Batch: 0; loss: 0.32; acc: 0.88
Batch: 20; loss: 0.45; acc: 0.83
Batch: 40; loss: 0.26; acc: 0.94
Batch: 60; loss: 0.33; acc: 0.92
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.29; acc: 0.95
Batch: 120; loss: 0.57; acc: 0.83
Batch: 140; loss: 0.13; acc: 0.97
Val Epoch over. val_loss: 0.3715320286002888; val_accuracy: 0.892515923566879 

The current subspace-distance is: 8.947536116465926e-06 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.57; acc: 0.8
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.26; acc: 0.88
Batch: 60; loss: 0.41; acc: 0.91
Batch: 80; loss: 0.51; acc: 0.86
Batch: 100; loss: 0.25; acc: 0.89
Batch: 120; loss: 0.5; acc: 0.84
Batch: 140; loss: 0.52; acc: 0.83
Batch: 160; loss: 0.23; acc: 0.95
Batch: 180; loss: 0.16; acc: 0.95
Batch: 200; loss: 0.16; acc: 0.97
Batch: 220; loss: 0.35; acc: 0.88
Batch: 240; loss: 0.19; acc: 0.95
Batch: 260; loss: 0.21; acc: 0.95
Batch: 280; loss: 0.43; acc: 0.89
Batch: 300; loss: 0.44; acc: 0.84
Batch: 320; loss: 0.6; acc: 0.83
Batch: 340; loss: 0.37; acc: 0.89
Batch: 360; loss: 0.3; acc: 0.86
Batch: 380; loss: 0.19; acc: 0.92
Batch: 400; loss: 0.45; acc: 0.89
Batch: 420; loss: 0.38; acc: 0.88
Batch: 440; loss: 0.42; acc: 0.84
Batch: 460; loss: 0.18; acc: 0.92
Batch: 480; loss: 0.26; acc: 0.91
Batch: 500; loss: 0.2; acc: 0.92
Batch: 520; loss: 0.41; acc: 0.89
Batch: 540; loss: 0.6; acc: 0.84
Batch: 560; loss: 0.17; acc: 0.92
Batch: 580; loss: 0.32; acc: 0.88
Batch: 600; loss: 0.63; acc: 0.83
Batch: 620; loss: 0.33; acc: 0.89
Batch: 640; loss: 0.11; acc: 1.0
Batch: 660; loss: 0.25; acc: 0.94
Batch: 680; loss: 0.24; acc: 0.91
Batch: 700; loss: 0.37; acc: 0.84
Batch: 720; loss: 0.22; acc: 0.92
Batch: 740; loss: 0.55; acc: 0.88
Batch: 760; loss: 0.16; acc: 0.92
Batch: 780; loss: 0.28; acc: 0.92
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

2.6964211429003626e-05
9.293853509007022e-06
Batch: 0; loss: 0.29; acc: 0.89
Batch: 20; loss: 0.38; acc: 0.86
Batch: 40; loss: 0.2; acc: 0.92
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.46; acc: 0.91
Batch: 140; loss: 0.13; acc: 0.94
Val Epoch over. val_loss: 0.3425084567943196; val_accuracy: 0.900577229299363 

The current subspace-distance is: 9.293853509007022e-06 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.38; acc: 0.86
Batch: 20; loss: 0.28; acc: 0.91
Batch: 40; loss: 0.27; acc: 0.89
Batch: 60; loss: 0.49; acc: 0.86
Batch: 80; loss: 0.39; acc: 0.88
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.33; acc: 0.91
Batch: 140; loss: 0.38; acc: 0.88
Batch: 160; loss: 0.27; acc: 0.91
Batch: 180; loss: 0.65; acc: 0.83
Batch: 200; loss: 0.29; acc: 0.89
Batch: 220; loss: 0.26; acc: 0.89
Batch: 240; loss: 0.21; acc: 0.91
Batch: 260; loss: 0.35; acc: 0.88
Batch: 280; loss: 0.32; acc: 0.89
Batch: 300; loss: 0.3; acc: 0.91
Batch: 320; loss: 0.56; acc: 0.84
Batch: 340; loss: 0.36; acc: 0.89
Batch: 360; loss: 0.35; acc: 0.92
Batch: 380; loss: 0.4; acc: 0.83
Batch: 400; loss: 0.34; acc: 0.86
Batch: 420; loss: 0.29; acc: 0.91
Batch: 440; loss: 0.21; acc: 0.94
Batch: 460; loss: 0.17; acc: 0.94
Batch: 480; loss: 0.4; acc: 0.86
Batch: 500; loss: 0.36; acc: 0.89
Batch: 520; loss: 0.3; acc: 0.92
Batch: 540; loss: 0.35; acc: 0.88
Batch: 560; loss: 0.27; acc: 0.94
Batch: 580; loss: 0.54; acc: 0.83
Batch: 600; loss: 0.33; acc: 0.89
Batch: 620; loss: 0.46; acc: 0.89
Batch: 640; loss: 0.29; acc: 0.91
Batch: 660; loss: 0.36; acc: 0.89
Batch: 680; loss: 0.62; acc: 0.84
Batch: 700; loss: 0.39; acc: 0.86
Batch: 720; loss: 0.21; acc: 0.92
Batch: 740; loss: 0.27; acc: 0.92
Batch: 760; loss: 0.29; acc: 0.89
Batch: 780; loss: 0.48; acc: 0.88
Train Epoch over. train_loss: 0.35; train_accuracy: 0.9 

2.6063236873596907e-05
8.052435077843256e-06
Batch: 0; loss: 0.23; acc: 0.92
Batch: 20; loss: 0.58; acc: 0.77
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.5; acc: 0.84
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.39; acc: 0.95
Batch: 120; loss: 0.64; acc: 0.77
Batch: 140; loss: 0.12; acc: 0.95
Val Epoch over. val_loss: 0.3399057637923842; val_accuracy: 0.8976910828025477 

The current subspace-distance is: 8.052435077843256e-06 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.46; acc: 0.86
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.54; acc: 0.86
Batch: 60; loss: 0.39; acc: 0.89
Batch: 80; loss: 0.27; acc: 0.91
Batch: 100; loss: 0.5; acc: 0.88
Batch: 120; loss: 0.16; acc: 0.95
Batch: 140; loss: 0.67; acc: 0.83
Batch: 160; loss: 0.24; acc: 0.91
Batch: 180; loss: 0.23; acc: 0.91
Batch: 200; loss: 0.26; acc: 0.92
Batch: 220; loss: 0.58; acc: 0.83
Batch: 240; loss: 0.26; acc: 0.91
Batch: 260; loss: 0.4; acc: 0.88
Batch: 280; loss: 0.33; acc: 0.89
Batch: 300; loss: 0.1; acc: 0.95
Batch: 320; loss: 0.46; acc: 0.88
Batch: 340; loss: 0.3; acc: 0.91
Batch: 360; loss: 0.28; acc: 0.91
Batch: 380; loss: 0.34; acc: 0.91
Batch: 400; loss: 0.34; acc: 0.86
Batch: 420; loss: 0.26; acc: 0.94
Batch: 440; loss: 0.38; acc: 0.86
Batch: 460; loss: 0.25; acc: 0.92
Batch: 480; loss: 0.42; acc: 0.89
Batch: 500; loss: 0.26; acc: 0.92
Batch: 520; loss: 0.37; acc: 0.92
Batch: 540; loss: 0.21; acc: 0.94
Batch: 560; loss: 0.42; acc: 0.86
Batch: 580; loss: 0.31; acc: 0.92
Batch: 600; loss: 0.16; acc: 0.98
Batch: 620; loss: 0.32; acc: 0.89
Batch: 640; loss: 0.33; acc: 0.94
Batch: 660; loss: 0.25; acc: 0.94
Batch: 680; loss: 0.26; acc: 0.94
Batch: 700; loss: 0.39; acc: 0.88
Batch: 720; loss: 0.53; acc: 0.84
Batch: 740; loss: 0.44; acc: 0.91
Batch: 760; loss: 0.21; acc: 0.94
Batch: 780; loss: 0.6; acc: 0.84
Train Epoch over. train_loss: 0.34; train_accuracy: 0.9 

2.7221019990975037e-05
8.346106369572226e-06
Batch: 0; loss: 0.34; acc: 0.91
Batch: 20; loss: 0.51; acc: 0.84
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.49; acc: 0.89
Batch: 80; loss: 0.28; acc: 0.89
Batch: 100; loss: 0.36; acc: 0.94
Batch: 120; loss: 0.59; acc: 0.77
Batch: 140; loss: 0.14; acc: 0.97
Val Epoch over. val_loss: 0.38567729064138834; val_accuracy: 0.8876393312101911 

The current subspace-distance is: 8.346106369572226e-06 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.38; acc: 0.89
Batch: 20; loss: 0.49; acc: 0.86
Batch: 40; loss: 0.47; acc: 0.88
Batch: 60; loss: 0.34; acc: 0.92
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.18; acc: 0.95
Batch: 140; loss: 0.32; acc: 0.88
Batch: 160; loss: 0.27; acc: 0.92
Batch: 180; loss: 0.29; acc: 0.86
Batch: 200; loss: 0.54; acc: 0.89
Batch: 220; loss: 0.35; acc: 0.84
Batch: 240; loss: 0.21; acc: 0.92
Batch: 260; loss: 0.36; acc: 0.92
Batch: 280; loss: 0.22; acc: 0.92
Batch: 300; loss: 0.16; acc: 0.95
Batch: 320; loss: 0.38; acc: 0.88
Batch: 340; loss: 0.33; acc: 0.94
Batch: 360; loss: 0.34; acc: 0.92
Batch: 380; loss: 0.23; acc: 0.95
Batch: 400; loss: 0.55; acc: 0.89
Batch: 420; loss: 0.26; acc: 0.92
Batch: 440; loss: 0.2; acc: 0.89
Batch: 460; loss: 0.14; acc: 0.95
Batch: 480; loss: 0.16; acc: 0.95
Batch: 500; loss: 0.29; acc: 0.89
Batch: 520; loss: 0.31; acc: 0.91
Batch: 540; loss: 0.45; acc: 0.83
Batch: 560; loss: 0.47; acc: 0.86
Batch: 580; loss: 0.31; acc: 0.89
Batch: 600; loss: 0.36; acc: 0.92
Batch: 620; loss: 0.3; acc: 0.94
Batch: 640; loss: 0.26; acc: 0.94
Batch: 660; loss: 0.44; acc: 0.89
Batch: 680; loss: 0.23; acc: 0.89
Batch: 700; loss: 0.14; acc: 0.95
Batch: 720; loss: 0.25; acc: 0.95
Batch: 740; loss: 0.32; acc: 0.91
Batch: 760; loss: 0.34; acc: 0.91
Batch: 780; loss: 0.2; acc: 0.91
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.7813963242806494e-05
8.674564014654607e-06
Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.35; acc: 0.89
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.24; acc: 0.95
Batch: 120; loss: 0.44; acc: 0.84
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.29044447535542167; val_accuracy: 0.9190883757961783 

The current subspace-distance is: 8.674564014654607e-06 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.26; acc: 0.94
Batch: 20; loss: 0.33; acc: 0.91
Batch: 40; loss: 0.34; acc: 0.94
Batch: 60; loss: 0.23; acc: 0.97
Batch: 80; loss: 0.35; acc: 0.92
Batch: 100; loss: 0.21; acc: 0.89
Batch: 120; loss: 0.33; acc: 0.88
Batch: 140; loss: 0.39; acc: 0.89
Batch: 160; loss: 0.2; acc: 0.91
Batch: 180; loss: 0.31; acc: 0.95
Batch: 200; loss: 0.33; acc: 0.91
Batch: 220; loss: 0.16; acc: 0.92
Batch: 240; loss: 0.16; acc: 0.94
Batch: 260; loss: 0.14; acc: 0.95
Batch: 280; loss: 0.11; acc: 0.98
Batch: 300; loss: 0.1; acc: 0.97
Batch: 320; loss: 0.25; acc: 0.88
Batch: 340; loss: 0.31; acc: 0.94
Batch: 360; loss: 0.3; acc: 0.89
Batch: 380; loss: 0.32; acc: 0.91
Batch: 400; loss: 0.25; acc: 0.91
Batch: 420; loss: 0.4; acc: 0.88
Batch: 440; loss: 0.45; acc: 0.89
Batch: 460; loss: 0.4; acc: 0.91
Batch: 480; loss: 0.37; acc: 0.92
Batch: 500; loss: 0.43; acc: 0.86
Batch: 520; loss: 0.41; acc: 0.94
Batch: 540; loss: 0.35; acc: 0.92
Batch: 560; loss: 0.32; acc: 0.91
Batch: 580; loss: 0.23; acc: 0.92
Batch: 600; loss: 0.19; acc: 0.94
Batch: 620; loss: 0.41; acc: 0.88
Batch: 640; loss: 0.34; acc: 0.92
Batch: 660; loss: 0.24; acc: 0.92
Batch: 680; loss: 0.36; acc: 0.89
Batch: 700; loss: 0.29; acc: 0.92
Batch: 720; loss: 0.29; acc: 0.88
Batch: 740; loss: 0.4; acc: 0.86
Batch: 760; loss: 0.54; acc: 0.84
Batch: 780; loss: 0.16; acc: 0.95
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.584395042504184e-05
8.722970051167067e-06
Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.47; acc: 0.88
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.23; acc: 0.95
Batch: 120; loss: 0.41; acc: 0.89
Batch: 140; loss: 0.13; acc: 0.97
Val Epoch over. val_loss: 0.29945793702818785; val_accuracy: 0.9124203821656051 

The current subspace-distance is: 8.722970051167067e-06 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.27; acc: 0.92
Batch: 20; loss: 0.38; acc: 0.89
Batch: 40; loss: 0.33; acc: 0.89
Batch: 60; loss: 0.2; acc: 0.92
Batch: 80; loss: 0.48; acc: 0.84
Batch: 100; loss: 0.39; acc: 0.91
Batch: 120; loss: 0.34; acc: 0.91
Batch: 140; loss: 0.29; acc: 0.91
Batch: 160; loss: 0.34; acc: 0.88
Batch: 180; loss: 0.12; acc: 0.95
Batch: 200; loss: 0.39; acc: 0.94
Batch: 220; loss: 0.24; acc: 0.95
Batch: 240; loss: 0.2; acc: 0.91
Batch: 260; loss: 0.12; acc: 0.94
Batch: 280; loss: 0.19; acc: 0.97
Batch: 300; loss: 0.31; acc: 0.86
Batch: 320; loss: 0.36; acc: 0.91
Batch: 340; loss: 0.2; acc: 0.94
Batch: 360; loss: 0.18; acc: 0.95
Batch: 380; loss: 0.4; acc: 0.83
Batch: 400; loss: 0.27; acc: 0.92
Batch: 420; loss: 0.34; acc: 0.92
Batch: 440; loss: 0.18; acc: 0.95
Batch: 460; loss: 0.2; acc: 0.94
Batch: 480; loss: 0.22; acc: 0.95
Batch: 500; loss: 0.27; acc: 0.91
Batch: 520; loss: 0.16; acc: 0.97
Batch: 540; loss: 0.61; acc: 0.78
Batch: 560; loss: 0.24; acc: 0.95
Batch: 580; loss: 0.43; acc: 0.84
Batch: 600; loss: 0.41; acc: 0.86
Batch: 620; loss: 0.38; acc: 0.91
Batch: 640; loss: 0.28; acc: 0.92
Batch: 660; loss: 0.23; acc: 0.92
Batch: 680; loss: 0.22; acc: 0.95
Batch: 700; loss: 0.49; acc: 0.86
Batch: 720; loss: 0.09; acc: 0.97
Batch: 740; loss: 0.27; acc: 0.91
Batch: 760; loss: 0.46; acc: 0.84
Batch: 780; loss: 0.45; acc: 0.88
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.754168599494733e-05
8.426506610703655e-06
Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.33; acc: 0.88
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.41; acc: 0.88
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.95
Batch: 120; loss: 0.43; acc: 0.83
Batch: 140; loss: 0.12; acc: 0.95
Val Epoch over. val_loss: 0.2744660656306015; val_accuracy: 0.9205812101910829 

The current subspace-distance is: 8.426506610703655e-06 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.17; acc: 0.97
Batch: 20; loss: 0.33; acc: 0.89
Batch: 40; loss: 0.29; acc: 0.92
Batch: 60; loss: 0.18; acc: 0.95
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.17; acc: 0.97
Batch: 120; loss: 0.39; acc: 0.86
Batch: 140; loss: 0.48; acc: 0.8
Batch: 160; loss: 0.3; acc: 0.91
Batch: 180; loss: 0.16; acc: 0.94
Batch: 200; loss: 0.29; acc: 0.89
Batch: 220; loss: 0.59; acc: 0.86
Batch: 240; loss: 0.19; acc: 0.92
Batch: 260; loss: 0.29; acc: 0.89
Batch: 280; loss: 0.2; acc: 0.92
Batch: 300; loss: 0.22; acc: 0.92
Batch: 320; loss: 0.26; acc: 0.95
Batch: 340; loss: 0.32; acc: 0.91
Batch: 360; loss: 0.39; acc: 0.88
Batch: 380; loss: 0.21; acc: 0.95
Batch: 400; loss: 0.46; acc: 0.84
Batch: 420; loss: 0.34; acc: 0.91
Batch: 440; loss: 0.28; acc: 0.91
Batch: 460; loss: 0.2; acc: 0.91
Batch: 480; loss: 0.33; acc: 0.88
Batch: 500; loss: 0.38; acc: 0.89
Batch: 520; loss: 0.3; acc: 0.88
Batch: 540; loss: 0.31; acc: 0.88
Batch: 560; loss: 0.39; acc: 0.86
Batch: 580; loss: 0.35; acc: 0.92
Batch: 600; loss: 0.38; acc: 0.86
Batch: 620; loss: 0.43; acc: 0.92
Batch: 640; loss: 0.35; acc: 0.86
Batch: 660; loss: 0.2; acc: 0.91
Batch: 680; loss: 0.43; acc: 0.83
Batch: 700; loss: 0.28; acc: 0.89
Batch: 720; loss: 0.25; acc: 0.91
Batch: 740; loss: 0.18; acc: 0.95
Batch: 760; loss: 0.23; acc: 0.92
Batch: 780; loss: 0.45; acc: 0.84
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.6481073291506618e-05
8.310150406032335e-06
Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.23; acc: 0.91
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.36; acc: 0.91
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.21; acc: 0.97
Batch: 120; loss: 0.36; acc: 0.88
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.2624655577360065; val_accuracy: 0.9238654458598726 

The current subspace-distance is: 8.310150406032335e-06 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.35; acc: 0.86
Batch: 20; loss: 0.24; acc: 0.89
Batch: 40; loss: 0.3; acc: 0.91
Batch: 60; loss: 0.26; acc: 0.94
Batch: 80; loss: 0.28; acc: 0.94
Batch: 100; loss: 0.31; acc: 0.88
Batch: 120; loss: 0.33; acc: 0.91
Batch: 140; loss: 0.34; acc: 0.92
Batch: 160; loss: 0.28; acc: 0.92
Batch: 180; loss: 0.4; acc: 0.89
Batch: 200; loss: 0.2; acc: 0.94
Batch: 220; loss: 0.31; acc: 0.84
Batch: 240; loss: 0.43; acc: 0.89
Batch: 260; loss: 0.18; acc: 0.95
Batch: 280; loss: 0.09; acc: 1.0
Batch: 300; loss: 0.3; acc: 0.89
Batch: 320; loss: 0.33; acc: 0.92
Batch: 340; loss: 0.34; acc: 0.88
Batch: 360; loss: 0.54; acc: 0.84
Batch: 380; loss: 0.44; acc: 0.86
Batch: 400; loss: 0.2; acc: 0.92
Batch: 420; loss: 0.33; acc: 0.91
Batch: 440; loss: 0.43; acc: 0.89
Batch: 460; loss: 0.41; acc: 0.88
Batch: 480; loss: 0.18; acc: 0.94
Batch: 500; loss: 0.38; acc: 0.89
Batch: 520; loss: 0.28; acc: 0.91
Batch: 540; loss: 0.17; acc: 0.94
Batch: 560; loss: 0.39; acc: 0.88
Batch: 580; loss: 0.23; acc: 0.91
Batch: 600; loss: 0.35; acc: 0.89
Batch: 620; loss: 0.18; acc: 0.95
Batch: 640; loss: 0.28; acc: 0.91
Batch: 660; loss: 0.21; acc: 0.91
Batch: 680; loss: 0.37; acc: 0.92
Batch: 700; loss: 0.21; acc: 0.94
Batch: 720; loss: 0.39; acc: 0.88
Batch: 740; loss: 0.27; acc: 0.92
Batch: 760; loss: 0.37; acc: 0.86
Batch: 780; loss: 0.11; acc: 0.98
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.789791687973775e-05
8.686488399689551e-06
Batch: 0; loss: 0.22; acc: 0.91
Batch: 20; loss: 0.34; acc: 0.88
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.42; acc: 0.84
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.23; acc: 0.97
Batch: 120; loss: 0.42; acc: 0.86
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.28575134965454696; val_accuracy: 0.9137141719745223 

The current subspace-distance is: 8.686488399689551e-06 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.31; acc: 0.88
Batch: 20; loss: 0.33; acc: 0.92
Batch: 40; loss: 0.24; acc: 0.95
Batch: 60; loss: 0.14; acc: 0.95
Batch: 80; loss: 0.29; acc: 0.94
Batch: 100; loss: 0.28; acc: 0.86
Batch: 120; loss: 0.5; acc: 0.89
Batch: 140; loss: 0.14; acc: 0.95
Batch: 160; loss: 0.39; acc: 0.89
Batch: 180; loss: 0.35; acc: 0.92
Batch: 200; loss: 0.25; acc: 0.91
Batch: 220; loss: 0.23; acc: 0.94
Batch: 240; loss: 0.17; acc: 0.95
Batch: 260; loss: 0.25; acc: 0.88
Batch: 280; loss: 0.5; acc: 0.84
Batch: 300; loss: 0.19; acc: 0.92
Batch: 320; loss: 0.4; acc: 0.88
Batch: 340; loss: 0.57; acc: 0.86
Batch: 360; loss: 0.3; acc: 0.92
Batch: 380; loss: 0.39; acc: 0.84
Batch: 400; loss: 0.47; acc: 0.91
Batch: 420; loss: 0.23; acc: 0.95
Batch: 440; loss: 0.3; acc: 0.89
Batch: 460; loss: 0.3; acc: 0.92
Batch: 480; loss: 0.16; acc: 0.95
Batch: 500; loss: 0.51; acc: 0.86
Batch: 520; loss: 0.16; acc: 0.97
Batch: 540; loss: 0.26; acc: 0.89
Batch: 560; loss: 0.22; acc: 0.92
Batch: 580; loss: 0.15; acc: 0.94
Batch: 600; loss: 0.17; acc: 0.95
Batch: 620; loss: 0.23; acc: 0.89
Batch: 640; loss: 0.36; acc: 0.84
Batch: 660; loss: 0.23; acc: 0.89
Batch: 680; loss: 0.14; acc: 0.95
Batch: 700; loss: 0.34; acc: 0.84
Batch: 720; loss: 0.28; acc: 0.91
Batch: 740; loss: 0.18; acc: 0.91
Batch: 760; loss: 0.3; acc: 0.84
Batch: 780; loss: 0.4; acc: 0.91
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.6196141334366985e-05
7.79659876570804e-06
Batch: 0; loss: 0.19; acc: 0.92
Batch: 20; loss: 0.27; acc: 0.91
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.45; acc: 0.83
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.97
Batch: 120; loss: 0.39; acc: 0.86
Batch: 140; loss: 0.09; acc: 0.95
Val Epoch over. val_loss: 0.27366185117109565; val_accuracy: 0.9190883757961783 

The current subspace-distance is: 7.79659876570804e-06 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.38; acc: 0.84
Batch: 40; loss: 0.5; acc: 0.88
Batch: 60; loss: 0.31; acc: 0.91
Batch: 80; loss: 0.34; acc: 0.91
Batch: 100; loss: 0.31; acc: 0.89
Batch: 120; loss: 0.21; acc: 0.92
Batch: 140; loss: 0.16; acc: 0.97
Batch: 160; loss: 0.52; acc: 0.88
Batch: 180; loss: 0.29; acc: 0.94
Batch: 200; loss: 0.31; acc: 0.91
Batch: 220; loss: 0.09; acc: 0.97
Batch: 240; loss: 0.51; acc: 0.88
Batch: 260; loss: 0.19; acc: 0.92
Batch: 280; loss: 0.26; acc: 0.91
Batch: 300; loss: 0.5; acc: 0.84
Batch: 320; loss: 0.19; acc: 0.95
Batch: 340; loss: 0.12; acc: 0.95
Batch: 360; loss: 0.44; acc: 0.89
Batch: 380; loss: 0.37; acc: 0.86
Batch: 400; loss: 0.36; acc: 0.88
Batch: 420; loss: 0.29; acc: 0.92
Batch: 440; loss: 0.16; acc: 0.97
Batch: 460; loss: 0.16; acc: 0.95
Batch: 480; loss: 0.17; acc: 0.92
Batch: 500; loss: 0.28; acc: 0.91
Batch: 520; loss: 0.32; acc: 0.89
Batch: 540; loss: 0.36; acc: 0.84
Batch: 560; loss: 0.39; acc: 0.91
Batch: 580; loss: 0.34; acc: 0.89
Batch: 600; loss: 0.26; acc: 0.91
Batch: 620; loss: 0.13; acc: 0.98
Batch: 640; loss: 0.39; acc: 0.94
Batch: 660; loss: 0.29; acc: 0.86
Batch: 680; loss: 0.18; acc: 0.91
Batch: 700; loss: 0.11; acc: 0.97
Batch: 720; loss: 0.16; acc: 0.95
Batch: 740; loss: 0.34; acc: 0.89
Batch: 760; loss: 0.22; acc: 0.92
Batch: 780; loss: 0.39; acc: 0.88
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.933240648417268e-05
9.300045348936692e-06
Batch: 0; loss: 0.24; acc: 0.91
Batch: 20; loss: 0.4; acc: 0.86
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.97
Batch: 120; loss: 0.39; acc: 0.89
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.2907961944153734; val_accuracy: 0.9163017515923567 

The current subspace-distance is: 9.300045348936692e-06 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.22; acc: 0.92
Batch: 20; loss: 0.23; acc: 0.89
Batch: 40; loss: 0.45; acc: 0.89
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.26; acc: 0.94
Batch: 120; loss: 0.26; acc: 0.94
Batch: 140; loss: 0.33; acc: 0.89
Batch: 160; loss: 0.2; acc: 0.94
Batch: 180; loss: 0.27; acc: 0.88
Batch: 200; loss: 0.2; acc: 0.95
Batch: 220; loss: 0.18; acc: 0.95
Batch: 240; loss: 0.26; acc: 0.89
Batch: 260; loss: 0.43; acc: 0.89
Batch: 280; loss: 0.3; acc: 0.92
Batch: 300; loss: 0.48; acc: 0.91
Batch: 320; loss: 0.23; acc: 0.94
Batch: 340; loss: 0.11; acc: 0.97
Batch: 360; loss: 0.24; acc: 0.92
Batch: 380; loss: 0.21; acc: 0.89
Batch: 400; loss: 0.3; acc: 0.91
Batch: 420; loss: 0.13; acc: 0.97
Batch: 440; loss: 0.27; acc: 0.91
Batch: 460; loss: 0.35; acc: 0.84
Batch: 480; loss: 0.25; acc: 0.91
Batch: 500; loss: 0.17; acc: 0.94
Batch: 520; loss: 0.35; acc: 0.89
Batch: 540; loss: 0.35; acc: 0.89
Batch: 560; loss: 0.22; acc: 0.92
Batch: 580; loss: 0.3; acc: 0.91
Batch: 600; loss: 0.23; acc: 0.92
Batch: 620; loss: 0.29; acc: 0.89
Batch: 640; loss: 0.25; acc: 0.95
Batch: 660; loss: 0.16; acc: 0.97
Batch: 680; loss: 0.14; acc: 0.97
Batch: 700; loss: 0.46; acc: 0.88
Batch: 720; loss: 0.21; acc: 0.94
Batch: 740; loss: 0.15; acc: 0.92
Batch: 760; loss: 0.25; acc: 0.92
Batch: 780; loss: 0.26; acc: 0.94
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

2.6293122573406436e-05
9.716343811305705e-06
Batch: 0; loss: 0.21; acc: 0.92
Batch: 20; loss: 0.38; acc: 0.89
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.39; acc: 0.88
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.21; acc: 0.97
Batch: 120; loss: 0.35; acc: 0.88
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2577181736090381; val_accuracy: 0.923765923566879 

The current subspace-distance is: 9.716343811305705e-06 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.27; acc: 0.89
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.29; acc: 0.86
Batch: 60; loss: 0.36; acc: 0.92
Batch: 80; loss: 0.36; acc: 0.84
Batch: 100; loss: 0.48; acc: 0.84
Batch: 120; loss: 0.13; acc: 0.94
Batch: 140; loss: 0.48; acc: 0.91
Batch: 160; loss: 0.28; acc: 0.92
Batch: 180; loss: 0.33; acc: 0.92
Batch: 200; loss: 0.55; acc: 0.86
Batch: 220; loss: 0.4; acc: 0.91
Batch: 240; loss: 0.26; acc: 0.92
Batch: 260; loss: 0.45; acc: 0.84
Batch: 280; loss: 0.38; acc: 0.91
Batch: 300; loss: 0.52; acc: 0.86
Batch: 320; loss: 0.55; acc: 0.83
Batch: 340; loss: 0.23; acc: 0.94
Batch: 360; loss: 0.17; acc: 0.97
Batch: 380; loss: 0.39; acc: 0.81
Batch: 400; loss: 0.38; acc: 0.86
Batch: 420; loss: 0.22; acc: 0.95
Batch: 440; loss: 0.43; acc: 0.84
Batch: 460; loss: 0.32; acc: 0.89
Batch: 480; loss: 0.25; acc: 0.91
Batch: 500; loss: 0.16; acc: 0.95
Batch: 520; loss: 0.37; acc: 0.89
Batch: 540; loss: 0.3; acc: 0.92
Batch: 560; loss: 0.11; acc: 0.97
Batch: 580; loss: 0.31; acc: 0.95
Batch: 600; loss: 0.13; acc: 0.94
Batch: 620; loss: 0.39; acc: 0.91
Batch: 640; loss: 0.23; acc: 0.91
Batch: 660; loss: 0.18; acc: 0.97
Batch: 680; loss: 0.42; acc: 0.89
Batch: 700; loss: 0.11; acc: 1.0
Batch: 720; loss: 0.36; acc: 0.91
Batch: 740; loss: 0.24; acc: 0.94
Batch: 760; loss: 0.16; acc: 0.98
Batch: 780; loss: 0.22; acc: 0.89
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

2.7644060537568294e-05
8.892098776414059e-06
Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.4; acc: 0.86
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.46; acc: 0.89
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.95
Batch: 120; loss: 0.49; acc: 0.8
Batch: 140; loss: 0.08; acc: 0.97
Val Epoch over. val_loss: 0.29453089643435876; val_accuracy: 0.9124203821656051 

The current subspace-distance is: 8.892098776414059e-06 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.27; acc: 0.97
Batch: 60; loss: 0.15; acc: 0.95
Batch: 80; loss: 0.22; acc: 0.92
Batch: 100; loss: 0.11; acc: 0.95
Batch: 120; loss: 0.28; acc: 0.95
Batch: 140; loss: 0.19; acc: 0.95
Batch: 160; loss: 0.3; acc: 0.89
Batch: 180; loss: 0.14; acc: 0.95
Batch: 200; loss: 0.16; acc: 0.94
Batch: 220; loss: 0.36; acc: 0.91
Batch: 240; loss: 0.21; acc: 0.92
Batch: 260; loss: 0.21; acc: 0.95
Batch: 280; loss: 0.25; acc: 0.94
Batch: 300; loss: 0.36; acc: 0.88
Batch: 320; loss: 0.39; acc: 0.91
Batch: 340; loss: 0.16; acc: 0.94
Batch: 360; loss: 0.38; acc: 0.88
Batch: 380; loss: 0.42; acc: 0.86
Batch: 400; loss: 0.34; acc: 0.88
Batch: 420; loss: 0.29; acc: 0.89
Batch: 440; loss: 0.25; acc: 0.92
Batch: 460; loss: 0.2; acc: 0.92
Batch: 480; loss: 0.21; acc: 0.91
Batch: 500; loss: 0.15; acc: 0.94
Batch: 520; loss: 0.38; acc: 0.91
Batch: 540; loss: 0.22; acc: 0.92
Batch: 560; loss: 0.29; acc: 0.92
Batch: 580; loss: 0.14; acc: 0.95
Batch: 600; loss: 0.37; acc: 0.86
Batch: 620; loss: 0.35; acc: 0.88
Batch: 640; loss: 0.34; acc: 0.86
Batch: 660; loss: 0.23; acc: 0.94
Batch: 680; loss: 0.32; acc: 0.91
Batch: 700; loss: 0.27; acc: 0.91
Batch: 720; loss: 0.29; acc: 0.91
Batch: 740; loss: 0.31; acc: 0.89
Batch: 760; loss: 0.4; acc: 0.84
Batch: 780; loss: 0.14; acc: 0.95
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

2.8027119697071612e-05
8.082247404672671e-06
Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.43; acc: 0.89
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.25; acc: 0.94
Batch: 120; loss: 0.35; acc: 0.88
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.25869105528494357; val_accuracy: 0.9231687898089171 

The current subspace-distance is: 8.082247404672671e-06 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.62; acc: 0.84
Batch: 20; loss: 0.27; acc: 0.91
Batch: 40; loss: 0.29; acc: 0.86
Batch: 60; loss: 0.32; acc: 0.88
Batch: 80; loss: 0.52; acc: 0.89
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.23; acc: 0.95
Batch: 140; loss: 0.21; acc: 0.94
Batch: 160; loss: 0.24; acc: 0.94
Batch: 180; loss: 0.37; acc: 0.88
Batch: 200; loss: 0.13; acc: 0.94
Batch: 220; loss: 0.19; acc: 0.94
Batch: 240; loss: 0.06; acc: 1.0
Batch: 260; loss: 0.22; acc: 0.95
Batch: 280; loss: 0.29; acc: 0.91
Batch: 300; loss: 0.15; acc: 0.95
Batch: 320; loss: 0.27; acc: 0.91
Batch: 340; loss: 0.24; acc: 0.88
Batch: 360; loss: 0.17; acc: 0.95
Batch: 380; loss: 0.17; acc: 0.97
Batch: 400; loss: 0.22; acc: 0.95
Batch: 420; loss: 0.13; acc: 0.95
Batch: 440; loss: 0.06; acc: 0.98
Batch: 460; loss: 0.17; acc: 0.94
Batch: 480; loss: 0.38; acc: 0.89
Batch: 500; loss: 0.22; acc: 0.91
Batch: 520; loss: 0.27; acc: 0.91
Batch: 540; loss: 0.13; acc: 0.95
Batch: 560; loss: 0.36; acc: 0.89
Batch: 580; loss: 0.25; acc: 0.95
Batch: 600; loss: 0.15; acc: 0.94
Batch: 620; loss: 0.25; acc: 0.95
Batch: 640; loss: 0.23; acc: 0.94
Batch: 660; loss: 0.19; acc: 0.91
Batch: 680; loss: 0.19; acc: 0.92
Batch: 700; loss: 0.22; acc: 0.92
Batch: 720; loss: 0.22; acc: 0.92
Batch: 740; loss: 0.27; acc: 0.89
Batch: 760; loss: 0.44; acc: 0.88
Batch: 780; loss: 0.28; acc: 0.91
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.6964553399011493e-05
8.96481560630491e-06
Batch: 0; loss: 0.22; acc: 0.92
Batch: 20; loss: 0.29; acc: 0.88
Batch: 40; loss: 0.16; acc: 0.97
Batch: 60; loss: 0.42; acc: 0.89
Batch: 80; loss: 0.1; acc: 0.98
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.37; acc: 0.89
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.25157108974115105; val_accuracy: 0.9267515923566879 

The current subspace-distance is: 8.96481560630491e-06 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.24; acc: 0.97
Batch: 20; loss: 0.32; acc: 0.91
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.08; acc: 0.98
Batch: 80; loss: 0.19; acc: 0.97
Batch: 100; loss: 0.18; acc: 0.97
Batch: 120; loss: 0.48; acc: 0.88
Batch: 140; loss: 0.27; acc: 0.95
Batch: 160; loss: 0.34; acc: 0.89
Batch: 180; loss: 0.14; acc: 0.95
Batch: 200; loss: 0.35; acc: 0.91
Batch: 220; loss: 0.12; acc: 0.98
Batch: 240; loss: 0.17; acc: 0.97
Batch: 260; loss: 0.28; acc: 0.91
Batch: 280; loss: 0.32; acc: 0.92
Batch: 300; loss: 0.26; acc: 0.91
Batch: 320; loss: 0.19; acc: 0.92
Batch: 340; loss: 0.13; acc: 0.97
Batch: 360; loss: 0.24; acc: 0.92
Batch: 380; loss: 0.2; acc: 0.94
Batch: 400; loss: 0.15; acc: 0.94
Batch: 420; loss: 0.3; acc: 0.95
Batch: 440; loss: 0.29; acc: 0.94
Batch: 460; loss: 0.24; acc: 0.91
Batch: 480; loss: 0.21; acc: 0.92
Batch: 500; loss: 0.25; acc: 0.92
Batch: 520; loss: 0.35; acc: 0.92
Batch: 540; loss: 0.34; acc: 0.91
Batch: 560; loss: 0.24; acc: 0.88
Batch: 580; loss: 0.15; acc: 0.91
Batch: 600; loss: 0.35; acc: 0.91
Batch: 620; loss: 0.12; acc: 0.97
Batch: 640; loss: 0.31; acc: 0.91
Batch: 660; loss: 0.27; acc: 0.89
Batch: 680; loss: 0.32; acc: 0.88
Batch: 700; loss: 0.13; acc: 0.94
Batch: 720; loss: 0.28; acc: 0.94
Batch: 740; loss: 0.17; acc: 0.97
Batch: 760; loss: 0.31; acc: 0.91
Batch: 780; loss: 0.14; acc: 0.95
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.76334449154092e-05
8.500745934725273e-06
Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.32; acc: 0.88
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.42; acc: 0.89
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.23; acc: 0.95
Batch: 120; loss: 0.37; acc: 0.89
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.24559585804677314; val_accuracy: 0.9279458598726115 

The current subspace-distance is: 8.500745934725273e-06 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.38; acc: 0.92
Batch: 60; loss: 0.42; acc: 0.92
Batch: 80; loss: 0.29; acc: 0.91
Batch: 100; loss: 0.21; acc: 0.92
Batch: 120; loss: 0.54; acc: 0.89
Batch: 140; loss: 0.22; acc: 0.95
Batch: 160; loss: 0.27; acc: 0.89
Batch: 180; loss: 0.31; acc: 0.91
Batch: 200; loss: 0.27; acc: 0.92
Batch: 220; loss: 0.26; acc: 0.91
Batch: 240; loss: 0.39; acc: 0.89
Batch: 260; loss: 0.34; acc: 0.88
Batch: 280; loss: 0.24; acc: 0.94
Batch: 300; loss: 0.13; acc: 0.94
Batch: 320; loss: 0.41; acc: 0.92
Batch: 340; loss: 0.18; acc: 0.94
Batch: 360; loss: 0.31; acc: 0.92
Batch: 380; loss: 0.34; acc: 0.91
Batch: 400; loss: 0.41; acc: 0.89
Batch: 420; loss: 0.13; acc: 0.95
Batch: 440; loss: 0.64; acc: 0.84
Batch: 460; loss: 0.18; acc: 0.97
Batch: 480; loss: 0.24; acc: 0.92
Batch: 500; loss: 0.22; acc: 0.94
Batch: 520; loss: 0.4; acc: 0.88
Batch: 540; loss: 0.23; acc: 0.92
Batch: 560; loss: 0.21; acc: 0.95
Batch: 580; loss: 0.24; acc: 0.92
Batch: 600; loss: 0.19; acc: 0.94
Batch: 620; loss: 0.26; acc: 0.91
Batch: 640; loss: 0.31; acc: 0.88
Batch: 660; loss: 0.1; acc: 0.97
Batch: 680; loss: 0.17; acc: 0.95
Batch: 700; loss: 0.26; acc: 0.92
Batch: 720; loss: 0.26; acc: 0.95
Batch: 740; loss: 0.16; acc: 0.94
Batch: 760; loss: 0.18; acc: 0.97
Batch: 780; loss: 0.28; acc: 0.94
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.8433081752154976e-05
8.873916158336215e-06
Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.3; acc: 0.88
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.22; acc: 0.95
Batch: 120; loss: 0.37; acc: 0.89
Batch: 140; loss: 0.06; acc: 0.97
Val Epoch over. val_loss: 0.2463581085347446; val_accuracy: 0.9284434713375797 

The current subspace-distance is: 8.873916158336215e-06 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.35; acc: 0.89
Batch: 20; loss: 0.18; acc: 0.95
Batch: 40; loss: 0.45; acc: 0.84
Batch: 60; loss: 0.29; acc: 0.88
Batch: 80; loss: 0.44; acc: 0.92
Batch: 100; loss: 0.22; acc: 0.92
Batch: 120; loss: 0.26; acc: 0.91
Batch: 140; loss: 0.22; acc: 0.94
Batch: 160; loss: 0.22; acc: 0.97
Batch: 180; loss: 0.27; acc: 0.92
Batch: 200; loss: 0.15; acc: 0.95
Batch: 220; loss: 0.33; acc: 0.88
Batch: 240; loss: 0.18; acc: 0.92
Batch: 260; loss: 0.21; acc: 0.95
Batch: 280; loss: 0.29; acc: 0.88
Batch: 300; loss: 0.19; acc: 0.92
Batch: 320; loss: 0.19; acc: 0.95
Batch: 340; loss: 0.23; acc: 0.95
Batch: 360; loss: 0.4; acc: 0.92
Batch: 380; loss: 0.14; acc: 0.94
Batch: 400; loss: 0.17; acc: 0.94
Batch: 420; loss: 0.34; acc: 0.89
Batch: 440; loss: 0.1; acc: 0.97
Batch: 460; loss: 0.19; acc: 0.92
Batch: 480; loss: 0.33; acc: 0.91
Batch: 500; loss: 0.24; acc: 0.97
Batch: 520; loss: 0.23; acc: 0.92
Batch: 540; loss: 0.22; acc: 0.92
Batch: 560; loss: 0.2; acc: 0.94
Batch: 580; loss: 0.39; acc: 0.88
Batch: 600; loss: 0.23; acc: 0.94
Batch: 620; loss: 0.29; acc: 0.89
Batch: 640; loss: 0.54; acc: 0.88
Batch: 660; loss: 0.28; acc: 0.94
Batch: 680; loss: 0.3; acc: 0.92
Batch: 700; loss: 0.16; acc: 0.97
Batch: 720; loss: 0.23; acc: 0.92
Batch: 740; loss: 0.22; acc: 0.92
Batch: 760; loss: 0.37; acc: 0.92
Batch: 780; loss: 0.61; acc: 0.84
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.8196500352350995e-05
8.659006198286079e-06
Batch: 0; loss: 0.19; acc: 0.92
Batch: 20; loss: 0.29; acc: 0.89
Batch: 40; loss: 0.16; acc: 0.98
Batch: 60; loss: 0.39; acc: 0.88
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.23; acc: 0.95
Batch: 120; loss: 0.34; acc: 0.89
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.24178925749792415; val_accuracy: 0.9280453821656051 

The current subspace-distance is: 8.659006198286079e-06 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.29; acc: 0.92
Batch: 20; loss: 0.57; acc: 0.89
Batch: 40; loss: 0.26; acc: 0.95
Batch: 60; loss: 0.38; acc: 0.86
Batch: 80; loss: 0.27; acc: 0.89
Batch: 100; loss: 0.35; acc: 0.88
Batch: 120; loss: 0.25; acc: 0.92
Batch: 140; loss: 0.26; acc: 0.92
Batch: 160; loss: 0.28; acc: 0.94
Batch: 180; loss: 0.24; acc: 0.91
Batch: 200; loss: 0.1; acc: 0.97
Batch: 220; loss: 0.14; acc: 0.92
Batch: 240; loss: 0.36; acc: 0.92
Batch: 260; loss: 0.16; acc: 0.95
Batch: 280; loss: 0.17; acc: 0.94
Batch: 300; loss: 0.21; acc: 0.91
Batch: 320; loss: 0.29; acc: 0.91
Batch: 340; loss: 0.25; acc: 0.92
Batch: 360; loss: 0.16; acc: 0.95
Batch: 380; loss: 0.27; acc: 0.97
Batch: 400; loss: 0.37; acc: 0.86
Batch: 420; loss: 0.39; acc: 0.89
Batch: 440; loss: 0.31; acc: 0.91
Batch: 460; loss: 0.37; acc: 0.92
Batch: 480; loss: 0.17; acc: 0.95
Batch: 500; loss: 0.38; acc: 0.91
Batch: 520; loss: 0.2; acc: 0.94
Batch: 540; loss: 0.26; acc: 0.94
Batch: 560; loss: 0.12; acc: 0.94
Batch: 580; loss: 0.1; acc: 0.98
Batch: 600; loss: 0.34; acc: 0.91
Batch: 620; loss: 0.25; acc: 0.91
Batch: 640; loss: 0.3; acc: 0.91
Batch: 660; loss: 0.38; acc: 0.88
Batch: 680; loss: 0.44; acc: 0.94
Batch: 700; loss: 0.08; acc: 0.98
Batch: 720; loss: 0.17; acc: 0.94
Batch: 740; loss: 0.29; acc: 0.94
Batch: 760; loss: 0.39; acc: 0.86
Batch: 780; loss: 0.2; acc: 0.92
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.7437967219157144e-05
8.259370588348247e-06
Batch: 0; loss: 0.19; acc: 0.92
Batch: 20; loss: 0.29; acc: 0.88
Batch: 40; loss: 0.16; acc: 0.98
Batch: 60; loss: 0.35; acc: 0.91
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.21; acc: 0.95
Batch: 120; loss: 0.35; acc: 0.89
Batch: 140; loss: 0.04; acc: 0.97
Val Epoch over. val_loss: 0.23828151845818113; val_accuracy: 0.9289410828025477 

The current subspace-distance is: 8.259370588348247e-06 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.26; acc: 0.89
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.3; acc: 0.91
Batch: 80; loss: 0.44; acc: 0.88
Batch: 100; loss: 0.21; acc: 0.94
Batch: 120; loss: 0.13; acc: 0.94
Batch: 140; loss: 0.13; acc: 0.97
Batch: 160; loss: 0.37; acc: 0.89
Batch: 180; loss: 0.17; acc: 0.95
Batch: 200; loss: 0.35; acc: 0.92
Batch: 220; loss: 0.36; acc: 0.89
Batch: 240; loss: 0.33; acc: 0.91
Batch: 260; loss: 0.23; acc: 0.94
Batch: 280; loss: 0.34; acc: 0.94
Batch: 300; loss: 0.34; acc: 0.94
Batch: 320; loss: 0.27; acc: 0.88
Batch: 340; loss: 0.17; acc: 0.94
Batch: 360; loss: 0.34; acc: 0.91
Batch: 380; loss: 0.27; acc: 0.89
Batch: 400; loss: 0.21; acc: 0.91
Batch: 420; loss: 0.24; acc: 0.94
Batch: 440; loss: 0.14; acc: 0.95
Batch: 460; loss: 0.4; acc: 0.91
Batch: 480; loss: 0.19; acc: 0.94
Batch: 500; loss: 0.24; acc: 0.94
Batch: 520; loss: 0.18; acc: 0.94
Batch: 540; loss: 0.25; acc: 0.92
Batch: 560; loss: 0.37; acc: 0.92
Batch: 580; loss: 0.19; acc: 0.94
Batch: 600; loss: 0.19; acc: 0.94
Batch: 620; loss: 0.26; acc: 0.92
Batch: 640; loss: 0.35; acc: 0.89
Batch: 660; loss: 0.42; acc: 0.86
Batch: 680; loss: 0.12; acc: 0.95
Batch: 700; loss: 0.24; acc: 0.92
Batch: 720; loss: 0.25; acc: 0.94
Batch: 740; loss: 0.21; acc: 0.89
Batch: 760; loss: 0.26; acc: 0.92
Batch: 780; loss: 0.2; acc: 0.94
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.719105214055162e-05
8.382041414733976e-06
Batch: 0; loss: 0.21; acc: 0.92
Batch: 20; loss: 0.28; acc: 0.91
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.38; acc: 0.83
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.2536792897494735; val_accuracy: 0.9238654458598726 

The current subspace-distance is: 8.382041414733976e-06 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.34; acc: 0.91
Batch: 60; loss: 0.28; acc: 0.91
Batch: 80; loss: 0.36; acc: 0.88
Batch: 100; loss: 0.21; acc: 0.95
Batch: 120; loss: 0.21; acc: 0.92
Batch: 140; loss: 0.16; acc: 0.92
Batch: 160; loss: 0.47; acc: 0.86
Batch: 180; loss: 0.21; acc: 0.92
Batch: 200; loss: 0.36; acc: 0.89
Batch: 220; loss: 0.24; acc: 0.91
Batch: 240; loss: 0.22; acc: 0.94
Batch: 260; loss: 0.32; acc: 0.95
Batch: 280; loss: 0.33; acc: 0.89
Batch: 300; loss: 0.22; acc: 0.97
Batch: 320; loss: 0.29; acc: 0.92
Batch: 340; loss: 0.12; acc: 0.97
Batch: 360; loss: 0.1; acc: 0.98
Batch: 380; loss: 0.44; acc: 0.88
Batch: 400; loss: 0.09; acc: 0.98
Batch: 420; loss: 0.47; acc: 0.84
Batch: 440; loss: 0.14; acc: 0.94
Batch: 460; loss: 0.52; acc: 0.89
Batch: 480; loss: 0.23; acc: 0.94
Batch: 500; loss: 0.22; acc: 0.94
Batch: 520; loss: 0.23; acc: 0.94
Batch: 540; loss: 0.46; acc: 0.94
Batch: 560; loss: 0.24; acc: 0.91
Batch: 580; loss: 0.29; acc: 0.88
Batch: 600; loss: 0.18; acc: 0.94
Batch: 620; loss: 0.36; acc: 0.91
Batch: 640; loss: 0.19; acc: 0.95
Batch: 660; loss: 0.35; acc: 0.89
Batch: 680; loss: 0.25; acc: 0.92
Batch: 700; loss: 0.31; acc: 0.89
Batch: 720; loss: 0.25; acc: 0.94
Batch: 740; loss: 0.22; acc: 0.91
Batch: 760; loss: 0.22; acc: 0.91
Batch: 780; loss: 0.24; acc: 0.95
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.8162316084490158e-05
8.373331183975097e-06
Batch: 0; loss: 0.23; acc: 0.94
Batch: 20; loss: 0.3; acc: 0.88
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.36; acc: 0.92
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.95
Batch: 120; loss: 0.38; acc: 0.88
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.24878658783758523; val_accuracy: 0.9279458598726115 

The current subspace-distance is: 8.373331183975097e-06 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.27; acc: 0.92
Batch: 20; loss: 0.22; acc: 0.95
Batch: 40; loss: 0.22; acc: 0.92
Batch: 60; loss: 0.31; acc: 0.89
Batch: 80; loss: 0.24; acc: 0.92
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.19; acc: 0.95
Batch: 140; loss: 0.26; acc: 0.95
Batch: 160; loss: 0.17; acc: 0.95
Batch: 180; loss: 0.32; acc: 0.89
Batch: 200; loss: 0.13; acc: 0.98
Batch: 220; loss: 0.24; acc: 0.94
Batch: 240; loss: 0.32; acc: 0.91
Batch: 260; loss: 0.33; acc: 0.92
Batch: 280; loss: 0.19; acc: 0.95
Batch: 300; loss: 0.47; acc: 0.84
Batch: 320; loss: 0.08; acc: 0.97
Batch: 340; loss: 0.27; acc: 0.91
Batch: 360; loss: 0.27; acc: 0.94
Batch: 380; loss: 0.21; acc: 0.92
Batch: 400; loss: 0.36; acc: 0.89
Batch: 420; loss: 0.36; acc: 0.92
Batch: 440; loss: 0.21; acc: 0.94
Batch: 460; loss: 0.3; acc: 0.91
Batch: 480; loss: 0.27; acc: 0.92
Batch: 500; loss: 0.3; acc: 0.88
Batch: 520; loss: 0.3; acc: 0.91
Batch: 540; loss: 0.29; acc: 0.97
Batch: 560; loss: 0.22; acc: 0.94
Batch: 580; loss: 0.31; acc: 0.92
Batch: 600; loss: 0.4; acc: 0.94
Batch: 620; loss: 0.18; acc: 0.94
Batch: 640; loss: 0.06; acc: 1.0
Batch: 660; loss: 0.42; acc: 0.88
Batch: 680; loss: 0.19; acc: 0.95
Batch: 700; loss: 0.27; acc: 0.89
Batch: 720; loss: 0.31; acc: 0.89
Batch: 740; loss: 0.36; acc: 0.92
Batch: 760; loss: 0.32; acc: 0.91
Batch: 780; loss: 0.47; acc: 0.92
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.7276724722469226e-05
9.70950259215897e-06
Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.27; acc: 0.91
Batch: 40; loss: 0.16; acc: 0.98
Batch: 60; loss: 0.38; acc: 0.91
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.35; acc: 0.88
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.23838060520067336; val_accuracy: 0.9282444267515924 

The current subspace-distance is: 9.70950259215897e-06 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.3; acc: 0.92
Batch: 20; loss: 0.19; acc: 0.92
Batch: 40; loss: 0.11; acc: 1.0
Batch: 60; loss: 0.27; acc: 0.94
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.16; acc: 0.94
Batch: 120; loss: 0.11; acc: 0.97
Batch: 140; loss: 0.2; acc: 0.94
Batch: 160; loss: 0.21; acc: 0.92
Batch: 180; loss: 0.25; acc: 0.94
Batch: 200; loss: 0.2; acc: 0.95
Batch: 220; loss: 0.29; acc: 0.89
Batch: 240; loss: 0.08; acc: 1.0
Batch: 260; loss: 0.53; acc: 0.81
Batch: 280; loss: 0.32; acc: 0.91
Batch: 300; loss: 0.19; acc: 0.97
Batch: 320; loss: 0.2; acc: 0.95
Batch: 340; loss: 0.2; acc: 0.91
Batch: 360; loss: 0.28; acc: 0.86
Batch: 380; loss: 0.21; acc: 0.91
Batch: 400; loss: 0.21; acc: 0.94
Batch: 420; loss: 0.2; acc: 0.92
Batch: 440; loss: 0.32; acc: 0.92
Batch: 460; loss: 0.27; acc: 0.94
Batch: 480; loss: 0.11; acc: 0.97
Batch: 500; loss: 0.13; acc: 0.95
Batch: 520; loss: 0.19; acc: 0.94
Batch: 540; loss: 0.07; acc: 0.97
Batch: 560; loss: 0.19; acc: 0.94
Batch: 580; loss: 0.27; acc: 0.92
Batch: 600; loss: 0.25; acc: 0.94
Batch: 620; loss: 0.29; acc: 0.92
Batch: 640; loss: 0.3; acc: 0.91
Batch: 660; loss: 0.08; acc: 0.97
Batch: 680; loss: 0.41; acc: 0.91
Batch: 700; loss: 0.27; acc: 0.88
Batch: 720; loss: 0.27; acc: 0.91
Batch: 740; loss: 0.16; acc: 0.95
Batch: 760; loss: 0.18; acc: 0.94
Batch: 780; loss: 0.15; acc: 0.95
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.711379056563601e-05
8.564845302316826e-06
Batch: 0; loss: 0.21; acc: 0.91
Batch: 20; loss: 0.32; acc: 0.89
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.43; acc: 0.89
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.94
Batch: 120; loss: 0.42; acc: 0.83
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.2553407608703443; val_accuracy: 0.9243630573248408 

The current subspace-distance is: 8.564845302316826e-06 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.29; acc: 0.92
Batch: 20; loss: 0.31; acc: 0.88
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.28; acc: 0.91
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.25; acc: 0.91
Batch: 120; loss: 0.31; acc: 0.94
Batch: 140; loss: 0.19; acc: 0.95
Batch: 160; loss: 0.21; acc: 0.95
Batch: 180; loss: 0.19; acc: 0.94
Batch: 200; loss: 0.12; acc: 0.98
Batch: 220; loss: 0.4; acc: 0.89
Batch: 240; loss: 0.21; acc: 0.89
Batch: 260; loss: 0.17; acc: 0.95
Batch: 280; loss: 0.23; acc: 0.91
Batch: 300; loss: 0.19; acc: 0.91
Batch: 320; loss: 0.38; acc: 0.88
Batch: 340; loss: 0.12; acc: 0.97
Batch: 360; loss: 0.21; acc: 0.92
Batch: 380; loss: 0.28; acc: 0.92
Batch: 400; loss: 0.26; acc: 0.94
Batch: 420; loss: 0.17; acc: 0.92
Batch: 440; loss: 0.43; acc: 0.91
Batch: 460; loss: 0.33; acc: 0.86
Batch: 480; loss: 0.18; acc: 0.95
Batch: 500; loss: 0.19; acc: 0.95
Batch: 520; loss: 0.2; acc: 0.94
Batch: 540; loss: 0.14; acc: 0.97
Batch: 560; loss: 0.34; acc: 0.89
Batch: 580; loss: 0.27; acc: 0.89
Batch: 600; loss: 0.26; acc: 0.94
Batch: 620; loss: 0.43; acc: 0.92
Batch: 640; loss: 0.39; acc: 0.86
Batch: 660; loss: 0.18; acc: 0.97
Batch: 680; loss: 0.26; acc: 0.94
Batch: 700; loss: 0.33; acc: 0.88
Batch: 720; loss: 0.2; acc: 0.94
Batch: 740; loss: 0.17; acc: 0.95
Batch: 760; loss: 0.11; acc: 0.95
Batch: 780; loss: 0.28; acc: 0.95
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.8454845960368402e-05
7.780785381328315e-06
Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.17; acc: 0.98
Batch: 60; loss: 0.36; acc: 0.89
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.37; acc: 0.88
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.2358139961673196; val_accuracy: 0.9314291401273885 

The current subspace-distance is: 7.780785381328315e-06 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.32; acc: 0.92
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.25; acc: 0.91
Batch: 60; loss: 0.29; acc: 0.92
Batch: 80; loss: 0.22; acc: 0.91
Batch: 100; loss: 0.22; acc: 0.92
Batch: 120; loss: 0.48; acc: 0.86
Batch: 140; loss: 0.6; acc: 0.83
Batch: 160; loss: 0.42; acc: 0.86
Batch: 180; loss: 0.23; acc: 0.89
Batch: 200; loss: 0.32; acc: 0.89
Batch: 220; loss: 0.19; acc: 0.92
Batch: 240; loss: 0.32; acc: 0.88
Batch: 260; loss: 0.16; acc: 0.94
Batch: 280; loss: 0.37; acc: 0.86
Batch: 300; loss: 0.28; acc: 0.94
Batch: 320; loss: 0.14; acc: 0.95
Batch: 340; loss: 0.27; acc: 0.91
Batch: 360; loss: 0.12; acc: 0.98
Batch: 380; loss: 0.12; acc: 0.97
Batch: 400; loss: 0.19; acc: 0.94
Batch: 420; loss: 0.25; acc: 0.92
Batch: 440; loss: 0.39; acc: 0.92
Batch: 460; loss: 0.39; acc: 0.88
Batch: 480; loss: 0.19; acc: 0.94
Batch: 500; loss: 0.24; acc: 0.92
Batch: 520; loss: 0.26; acc: 0.92
Batch: 540; loss: 0.27; acc: 0.92
Batch: 560; loss: 0.18; acc: 0.94
Batch: 580; loss: 0.33; acc: 0.89
Batch: 600; loss: 0.33; acc: 0.92
Batch: 620; loss: 0.13; acc: 0.97
Batch: 640; loss: 0.45; acc: 0.89
Batch: 660; loss: 0.19; acc: 0.92
Batch: 680; loss: 0.16; acc: 0.94
Batch: 700; loss: 0.27; acc: 0.94
Batch: 720; loss: 0.26; acc: 0.97
Batch: 740; loss: 0.24; acc: 0.91
Batch: 760; loss: 0.31; acc: 0.88
Batch: 780; loss: 0.21; acc: 0.91
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

2.7639342079055496e-05
9.251856681657955e-06
Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.16; acc: 0.98
Batch: 60; loss: 0.36; acc: 0.89
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.37; acc: 0.88
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.2326128462175275; val_accuracy: 0.9324243630573248 

The current subspace-distance is: 9.251856681657955e-06 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.21; acc: 0.91
Batch: 20; loss: 0.16; acc: 0.94
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.15; acc: 0.94
Batch: 80; loss: 0.31; acc: 0.92
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.33; acc: 0.91
Batch: 140; loss: 0.35; acc: 0.89
Batch: 160; loss: 0.18; acc: 0.92
Batch: 180; loss: 0.17; acc: 0.94
Batch: 200; loss: 0.35; acc: 0.94
Batch: 220; loss: 0.32; acc: 0.91
Batch: 240; loss: 0.1; acc: 0.98
Batch: 260; loss: 0.1; acc: 0.98
Batch: 280; loss: 0.44; acc: 0.89
Batch: 300; loss: 0.64; acc: 0.83
Batch: 320; loss: 0.13; acc: 0.97
Batch: 340; loss: 0.39; acc: 0.89
Batch: 360; loss: 0.2; acc: 0.95
Batch: 380; loss: 0.15; acc: 0.97
Batch: 400; loss: 0.28; acc: 0.92
Batch: 420; loss: 0.3; acc: 0.89
Batch: 440; loss: 0.17; acc: 0.92
Batch: 460; loss: 0.23; acc: 0.94
Batch: 480; loss: 0.1; acc: 0.97
Batch: 500; loss: 0.43; acc: 0.89
Batch: 520; loss: 0.22; acc: 0.94
Batch: 540; loss: 0.09; acc: 0.98
Batch: 560; loss: 0.36; acc: 0.88
Batch: 580; loss: 0.2; acc: 0.94
Batch: 600; loss: 0.13; acc: 0.95
Batch: 620; loss: 0.62; acc: 0.84
Batch: 640; loss: 0.16; acc: 0.98
Batch: 660; loss: 0.23; acc: 0.94
Batch: 680; loss: 0.21; acc: 0.94
Batch: 700; loss: 0.09; acc: 0.98
Batch: 720; loss: 0.16; acc: 0.94
Batch: 740; loss: 0.2; acc: 0.95
Batch: 760; loss: 0.3; acc: 0.88
Batch: 780; loss: 0.29; acc: 0.91
Train Epoch over. train_loss: 0.25; train_accuracy: 0.93 

2.8575206670211628e-05
8.913274541555438e-06
Batch: 0; loss: 0.21; acc: 0.92
Batch: 20; loss: 0.28; acc: 0.89
Batch: 40; loss: 0.16; acc: 0.98
Batch: 60; loss: 0.36; acc: 0.89
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.36; acc: 0.88
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.23242607437501286; val_accuracy: 0.9320262738853503 

The current subspace-distance is: 8.913274541555438e-06 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.15; acc: 0.94
Batch: 20; loss: 0.33; acc: 0.91
Batch: 40; loss: 0.27; acc: 0.89
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.15; acc: 0.98
Batch: 100; loss: 0.15; acc: 0.94
Batch: 120; loss: 0.26; acc: 0.91
Batch: 140; loss: 0.34; acc: 0.89
Batch: 160; loss: 0.17; acc: 0.94
Batch: 180; loss: 0.25; acc: 0.92
Batch: 200; loss: 0.26; acc: 0.89
Batch: 220; loss: 0.26; acc: 0.92
Batch: 240; loss: 0.33; acc: 0.88
Batch: 260; loss: 0.31; acc: 0.92
Batch: 280; loss: 0.27; acc: 0.92
Batch: 300; loss: 0.1; acc: 0.97
Batch: 320; loss: 0.16; acc: 0.95
Batch: 340; loss: 0.21; acc: 0.94
Batch: 360; loss: 0.17; acc: 0.94
Batch: 380; loss: 0.19; acc: 0.94
Batch: 400; loss: 0.15; acc: 0.95
Batch: 420; loss: 0.23; acc: 0.92
Batch: 440; loss: 0.1; acc: 0.97
Batch: 460; loss: 0.21; acc: 0.95
Batch: 480; loss: 0.22; acc: 0.94
Batch: 500; loss: 0.18; acc: 0.95
Batch: 520; loss: 0.16; acc: 0.95
Batch: 540; loss: 0.19; acc: 0.95
Batch: 560; loss: 0.13; acc: 0.98
Batch: 580; loss: 0.38; acc: 0.89
Batch: 600; loss: 0.28; acc: 0.92
Batch: 620; loss: 0.28; acc: 0.92
Batch: 640; loss: 0.23; acc: 0.91
Batch: 660; loss: 0.18; acc: 0.92
Batch: 680; loss: 0.48; acc: 0.86
Batch: 700; loss: 0.22; acc: 0.94
Batch: 720; loss: 0.13; acc: 0.92
Batch: 740; loss: 0.43; acc: 0.94
Batch: 760; loss: 0.19; acc: 0.94
Batch: 780; loss: 0.3; acc: 0.88
Train Epoch over. train_loss: 0.25; train_accuracy: 0.93 

2.729268635448534e-05
8.19278557173675e-06
Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.26; acc: 0.89
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.34; acc: 0.89
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.37; acc: 0.88
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.2317291913898128; val_accuracy: 0.9321257961783439 

The current subspace-distance is: 8.19278557173675e-06 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.23; acc: 0.94
Batch: 20; loss: 0.35; acc: 0.92
Batch: 40; loss: 0.31; acc: 0.89
Batch: 60; loss: 0.23; acc: 0.92
Batch: 80; loss: 0.2; acc: 0.97
Batch: 100; loss: 0.32; acc: 0.92
Batch: 120; loss: 0.39; acc: 0.89
Batch: 140; loss: 0.3; acc: 0.92
Batch: 160; loss: 0.29; acc: 0.89
Batch: 180; loss: 0.15; acc: 0.97
Batch: 200; loss: 0.47; acc: 0.89
Batch: 220; loss: 0.24; acc: 0.88
Batch: 240; loss: 0.15; acc: 0.95
Batch: 260; loss: 0.24; acc: 0.92
Batch: 280; loss: 0.2; acc: 0.92
Batch: 300; loss: 0.12; acc: 0.94
Batch: 320; loss: 0.38; acc: 0.88
Batch: 340; loss: 0.38; acc: 0.88
Batch: 360; loss: 0.17; acc: 0.95
Batch: 380; loss: 0.14; acc: 0.97
Batch: 400; loss: 0.42; acc: 0.88
Batch: 420; loss: 0.19; acc: 0.95
Batch: 440; loss: 0.21; acc: 0.92
Batch: 460; loss: 0.23; acc: 0.91
Batch: 480; loss: 0.09; acc: 0.97
Batch: 500; loss: 0.23; acc: 0.92
Batch: 520; loss: 0.08; acc: 0.98
Batch: 540; loss: 0.24; acc: 0.91
Batch: 560; loss: 0.27; acc: 0.88
Batch: 580; loss: 0.16; acc: 0.94
Batch: 600; loss: 0.15; acc: 0.95
Batch: 620; loss: 0.19; acc: 0.94
Batch: 640; loss: 0.1; acc: 0.97
Batch: 660; loss: 0.57; acc: 0.86
Batch: 680; loss: 0.19; acc: 0.92
Batch: 700; loss: 0.41; acc: 0.91
Batch: 720; loss: 0.19; acc: 0.94
Batch: 740; loss: 0.23; acc: 0.92
Batch: 760; loss: 0.19; acc: 0.97
Batch: 780; loss: 0.15; acc: 0.94
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

2.6810046620084904e-05
8.278274435724597e-06
Batch: 0; loss: 0.2; acc: 0.92
Batch: 20; loss: 0.29; acc: 0.88
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.36; acc: 0.91
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.38; acc: 0.88
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.23099667291827264; val_accuracy: 0.9321257961783439 

The current subspace-distance is: 8.278274435724597e-06 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.23; acc: 0.95
Batch: 20; loss: 0.21; acc: 0.95
Batch: 40; loss: 0.33; acc: 0.92
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.25; acc: 0.91
Batch: 140; loss: 0.26; acc: 0.95
Batch: 160; loss: 0.24; acc: 0.95
Batch: 180; loss: 0.15; acc: 0.97
Batch: 200; loss: 0.35; acc: 0.86
Batch: 220; loss: 0.36; acc: 0.91
Batch: 240; loss: 0.25; acc: 0.92
Batch: 260; loss: 0.21; acc: 0.91
Batch: 280; loss: 0.37; acc: 0.89
Batch: 300; loss: 0.16; acc: 0.97
Batch: 320; loss: 0.24; acc: 0.94
Batch: 340; loss: 0.14; acc: 0.95
Batch: 360; loss: 0.34; acc: 0.94
Batch: 380; loss: 0.22; acc: 0.92
Batch: 400; loss: 0.31; acc: 0.89
Batch: 420; loss: 0.43; acc: 0.91
Batch: 440; loss: 0.34; acc: 0.92
Batch: 460; loss: 0.26; acc: 0.92
Batch: 480; loss: 0.12; acc: 0.98
Batch: 500; loss: 0.18; acc: 0.92
Batch: 520; loss: 0.14; acc: 0.95
Batch: 540; loss: 0.26; acc: 0.92
Batch: 560; loss: 0.1; acc: 0.95
Batch: 580; loss: 0.2; acc: 0.94
Batch: 600; loss: 0.35; acc: 0.92
Batch: 620; loss: 0.32; acc: 0.86
Batch: 640; loss: 0.41; acc: 0.89
Batch: 660; loss: 0.38; acc: 0.94
Batch: 680; loss: 0.08; acc: 1.0
Batch: 700; loss: 0.2; acc: 0.94
Batch: 720; loss: 0.31; acc: 0.94
Batch: 740; loss: 0.24; acc: 0.94
Batch: 760; loss: 0.24; acc: 0.91
Batch: 780; loss: 0.34; acc: 0.88
Train Epoch over. train_loss: 0.25; train_accuracy: 0.93 

2.7616017177933827e-05
7.574718438263517e-06
Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.26; acc: 0.92
Batch: 40; loss: 0.16; acc: 0.98
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.36; acc: 0.88
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.23059296233069365; val_accuracy: 0.931827229299363 

The current subspace-distance is: 7.574718438263517e-06 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.08; acc: 0.97
Batch: 20; loss: 0.37; acc: 0.88
Batch: 40; loss: 0.33; acc: 0.88
Batch: 60; loss: 0.35; acc: 0.92
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.28; acc: 0.86
Batch: 120; loss: 0.41; acc: 0.91
Batch: 140; loss: 0.23; acc: 0.94
Batch: 160; loss: 0.17; acc: 0.95
Batch: 180; loss: 0.44; acc: 0.92
Batch: 200; loss: 0.21; acc: 0.94
Batch: 220; loss: 0.09; acc: 1.0
Batch: 240; loss: 0.19; acc: 0.94
Batch: 260; loss: 0.18; acc: 0.94
Batch: 280; loss: 0.43; acc: 0.86
Batch: 300; loss: 0.28; acc: 0.91
Batch: 320; loss: 0.27; acc: 0.89
Batch: 340; loss: 0.26; acc: 0.94
Batch: 360; loss: 0.33; acc: 0.88
Batch: 380; loss: 0.25; acc: 0.92
Batch: 400; loss: 0.1; acc: 0.97
Batch: 420; loss: 0.16; acc: 0.92
Batch: 440; loss: 0.25; acc: 0.91
Batch: 460; loss: 0.21; acc: 0.97
Batch: 480; loss: 0.31; acc: 0.91
Batch: 500; loss: 0.28; acc: 0.91
Batch: 520; loss: 0.16; acc: 0.95
Batch: 540; loss: 0.38; acc: 0.84
Batch: 560; loss: 0.18; acc: 0.95
Batch: 580; loss: 0.38; acc: 0.88
Batch: 600; loss: 0.24; acc: 0.94
Batch: 620; loss: 0.31; acc: 0.91
Batch: 640; loss: 0.45; acc: 0.86
Batch: 660; loss: 0.34; acc: 0.91
Batch: 680; loss: 0.2; acc: 0.95
Batch: 700; loss: 0.26; acc: 0.92
Batch: 720; loss: 0.25; acc: 0.95
Batch: 740; loss: 0.34; acc: 0.88
Batch: 760; loss: 0.18; acc: 0.92
Batch: 780; loss: 0.27; acc: 0.89
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

2.7138499717693776e-05
8.764187441556714e-06
Batch: 0; loss: 0.2; acc: 0.92
Batch: 20; loss: 0.27; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.37; acc: 0.88
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.2305575495075648; val_accuracy: 0.9308320063694268 

The current subspace-distance is: 8.764187441556714e-06 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.2; acc: 0.95
Batch: 40; loss: 0.13; acc: 0.94
Batch: 60; loss: 0.38; acc: 0.92
Batch: 80; loss: 0.15; acc: 0.94
Batch: 100; loss: 0.29; acc: 0.88
Batch: 120; loss: 0.12; acc: 0.95
Batch: 140; loss: 0.22; acc: 0.95
Batch: 160; loss: 0.37; acc: 0.91
Batch: 180; loss: 0.24; acc: 0.94
Batch: 200; loss: 0.17; acc: 0.94
Batch: 220; loss: 0.24; acc: 0.88
Batch: 240; loss: 0.28; acc: 0.91
Batch: 260; loss: 0.21; acc: 0.91
Batch: 280; loss: 0.27; acc: 0.89
Batch: 300; loss: 0.28; acc: 0.92
Batch: 320; loss: 0.21; acc: 0.95
Batch: 340; loss: 0.5; acc: 0.86
Batch: 360; loss: 0.2; acc: 0.92
Batch: 380; loss: 0.13; acc: 0.97
Batch: 400; loss: 0.21; acc: 0.94
Batch: 420; loss: 0.13; acc: 0.95
Batch: 440; loss: 0.12; acc: 0.95
Batch: 460; loss: 0.32; acc: 0.89
Batch: 480; loss: 0.33; acc: 0.94
Batch: 500; loss: 0.27; acc: 0.91
Batch: 520; loss: 0.14; acc: 0.95
Batch: 540; loss: 0.32; acc: 0.94
Batch: 560; loss: 0.19; acc: 0.95
Batch: 580; loss: 0.43; acc: 0.89
Batch: 600; loss: 0.34; acc: 0.86
Batch: 620; loss: 0.22; acc: 0.92
Batch: 640; loss: 0.31; acc: 0.92
Batch: 660; loss: 0.27; acc: 0.91
Batch: 680; loss: 0.12; acc: 0.97
Batch: 700; loss: 0.25; acc: 0.91
Batch: 720; loss: 0.19; acc: 0.94
Batch: 740; loss: 0.17; acc: 0.94
Batch: 760; loss: 0.32; acc: 0.92
Batch: 780; loss: 0.31; acc: 0.89
Train Epoch over. train_loss: 0.25; train_accuracy: 0.93 

2.7596579457167536e-05
8.641897693451028e-06
Batch: 0; loss: 0.21; acc: 0.92
Batch: 20; loss: 0.28; acc: 0.91
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.36; acc: 0.89
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.38; acc: 0.88
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.23120135602772615; val_accuracy: 0.9326234076433121 

The current subspace-distance is: 8.641897693451028e-06 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.24; acc: 0.92
Batch: 20; loss: 0.28; acc: 0.92
Batch: 40; loss: 0.22; acc: 0.92
Batch: 60; loss: 0.2; acc: 0.95
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.4; acc: 0.92
Batch: 120; loss: 0.31; acc: 0.88
Batch: 140; loss: 0.27; acc: 0.94
Batch: 160; loss: 0.21; acc: 0.94
Batch: 180; loss: 0.21; acc: 0.94
Batch: 200; loss: 0.13; acc: 0.94
Batch: 220; loss: 0.31; acc: 0.92
Batch: 240; loss: 0.38; acc: 0.88
Batch: 260; loss: 0.1; acc: 0.95
Batch: 280; loss: 0.36; acc: 0.92
Batch: 300; loss: 0.27; acc: 0.89
Batch: 320; loss: 0.15; acc: 0.95
Batch: 340; loss: 0.19; acc: 0.92
Batch: 360; loss: 0.32; acc: 0.92
Batch: 380; loss: 0.24; acc: 0.94
Batch: 400; loss: 0.1; acc: 0.98
Batch: 420; loss: 0.22; acc: 0.98
Batch: 440; loss: 0.44; acc: 0.91
Batch: 460; loss: 0.13; acc: 0.97
Batch: 480; loss: 0.21; acc: 0.91
Batch: 500; loss: 0.13; acc: 0.94
Batch: 520; loss: 0.41; acc: 0.88
Batch: 540; loss: 0.4; acc: 0.86
Batch: 560; loss: 0.24; acc: 0.94
Batch: 580; loss: 0.15; acc: 0.94
Batch: 600; loss: 0.31; acc: 0.92
Batch: 620; loss: 0.2; acc: 0.94
Batch: 640; loss: 0.13; acc: 0.95
Batch: 660; loss: 0.2; acc: 0.95
Batch: 680; loss: 0.31; acc: 0.91
Batch: 700; loss: 0.3; acc: 0.91
Batch: 720; loss: 0.18; acc: 0.97
Batch: 740; loss: 0.18; acc: 0.94
Batch: 760; loss: 0.24; acc: 0.94
Batch: 780; loss: 0.25; acc: 0.92
Train Epoch over. train_loss: 0.25; train_accuracy: 0.93 

2.7476684408611618e-05
8.326326678798068e-06
Batch: 0; loss: 0.18; acc: 0.92
Batch: 20; loss: 0.29; acc: 0.88
Batch: 40; loss: 0.16; acc: 0.98
Batch: 60; loss: 0.32; acc: 0.89
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.38; acc: 0.88
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.23339059597747341; val_accuracy: 0.9301353503184714 

The current subspace-distance is: 8.326326678798068e-06 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.35; acc: 0.89
Batch: 20; loss: 0.28; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.13; acc: 0.97
Batch: 80; loss: 0.3; acc: 0.91
Batch: 100; loss: 0.32; acc: 0.91
Batch: 120; loss: 0.37; acc: 0.88
Batch: 140; loss: 0.19; acc: 0.91
Batch: 160; loss: 0.29; acc: 0.95
Batch: 180; loss: 0.18; acc: 0.92
Batch: 200; loss: 0.29; acc: 0.88
Batch: 220; loss: 0.33; acc: 0.92
Batch: 240; loss: 0.2; acc: 0.94
Batch: 260; loss: 0.31; acc: 0.91
Batch: 280; loss: 0.25; acc: 0.92
Batch: 300; loss: 0.53; acc: 0.84
Batch: 320; loss: 0.42; acc: 0.89
Batch: 340; loss: 0.34; acc: 0.91
Batch: 360; loss: 0.07; acc: 0.97
Batch: 380; loss: 0.26; acc: 0.92
Batch: 400; loss: 0.08; acc: 0.97
Batch: 420; loss: 0.39; acc: 0.92
Batch: 440; loss: 0.16; acc: 0.97
Batch: 460; loss: 0.11; acc: 0.97
Batch: 480; loss: 0.11; acc: 0.97
Batch: 500; loss: 0.18; acc: 0.95
Batch: 520; loss: 0.35; acc: 0.94
Batch: 540; loss: 0.11; acc: 0.95
Batch: 560; loss: 0.34; acc: 0.92
Batch: 580; loss: 0.38; acc: 0.88
Batch: 600; loss: 0.1; acc: 0.98
Batch: 620; loss: 0.13; acc: 0.95
Batch: 640; loss: 0.14; acc: 0.94
Batch: 660; loss: 0.19; acc: 0.97
Batch: 680; loss: 0.12; acc: 0.94
Batch: 700; loss: 0.19; acc: 0.91
Batch: 720; loss: 0.51; acc: 0.88
Batch: 740; loss: 0.26; acc: 0.89
Batch: 760; loss: 0.19; acc: 0.92
Batch: 780; loss: 0.1; acc: 0.95
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

2.8680917239398696e-05
8.448107109870762e-06
Batch: 0; loss: 0.22; acc: 0.92
Batch: 20; loss: 0.3; acc: 0.88
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.36; acc: 0.89
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.39; acc: 0.88
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.2316448697049147; val_accuracy: 0.9323248407643312 

The current subspace-distance is: 8.448107109870762e-06 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.21; acc: 0.92
Batch: 20; loss: 0.24; acc: 0.94
Batch: 40; loss: 0.27; acc: 0.92
Batch: 60; loss: 0.39; acc: 0.88
Batch: 80; loss: 0.2; acc: 0.91
Batch: 100; loss: 0.23; acc: 0.97
Batch: 120; loss: 0.38; acc: 0.91
Batch: 140; loss: 0.17; acc: 0.94
Batch: 160; loss: 0.31; acc: 0.89
Batch: 180; loss: 0.17; acc: 0.95
Batch: 200; loss: 0.09; acc: 0.97
Batch: 220; loss: 0.22; acc: 0.91
Batch: 240; loss: 0.32; acc: 0.89
Batch: 260; loss: 0.18; acc: 0.94
Batch: 280; loss: 0.31; acc: 0.92
Batch: 300; loss: 0.24; acc: 0.92
Batch: 320; loss: 0.23; acc: 0.91
Batch: 340; loss: 0.31; acc: 0.88
Batch: 360; loss: 0.17; acc: 0.97
Batch: 380; loss: 0.33; acc: 0.92
Batch: 400; loss: 0.17; acc: 0.97
Batch: 420; loss: 0.2; acc: 0.92
Batch: 440; loss: 0.31; acc: 0.91
Batch: 460; loss: 0.26; acc: 0.92
Batch: 480; loss: 0.2; acc: 0.95
Batch: 500; loss: 0.29; acc: 0.91
Batch: 520; loss: 0.09; acc: 0.97
Batch: 540; loss: 0.16; acc: 0.95
Batch: 560; loss: 0.1; acc: 0.97
Batch: 580; loss: 0.16; acc: 0.95
Batch: 600; loss: 0.24; acc: 0.91
Batch: 620; loss: 0.26; acc: 0.91
Batch: 640; loss: 0.31; acc: 0.91
Batch: 660; loss: 0.26; acc: 0.92
Batch: 680; loss: 0.28; acc: 0.89
Batch: 700; loss: 0.28; acc: 0.89
Batch: 720; loss: 0.33; acc: 0.91
Batch: 740; loss: 0.19; acc: 0.95
Batch: 760; loss: 0.24; acc: 0.91
Batch: 780; loss: 0.16; acc: 0.98
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

2.8925987862749025e-05
9.122681149165146e-06
Batch: 0; loss: 0.2; acc: 0.92
Batch: 20; loss: 0.25; acc: 0.91
Batch: 40; loss: 0.16; acc: 0.98
Batch: 60; loss: 0.36; acc: 0.91
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.24; acc: 0.92
Batch: 120; loss: 0.36; acc: 0.88
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.22952500325004765; val_accuracy: 0.931827229299363 

The current subspace-distance is: 9.122681149165146e-06 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.33; acc: 0.91
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.22; acc: 0.95
Batch: 100; loss: 0.51; acc: 0.86
Batch: 120; loss: 0.29; acc: 0.91
Batch: 140; loss: 0.16; acc: 0.97
Batch: 160; loss: 0.32; acc: 0.89
Batch: 180; loss: 0.32; acc: 0.91
Batch: 200; loss: 0.19; acc: 0.95
Batch: 220; loss: 0.29; acc: 0.97
Batch: 240; loss: 0.32; acc: 0.88
Batch: 260; loss: 0.21; acc: 0.95
Batch: 280; loss: 0.34; acc: 0.89
Batch: 300; loss: 0.27; acc: 0.95
Batch: 320; loss: 0.17; acc: 0.92
Batch: 340; loss: 0.21; acc: 0.94
Batch: 360; loss: 0.35; acc: 0.94
Batch: 380; loss: 0.37; acc: 0.88
Batch: 400; loss: 0.08; acc: 0.98
Batch: 420; loss: 0.17; acc: 0.94
Batch: 440; loss: 0.18; acc: 0.95
Batch: 460; loss: 0.17; acc: 0.94
Batch: 480; loss: 0.18; acc: 0.92
Batch: 500; loss: 0.11; acc: 0.97
Batch: 520; loss: 0.22; acc: 0.94
Batch: 540; loss: 0.23; acc: 0.92
Batch: 560; loss: 0.3; acc: 0.91
Batch: 580; loss: 0.14; acc: 0.95
Batch: 600; loss: 0.31; acc: 0.88
Batch: 620; loss: 0.1; acc: 0.98
Batch: 640; loss: 0.18; acc: 0.89
Batch: 660; loss: 0.27; acc: 0.94
Batch: 680; loss: 0.18; acc: 0.95
Batch: 700; loss: 0.31; acc: 0.91
Batch: 720; loss: 0.26; acc: 0.92
Batch: 740; loss: 0.08; acc: 0.98
Batch: 760; loss: 0.11; acc: 0.95
Batch: 780; loss: 0.1; acc: 0.97
Train Epoch over. train_loss: 0.25; train_accuracy: 0.93 

2.767185287666507e-05
8.816436093184166e-06
Batch: 0; loss: 0.2; acc: 0.92
Batch: 20; loss: 0.27; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.33; acc: 0.89
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.38; acc: 0.88
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.22834149883336322; val_accuracy: 0.9332205414012739 

The current subspace-distance is: 8.816436093184166e-06 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.16; acc: 0.94
Batch: 20; loss: 0.21; acc: 0.95
Batch: 40; loss: 0.24; acc: 0.91
Batch: 60; loss: 0.26; acc: 0.94
Batch: 80; loss: 0.43; acc: 0.89
Batch: 100; loss: 0.14; acc: 0.97
Batch: 120; loss: 0.35; acc: 0.91
Batch: 140; loss: 0.17; acc: 0.95
Batch: 160; loss: 0.33; acc: 0.92
Batch: 180; loss: 0.17; acc: 0.95
Batch: 200; loss: 0.2; acc: 0.97
Batch: 220; loss: 0.25; acc: 0.94
Batch: 240; loss: 0.19; acc: 0.94
Batch: 260; loss: 0.26; acc: 0.92
Batch: 280; loss: 0.23; acc: 0.95
Batch: 300; loss: 0.16; acc: 0.97
Batch: 320; loss: 0.19; acc: 0.91
Batch: 340; loss: 0.19; acc: 0.92
Batch: 360; loss: 0.33; acc: 0.92
Batch: 380; loss: 0.14; acc: 0.95
Batch: 400; loss: 0.22; acc: 0.92
Batch: 420; loss: 0.23; acc: 0.92
Batch: 440; loss: 0.3; acc: 0.89
Batch: 460; loss: 0.17; acc: 0.94
Batch: 480; loss: 0.17; acc: 0.92
Batch: 500; loss: 0.25; acc: 0.94
Batch: 520; loss: 0.28; acc: 0.91
Batch: 540; loss: 0.23; acc: 0.92
Batch: 560; loss: 0.26; acc: 0.88
Batch: 580; loss: 0.23; acc: 0.92
Batch: 600; loss: 0.39; acc: 0.83
Batch: 620; loss: 0.19; acc: 0.94
Batch: 640; loss: 0.16; acc: 0.95
Batch: 660; loss: 0.23; acc: 0.88
Batch: 680; loss: 0.25; acc: 0.89
Batch: 700; loss: 0.35; acc: 0.94
Batch: 720; loss: 0.21; acc: 0.92
Batch: 740; loss: 0.23; acc: 0.91
Batch: 760; loss: 0.16; acc: 0.95
Batch: 780; loss: 0.34; acc: 0.91
Train Epoch over. train_loss: 0.25; train_accuracy: 0.93 

2.7150334062753245e-05
9.253930329577997e-06
Batch: 0; loss: 0.2; acc: 0.92
Batch: 20; loss: 0.27; acc: 0.89
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.33; acc: 0.89
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.37; acc: 0.88
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.22835574590951013; val_accuracy: 0.9324243630573248 

The current subspace-distance is: 9.253930329577997e-06 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.25; acc: 0.94
Batch: 20; loss: 0.53; acc: 0.89
Batch: 40; loss: 0.25; acc: 0.95
Batch: 60; loss: 0.29; acc: 0.91
Batch: 80; loss: 0.25; acc: 0.91
Batch: 100; loss: 0.21; acc: 0.92
Batch: 120; loss: 0.35; acc: 0.88
Batch: 140; loss: 0.18; acc: 0.92
Batch: 160; loss: 0.23; acc: 0.91
Batch: 180; loss: 0.32; acc: 0.92
Batch: 200; loss: 0.09; acc: 0.98
Batch: 220; loss: 0.22; acc: 0.92
Batch: 240; loss: 0.54; acc: 0.89
Batch: 260; loss: 0.33; acc: 0.91
Batch: 280; loss: 0.12; acc: 0.97
Batch: 300; loss: 0.18; acc: 0.92
Batch: 320; loss: 0.1; acc: 1.0
Batch: 340; loss: 0.25; acc: 0.91
Batch: 360; loss: 0.12; acc: 0.95
Batch: 380; loss: 0.2; acc: 0.95
Batch: 400; loss: 0.22; acc: 0.92
Batch: 420; loss: 0.24; acc: 0.91
Batch: 440; loss: 0.15; acc: 0.98
Batch: 460; loss: 0.24; acc: 0.92
Batch: 480; loss: 0.17; acc: 0.95
Batch: 500; loss: 0.26; acc: 0.92
Batch: 520; loss: 0.41; acc: 0.91
Batch: 540; loss: 0.32; acc: 0.89
Batch: 560; loss: 0.22; acc: 0.94
Batch: 580; loss: 0.33; acc: 0.86
Batch: 600; loss: 0.31; acc: 0.94
Batch: 620; loss: 0.13; acc: 0.97
Batch: 640; loss: 0.05; acc: 0.98
Batch: 660; loss: 0.19; acc: 0.94
Batch: 680; loss: 0.23; acc: 0.94
Batch: 700; loss: 0.12; acc: 0.94
Batch: 720; loss: 0.15; acc: 0.98
Batch: 740; loss: 0.42; acc: 0.88
Batch: 760; loss: 0.27; acc: 0.88
Batch: 780; loss: 0.22; acc: 0.94
Train Epoch over. train_loss: 0.25; train_accuracy: 0.93 

2.7285728720016778e-05
9.538529411656782e-06
Batch: 0; loss: 0.19; acc: 0.92
Batch: 20; loss: 0.27; acc: 0.89
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.33; acc: 0.89
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.37; acc: 0.88
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.22756484343083042; val_accuracy: 0.9326234076433121 

The current subspace-distance is: 9.538529411656782e-06 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.23; acc: 0.94
Batch: 20; loss: 0.34; acc: 0.89
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.24; acc: 0.92
Batch: 100; loss: 0.34; acc: 0.89
Batch: 120; loss: 0.2; acc: 0.92
Batch: 140; loss: 0.23; acc: 0.97
Batch: 160; loss: 0.3; acc: 0.91
Batch: 180; loss: 0.36; acc: 0.92
Batch: 200; loss: 0.17; acc: 0.97
Batch: 220; loss: 0.23; acc: 0.92
Batch: 240; loss: 0.35; acc: 0.91
Batch: 260; loss: 0.32; acc: 0.88
Batch: 280; loss: 0.28; acc: 0.91
Batch: 300; loss: 0.24; acc: 0.94
Batch: 320; loss: 0.3; acc: 0.94
Batch: 340; loss: 0.24; acc: 0.92
Batch: 360; loss: 0.12; acc: 0.97
Batch: 380; loss: 0.34; acc: 0.89
Batch: 400; loss: 0.4; acc: 0.86
Batch: 420; loss: 0.3; acc: 0.89
Batch: 440; loss: 0.33; acc: 0.89
Batch: 460; loss: 0.22; acc: 0.92
Batch: 480; loss: 0.33; acc: 0.88
Batch: 500; loss: 0.43; acc: 0.88
Batch: 520; loss: 0.36; acc: 0.88
Batch: 540; loss: 0.18; acc: 0.97
Batch: 560; loss: 0.1; acc: 0.98
Batch: 580; loss: 0.23; acc: 0.94
Batch: 600; loss: 0.3; acc: 0.89
Batch: 620; loss: 0.24; acc: 0.95
Batch: 640; loss: 0.33; acc: 0.86
Batch: 660; loss: 0.49; acc: 0.86
Batch: 680; loss: 0.16; acc: 0.94
Batch: 700; loss: 0.24; acc: 0.88
Batch: 720; loss: 0.15; acc: 0.95
Batch: 740; loss: 0.56; acc: 0.91
Batch: 760; loss: 0.17; acc: 0.94
Batch: 780; loss: 0.13; acc: 0.98
Train Epoch over. train_loss: 0.25; train_accuracy: 0.93 

2.768087688309606e-05
8.434720257355366e-06
Batch: 0; loss: 0.2; acc: 0.92
Batch: 20; loss: 0.27; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.38; acc: 0.88
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.22736393636578967; val_accuracy: 0.932921974522293 

The current subspace-distance is: 8.434720257355366e-06 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.3; acc: 0.92
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.1; acc: 0.95
Batch: 120; loss: 0.21; acc: 0.97
Batch: 140; loss: 0.17; acc: 0.94
Batch: 160; loss: 0.08; acc: 0.98
Batch: 180; loss: 0.07; acc: 1.0
Batch: 200; loss: 0.22; acc: 0.92
Batch: 220; loss: 0.13; acc: 0.97
Batch: 240; loss: 0.35; acc: 0.91
Batch: 260; loss: 0.16; acc: 0.97
Batch: 280; loss: 0.35; acc: 0.88
Batch: 300; loss: 0.23; acc: 0.91
Batch: 320; loss: 0.22; acc: 0.91
Batch: 340; loss: 0.14; acc: 0.94
Batch: 360; loss: 0.16; acc: 0.95
Batch: 380; loss: 0.11; acc: 0.97
Batch: 400; loss: 0.15; acc: 0.92
Batch: 420; loss: 0.14; acc: 0.95
Batch: 440; loss: 0.27; acc: 0.92
Batch: 460; loss: 0.3; acc: 0.94
Batch: 480; loss: 0.19; acc: 0.94
Batch: 500; loss: 0.19; acc: 0.94
Batch: 520; loss: 0.23; acc: 0.92
Batch: 540; loss: 0.24; acc: 0.92
Batch: 560; loss: 0.12; acc: 0.97
Batch: 580; loss: 0.2; acc: 0.92
Batch: 600; loss: 0.27; acc: 0.92
Batch: 620; loss: 0.22; acc: 0.92
Batch: 640; loss: 0.14; acc: 0.95
Batch: 660; loss: 0.32; acc: 0.91
Batch: 680; loss: 0.32; acc: 0.92
Batch: 700; loss: 0.35; acc: 0.92
Batch: 720; loss: 0.34; acc: 0.88
Batch: 740; loss: 0.22; acc: 0.92
Batch: 760; loss: 0.21; acc: 0.92
Batch: 780; loss: 0.13; acc: 0.95
Train Epoch over. train_loss: 0.25; train_accuracy: 0.93 

2.6580544727039523e-05
7.961557457747404e-06
Batch: 0; loss: 0.2; acc: 0.92
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.38; acc: 0.88
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.22706312878401416; val_accuracy: 0.9330214968152867 

The current subspace-distance is: 7.961557457747404e-06 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.16; acc: 0.92
Batch: 20; loss: 0.32; acc: 0.88
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.2; acc: 0.97
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.27; acc: 0.91
Batch: 120; loss: 0.35; acc: 0.92
Batch: 140; loss: 0.22; acc: 0.94
Batch: 160; loss: 0.15; acc: 0.95
Batch: 180; loss: 0.06; acc: 0.97
Batch: 200; loss: 0.27; acc: 0.89
Batch: 220; loss: 0.29; acc: 0.89
Batch: 240; loss: 0.25; acc: 0.92
Batch: 260; loss: 0.15; acc: 0.97
Batch: 280; loss: 0.4; acc: 0.92
Batch: 300; loss: 0.21; acc: 0.92
Batch: 320; loss: 0.5; acc: 0.88
Batch: 340; loss: 0.29; acc: 0.92
Batch: 360; loss: 0.39; acc: 0.88
Batch: 380; loss: 0.31; acc: 0.92
Batch: 400; loss: 0.24; acc: 0.91
Batch: 420; loss: 0.37; acc: 0.89
Batch: 440; loss: 0.16; acc: 0.95
Batch: 460; loss: 0.26; acc: 0.94
Batch: 480; loss: 0.25; acc: 0.92
Batch: 500; loss: 0.3; acc: 0.94
Batch: 520; loss: 0.37; acc: 0.94
Batch: 540; loss: 0.44; acc: 0.86
Batch: 560; loss: 0.27; acc: 0.89
Batch: 580; loss: 0.19; acc: 0.92
Batch: 600; loss: 0.11; acc: 0.95
Batch: 620; loss: 0.33; acc: 0.89
Batch: 640; loss: 0.19; acc: 0.94
Batch: 660; loss: 0.11; acc: 0.98
Batch: 680; loss: 0.11; acc: 0.97
Batch: 700; loss: 0.2; acc: 0.94
Batch: 720; loss: 0.25; acc: 0.89
Batch: 740; loss: 0.24; acc: 0.92
Batch: 760; loss: 0.18; acc: 0.94
Batch: 780; loss: 0.17; acc: 0.97
Train Epoch over. train_loss: 0.25; train_accuracy: 0.93 

2.849759766831994e-05
9.057674105861224e-06
Batch: 0; loss: 0.19; acc: 0.92
Batch: 20; loss: 0.27; acc: 0.89
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.32; acc: 0.89
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.38; acc: 0.88
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.2296641018882299; val_accuracy: 0.9316281847133758 

The current subspace-distance is: 9.057674105861224e-06 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.19; acc: 0.97
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.23; acc: 0.92
Batch: 80; loss: 0.29; acc: 0.88
Batch: 100; loss: 0.4; acc: 0.88
Batch: 120; loss: 0.37; acc: 0.86
Batch: 140; loss: 0.5; acc: 0.91
Batch: 160; loss: 0.4; acc: 0.91
Batch: 180; loss: 0.27; acc: 0.94
Batch: 200; loss: 0.26; acc: 0.92
Batch: 220; loss: 0.2; acc: 0.92
Batch: 240; loss: 0.09; acc: 0.97
Batch: 260; loss: 0.22; acc: 0.94
Batch: 280; loss: 0.1; acc: 0.95
Batch: 300; loss: 0.07; acc: 0.98
Batch: 320; loss: 0.29; acc: 0.92
Batch: 340; loss: 0.27; acc: 0.94
Batch: 360; loss: 0.23; acc: 0.91
Batch: 380; loss: 0.14; acc: 0.97
Batch: 400; loss: 0.2; acc: 0.95
Batch: 420; loss: 0.23; acc: 0.92
Batch: 440; loss: 0.21; acc: 0.94
Batch: 460; loss: 0.2; acc: 0.94
Batch: 480; loss: 0.15; acc: 0.95
Batch: 500; loss: 0.13; acc: 0.97
Batch: 520; loss: 0.29; acc: 0.92
Batch: 540; loss: 0.25; acc: 0.92
Batch: 560; loss: 0.25; acc: 0.92
Batch: 580; loss: 0.31; acc: 0.89
Batch: 600; loss: 0.39; acc: 0.88
Batch: 620; loss: 0.18; acc: 0.97
Batch: 640; loss: 0.23; acc: 0.92
Batch: 660; loss: 0.21; acc: 0.94
Batch: 680; loss: 0.51; acc: 0.86
Batch: 700; loss: 0.4; acc: 0.89
Batch: 720; loss: 0.24; acc: 0.95
Batch: 740; loss: 0.29; acc: 0.89
Batch: 760; loss: 0.3; acc: 0.91
Batch: 780; loss: 0.2; acc: 0.97
Train Epoch over. train_loss: 0.25; train_accuracy: 0.93 

2.575586586317513e-05
8.096335477603134e-06
Batch: 0; loss: 0.2; acc: 0.92
Batch: 20; loss: 0.27; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.38; acc: 0.88
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.22730233214178663; val_accuracy: 0.9332205414012739 

The current subspace-distance is: 8.096335477603134e-06 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.29; acc: 0.94
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.36; acc: 0.89
Batch: 100; loss: 0.37; acc: 0.92
Batch: 120; loss: 0.17; acc: 0.95
Batch: 140; loss: 0.25; acc: 0.92
Batch: 160; loss: 0.18; acc: 0.94
Batch: 180; loss: 0.22; acc: 0.92
Batch: 200; loss: 0.18; acc: 0.94
Batch: 220; loss: 0.24; acc: 0.94
Batch: 240; loss: 0.16; acc: 0.94
Batch: 260; loss: 0.29; acc: 0.94
Batch: 280; loss: 0.28; acc: 0.89
Batch: 300; loss: 0.18; acc: 0.92
Batch: 320; loss: 0.2; acc: 0.95
Batch: 340; loss: 0.16; acc: 0.94
Batch: 360; loss: 0.31; acc: 0.84
Batch: 380; loss: 0.27; acc: 0.94
Batch: 400; loss: 0.15; acc: 0.94
Batch: 420; loss: 0.21; acc: 0.95
Batch: 440; loss: 0.22; acc: 0.94
Batch: 460; loss: 0.22; acc: 0.94
Batch: 480; loss: 0.2; acc: 0.92
Batch: 500; loss: 0.49; acc: 0.88
Batch: 520; loss: 0.22; acc: 0.92
Batch: 540; loss: 0.48; acc: 0.86
Batch: 560; loss: 0.22; acc: 0.91
Batch: 580; loss: 0.21; acc: 0.95
Batch: 600; loss: 0.27; acc: 0.92
Batch: 620; loss: 0.1; acc: 0.98
Batch: 640; loss: 0.12; acc: 0.97
Batch: 660; loss: 0.09; acc: 0.97
Batch: 680; loss: 0.19; acc: 0.94
Batch: 700; loss: 0.33; acc: 0.95
Batch: 720; loss: 0.22; acc: 0.95
Batch: 740; loss: 0.41; acc: 0.91
Batch: 760; loss: 0.15; acc: 0.95
Batch: 780; loss: 0.23; acc: 0.92
Train Epoch over. train_loss: 0.25; train_accuracy: 0.93 

2.8963268050574698e-05
8.64547928358661e-06
Batch: 0; loss: 0.2; acc: 0.92
Batch: 20; loss: 0.28; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.33; acc: 0.89
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.39; acc: 0.88
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.22841881573864609; val_accuracy: 0.932921974522293 

The current subspace-distance is: 8.64547928358661e-06 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.37; acc: 0.89
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.28; acc: 0.94
Batch: 80; loss: 0.22; acc: 0.92
Batch: 100; loss: 0.15; acc: 0.91
Batch: 120; loss: 0.16; acc: 0.97
Batch: 140; loss: 0.34; acc: 0.89
Batch: 160; loss: 0.2; acc: 0.94
Batch: 180; loss: 0.23; acc: 0.91
Batch: 200; loss: 0.37; acc: 0.91
Batch: 220; loss: 0.17; acc: 0.95
Batch: 240; loss: 0.16; acc: 0.95
Batch: 260; loss: 0.21; acc: 0.91
Batch: 280; loss: 0.21; acc: 0.92
Batch: 300; loss: 0.24; acc: 0.88
Batch: 320; loss: 0.16; acc: 0.95
Batch: 340; loss: 0.32; acc: 0.92
Batch: 360; loss: 0.19; acc: 0.92
Batch: 380; loss: 0.25; acc: 0.91
Batch: 400; loss: 0.2; acc: 0.94
Batch: 420; loss: 0.2; acc: 0.97
Batch: 440; loss: 0.1; acc: 0.97
Batch: 460; loss: 0.23; acc: 0.94
Batch: 480; loss: 0.29; acc: 0.92
Batch: 500; loss: 0.37; acc: 0.86
Batch: 520; loss: 0.37; acc: 0.91
Batch: 540; loss: 0.27; acc: 0.88
Batch: 560; loss: 0.35; acc: 0.92
Batch: 580; loss: 0.13; acc: 0.95
Batch: 600; loss: 0.19; acc: 0.92
Batch: 620; loss: 0.13; acc: 0.97
Batch: 640; loss: 0.26; acc: 0.89
Batch: 660; loss: 0.1; acc: 0.97
Batch: 680; loss: 0.15; acc: 0.94
Batch: 700; loss: 0.11; acc: 0.97
Batch: 720; loss: 0.18; acc: 0.92
Batch: 740; loss: 0.18; acc: 0.94
Batch: 760; loss: 0.26; acc: 0.95
Batch: 780; loss: 0.3; acc: 0.94
Train Epoch over. train_loss: 0.25; train_accuracy: 0.93 

2.7777521609095857e-05
9.533689990348648e-06
Batch: 0; loss: 0.2; acc: 0.92
Batch: 20; loss: 0.27; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.39; acc: 0.88
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.22779672906087461; val_accuracy: 0.9330214968152867 

The current subspace-distance is: 9.533689990348648e-06 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.15; acc: 0.92
Batch: 20; loss: 0.32; acc: 0.89
Batch: 40; loss: 0.27; acc: 0.92
Batch: 60; loss: 0.18; acc: 0.95
Batch: 80; loss: 0.28; acc: 0.94
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.26; acc: 0.94
Batch: 140; loss: 0.22; acc: 0.94
Batch: 160; loss: 0.2; acc: 0.94
Batch: 180; loss: 0.16; acc: 0.95
Batch: 200; loss: 0.35; acc: 0.91
Batch: 220; loss: 0.32; acc: 0.86
Batch: 240; loss: 0.36; acc: 0.92
Batch: 260; loss: 0.28; acc: 0.92
Batch: 280; loss: 0.19; acc: 0.91
Batch: 300; loss: 0.18; acc: 0.95
Batch: 320; loss: 0.2; acc: 0.92
Batch: 340; loss: 0.14; acc: 0.94
Batch: 360; loss: 0.26; acc: 0.92
Batch: 380; loss: 0.28; acc: 0.89
Batch: 400; loss: 0.25; acc: 0.94
Batch: 420; loss: 0.19; acc: 0.94
Batch: 440; loss: 0.16; acc: 0.92
Batch: 460; loss: 0.32; acc: 0.94
Batch: 480; loss: 0.31; acc: 0.91
Batch: 500; loss: 0.22; acc: 0.89
Batch: 520; loss: 0.22; acc: 0.94
Batch: 540; loss: 0.26; acc: 0.92
Batch: 560; loss: 0.37; acc: 0.86
Batch: 580; loss: 0.19; acc: 0.94
Batch: 600; loss: 0.23; acc: 0.95
Batch: 620; loss: 0.27; acc: 0.94
Batch: 640; loss: 0.18; acc: 0.94
Batch: 660; loss: 0.14; acc: 0.94
Batch: 680; loss: 0.24; acc: 0.94
Batch: 700; loss: 0.26; acc: 0.92
Batch: 720; loss: 0.17; acc: 0.95
Batch: 740; loss: 0.32; acc: 0.91
Batch: 760; loss: 0.25; acc: 0.91
Batch: 780; loss: 0.42; acc: 0.86
Train Epoch over. train_loss: 0.25; train_accuracy: 0.93 

2.9904553230153397e-05
9.14081192604499e-06
Batch: 0; loss: 0.2; acc: 0.92
Batch: 20; loss: 0.26; acc: 0.89
Batch: 40; loss: 0.16; acc: 0.98
Batch: 60; loss: 0.33; acc: 0.89
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.37; acc: 0.88
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.2267090092608883; val_accuracy: 0.9326234076433121 

The current subspace-distance is: 9.14081192604499e-06 

plots/subspace_training/reg_lenet_3/2020-01-22 20:51:04/d_dim_170_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
nonzero elements in E: 38584
elements in E: 8098200
fraction nonzero: 0.0047645155713615375
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.31; acc: 0.08
Batch: 20; loss: 2.29; acc: 0.05
Batch: 40; loss: 2.3; acc: 0.09
Batch: 60; loss: 2.3; acc: 0.02
Batch: 80; loss: 2.3; acc: 0.08
Batch: 100; loss: 2.3; acc: 0.12
Batch: 120; loss: 2.3; acc: 0.11
Batch: 140; loss: 2.32; acc: 0.08
Batch: 160; loss: 2.3; acc: 0.08
Batch: 180; loss: 2.3; acc: 0.11
Batch: 200; loss: 2.29; acc: 0.14
Batch: 220; loss: 2.31; acc: 0.06
Batch: 240; loss: 2.3; acc: 0.05
Batch: 260; loss: 2.3; acc: 0.09
Batch: 280; loss: 2.28; acc: 0.05
Batch: 300; loss: 2.29; acc: 0.05
Batch: 320; loss: 2.3; acc: 0.03
Batch: 340; loss: 2.28; acc: 0.05
Batch: 360; loss: 2.28; acc: 0.16
Batch: 380; loss: 2.29; acc: 0.08
Batch: 400; loss: 2.29; acc: 0.14
Batch: 420; loss: 2.3; acc: 0.11
Batch: 440; loss: 2.28; acc: 0.25
Batch: 460; loss: 2.28; acc: 0.19
Batch: 480; loss: 2.28; acc: 0.22
Batch: 500; loss: 2.26; acc: 0.25
Batch: 520; loss: 2.26; acc: 0.3
Batch: 540; loss: 2.24; acc: 0.41
Batch: 560; loss: 2.24; acc: 0.27
Batch: 580; loss: 2.23; acc: 0.27
Batch: 600; loss: 2.23; acc: 0.23
Batch: 620; loss: 2.17; acc: 0.5
Batch: 640; loss: 2.17; acc: 0.42
Batch: 660; loss: 2.14; acc: 0.34
Batch: 680; loss: 2.18; acc: 0.31
Batch: 700; loss: 2.06; acc: 0.36
Batch: 720; loss: 1.92; acc: 0.45
Batch: 740; loss: 1.75; acc: 0.48
Batch: 760; loss: 1.67; acc: 0.48
Batch: 780; loss: 1.47; acc: 0.44
Train Epoch over. train_loss: 2.21; train_accuracy: 0.2 

7.7429194789147e-06
3.513510591801605e-06
Batch: 0; loss: 1.46; acc: 0.56
Batch: 20; loss: 1.77; acc: 0.45
Batch: 40; loss: 1.24; acc: 0.64
Batch: 60; loss: 1.27; acc: 0.61
Batch: 80; loss: 1.27; acc: 0.59
Batch: 100; loss: 1.41; acc: 0.47
Batch: 120; loss: 1.46; acc: 0.53
Batch: 140; loss: 1.53; acc: 0.41
Val Epoch over. val_loss: 1.4474251156399964; val_accuracy: 0.5187101910828026 

The current subspace-distance is: 3.513510591801605e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 1.48; acc: 0.53
Batch: 20; loss: 1.51; acc: 0.5
Batch: 40; loss: 1.27; acc: 0.55
Batch: 60; loss: 1.08; acc: 0.64
Batch: 80; loss: 1.06; acc: 0.67
Batch: 100; loss: 0.96; acc: 0.7
Batch: 120; loss: 1.08; acc: 0.64
Batch: 140; loss: 0.78; acc: 0.75
Batch: 160; loss: 1.01; acc: 0.69
Batch: 180; loss: 1.21; acc: 0.58
Batch: 200; loss: 1.03; acc: 0.62
Batch: 220; loss: 1.11; acc: 0.64
Batch: 240; loss: 0.76; acc: 0.77
Batch: 260; loss: 1.02; acc: 0.69
Batch: 280; loss: 0.95; acc: 0.7
Batch: 300; loss: 0.65; acc: 0.86
Batch: 320; loss: 0.87; acc: 0.73
Batch: 340; loss: 1.05; acc: 0.67
Batch: 360; loss: 0.99; acc: 0.72
Batch: 380; loss: 0.62; acc: 0.83
Batch: 400; loss: 0.91; acc: 0.73
Batch: 420; loss: 0.82; acc: 0.73
Batch: 440; loss: 0.88; acc: 0.66
Batch: 460; loss: 1.32; acc: 0.59
Batch: 480; loss: 1.02; acc: 0.61
Batch: 500; loss: 0.85; acc: 0.73
Batch: 520; loss: 0.88; acc: 0.75
Batch: 540; loss: 0.56; acc: 0.81
Batch: 560; loss: 0.58; acc: 0.78
Batch: 580; loss: 0.55; acc: 0.84
Batch: 600; loss: 0.86; acc: 0.7
Batch: 620; loss: 0.48; acc: 0.91
Batch: 640; loss: 0.8; acc: 0.77
Batch: 660; loss: 0.97; acc: 0.7
Batch: 680; loss: 0.65; acc: 0.83
Batch: 700; loss: 0.79; acc: 0.75
Batch: 720; loss: 0.75; acc: 0.73
Batch: 740; loss: 0.76; acc: 0.83
Batch: 760; loss: 1.01; acc: 0.75
Batch: 780; loss: 0.77; acc: 0.77
Train Epoch over. train_loss: 0.92; train_accuracy: 0.7 

1.7867489077616483e-05
6.90188744556508e-06
Batch: 0; loss: 1.35; acc: 0.59
Batch: 20; loss: 1.73; acc: 0.53
Batch: 40; loss: 1.2; acc: 0.66
Batch: 60; loss: 1.62; acc: 0.64
Batch: 80; loss: 1.38; acc: 0.66
Batch: 100; loss: 1.13; acc: 0.73
Batch: 120; loss: 1.63; acc: 0.58
Batch: 140; loss: 1.63; acc: 0.59
Val Epoch over. val_loss: 1.3563397014217011; val_accuracy: 0.6155453821656051 

The current subspace-distance is: 6.90188744556508e-06 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 1.37; acc: 0.61
Batch: 20; loss: 0.42; acc: 0.86
Batch: 40; loss: 0.52; acc: 0.86
Batch: 60; loss: 0.54; acc: 0.83
Batch: 80; loss: 0.86; acc: 0.7
Batch: 100; loss: 0.61; acc: 0.78
Batch: 120; loss: 0.77; acc: 0.75
Batch: 140; loss: 0.82; acc: 0.77
Batch: 160; loss: 0.47; acc: 0.92
Batch: 180; loss: 0.67; acc: 0.8
Batch: 200; loss: 0.57; acc: 0.8
Batch: 220; loss: 0.52; acc: 0.83
Batch: 240; loss: 0.83; acc: 0.72
Batch: 260; loss: 0.71; acc: 0.81
Batch: 280; loss: 0.67; acc: 0.83
Batch: 300; loss: 0.53; acc: 0.83
Batch: 320; loss: 0.66; acc: 0.78
Batch: 340; loss: 0.49; acc: 0.83
Batch: 360; loss: 0.48; acc: 0.86
Batch: 380; loss: 0.56; acc: 0.84
Batch: 400; loss: 0.65; acc: 0.86
Batch: 420; loss: 0.51; acc: 0.81
Batch: 440; loss: 0.38; acc: 0.88
Batch: 460; loss: 0.6; acc: 0.77
Batch: 480; loss: 0.5; acc: 0.88
Batch: 500; loss: 0.6; acc: 0.8
Batch: 520; loss: 0.35; acc: 0.89
Batch: 540; loss: 0.45; acc: 0.81
Batch: 560; loss: 0.54; acc: 0.84
Batch: 580; loss: 0.54; acc: 0.84
Batch: 600; loss: 0.62; acc: 0.81
Batch: 620; loss: 1.05; acc: 0.73
Batch: 640; loss: 0.43; acc: 0.83
Batch: 660; loss: 0.62; acc: 0.8
Batch: 680; loss: 0.37; acc: 0.86
Batch: 700; loss: 0.44; acc: 0.86
Batch: 720; loss: 0.29; acc: 0.92
Batch: 740; loss: 0.51; acc: 0.88
Batch: 760; loss: 0.48; acc: 0.83
Batch: 780; loss: 0.45; acc: 0.84
Train Epoch over. train_loss: 0.57; train_accuracy: 0.82 

2.303368819411844e-05
7.775218364258762e-06
Batch: 0; loss: 0.71; acc: 0.8
Batch: 20; loss: 0.65; acc: 0.75
Batch: 40; loss: 0.26; acc: 0.91
Batch: 60; loss: 0.54; acc: 0.84
Batch: 80; loss: 0.4; acc: 0.88
Batch: 100; loss: 0.38; acc: 0.86
Batch: 120; loss: 0.6; acc: 0.8
Batch: 140; loss: 0.3; acc: 0.86
Val Epoch over. val_loss: 0.5760553786709051; val_accuracy: 0.8229498407643312 

The current subspace-distance is: 7.775218364258762e-06 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.56; acc: 0.8
Batch: 20; loss: 0.61; acc: 0.8
Batch: 40; loss: 0.38; acc: 0.88
Batch: 60; loss: 0.48; acc: 0.83
Batch: 80; loss: 0.35; acc: 0.91
Batch: 100; loss: 0.41; acc: 0.84
Batch: 120; loss: 0.36; acc: 0.83
Batch: 140; loss: 0.27; acc: 0.94
Batch: 160; loss: 0.39; acc: 0.86
Batch: 180; loss: 0.57; acc: 0.83
Batch: 200; loss: 0.33; acc: 0.89
Batch: 220; loss: 0.79; acc: 0.83
Batch: 240; loss: 0.48; acc: 0.86
Batch: 260; loss: 0.54; acc: 0.8
Batch: 280; loss: 0.58; acc: 0.84
Batch: 300; loss: 0.51; acc: 0.83
Batch: 320; loss: 0.5; acc: 0.88
Batch: 340; loss: 0.37; acc: 0.92
Batch: 360; loss: 0.57; acc: 0.8
Batch: 380; loss: 0.45; acc: 0.86
Batch: 400; loss: 0.34; acc: 0.88
Batch: 420; loss: 0.52; acc: 0.86
Batch: 440; loss: 0.18; acc: 0.92
Batch: 460; loss: 0.32; acc: 0.91
Batch: 480; loss: 0.57; acc: 0.8
Batch: 500; loss: 0.23; acc: 0.92
Batch: 520; loss: 0.41; acc: 0.84
Batch: 540; loss: 0.48; acc: 0.83
Batch: 560; loss: 0.55; acc: 0.83
Batch: 580; loss: 0.34; acc: 0.86
Batch: 600; loss: 0.34; acc: 0.89
Batch: 620; loss: 0.5; acc: 0.89
Batch: 640; loss: 0.46; acc: 0.89
Batch: 660; loss: 0.65; acc: 0.83
Batch: 680; loss: 0.3; acc: 0.91
Batch: 700; loss: 0.22; acc: 0.92
Batch: 720; loss: 0.57; acc: 0.8
Batch: 740; loss: 0.42; acc: 0.89
Batch: 760; loss: 0.34; acc: 0.91
Batch: 780; loss: 0.36; acc: 0.86
Train Epoch over. train_loss: 0.44; train_accuracy: 0.86 

2.4929728169809096e-05
9.346971637569368e-06
Batch: 0; loss: 0.58; acc: 0.83
Batch: 20; loss: 0.49; acc: 0.81
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.58; acc: 0.84
Batch: 80; loss: 0.2; acc: 0.91
Batch: 100; loss: 0.31; acc: 0.94
Batch: 120; loss: 0.54; acc: 0.88
Batch: 140; loss: 0.25; acc: 0.92
Val Epoch over. val_loss: 0.41954549947741687; val_accuracy: 0.8696257961783439 

The current subspace-distance is: 9.346971637569368e-06 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.42; acc: 0.86
Batch: 20; loss: 0.36; acc: 0.91
Batch: 40; loss: 0.57; acc: 0.81
Batch: 60; loss: 0.36; acc: 0.89
Batch: 80; loss: 0.5; acc: 0.84
Batch: 100; loss: 0.25; acc: 0.94
Batch: 120; loss: 0.48; acc: 0.83
Batch: 140; loss: 0.48; acc: 0.83
Batch: 160; loss: 0.35; acc: 0.89
Batch: 180; loss: 0.25; acc: 0.92
Batch: 200; loss: 0.37; acc: 0.86
Batch: 220; loss: 0.38; acc: 0.86
Batch: 240; loss: 0.44; acc: 0.83
Batch: 260; loss: 0.5; acc: 0.81
Batch: 280; loss: 0.31; acc: 0.91
Batch: 300; loss: 0.21; acc: 0.91
Batch: 320; loss: 0.28; acc: 0.95
Batch: 340; loss: 0.31; acc: 0.92
Batch: 360; loss: 0.41; acc: 0.89
Batch: 380; loss: 0.22; acc: 0.94
Batch: 400; loss: 0.51; acc: 0.86
Batch: 420; loss: 0.35; acc: 0.91
Batch: 440; loss: 0.34; acc: 0.91
Batch: 460; loss: 0.35; acc: 0.88
Batch: 480; loss: 0.36; acc: 0.81
Batch: 500; loss: 0.27; acc: 0.91
Batch: 520; loss: 0.35; acc: 0.88
Batch: 540; loss: 0.34; acc: 0.92
Batch: 560; loss: 0.35; acc: 0.91
Batch: 580; loss: 0.45; acc: 0.86
Batch: 600; loss: 0.31; acc: 0.91
Batch: 620; loss: 0.38; acc: 0.84
Batch: 640; loss: 0.34; acc: 0.88
Batch: 660; loss: 0.87; acc: 0.8
Batch: 680; loss: 0.42; acc: 0.86
Batch: 700; loss: 0.45; acc: 0.83
Batch: 720; loss: 0.31; acc: 0.92
Batch: 740; loss: 0.33; acc: 0.89
Batch: 760; loss: 0.2; acc: 0.92
Batch: 780; loss: 0.29; acc: 0.94
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

2.665389547473751e-05
9.53496783040464e-06
Batch: 0; loss: 0.44; acc: 0.89
Batch: 20; loss: 0.47; acc: 0.84
Batch: 40; loss: 0.2; acc: 0.91
Batch: 60; loss: 0.71; acc: 0.81
Batch: 80; loss: 0.19; acc: 0.97
Batch: 100; loss: 0.39; acc: 0.88
Batch: 120; loss: 0.77; acc: 0.77
Batch: 140; loss: 0.28; acc: 0.91
Val Epoch over. val_loss: 0.4197823080192706; val_accuracy: 0.868531050955414 

The current subspace-distance is: 9.53496783040464e-06 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.49; acc: 0.84
Batch: 20; loss: 0.24; acc: 0.91
Batch: 40; loss: 0.6; acc: 0.81
Batch: 60; loss: 0.29; acc: 0.91
Batch: 80; loss: 0.3; acc: 0.91
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.35; acc: 0.89
Batch: 140; loss: 0.58; acc: 0.8
Batch: 160; loss: 0.25; acc: 0.91
Batch: 180; loss: 0.27; acc: 0.89
Batch: 200; loss: 0.41; acc: 0.86
Batch: 220; loss: 0.35; acc: 0.86
Batch: 240; loss: 0.51; acc: 0.89
Batch: 260; loss: 0.43; acc: 0.92
Batch: 280; loss: 0.21; acc: 0.92
Batch: 300; loss: 0.54; acc: 0.86
Batch: 320; loss: 0.37; acc: 0.86
Batch: 340; loss: 0.26; acc: 0.94
Batch: 360; loss: 0.54; acc: 0.86
Batch: 380; loss: 0.64; acc: 0.84
Batch: 400; loss: 0.26; acc: 0.92
Batch: 420; loss: 0.22; acc: 0.92
Batch: 440; loss: 0.26; acc: 0.91
Batch: 460; loss: 0.49; acc: 0.83
Batch: 480; loss: 0.29; acc: 0.91
Batch: 500; loss: 0.42; acc: 0.84
Batch: 520; loss: 0.27; acc: 0.91
Batch: 540; loss: 0.27; acc: 0.91
Batch: 560; loss: 0.36; acc: 0.86
Batch: 580; loss: 0.26; acc: 0.92
Batch: 600; loss: 0.28; acc: 0.92
Batch: 620; loss: 0.31; acc: 0.91
Batch: 640; loss: 0.27; acc: 0.92
Batch: 660; loss: 0.65; acc: 0.86
Batch: 680; loss: 0.17; acc: 0.95
Batch: 700; loss: 0.31; acc: 0.86
Batch: 720; loss: 0.65; acc: 0.8
Batch: 740; loss: 0.25; acc: 0.95
Batch: 760; loss: 0.45; acc: 0.86
Batch: 780; loss: 0.34; acc: 0.97
Train Epoch over. train_loss: 0.35; train_accuracy: 0.89 

2.824471448548138e-05
1.1039518540201243e-05
Batch: 0; loss: 0.31; acc: 0.89
Batch: 20; loss: 0.29; acc: 0.88
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.32; acc: 0.92
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.26; acc: 0.95
Batch: 120; loss: 0.66; acc: 0.77
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.30934893956799414; val_accuracy: 0.9077428343949044 

The current subspace-distance is: 1.1039518540201243e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.44; acc: 0.88
Batch: 20; loss: 0.1; acc: 0.95
Batch: 40; loss: 0.41; acc: 0.83
Batch: 60; loss: 0.28; acc: 0.91
Batch: 80; loss: 0.36; acc: 0.91
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.27; acc: 0.86
Batch: 140; loss: 0.46; acc: 0.88
Batch: 160; loss: 0.46; acc: 0.86
Batch: 180; loss: 0.27; acc: 0.92
Batch: 200; loss: 0.51; acc: 0.91
Batch: 220; loss: 0.34; acc: 0.91
Batch: 240; loss: 0.34; acc: 0.94
Batch: 260; loss: 0.39; acc: 0.86
Batch: 280; loss: 0.22; acc: 0.91
Batch: 300; loss: 0.2; acc: 0.95
Batch: 320; loss: 0.29; acc: 0.88
Batch: 340; loss: 0.24; acc: 0.95
Batch: 360; loss: 0.23; acc: 0.92
Batch: 380; loss: 0.33; acc: 0.92
Batch: 400; loss: 0.33; acc: 0.91
Batch: 420; loss: 0.42; acc: 0.84
Batch: 440; loss: 0.33; acc: 0.89
Batch: 460; loss: 0.21; acc: 0.92
Batch: 480; loss: 0.23; acc: 0.88
Batch: 500; loss: 0.17; acc: 0.95
Batch: 520; loss: 0.26; acc: 0.92
Batch: 540; loss: 0.3; acc: 0.92
Batch: 560; loss: 0.18; acc: 0.94
Batch: 580; loss: 0.17; acc: 0.94
Batch: 600; loss: 0.18; acc: 0.95
Batch: 620; loss: 0.16; acc: 0.94
Batch: 640; loss: 0.49; acc: 0.88
Batch: 660; loss: 0.2; acc: 0.94
Batch: 680; loss: 0.29; acc: 0.92
Batch: 700; loss: 0.32; acc: 0.91
Batch: 720; loss: 0.39; acc: 0.91
Batch: 740; loss: 0.29; acc: 0.89
Batch: 760; loss: 0.26; acc: 0.91
Batch: 780; loss: 0.2; acc: 0.94
Train Epoch over. train_loss: 0.31; train_accuracy: 0.9 

2.903262065956369e-05
1.0068332812807057e-05
Batch: 0; loss: 0.28; acc: 0.88
Batch: 20; loss: 0.41; acc: 0.86
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.53; acc: 0.88
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.28; acc: 0.97
Batch: 120; loss: 0.45; acc: 0.84
Batch: 140; loss: 0.13; acc: 0.98
Val Epoch over. val_loss: 0.33218181085814336; val_accuracy: 0.894406847133758 

The current subspace-distance is: 1.0068332812807057e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.46; acc: 0.88
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.18; acc: 0.97
Batch: 60; loss: 0.23; acc: 0.92
Batch: 80; loss: 0.6; acc: 0.84
Batch: 100; loss: 0.34; acc: 0.89
Batch: 120; loss: 0.25; acc: 0.89
Batch: 140; loss: 0.29; acc: 0.88
Batch: 160; loss: 0.21; acc: 0.92
Batch: 180; loss: 0.12; acc: 0.94
Batch: 200; loss: 0.23; acc: 0.92
Batch: 220; loss: 0.32; acc: 0.89
Batch: 240; loss: 0.2; acc: 0.92
Batch: 260; loss: 0.13; acc: 0.95
Batch: 280; loss: 0.38; acc: 0.91
Batch: 300; loss: 0.33; acc: 0.91
Batch: 320; loss: 0.54; acc: 0.84
Batch: 340; loss: 0.26; acc: 0.91
Batch: 360; loss: 0.09; acc: 0.98
Batch: 380; loss: 0.18; acc: 0.94
Batch: 400; loss: 0.23; acc: 0.95
Batch: 420; loss: 0.26; acc: 0.92
Batch: 440; loss: 0.25; acc: 0.91
Batch: 460; loss: 0.13; acc: 0.97
Batch: 480; loss: 0.15; acc: 0.95
Batch: 500; loss: 0.16; acc: 0.94
Batch: 520; loss: 0.54; acc: 0.89
Batch: 540; loss: 0.22; acc: 0.94
Batch: 560; loss: 0.15; acc: 0.95
Batch: 580; loss: 0.36; acc: 0.91
Batch: 600; loss: 0.38; acc: 0.88
Batch: 620; loss: 0.33; acc: 0.91
Batch: 640; loss: 0.15; acc: 0.94
Batch: 660; loss: 0.26; acc: 0.91
Batch: 680; loss: 0.16; acc: 0.95
Batch: 700; loss: 0.38; acc: 0.88
Batch: 720; loss: 0.12; acc: 0.95
Batch: 740; loss: 0.34; acc: 0.89
Batch: 760; loss: 0.2; acc: 0.92
Batch: 780; loss: 0.23; acc: 0.94
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.866088289010804e-05
1.0468638720340095e-05
Batch: 0; loss: 0.3; acc: 0.89
Batch: 20; loss: 0.29; acc: 0.94
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.45; acc: 0.89
Batch: 80; loss: 0.27; acc: 0.94
Batch: 100; loss: 0.29; acc: 0.95
Batch: 120; loss: 0.51; acc: 0.83
Batch: 140; loss: 0.08; acc: 0.97
Val Epoch over. val_loss: 0.3040563517789932; val_accuracy: 0.9104299363057324 

The current subspace-distance is: 1.0468638720340095e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.51; acc: 0.88
Batch: 20; loss: 0.23; acc: 0.91
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.45; acc: 0.88
Batch: 80; loss: 0.42; acc: 0.86
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.19; acc: 0.94
Batch: 140; loss: 0.36; acc: 0.88
Batch: 160; loss: 0.35; acc: 0.88
Batch: 180; loss: 0.48; acc: 0.84
Batch: 200; loss: 0.23; acc: 0.89
Batch: 220; loss: 0.22; acc: 0.92
Batch: 240; loss: 0.28; acc: 0.91
Batch: 260; loss: 0.22; acc: 0.92
Batch: 280; loss: 0.29; acc: 0.94
Batch: 300; loss: 0.22; acc: 0.94
Batch: 320; loss: 0.31; acc: 0.91
Batch: 340; loss: 0.27; acc: 0.94
Batch: 360; loss: 0.35; acc: 0.94
Batch: 380; loss: 0.24; acc: 0.95
Batch: 400; loss: 0.35; acc: 0.91
Batch: 420; loss: 0.26; acc: 0.89
Batch: 440; loss: 0.28; acc: 0.91
Batch: 460; loss: 0.09; acc: 0.97
Batch: 480; loss: 0.36; acc: 0.86
Batch: 500; loss: 0.34; acc: 0.92
Batch: 520; loss: 0.33; acc: 0.91
Batch: 540; loss: 0.25; acc: 0.91
Batch: 560; loss: 0.19; acc: 0.92
Batch: 580; loss: 0.2; acc: 0.92
Batch: 600; loss: 0.35; acc: 0.88
Batch: 620; loss: 0.37; acc: 0.84
Batch: 640; loss: 0.39; acc: 0.88
Batch: 660; loss: 0.46; acc: 0.89
Batch: 680; loss: 0.32; acc: 0.94
Batch: 700; loss: 0.27; acc: 0.91
Batch: 720; loss: 0.27; acc: 0.88
Batch: 740; loss: 0.17; acc: 0.95
Batch: 760; loss: 0.28; acc: 0.89
Batch: 780; loss: 0.32; acc: 0.92
Train Epoch over. train_loss: 0.28; train_accuracy: 0.92 

2.958968616439961e-05
9.664528079156298e-06
Batch: 0; loss: 0.31; acc: 0.92
Batch: 20; loss: 0.44; acc: 0.89
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.37; acc: 0.91
Batch: 80; loss: 0.11; acc: 0.95
Batch: 100; loss: 0.3; acc: 0.97
Batch: 120; loss: 0.43; acc: 0.84
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.2564345001225259; val_accuracy: 0.923765923566879 

The current subspace-distance is: 9.664528079156298e-06 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.25; acc: 0.89
Batch: 20; loss: 0.18; acc: 0.91
Batch: 40; loss: 0.32; acc: 0.88
Batch: 60; loss: 0.24; acc: 0.89
Batch: 80; loss: 0.14; acc: 0.94
Batch: 100; loss: 0.32; acc: 0.94
Batch: 120; loss: 0.23; acc: 0.92
Batch: 140; loss: 0.58; acc: 0.88
Batch: 160; loss: 0.34; acc: 0.92
Batch: 180; loss: 0.13; acc: 0.97
Batch: 200; loss: 0.26; acc: 0.92
Batch: 220; loss: 0.52; acc: 0.83
Batch: 240; loss: 0.28; acc: 0.94
Batch: 260; loss: 0.28; acc: 0.92
Batch: 280; loss: 0.23; acc: 0.91
Batch: 300; loss: 0.11; acc: 0.97
Batch: 320; loss: 0.49; acc: 0.88
Batch: 340; loss: 0.37; acc: 0.89
Batch: 360; loss: 0.29; acc: 0.91
Batch: 380; loss: 0.18; acc: 0.92
Batch: 400; loss: 0.22; acc: 0.91
Batch: 420; loss: 0.22; acc: 0.91
Batch: 440; loss: 0.25; acc: 0.94
Batch: 460; loss: 0.28; acc: 0.91
Batch: 480; loss: 0.18; acc: 0.97
Batch: 500; loss: 0.31; acc: 0.92
Batch: 520; loss: 0.19; acc: 0.95
Batch: 540; loss: 0.28; acc: 0.98
Batch: 560; loss: 0.37; acc: 0.94
Batch: 580; loss: 0.23; acc: 0.92
Batch: 600; loss: 0.1; acc: 0.97
Batch: 620; loss: 0.39; acc: 0.84
Batch: 640; loss: 0.33; acc: 0.95
Batch: 660; loss: 0.26; acc: 0.91
Batch: 680; loss: 0.13; acc: 0.97
Batch: 700; loss: 0.28; acc: 0.91
Batch: 720; loss: 0.35; acc: 0.91
Batch: 740; loss: 0.33; acc: 0.91
Batch: 760; loss: 0.09; acc: 0.98
Batch: 780; loss: 0.28; acc: 0.92
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

3.057829599129036e-05
1.0991746421495918e-05
Batch: 0; loss: 0.5; acc: 0.81
Batch: 20; loss: 0.38; acc: 0.84
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.51; acc: 0.83
Batch: 80; loss: 0.38; acc: 0.89
Batch: 100; loss: 0.41; acc: 0.88
Batch: 120; loss: 0.64; acc: 0.78
Batch: 140; loss: 0.13; acc: 0.92
Val Epoch over. val_loss: 0.3860464619982774; val_accuracy: 0.8733081210191083 

The current subspace-distance is: 1.0991746421495918e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.33; acc: 0.88
Batch: 20; loss: 0.33; acc: 0.84
Batch: 40; loss: 0.3; acc: 0.92
Batch: 60; loss: 0.17; acc: 0.94
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.22; acc: 0.91
Batch: 140; loss: 0.25; acc: 0.94
Batch: 160; loss: 0.12; acc: 0.97
Batch: 180; loss: 0.29; acc: 0.92
Batch: 200; loss: 0.38; acc: 0.89
Batch: 220; loss: 0.24; acc: 0.94
Batch: 240; loss: 0.25; acc: 0.91
Batch: 260; loss: 0.26; acc: 0.91
Batch: 280; loss: 0.09; acc: 0.98
Batch: 300; loss: 0.14; acc: 0.95
Batch: 320; loss: 0.42; acc: 0.92
Batch: 340; loss: 0.24; acc: 0.95
Batch: 360; loss: 0.32; acc: 0.91
Batch: 380; loss: 0.27; acc: 0.95
Batch: 400; loss: 0.74; acc: 0.88
Batch: 420; loss: 0.1; acc: 0.95
Batch: 440; loss: 0.15; acc: 0.94
Batch: 460; loss: 0.17; acc: 0.92
Batch: 480; loss: 0.26; acc: 0.92
Batch: 500; loss: 0.3; acc: 0.91
Batch: 520; loss: 0.22; acc: 0.92
Batch: 540; loss: 0.39; acc: 0.91
Batch: 560; loss: 0.33; acc: 0.89
Batch: 580; loss: 0.37; acc: 0.91
Batch: 600; loss: 0.33; acc: 0.89
Batch: 620; loss: 0.16; acc: 0.97
Batch: 640; loss: 0.12; acc: 0.98
Batch: 660; loss: 0.29; acc: 0.94
Batch: 680; loss: 0.41; acc: 0.88
Batch: 700; loss: 0.12; acc: 0.97
Batch: 720; loss: 0.21; acc: 0.91
Batch: 740; loss: 0.24; acc: 0.94
Batch: 760; loss: 0.23; acc: 0.89
Batch: 780; loss: 0.23; acc: 0.94
Train Epoch over. train_loss: 0.25; train_accuracy: 0.93 

3.054986154893413e-05
1.144647194450954e-05
Batch: 0; loss: 0.3; acc: 0.88
Batch: 20; loss: 0.35; acc: 0.89
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.26; acc: 0.95
Batch: 80; loss: 0.11; acc: 0.95
Batch: 100; loss: 0.26; acc: 0.94
Batch: 120; loss: 0.5; acc: 0.83
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.23248343055794954; val_accuracy: 0.9313296178343949 

The current subspace-distance is: 1.144647194450954e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.47; acc: 0.88
Batch: 20; loss: 0.25; acc: 0.94
Batch: 40; loss: 0.34; acc: 0.92
Batch: 60; loss: 0.23; acc: 0.92
Batch: 80; loss: 0.26; acc: 0.91
Batch: 100; loss: 0.24; acc: 0.95
Batch: 120; loss: 0.17; acc: 0.92
Batch: 140; loss: 0.25; acc: 0.92
Batch: 160; loss: 0.24; acc: 0.91
Batch: 180; loss: 0.19; acc: 0.95
Batch: 200; loss: 0.2; acc: 0.95
Batch: 220; loss: 0.29; acc: 0.86
Batch: 240; loss: 0.17; acc: 0.94
Batch: 260; loss: 0.17; acc: 0.94
Batch: 280; loss: 0.05; acc: 1.0
Batch: 300; loss: 0.1; acc: 0.95
Batch: 320; loss: 0.32; acc: 0.91
Batch: 340; loss: 0.28; acc: 0.91
Batch: 360; loss: 0.42; acc: 0.89
Batch: 380; loss: 0.3; acc: 0.92
Batch: 400; loss: 0.25; acc: 0.89
Batch: 420; loss: 0.22; acc: 0.91
Batch: 440; loss: 0.37; acc: 0.89
Batch: 460; loss: 0.17; acc: 0.94
Batch: 480; loss: 0.15; acc: 0.95
Batch: 500; loss: 0.45; acc: 0.84
Batch: 520; loss: 0.3; acc: 0.91
Batch: 540; loss: 0.17; acc: 0.94
Batch: 560; loss: 0.23; acc: 0.91
Batch: 580; loss: 0.28; acc: 0.94
Batch: 600; loss: 0.12; acc: 0.98
Batch: 620; loss: 0.28; acc: 0.92
Batch: 640; loss: 0.23; acc: 0.97
Batch: 660; loss: 0.21; acc: 0.91
Batch: 680; loss: 0.36; acc: 0.86
Batch: 700; loss: 0.24; acc: 0.94
Batch: 720; loss: 0.16; acc: 0.95
Batch: 740; loss: 0.43; acc: 0.86
Batch: 760; loss: 0.35; acc: 0.89
Batch: 780; loss: 0.2; acc: 0.91
Train Epoch over. train_loss: 0.25; train_accuracy: 0.93 

2.8459957320592366e-05
1.0910534911090508e-05
Batch: 0; loss: 0.27; acc: 0.92
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.46; acc: 0.88
Batch: 80; loss: 0.22; acc: 0.95
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.42; acc: 0.84
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.2504744009607157; val_accuracy: 0.9262539808917197 

The current subspace-distance is: 1.0910534911090508e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.21; acc: 0.92
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.26; acc: 0.88
Batch: 60; loss: 0.17; acc: 0.95
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.35; acc: 0.92
Batch: 120; loss: 0.3; acc: 0.92
Batch: 140; loss: 0.26; acc: 0.92
Batch: 160; loss: 0.2; acc: 0.92
Batch: 180; loss: 0.17; acc: 0.95
Batch: 200; loss: 0.26; acc: 0.92
Batch: 220; loss: 0.42; acc: 0.92
Batch: 240; loss: 0.14; acc: 0.95
Batch: 260; loss: 0.1; acc: 0.97
Batch: 280; loss: 0.23; acc: 0.94
Batch: 300; loss: 0.34; acc: 0.91
Batch: 320; loss: 0.24; acc: 0.94
Batch: 340; loss: 0.17; acc: 0.91
Batch: 360; loss: 0.17; acc: 0.95
Batch: 380; loss: 0.25; acc: 0.91
Batch: 400; loss: 0.16; acc: 0.95
Batch: 420; loss: 0.14; acc: 0.95
Batch: 440; loss: 0.36; acc: 0.88
Batch: 460; loss: 0.38; acc: 0.94
Batch: 480; loss: 0.09; acc: 0.98
Batch: 500; loss: 0.26; acc: 0.91
Batch: 520; loss: 0.11; acc: 0.97
Batch: 540; loss: 0.19; acc: 0.94
Batch: 560; loss: 0.09; acc: 0.97
Batch: 580; loss: 0.35; acc: 0.88
Batch: 600; loss: 0.25; acc: 0.95
Batch: 620; loss: 0.35; acc: 0.92
Batch: 640; loss: 0.13; acc: 0.95
Batch: 660; loss: 0.31; acc: 0.95
Batch: 680; loss: 0.26; acc: 0.94
Batch: 700; loss: 0.42; acc: 0.88
Batch: 720; loss: 0.21; acc: 0.95
Batch: 740; loss: 0.11; acc: 0.98
Batch: 760; loss: 0.5; acc: 0.86
Batch: 780; loss: 0.38; acc: 0.91
Train Epoch over. train_loss: 0.25; train_accuracy: 0.93 

2.9475415431079455e-05
1.0375683814345393e-05
Batch: 0; loss: 0.22; acc: 0.91
Batch: 20; loss: 0.28; acc: 0.92
Batch: 40; loss: 0.08; acc: 0.95
Batch: 60; loss: 0.28; acc: 0.92
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.97
Batch: 120; loss: 0.49; acc: 0.83
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.21981416780288052; val_accuracy: 0.9377985668789809 

The current subspace-distance is: 1.0375683814345393e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.24; acc: 0.92
Batch: 60; loss: 0.2; acc: 0.94
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.33; acc: 0.94
Batch: 140; loss: 0.27; acc: 0.91
Batch: 160; loss: 0.27; acc: 0.89
Batch: 180; loss: 0.09; acc: 0.97
Batch: 200; loss: 0.11; acc: 0.97
Batch: 220; loss: 0.3; acc: 0.92
Batch: 240; loss: 0.18; acc: 0.94
Batch: 260; loss: 0.17; acc: 0.92
Batch: 280; loss: 0.19; acc: 0.95
Batch: 300; loss: 0.27; acc: 0.91
Batch: 320; loss: 0.16; acc: 0.94
Batch: 340; loss: 0.41; acc: 0.89
Batch: 360; loss: 0.23; acc: 0.92
Batch: 380; loss: 0.17; acc: 0.94
Batch: 400; loss: 0.29; acc: 0.91
Batch: 420; loss: 0.16; acc: 0.91
Batch: 440; loss: 0.27; acc: 0.91
Batch: 460; loss: 0.29; acc: 0.92
Batch: 480; loss: 0.39; acc: 0.84
Batch: 500; loss: 0.34; acc: 0.92
Batch: 520; loss: 0.1; acc: 0.98
Batch: 540; loss: 0.4; acc: 0.92
Batch: 560; loss: 0.5; acc: 0.92
Batch: 580; loss: 0.22; acc: 0.92
Batch: 600; loss: 0.28; acc: 0.92
Batch: 620; loss: 0.48; acc: 0.89
Batch: 640; loss: 0.15; acc: 0.95
Batch: 660; loss: 0.29; acc: 0.92
Batch: 680; loss: 0.46; acc: 0.88
Batch: 700; loss: 0.24; acc: 0.94
Batch: 720; loss: 0.34; acc: 0.89
Batch: 740; loss: 0.09; acc: 0.97
Batch: 760; loss: 0.14; acc: 0.95
Batch: 780; loss: 0.22; acc: 0.94
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

3.020667099917773e-05
1.1232778888370376e-05
Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.28; acc: 0.92
Batch: 40; loss: 0.1; acc: 0.95
Batch: 60; loss: 0.26; acc: 0.94
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.22; acc: 0.97
Batch: 120; loss: 0.46; acc: 0.83
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.2139020888194157; val_accuracy: 0.9365047770700637 

The current subspace-distance is: 1.1232778888370376e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.19; acc: 0.95
Batch: 20; loss: 0.25; acc: 0.94
Batch: 40; loss: 0.29; acc: 0.94
Batch: 60; loss: 0.13; acc: 0.97
Batch: 80; loss: 0.26; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.92
Batch: 120; loss: 0.21; acc: 0.92
Batch: 140; loss: 0.19; acc: 0.91
Batch: 160; loss: 0.15; acc: 0.97
Batch: 180; loss: 0.27; acc: 0.91
Batch: 200; loss: 0.17; acc: 0.95
Batch: 220; loss: 0.21; acc: 0.92
Batch: 240; loss: 0.28; acc: 0.89
Batch: 260; loss: 0.26; acc: 0.92
Batch: 280; loss: 0.09; acc: 0.98
Batch: 300; loss: 0.53; acc: 0.88
Batch: 320; loss: 0.38; acc: 0.92
Batch: 340; loss: 0.31; acc: 0.91
Batch: 360; loss: 0.27; acc: 0.92
Batch: 380; loss: 0.21; acc: 0.91
Batch: 400; loss: 0.13; acc: 0.95
Batch: 420; loss: 0.22; acc: 0.95
Batch: 440; loss: 0.24; acc: 0.94
Batch: 460; loss: 0.37; acc: 0.88
Batch: 480; loss: 0.22; acc: 0.94
Batch: 500; loss: 0.29; acc: 0.91
Batch: 520; loss: 0.31; acc: 0.97
Batch: 540; loss: 0.05; acc: 0.98
Batch: 560; loss: 0.31; acc: 0.88
Batch: 580; loss: 0.3; acc: 0.92
Batch: 600; loss: 0.18; acc: 0.97
Batch: 620; loss: 0.2; acc: 0.92
Batch: 640; loss: 0.2; acc: 0.92
Batch: 660; loss: 0.19; acc: 0.95
Batch: 680; loss: 0.27; acc: 0.89
Batch: 700; loss: 0.26; acc: 0.89
Batch: 720; loss: 0.24; acc: 0.92
Batch: 740; loss: 0.11; acc: 0.98
Batch: 760; loss: 0.4; acc: 0.88
Batch: 780; loss: 0.14; acc: 0.95
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

2.890141877287533e-05
1.0381853826402221e-05
Batch: 0; loss: 0.28; acc: 0.92
Batch: 20; loss: 0.36; acc: 0.89
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.27; acc: 0.94
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.95
Batch: 120; loss: 0.48; acc: 0.8
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.23017607164231074; val_accuracy: 0.9311305732484076 

The current subspace-distance is: 1.0381853826402221e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.37; acc: 0.92
Batch: 20; loss: 0.29; acc: 0.94
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.14; acc: 0.97
Batch: 80; loss: 0.34; acc: 0.95
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.37; acc: 0.88
Batch: 140; loss: 0.09; acc: 0.97
Batch: 160; loss: 0.46; acc: 0.86
Batch: 180; loss: 0.21; acc: 0.94
Batch: 200; loss: 0.2; acc: 0.92
Batch: 220; loss: 0.22; acc: 0.92
Batch: 240; loss: 0.15; acc: 0.95
Batch: 260; loss: 0.16; acc: 0.94
Batch: 280; loss: 0.45; acc: 0.89
Batch: 300; loss: 0.18; acc: 0.94
Batch: 320; loss: 0.31; acc: 0.89
Batch: 340; loss: 0.26; acc: 0.89
Batch: 360; loss: 0.18; acc: 0.92
Batch: 380; loss: 0.28; acc: 0.94
Batch: 400; loss: 0.57; acc: 0.88
Batch: 420; loss: 0.34; acc: 0.95
Batch: 440; loss: 0.15; acc: 0.97
Batch: 460; loss: 0.19; acc: 0.97
Batch: 480; loss: 0.3; acc: 0.88
Batch: 500; loss: 0.47; acc: 0.91
Batch: 520; loss: 0.14; acc: 0.91
Batch: 540; loss: 0.17; acc: 0.92
Batch: 560; loss: 0.22; acc: 0.92
Batch: 580; loss: 0.14; acc: 0.97
Batch: 600; loss: 0.33; acc: 0.89
Batch: 620; loss: 0.14; acc: 0.95
Batch: 640; loss: 0.27; acc: 0.91
Batch: 660; loss: 0.1; acc: 0.98
Batch: 680; loss: 0.1; acc: 0.97
Batch: 700; loss: 0.24; acc: 0.91
Batch: 720; loss: 0.09; acc: 0.97
Batch: 740; loss: 0.13; acc: 0.97
Batch: 760; loss: 0.25; acc: 0.94
Batch: 780; loss: 0.34; acc: 0.94
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

3.0016139135113917e-05
1.0957681297441013e-05
Batch: 0; loss: 0.23; acc: 0.88
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.32; acc: 0.92
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.29; acc: 0.95
Batch: 120; loss: 0.51; acc: 0.8
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.23192528241379246; val_accuracy: 0.9312300955414012 

The current subspace-distance is: 1.0957681297441013e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.32; acc: 0.88
Batch: 40; loss: 0.34; acc: 0.92
Batch: 60; loss: 0.12; acc: 0.98
Batch: 80; loss: 0.19; acc: 0.92
Batch: 100; loss: 0.33; acc: 0.92
Batch: 120; loss: 0.28; acc: 0.94
Batch: 140; loss: 0.14; acc: 0.95
Batch: 160; loss: 0.5; acc: 0.89
Batch: 180; loss: 0.38; acc: 0.86
Batch: 200; loss: 0.33; acc: 0.88
Batch: 220; loss: 0.08; acc: 0.97
Batch: 240; loss: 0.46; acc: 0.84
Batch: 260; loss: 0.37; acc: 0.88
Batch: 280; loss: 0.31; acc: 0.94
Batch: 300; loss: 0.2; acc: 0.94
Batch: 320; loss: 0.23; acc: 0.94
Batch: 340; loss: 0.16; acc: 0.94
Batch: 360; loss: 0.32; acc: 0.88
Batch: 380; loss: 0.46; acc: 0.88
Batch: 400; loss: 0.29; acc: 0.94
Batch: 420; loss: 0.35; acc: 0.89
Batch: 440; loss: 0.21; acc: 0.94
Batch: 460; loss: 0.27; acc: 0.94
Batch: 480; loss: 0.24; acc: 0.94
Batch: 500; loss: 0.11; acc: 0.97
Batch: 520; loss: 0.27; acc: 0.89
Batch: 540; loss: 0.15; acc: 0.95
Batch: 560; loss: 0.46; acc: 0.89
Batch: 580; loss: 0.1; acc: 0.97
Batch: 600; loss: 0.13; acc: 0.94
Batch: 620; loss: 0.24; acc: 0.92
Batch: 640; loss: 0.4; acc: 0.89
Batch: 660; loss: 0.34; acc: 0.94
Batch: 680; loss: 0.31; acc: 0.94
Batch: 700; loss: 0.12; acc: 0.95
Batch: 720; loss: 0.17; acc: 0.94
Batch: 740; loss: 0.31; acc: 0.89
Batch: 760; loss: 0.27; acc: 0.94
Batch: 780; loss: 0.27; acc: 0.89
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

2.9054923288640566e-05
1.0877484783122782e-05
Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.32; acc: 0.92
Batch: 40; loss: 0.08; acc: 0.95
Batch: 60; loss: 0.26; acc: 0.91
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.97
Batch: 120; loss: 0.39; acc: 0.84
Batch: 140; loss: 0.06; acc: 0.97
Val Epoch over. val_loss: 0.2151034687924537; val_accuracy: 0.9371019108280255 

The current subspace-distance is: 1.0877484783122782e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.17; acc: 0.94
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.26; acc: 0.89
Batch: 60; loss: 0.24; acc: 0.92
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.16; acc: 0.94
Batch: 120; loss: 0.15; acc: 0.94
Batch: 140; loss: 0.16; acc: 0.95
Batch: 160; loss: 0.22; acc: 0.92
Batch: 180; loss: 0.28; acc: 0.91
Batch: 200; loss: 0.2; acc: 0.97
Batch: 220; loss: 0.1; acc: 0.98
Batch: 240; loss: 0.16; acc: 0.97
Batch: 260; loss: 0.38; acc: 0.89
Batch: 280; loss: 0.29; acc: 0.94
Batch: 300; loss: 0.31; acc: 0.91
Batch: 320; loss: 0.32; acc: 0.89
Batch: 340; loss: 0.21; acc: 0.92
Batch: 360; loss: 0.09; acc: 0.97
Batch: 380; loss: 0.11; acc: 0.95
Batch: 400; loss: 0.2; acc: 0.94
Batch: 420; loss: 0.19; acc: 0.92
Batch: 440; loss: 0.24; acc: 0.91
Batch: 460; loss: 0.12; acc: 0.95
Batch: 480; loss: 0.12; acc: 0.97
Batch: 500; loss: 0.32; acc: 0.86
Batch: 520; loss: 0.22; acc: 0.94
Batch: 540; loss: 0.2; acc: 0.91
Batch: 560; loss: 0.35; acc: 0.89
Batch: 580; loss: 0.15; acc: 0.97
Batch: 600; loss: 0.32; acc: 0.92
Batch: 620; loss: 0.15; acc: 0.97
Batch: 640; loss: 0.22; acc: 0.97
Batch: 660; loss: 0.14; acc: 0.94
Batch: 680; loss: 0.24; acc: 0.95
Batch: 700; loss: 0.3; acc: 0.94
Batch: 720; loss: 0.23; acc: 0.95
Batch: 740; loss: 0.18; acc: 0.97
Batch: 760; loss: 0.12; acc: 0.95
Batch: 780; loss: 0.28; acc: 0.97
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

3.1173531169770285e-05
1.0214728717983235e-05
Batch: 0; loss: 0.39; acc: 0.88
Batch: 20; loss: 0.41; acc: 0.88
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.28; acc: 0.92
Batch: 80; loss: 0.13; acc: 0.94
Batch: 100; loss: 0.25; acc: 0.95
Batch: 120; loss: 0.39; acc: 0.88
Batch: 140; loss: 0.07; acc: 1.0
Val Epoch over. val_loss: 0.23379762902571138; val_accuracy: 0.9281449044585988 

The current subspace-distance is: 1.0214728717983235e-05 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.42; acc: 0.83
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.16; acc: 0.97
Batch: 60; loss: 0.43; acc: 0.95
Batch: 80; loss: 0.32; acc: 0.91
Batch: 100; loss: 0.41; acc: 0.91
Batch: 120; loss: 0.18; acc: 0.95
Batch: 140; loss: 0.22; acc: 0.91
Batch: 160; loss: 0.22; acc: 0.94
Batch: 180; loss: 0.37; acc: 0.88
Batch: 200; loss: 0.43; acc: 0.86
Batch: 220; loss: 0.34; acc: 0.91
Batch: 240; loss: 0.18; acc: 0.95
Batch: 260; loss: 0.31; acc: 0.89
Batch: 280; loss: 0.4; acc: 0.89
Batch: 300; loss: 0.14; acc: 0.97
Batch: 320; loss: 0.35; acc: 0.84
Batch: 340; loss: 0.28; acc: 0.89
Batch: 360; loss: 0.22; acc: 0.95
Batch: 380; loss: 0.13; acc: 0.97
Batch: 400; loss: 0.27; acc: 0.89
Batch: 420; loss: 0.18; acc: 0.95
Batch: 440; loss: 0.15; acc: 0.95
Batch: 460; loss: 0.09; acc: 0.97
Batch: 480; loss: 0.38; acc: 0.91
Batch: 500; loss: 0.28; acc: 0.94
Batch: 520; loss: 0.45; acc: 0.84
Batch: 540; loss: 0.23; acc: 0.89
Batch: 560; loss: 0.12; acc: 0.97
Batch: 580; loss: 0.22; acc: 0.92
Batch: 600; loss: 0.11; acc: 0.95
Batch: 620; loss: 0.19; acc: 0.95
Batch: 640; loss: 0.16; acc: 0.95
Batch: 660; loss: 0.12; acc: 0.98
Batch: 680; loss: 0.47; acc: 0.89
Batch: 700; loss: 0.18; acc: 0.97
Batch: 720; loss: 0.27; acc: 0.94
Batch: 740; loss: 0.14; acc: 0.95
Batch: 760; loss: 0.16; acc: 0.95
Batch: 780; loss: 0.17; acc: 0.97
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

2.909077375079505e-05
1.0946413567580748e-05
Batch: 0; loss: 0.23; acc: 0.89
Batch: 20; loss: 0.29; acc: 0.89
Batch: 40; loss: 0.1; acc: 0.95
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.95
Batch: 120; loss: 0.49; acc: 0.8
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.22543539818684766; val_accuracy: 0.9344148089171974 

The current subspace-distance is: 1.0946413567580748e-05 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.11; acc: 0.95
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.11; acc: 0.95
Batch: 80; loss: 0.27; acc: 0.89
Batch: 100; loss: 0.18; acc: 0.91
Batch: 120; loss: 0.26; acc: 0.94
Batch: 140; loss: 0.23; acc: 0.94
Batch: 160; loss: 0.19; acc: 0.92
Batch: 180; loss: 0.17; acc: 0.92
Batch: 200; loss: 0.2; acc: 0.92
Batch: 220; loss: 0.35; acc: 0.92
Batch: 240; loss: 0.27; acc: 0.89
Batch: 260; loss: 0.22; acc: 0.95
Batch: 280; loss: 0.16; acc: 0.95
Batch: 300; loss: 0.28; acc: 0.89
Batch: 320; loss: 0.29; acc: 0.92
Batch: 340; loss: 0.11; acc: 0.97
Batch: 360; loss: 0.23; acc: 0.92
Batch: 380; loss: 0.28; acc: 0.92
Batch: 400; loss: 0.2; acc: 0.95
Batch: 420; loss: 0.14; acc: 0.94
Batch: 440; loss: 0.53; acc: 0.91
Batch: 460; loss: 0.18; acc: 0.95
Batch: 480; loss: 0.14; acc: 0.98
Batch: 500; loss: 0.18; acc: 0.92
Batch: 520; loss: 0.2; acc: 0.94
Batch: 540; loss: 0.21; acc: 0.94
Batch: 560; loss: 0.28; acc: 0.92
Batch: 580; loss: 0.15; acc: 0.94
Batch: 600; loss: 0.31; acc: 0.88
Batch: 620; loss: 0.38; acc: 0.89
Batch: 640; loss: 0.27; acc: 0.91
Batch: 660; loss: 0.17; acc: 0.94
Batch: 680; loss: 0.16; acc: 0.94
Batch: 700; loss: 0.23; acc: 0.94
Batch: 720; loss: 0.22; acc: 0.94
Batch: 740; loss: 0.28; acc: 0.88
Batch: 760; loss: 0.28; acc: 0.92
Batch: 780; loss: 0.17; acc: 0.97
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

2.8172584279673174e-05
9.88160627457546e-06
Batch: 0; loss: 0.2; acc: 0.91
Batch: 20; loss: 0.28; acc: 0.92
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.97
Batch: 120; loss: 0.38; acc: 0.88
Batch: 140; loss: 0.06; acc: 0.97
Val Epoch over. val_loss: 0.21519895068779113; val_accuracy: 0.935609076433121 

The current subspace-distance is: 9.88160627457546e-06 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.35; acc: 0.88
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.25; acc: 0.95
Batch: 60; loss: 0.24; acc: 0.92
Batch: 80; loss: 0.32; acc: 0.89
Batch: 100; loss: 0.1; acc: 0.98
Batch: 120; loss: 0.36; acc: 0.88
Batch: 140; loss: 0.31; acc: 0.89
Batch: 160; loss: 0.23; acc: 0.95
Batch: 180; loss: 0.19; acc: 0.97
Batch: 200; loss: 0.18; acc: 0.95
Batch: 220; loss: 0.15; acc: 0.92
Batch: 240; loss: 0.23; acc: 0.91
Batch: 260; loss: 0.39; acc: 0.88
Batch: 280; loss: 0.19; acc: 0.91
Batch: 300; loss: 0.15; acc: 0.95
Batch: 320; loss: 0.25; acc: 0.92
Batch: 340; loss: 0.2; acc: 0.92
Batch: 360; loss: 0.07; acc: 0.98
Batch: 380; loss: 0.23; acc: 0.92
Batch: 400; loss: 0.34; acc: 0.89
Batch: 420; loss: 0.12; acc: 0.97
Batch: 440; loss: 0.21; acc: 0.95
Batch: 460; loss: 0.16; acc: 0.97
Batch: 480; loss: 0.24; acc: 0.91
Batch: 500; loss: 0.44; acc: 0.86
Batch: 520; loss: 0.12; acc: 0.98
Batch: 540; loss: 0.14; acc: 0.94
Batch: 560; loss: 0.23; acc: 0.91
Batch: 580; loss: 0.2; acc: 0.92
Batch: 600; loss: 0.17; acc: 0.92
Batch: 620; loss: 0.28; acc: 0.92
Batch: 640; loss: 0.18; acc: 0.94
Batch: 660; loss: 0.31; acc: 0.92
Batch: 680; loss: 0.19; acc: 0.95
Batch: 700; loss: 0.1; acc: 0.98
Batch: 720; loss: 0.16; acc: 0.97
Batch: 740; loss: 0.17; acc: 0.95
Batch: 760; loss: 0.2; acc: 0.94
Batch: 780; loss: 0.34; acc: 0.88
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.8603579266928136e-05
1.0191320143349003e-05
Batch: 0; loss: 0.28; acc: 0.88
Batch: 20; loss: 0.28; acc: 0.91
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.28; acc: 0.91
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.21; acc: 0.97
Batch: 120; loss: 0.37; acc: 0.88
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.21523637362536352; val_accuracy: 0.9371019108280255 

The current subspace-distance is: 1.0191320143349003e-05 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.07; acc: 0.97
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.08; acc: 0.98
Batch: 80; loss: 0.19; acc: 0.92
Batch: 100; loss: 0.2; acc: 0.91
Batch: 120; loss: 0.29; acc: 0.91
Batch: 140; loss: 0.27; acc: 0.95
Batch: 160; loss: 0.23; acc: 0.95
Batch: 180; loss: 0.13; acc: 0.92
Batch: 200; loss: 0.22; acc: 0.92
Batch: 220; loss: 0.11; acc: 0.94
Batch: 240; loss: 0.07; acc: 1.0
Batch: 260; loss: 0.18; acc: 0.97
Batch: 280; loss: 0.25; acc: 0.95
Batch: 300; loss: 0.26; acc: 0.94
Batch: 320; loss: 0.41; acc: 0.88
Batch: 340; loss: 0.12; acc: 0.95
Batch: 360; loss: 0.15; acc: 0.95
Batch: 380; loss: 0.31; acc: 0.89
Batch: 400; loss: 0.17; acc: 0.97
Batch: 420; loss: 0.16; acc: 0.92
Batch: 440; loss: 0.22; acc: 0.95
Batch: 460; loss: 0.15; acc: 0.97
Batch: 480; loss: 0.13; acc: 0.94
Batch: 500; loss: 0.23; acc: 0.91
Batch: 520; loss: 0.23; acc: 0.95
Batch: 540; loss: 0.3; acc: 0.94
Batch: 560; loss: 0.38; acc: 0.91
Batch: 580; loss: 0.32; acc: 0.95
Batch: 600; loss: 0.24; acc: 0.88
Batch: 620; loss: 0.06; acc: 1.0
Batch: 640; loss: 0.24; acc: 0.92
Batch: 660; loss: 0.22; acc: 0.92
Batch: 680; loss: 0.3; acc: 0.92
Batch: 700; loss: 0.13; acc: 0.97
Batch: 720; loss: 0.24; acc: 0.91
Batch: 740; loss: 0.16; acc: 0.97
Batch: 760; loss: 0.32; acc: 0.89
Batch: 780; loss: 0.15; acc: 0.94
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.9884611649322324e-05
1.021255138766719e-05
Batch: 0; loss: 0.28; acc: 0.89
Batch: 20; loss: 0.3; acc: 0.92
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.26; acc: 0.95
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.22; acc: 0.97
Batch: 120; loss: 0.39; acc: 0.88
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.20803755654650888; val_accuracy: 0.9398885350318471 

The current subspace-distance is: 1.021255138766719e-05 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.37; acc: 0.89
Batch: 40; loss: 0.37; acc: 0.92
Batch: 60; loss: 0.35; acc: 0.91
Batch: 80; loss: 0.29; acc: 0.94
Batch: 100; loss: 0.26; acc: 0.95
Batch: 120; loss: 0.53; acc: 0.88
Batch: 140; loss: 0.15; acc: 0.97
Batch: 160; loss: 0.21; acc: 0.94
Batch: 180; loss: 0.36; acc: 0.91
Batch: 200; loss: 0.32; acc: 0.89
Batch: 220; loss: 0.14; acc: 0.97
Batch: 240; loss: 0.43; acc: 0.91
Batch: 260; loss: 0.17; acc: 0.91
Batch: 280; loss: 0.13; acc: 0.97
Batch: 300; loss: 0.17; acc: 0.94
Batch: 320; loss: 0.36; acc: 0.91
Batch: 340; loss: 0.23; acc: 0.94
Batch: 360; loss: 0.17; acc: 0.92
Batch: 380; loss: 0.17; acc: 0.92
Batch: 400; loss: 0.27; acc: 0.88
Batch: 420; loss: 0.29; acc: 0.89
Batch: 440; loss: 0.57; acc: 0.86
Batch: 460; loss: 0.31; acc: 0.92
Batch: 480; loss: 0.4; acc: 0.91
Batch: 500; loss: 0.32; acc: 0.91
Batch: 520; loss: 0.32; acc: 0.94
Batch: 540; loss: 0.22; acc: 0.95
Batch: 560; loss: 0.25; acc: 0.92
Batch: 580; loss: 0.15; acc: 0.97
Batch: 600; loss: 0.29; acc: 0.91
Batch: 620; loss: 0.39; acc: 0.92
Batch: 640; loss: 0.33; acc: 0.95
Batch: 660; loss: 0.11; acc: 0.95
Batch: 680; loss: 0.15; acc: 0.95
Batch: 700; loss: 0.16; acc: 0.95
Batch: 720; loss: 0.29; acc: 0.91
Batch: 740; loss: 0.11; acc: 0.97
Batch: 760; loss: 0.09; acc: 0.97
Batch: 780; loss: 0.2; acc: 0.95
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.9980255931150168e-05
1.1482931768114213e-05
Batch: 0; loss: 0.26; acc: 0.89
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.29; acc: 0.91
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.21; acc: 0.95
Batch: 120; loss: 0.35; acc: 0.88
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.2116054369101099; val_accuracy: 0.93640525477707 

The current subspace-distance is: 1.1482931768114213e-05 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.21; acc: 0.95
Batch: 20; loss: 0.14; acc: 0.94
Batch: 40; loss: 0.25; acc: 0.89
Batch: 60; loss: 0.46; acc: 0.92
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.13; acc: 0.97
Batch: 140; loss: 0.19; acc: 0.92
Batch: 160; loss: 0.12; acc: 0.95
Batch: 180; loss: 0.13; acc: 0.97
Batch: 200; loss: 0.1; acc: 0.97
Batch: 220; loss: 0.33; acc: 0.89
Batch: 240; loss: 0.24; acc: 0.94
Batch: 260; loss: 0.22; acc: 0.94
Batch: 280; loss: 0.22; acc: 0.92
Batch: 300; loss: 0.13; acc: 0.97
Batch: 320; loss: 0.07; acc: 0.98
Batch: 340; loss: 0.55; acc: 0.86
Batch: 360; loss: 0.27; acc: 0.89
Batch: 380; loss: 0.15; acc: 0.97
Batch: 400; loss: 0.35; acc: 0.92
Batch: 420; loss: 0.42; acc: 0.88
Batch: 440; loss: 0.09; acc: 0.97
Batch: 460; loss: 0.09; acc: 0.98
Batch: 480; loss: 0.3; acc: 0.91
Batch: 500; loss: 0.21; acc: 0.95
Batch: 520; loss: 0.15; acc: 0.94
Batch: 540; loss: 0.23; acc: 0.92
Batch: 560; loss: 0.11; acc: 0.98
Batch: 580; loss: 0.34; acc: 0.91
Batch: 600; loss: 0.27; acc: 0.91
Batch: 620; loss: 0.21; acc: 0.94
Batch: 640; loss: 0.47; acc: 0.84
Batch: 660; loss: 0.21; acc: 0.92
Batch: 680; loss: 0.18; acc: 0.94
Batch: 700; loss: 0.19; acc: 0.97
Batch: 720; loss: 0.11; acc: 0.97
Batch: 740; loss: 0.28; acc: 0.94
Batch: 760; loss: 0.12; acc: 0.95
Batch: 780; loss: 0.33; acc: 0.88
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.918016616604291e-05
1.1128397090942599e-05
Batch: 0; loss: 0.21; acc: 0.89
Batch: 20; loss: 0.27; acc: 0.92
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.26; acc: 0.94
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.97
Batch: 120; loss: 0.38; acc: 0.88
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.20686477213908153; val_accuracy: 0.9407842356687898 

The current subspace-distance is: 1.1128397090942599e-05 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.31; acc: 0.92
Batch: 40; loss: 0.34; acc: 0.94
Batch: 60; loss: 0.28; acc: 0.91
Batch: 80; loss: 0.34; acc: 0.86
Batch: 100; loss: 0.29; acc: 0.89
Batch: 120; loss: 0.17; acc: 0.94
Batch: 140; loss: 0.09; acc: 0.98
Batch: 160; loss: 0.16; acc: 0.94
Batch: 180; loss: 0.11; acc: 0.95
Batch: 200; loss: 0.2; acc: 0.91
Batch: 220; loss: 0.22; acc: 0.95
Batch: 240; loss: 0.21; acc: 0.97
Batch: 260; loss: 0.09; acc: 0.95
Batch: 280; loss: 0.19; acc: 0.92
Batch: 300; loss: 0.24; acc: 0.91
Batch: 320; loss: 0.13; acc: 0.95
Batch: 340; loss: 0.27; acc: 0.91
Batch: 360; loss: 0.29; acc: 0.92
Batch: 380; loss: 0.4; acc: 0.88
Batch: 400; loss: 0.09; acc: 0.97
Batch: 420; loss: 0.23; acc: 0.89
Batch: 440; loss: 0.1; acc: 0.98
Batch: 460; loss: 0.31; acc: 0.91
Batch: 480; loss: 0.3; acc: 0.89
Batch: 500; loss: 0.23; acc: 0.94
Batch: 520; loss: 0.14; acc: 0.94
Batch: 540; loss: 0.32; acc: 0.92
Batch: 560; loss: 0.18; acc: 0.95
Batch: 580; loss: 0.17; acc: 0.92
Batch: 600; loss: 0.22; acc: 0.91
Batch: 620; loss: 0.18; acc: 0.97
Batch: 640; loss: 0.21; acc: 0.97
Batch: 660; loss: 0.37; acc: 0.91
Batch: 680; loss: 0.41; acc: 0.94
Batch: 700; loss: 0.07; acc: 0.98
Batch: 720; loss: 0.12; acc: 0.97
Batch: 740; loss: 0.2; acc: 0.97
Batch: 760; loss: 0.47; acc: 0.86
Batch: 780; loss: 0.16; acc: 0.97
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

3.060404196730815e-05
1.0745428880909458e-05
Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.3; acc: 0.92
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.97
Batch: 120; loss: 0.36; acc: 0.89
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.20507726215632857; val_accuracy: 0.9406847133757962 

The current subspace-distance is: 1.0745428880909458e-05 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.35; acc: 0.91
Batch: 20; loss: 0.2; acc: 0.92
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.15; acc: 0.98
Batch: 80; loss: 0.3; acc: 0.94
Batch: 100; loss: 0.15; acc: 0.94
Batch: 120; loss: 0.19; acc: 0.92
Batch: 140; loss: 0.2; acc: 0.92
Batch: 160; loss: 0.29; acc: 0.88
Batch: 180; loss: 0.25; acc: 0.95
Batch: 200; loss: 0.31; acc: 0.91
Batch: 220; loss: 0.44; acc: 0.83
Batch: 240; loss: 0.21; acc: 0.92
Batch: 260; loss: 0.22; acc: 0.91
Batch: 280; loss: 0.24; acc: 0.97
Batch: 300; loss: 0.34; acc: 0.92
Batch: 320; loss: 0.17; acc: 0.95
Batch: 340; loss: 0.17; acc: 0.94
Batch: 360; loss: 0.21; acc: 0.95
Batch: 380; loss: 0.16; acc: 0.97
Batch: 400; loss: 0.17; acc: 0.92
Batch: 420; loss: 0.2; acc: 0.92
Batch: 440; loss: 0.08; acc: 0.97
Batch: 460; loss: 0.32; acc: 0.92
Batch: 480; loss: 0.27; acc: 0.95
Batch: 500; loss: 0.1; acc: 0.97
Batch: 520; loss: 0.27; acc: 0.94
Batch: 540; loss: 0.18; acc: 0.92
Batch: 560; loss: 0.18; acc: 0.94
Batch: 580; loss: 0.35; acc: 0.91
Batch: 600; loss: 0.24; acc: 0.95
Batch: 620; loss: 0.2; acc: 0.95
Batch: 640; loss: 0.29; acc: 0.94
Batch: 660; loss: 0.26; acc: 0.91
Batch: 680; loss: 0.14; acc: 0.94
Batch: 700; loss: 0.27; acc: 0.91
Batch: 720; loss: 0.15; acc: 0.95
Batch: 740; loss: 0.13; acc: 0.95
Batch: 760; loss: 0.22; acc: 0.94
Batch: 780; loss: 0.08; acc: 0.97
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.949813278974034e-05
9.982531082641799e-06
Batch: 0; loss: 0.22; acc: 0.89
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.07; acc: 0.95
Batch: 60; loss: 0.28; acc: 0.91
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.95
Batch: 120; loss: 0.37; acc: 0.88
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.21058259126107404; val_accuracy: 0.9373009554140127 

The current subspace-distance is: 9.982531082641799e-06 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.31; acc: 0.94
Batch: 20; loss: 0.28; acc: 0.92
Batch: 40; loss: 0.36; acc: 0.92
Batch: 60; loss: 0.7; acc: 0.84
Batch: 80; loss: 0.34; acc: 0.89
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.31; acc: 0.94
Batch: 140; loss: 0.17; acc: 0.95
Batch: 160; loss: 0.37; acc: 0.92
Batch: 180; loss: 0.26; acc: 0.91
Batch: 200; loss: 0.15; acc: 0.95
Batch: 220; loss: 0.19; acc: 0.95
Batch: 240; loss: 0.17; acc: 0.94
Batch: 260; loss: 0.15; acc: 0.94
Batch: 280; loss: 0.27; acc: 0.88
Batch: 300; loss: 0.19; acc: 0.95
Batch: 320; loss: 0.26; acc: 0.91
Batch: 340; loss: 0.14; acc: 0.94
Batch: 360; loss: 0.14; acc: 0.95
Batch: 380; loss: 0.47; acc: 0.89
Batch: 400; loss: 0.09; acc: 0.98
Batch: 420; loss: 0.36; acc: 0.91
Batch: 440; loss: 0.11; acc: 0.95
Batch: 460; loss: 0.2; acc: 0.94
Batch: 480; loss: 0.27; acc: 0.94
Batch: 500; loss: 0.15; acc: 0.97
Batch: 520; loss: 0.16; acc: 0.98
Batch: 540; loss: 0.25; acc: 0.92
Batch: 560; loss: 0.19; acc: 0.94
Batch: 580; loss: 0.22; acc: 0.94
Batch: 600; loss: 0.28; acc: 0.92
Batch: 620; loss: 0.3; acc: 0.91
Batch: 640; loss: 0.17; acc: 0.94
Batch: 660; loss: 0.26; acc: 0.94
Batch: 680; loss: 0.25; acc: 0.95
Batch: 700; loss: 0.31; acc: 0.89
Batch: 720; loss: 0.15; acc: 0.95
Batch: 740; loss: 0.2; acc: 0.94
Batch: 760; loss: 0.32; acc: 0.88
Batch: 780; loss: 0.12; acc: 0.95
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

3.147097959299572e-05
1.0629950338625349e-05
Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.3; acc: 0.92
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.23; acc: 0.95
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.24; acc: 0.97
Batch: 120; loss: 0.41; acc: 0.88
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.21070694724085984; val_accuracy: 0.939390923566879 

The current subspace-distance is: 1.0629950338625349e-05 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.24; acc: 0.95
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.29; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.16; acc: 0.95
Batch: 140; loss: 0.29; acc: 0.94
Batch: 160; loss: 0.31; acc: 0.91
Batch: 180; loss: 0.08; acc: 0.98
Batch: 200; loss: 0.06; acc: 0.98
Batch: 220; loss: 0.15; acc: 0.97
Batch: 240; loss: 0.2; acc: 0.94
Batch: 260; loss: 0.3; acc: 0.91
Batch: 280; loss: 0.12; acc: 0.98
Batch: 300; loss: 0.35; acc: 0.91
Batch: 320; loss: 0.11; acc: 0.97
Batch: 340; loss: 0.12; acc: 0.97
Batch: 360; loss: 0.35; acc: 0.88
Batch: 380; loss: 0.3; acc: 0.94
Batch: 400; loss: 0.25; acc: 0.92
Batch: 420; loss: 0.22; acc: 0.95
Batch: 440; loss: 0.3; acc: 0.92
Batch: 460; loss: 0.36; acc: 0.88
Batch: 480; loss: 0.33; acc: 0.92
Batch: 500; loss: 0.28; acc: 0.94
Batch: 520; loss: 0.14; acc: 0.95
Batch: 540; loss: 0.37; acc: 0.88
Batch: 560; loss: 0.09; acc: 0.97
Batch: 580; loss: 0.19; acc: 0.92
Batch: 600; loss: 0.16; acc: 0.95
Batch: 620; loss: 0.15; acc: 0.95
Batch: 640; loss: 0.04; acc: 1.0
Batch: 660; loss: 0.21; acc: 0.92
Batch: 680; loss: 0.18; acc: 0.94
Batch: 700; loss: 0.21; acc: 0.91
Batch: 720; loss: 0.11; acc: 0.98
Batch: 740; loss: 0.3; acc: 0.94
Batch: 760; loss: 0.27; acc: 0.91
Batch: 780; loss: 0.53; acc: 0.92
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.9317054213606752e-05
1.2192496797069907e-05
Batch: 0; loss: 0.24; acc: 0.89
Batch: 20; loss: 0.3; acc: 0.92
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.27; acc: 0.94
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.97
Batch: 120; loss: 0.36; acc: 0.89
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.20450661991052566; val_accuracy: 0.9411823248407644 

The current subspace-distance is: 1.2192496797069907e-05 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.27; acc: 0.94
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.13; acc: 0.98
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.22; acc: 0.92
Batch: 140; loss: 0.22; acc: 0.92
Batch: 160; loss: 0.08; acc: 0.98
Batch: 180; loss: 0.21; acc: 0.94
Batch: 200; loss: 0.2; acc: 0.95
Batch: 220; loss: 0.24; acc: 0.95
Batch: 240; loss: 0.19; acc: 0.97
Batch: 260; loss: 0.44; acc: 0.84
Batch: 280; loss: 0.32; acc: 0.91
Batch: 300; loss: 0.08; acc: 1.0
Batch: 320; loss: 0.21; acc: 0.97
Batch: 340; loss: 0.16; acc: 0.92
Batch: 360; loss: 0.2; acc: 0.94
Batch: 380; loss: 0.35; acc: 0.91
Batch: 400; loss: 0.21; acc: 0.92
Batch: 420; loss: 0.21; acc: 0.92
Batch: 440; loss: 0.14; acc: 0.98
Batch: 460; loss: 0.21; acc: 0.91
Batch: 480; loss: 0.18; acc: 0.91
Batch: 500; loss: 0.11; acc: 0.95
Batch: 520; loss: 0.15; acc: 0.97
Batch: 540; loss: 0.14; acc: 0.95
Batch: 560; loss: 0.1; acc: 0.98
Batch: 580; loss: 0.16; acc: 0.94
Batch: 600; loss: 0.39; acc: 0.88
Batch: 620; loss: 0.18; acc: 0.92
Batch: 640; loss: 0.18; acc: 0.94
Batch: 660; loss: 0.12; acc: 0.95
Batch: 680; loss: 0.3; acc: 0.91
Batch: 700; loss: 0.15; acc: 0.95
Batch: 720; loss: 0.15; acc: 0.95
Batch: 740; loss: 0.14; acc: 0.95
Batch: 760; loss: 0.1; acc: 0.97
Batch: 780; loss: 0.14; acc: 0.95
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

3.023028330062516e-05
1.0796698916237801e-05
Batch: 0; loss: 0.23; acc: 0.91
Batch: 20; loss: 0.28; acc: 0.92
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.29; acc: 0.91
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.39; acc: 0.88
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.20858969458728838; val_accuracy: 0.9381966560509554 

The current subspace-distance is: 1.0796698916237801e-05 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.23; acc: 0.94
Batch: 20; loss: 0.36; acc: 0.83
Batch: 40; loss: 0.33; acc: 0.95
Batch: 60; loss: 0.3; acc: 0.91
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.18; acc: 0.92
Batch: 120; loss: 0.18; acc: 0.95
Batch: 140; loss: 0.17; acc: 0.95
Batch: 160; loss: 0.37; acc: 0.92
Batch: 180; loss: 0.26; acc: 0.94
Batch: 200; loss: 0.1; acc: 0.98
Batch: 220; loss: 0.36; acc: 0.86
Batch: 240; loss: 0.17; acc: 0.92
Batch: 260; loss: 0.13; acc: 0.97
Batch: 280; loss: 0.14; acc: 0.97
Batch: 300; loss: 0.44; acc: 0.88
Batch: 320; loss: 0.21; acc: 0.92
Batch: 340; loss: 0.12; acc: 0.98
Batch: 360; loss: 0.18; acc: 0.92
Batch: 380; loss: 0.36; acc: 0.88
Batch: 400; loss: 0.18; acc: 0.94
Batch: 420; loss: 0.1; acc: 0.97
Batch: 440; loss: 0.52; acc: 0.91
Batch: 460; loss: 0.21; acc: 0.92
Batch: 480; loss: 0.1; acc: 0.97
Batch: 500; loss: 0.06; acc: 1.0
Batch: 520; loss: 0.18; acc: 0.92
Batch: 540; loss: 0.31; acc: 0.89
Batch: 560; loss: 0.18; acc: 0.94
Batch: 580; loss: 0.3; acc: 0.91
Batch: 600; loss: 0.22; acc: 0.92
Batch: 620; loss: 0.39; acc: 0.88
Batch: 640; loss: 0.4; acc: 0.86
Batch: 660; loss: 0.04; acc: 1.0
Batch: 680; loss: 0.22; acc: 0.97
Batch: 700; loss: 0.19; acc: 0.95
Batch: 720; loss: 0.21; acc: 0.92
Batch: 740; loss: 0.15; acc: 0.94
Batch: 760; loss: 0.15; acc: 0.95
Batch: 780; loss: 0.19; acc: 0.95
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.992121699207928e-05
1.043004886014387e-05
Batch: 0; loss: 0.21; acc: 0.91
Batch: 20; loss: 0.28; acc: 0.92
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.25; acc: 0.95
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.95
Batch: 120; loss: 0.4; acc: 0.89
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.20699321995874878; val_accuracy: 0.9408837579617835 

The current subspace-distance is: 1.043004886014387e-05 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.15; acc: 0.94
Batch: 20; loss: 0.27; acc: 0.92
Batch: 40; loss: 0.17; acc: 0.91
Batch: 60; loss: 0.23; acc: 0.95
Batch: 80; loss: 0.26; acc: 0.95
Batch: 100; loss: 0.07; acc: 1.0
Batch: 120; loss: 0.34; acc: 0.91
Batch: 140; loss: 0.65; acc: 0.83
Batch: 160; loss: 0.27; acc: 0.94
Batch: 180; loss: 0.19; acc: 0.97
Batch: 200; loss: 0.24; acc: 0.95
Batch: 220; loss: 0.25; acc: 0.92
Batch: 240; loss: 0.36; acc: 0.91
Batch: 260; loss: 0.32; acc: 0.95
Batch: 280; loss: 0.24; acc: 0.92
Batch: 300; loss: 0.34; acc: 0.89
Batch: 320; loss: 0.25; acc: 0.89
Batch: 340; loss: 0.14; acc: 0.97
Batch: 360; loss: 0.15; acc: 0.95
Batch: 380; loss: 0.07; acc: 0.98
Batch: 400; loss: 0.13; acc: 0.94
Batch: 420; loss: 0.24; acc: 0.95
Batch: 440; loss: 0.13; acc: 0.95
Batch: 460; loss: 0.33; acc: 0.88
Batch: 480; loss: 0.15; acc: 0.95
Batch: 500; loss: 0.16; acc: 0.94
Batch: 520; loss: 0.22; acc: 0.94
Batch: 540; loss: 0.17; acc: 0.95
Batch: 560; loss: 0.21; acc: 0.92
Batch: 580; loss: 0.16; acc: 0.94
Batch: 600; loss: 0.21; acc: 0.92
Batch: 620; loss: 0.14; acc: 0.97
Batch: 640; loss: 0.14; acc: 0.97
Batch: 660; loss: 0.18; acc: 0.92
Batch: 680; loss: 0.13; acc: 0.97
Batch: 700; loss: 0.2; acc: 0.94
Batch: 720; loss: 0.19; acc: 0.94
Batch: 740; loss: 0.27; acc: 0.88
Batch: 760; loss: 0.41; acc: 0.89
Batch: 780; loss: 0.17; acc: 0.97
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.9500224627554417e-05
1.0998493962688372e-05
Batch: 0; loss: 0.23; acc: 0.91
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.25; acc: 0.95
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.97
Batch: 120; loss: 0.38; acc: 0.88
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.20267153730627838; val_accuracy: 0.9416799363057324 

The current subspace-distance is: 1.0998493962688372e-05 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.14; acc: 0.97
Batch: 40; loss: 0.31; acc: 0.92
Batch: 60; loss: 0.18; acc: 0.95
Batch: 80; loss: 0.44; acc: 0.92
Batch: 100; loss: 0.31; acc: 0.94
Batch: 120; loss: 0.15; acc: 0.97
Batch: 140; loss: 0.6; acc: 0.84
Batch: 160; loss: 0.26; acc: 0.91
Batch: 180; loss: 0.11; acc: 0.98
Batch: 200; loss: 0.21; acc: 0.91
Batch: 220; loss: 0.37; acc: 0.89
Batch: 240; loss: 0.07; acc: 1.0
Batch: 260; loss: 0.21; acc: 0.91
Batch: 280; loss: 0.31; acc: 0.91
Batch: 300; loss: 0.8; acc: 0.88
Batch: 320; loss: 0.16; acc: 0.94
Batch: 340; loss: 0.54; acc: 0.89
Batch: 360; loss: 0.1; acc: 0.98
Batch: 380; loss: 0.15; acc: 0.94
Batch: 400; loss: 0.09; acc: 0.97
Batch: 420; loss: 0.17; acc: 0.97
Batch: 440; loss: 0.26; acc: 0.94
Batch: 460; loss: 0.13; acc: 0.95
Batch: 480; loss: 0.12; acc: 0.97
Batch: 500; loss: 0.36; acc: 0.88
Batch: 520; loss: 0.22; acc: 0.92
Batch: 540; loss: 0.11; acc: 0.98
Batch: 560; loss: 0.2; acc: 0.94
Batch: 580; loss: 0.14; acc: 0.94
Batch: 600; loss: 0.12; acc: 0.95
Batch: 620; loss: 0.22; acc: 0.94
Batch: 640; loss: 0.17; acc: 0.95
Batch: 660; loss: 0.21; acc: 0.94
Batch: 680; loss: 0.29; acc: 0.91
Batch: 700; loss: 0.15; acc: 0.97
Batch: 720; loss: 0.19; acc: 0.97
Batch: 740; loss: 0.26; acc: 0.92
Batch: 760; loss: 0.22; acc: 0.95
Batch: 780; loss: 0.25; acc: 0.95
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.9418612029985525e-05
1.1026877473341301e-05
Batch: 0; loss: 0.24; acc: 0.91
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.95
Batch: 120; loss: 0.36; acc: 0.88
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.20334166781917498; val_accuracy: 0.9409832802547771 

The current subspace-distance is: 1.1026877473341301e-05 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.14; acc: 0.94
Batch: 20; loss: 0.33; acc: 0.91
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.15; acc: 0.95
Batch: 80; loss: 0.23; acc: 0.94
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.25; acc: 0.92
Batch: 140; loss: 0.27; acc: 0.92
Batch: 160; loss: 0.11; acc: 0.97
Batch: 180; loss: 0.22; acc: 0.94
Batch: 200; loss: 0.2; acc: 0.94
Batch: 220; loss: 0.49; acc: 0.92
Batch: 240; loss: 0.55; acc: 0.89
Batch: 260; loss: 0.17; acc: 0.94
Batch: 280; loss: 0.21; acc: 0.92
Batch: 300; loss: 0.2; acc: 0.94
Batch: 320; loss: 0.21; acc: 0.92
Batch: 340; loss: 0.29; acc: 0.91
Batch: 360; loss: 0.11; acc: 0.95
Batch: 380; loss: 0.17; acc: 0.97
Batch: 400; loss: 0.12; acc: 0.94
Batch: 420; loss: 0.2; acc: 0.92
Batch: 440; loss: 0.21; acc: 0.95
Batch: 460; loss: 0.17; acc: 0.91
Batch: 480; loss: 0.27; acc: 0.88
Batch: 500; loss: 0.39; acc: 0.91
Batch: 520; loss: 0.1; acc: 0.98
Batch: 540; loss: 0.32; acc: 0.91
Batch: 560; loss: 0.11; acc: 0.97
Batch: 580; loss: 0.46; acc: 0.89
Batch: 600; loss: 0.22; acc: 0.89
Batch: 620; loss: 0.22; acc: 0.92
Batch: 640; loss: 0.23; acc: 0.95
Batch: 660; loss: 0.26; acc: 0.94
Batch: 680; loss: 0.52; acc: 0.86
Batch: 700; loss: 0.1; acc: 0.95
Batch: 720; loss: 0.19; acc: 0.94
Batch: 740; loss: 0.24; acc: 0.94
Batch: 760; loss: 0.24; acc: 0.91
Batch: 780; loss: 0.18; acc: 0.97
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.9604692826978862e-05
1.1100062693003565e-05
Batch: 0; loss: 0.22; acc: 0.89
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.95
Batch: 120; loss: 0.37; acc: 0.88
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.20161866344464052; val_accuracy: 0.9414808917197452 

The current subspace-distance is: 1.1100062693003565e-05 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.3; acc: 0.88
Batch: 20; loss: 0.37; acc: 0.94
Batch: 40; loss: 0.2; acc: 0.94
Batch: 60; loss: 0.2; acc: 0.91
Batch: 80; loss: 0.27; acc: 0.89
Batch: 100; loss: 0.33; acc: 0.94
Batch: 120; loss: 0.24; acc: 0.89
Batch: 140; loss: 0.29; acc: 0.92
Batch: 160; loss: 0.21; acc: 0.92
Batch: 180; loss: 0.2; acc: 0.94
Batch: 200; loss: 0.34; acc: 0.91
Batch: 220; loss: 0.3; acc: 0.92
Batch: 240; loss: 0.23; acc: 0.92
Batch: 260; loss: 0.3; acc: 0.88
Batch: 280; loss: 0.18; acc: 0.97
Batch: 300; loss: 0.22; acc: 0.92
Batch: 320; loss: 0.3; acc: 0.89
Batch: 340; loss: 0.29; acc: 0.88
Batch: 360; loss: 0.16; acc: 0.92
Batch: 380; loss: 0.07; acc: 0.98
Batch: 400; loss: 0.32; acc: 0.92
Batch: 420; loss: 0.27; acc: 0.92
Batch: 440; loss: 0.2; acc: 0.92
Batch: 460; loss: 0.14; acc: 0.98
Batch: 480; loss: 0.04; acc: 1.0
Batch: 500; loss: 0.21; acc: 0.95
Batch: 520; loss: 0.1; acc: 0.97
Batch: 540; loss: 0.22; acc: 0.95
Batch: 560; loss: 0.15; acc: 0.97
Batch: 580; loss: 0.08; acc: 0.98
Batch: 600; loss: 0.3; acc: 0.92
Batch: 620; loss: 0.3; acc: 0.95
Batch: 640; loss: 0.12; acc: 0.95
Batch: 660; loss: 0.49; acc: 0.89
Batch: 680; loss: 0.2; acc: 0.95
Batch: 700; loss: 0.35; acc: 0.94
Batch: 720; loss: 0.18; acc: 0.94
Batch: 740; loss: 0.19; acc: 0.94
Batch: 760; loss: 0.23; acc: 0.94
Batch: 780; loss: 0.16; acc: 0.94
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.872356890293304e-05
1.088430144591257e-05
Batch: 0; loss: 0.23; acc: 0.91
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.27; acc: 0.94
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.97
Batch: 120; loss: 0.36; acc: 0.88
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.20223431080389934; val_accuracy: 0.942078025477707 

The current subspace-distance is: 1.088430144591257e-05 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.44; acc: 0.91
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.17; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.95
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.29; acc: 0.95
Batch: 120; loss: 0.26; acc: 0.92
Batch: 140; loss: 0.18; acc: 0.94
Batch: 160; loss: 0.3; acc: 0.89
Batch: 180; loss: 0.23; acc: 0.91
Batch: 200; loss: 0.17; acc: 0.95
Batch: 220; loss: 0.3; acc: 0.91
Batch: 240; loss: 0.26; acc: 0.94
Batch: 260; loss: 0.2; acc: 0.92
Batch: 280; loss: 0.35; acc: 0.91
Batch: 300; loss: 0.09; acc: 0.97
Batch: 320; loss: 0.19; acc: 0.94
Batch: 340; loss: 0.17; acc: 0.97
Batch: 360; loss: 0.34; acc: 0.89
Batch: 380; loss: 0.22; acc: 0.95
Batch: 400; loss: 0.49; acc: 0.89
Batch: 420; loss: 0.22; acc: 0.92
Batch: 440; loss: 0.45; acc: 0.94
Batch: 460; loss: 0.22; acc: 0.94
Batch: 480; loss: 0.2; acc: 0.97
Batch: 500; loss: 0.09; acc: 0.97
Batch: 520; loss: 0.24; acc: 0.91
Batch: 540; loss: 0.21; acc: 0.91
Batch: 560; loss: 0.12; acc: 0.95
Batch: 580; loss: 0.41; acc: 0.92
Batch: 600; loss: 0.14; acc: 0.95
Batch: 620; loss: 0.17; acc: 0.94
Batch: 640; loss: 0.31; acc: 0.91
Batch: 660; loss: 0.09; acc: 0.97
Batch: 680; loss: 0.21; acc: 0.92
Batch: 700; loss: 0.12; acc: 0.97
Batch: 720; loss: 0.34; acc: 0.88
Batch: 740; loss: 0.37; acc: 0.91
Batch: 760; loss: 0.23; acc: 0.97
Batch: 780; loss: 0.3; acc: 0.92
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.9872629966121167e-05
1.0673619726730976e-05
Batch: 0; loss: 0.23; acc: 0.89
Batch: 20; loss: 0.28; acc: 0.92
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.3; acc: 0.91
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.97
Batch: 120; loss: 0.34; acc: 0.89
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.20637625664662404; val_accuracy: 0.9379976114649682 

The current subspace-distance is: 1.0673619726730976e-05 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.06; acc: 0.98
Batch: 20; loss: 0.36; acc: 0.89
Batch: 40; loss: 0.25; acc: 0.92
Batch: 60; loss: 0.15; acc: 0.95
Batch: 80; loss: 0.13; acc: 0.94
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.24; acc: 0.94
Batch: 140; loss: 0.15; acc: 0.95
Batch: 160; loss: 0.11; acc: 0.97
Batch: 180; loss: 0.23; acc: 0.94
Batch: 200; loss: 0.19; acc: 0.94
Batch: 220; loss: 0.18; acc: 0.94
Batch: 240; loss: 0.28; acc: 0.91
Batch: 260; loss: 0.13; acc: 0.94
Batch: 280; loss: 0.59; acc: 0.94
Batch: 300; loss: 0.31; acc: 0.89
Batch: 320; loss: 0.28; acc: 0.92
Batch: 340; loss: 0.32; acc: 0.94
Batch: 360; loss: 0.32; acc: 0.86
Batch: 380; loss: 0.26; acc: 0.89
Batch: 400; loss: 0.07; acc: 0.97
Batch: 420; loss: 0.28; acc: 0.92
Batch: 440; loss: 0.23; acc: 0.92
Batch: 460; loss: 0.25; acc: 0.95
Batch: 480; loss: 0.42; acc: 0.88
Batch: 500; loss: 0.34; acc: 0.92
Batch: 520; loss: 0.22; acc: 0.94
Batch: 540; loss: 0.17; acc: 0.98
Batch: 560; loss: 0.22; acc: 0.97
Batch: 580; loss: 0.3; acc: 0.91
Batch: 600; loss: 0.27; acc: 0.94
Batch: 620; loss: 0.31; acc: 0.94
Batch: 640; loss: 0.42; acc: 0.88
Batch: 660; loss: 0.3; acc: 0.91
Batch: 680; loss: 0.11; acc: 0.95
Batch: 700; loss: 0.2; acc: 0.91
Batch: 720; loss: 0.29; acc: 0.88
Batch: 740; loss: 0.3; acc: 0.88
Batch: 760; loss: 0.34; acc: 0.91
Batch: 780; loss: 0.23; acc: 0.91
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.980591125378851e-05
1.1578847079363186e-05
Batch: 0; loss: 0.23; acc: 0.89
Batch: 20; loss: 0.3; acc: 0.92
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.95
Batch: 120; loss: 0.37; acc: 0.88
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.20345902533098392; val_accuracy: 0.9408837579617835 

The current subspace-distance is: 1.1578847079363186e-05 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.3; acc: 0.86
Batch: 20; loss: 0.38; acc: 0.88
Batch: 40; loss: 0.19; acc: 0.91
Batch: 60; loss: 0.31; acc: 0.92
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.15; acc: 0.94
Batch: 120; loss: 0.11; acc: 0.95
Batch: 140; loss: 0.12; acc: 0.95
Batch: 160; loss: 0.24; acc: 0.89
Batch: 180; loss: 0.2; acc: 0.94
Batch: 200; loss: 0.22; acc: 0.91
Batch: 220; loss: 0.21; acc: 0.91
Batch: 240; loss: 0.24; acc: 0.94
Batch: 260; loss: 0.19; acc: 0.92
Batch: 280; loss: 0.09; acc: 0.98
Batch: 300; loss: 0.24; acc: 0.91
Batch: 320; loss: 0.38; acc: 0.97
Batch: 340; loss: 0.48; acc: 0.89
Batch: 360; loss: 0.07; acc: 0.98
Batch: 380; loss: 0.09; acc: 0.97
Batch: 400; loss: 0.19; acc: 0.95
Batch: 420; loss: 0.21; acc: 0.95
Batch: 440; loss: 0.1; acc: 0.97
Batch: 460; loss: 0.23; acc: 0.91
Batch: 480; loss: 0.23; acc: 0.94
Batch: 500; loss: 0.13; acc: 0.95
Batch: 520; loss: 0.16; acc: 0.95
Batch: 540; loss: 0.49; acc: 0.91
Batch: 560; loss: 0.16; acc: 0.94
Batch: 580; loss: 0.31; acc: 0.89
Batch: 600; loss: 0.41; acc: 0.92
Batch: 620; loss: 0.08; acc: 0.98
Batch: 640; loss: 0.37; acc: 0.91
Batch: 660; loss: 0.17; acc: 0.95
Batch: 680; loss: 0.08; acc: 0.97
Batch: 700; loss: 0.24; acc: 0.92
Batch: 720; loss: 0.15; acc: 0.95
Batch: 740; loss: 0.22; acc: 0.95
Batch: 760; loss: 0.32; acc: 0.94
Batch: 780; loss: 0.33; acc: 0.94
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.9335553335840814e-05
1.1029144843632821e-05
Batch: 0; loss: 0.24; acc: 0.91
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.23; acc: 0.97
Batch: 120; loss: 0.36; acc: 0.88
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.20403108541752882; val_accuracy: 0.9413813694267515 

The current subspace-distance is: 1.1029144843632821e-05 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.06; acc: 1.0
Batch: 20; loss: 0.24; acc: 0.94
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.15; acc: 0.94
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.33; acc: 0.94
Batch: 120; loss: 0.29; acc: 0.89
Batch: 140; loss: 0.54; acc: 0.89
Batch: 160; loss: 0.17; acc: 0.92
Batch: 180; loss: 0.05; acc: 1.0
Batch: 200; loss: 0.14; acc: 0.95
Batch: 220; loss: 0.37; acc: 0.89
Batch: 240; loss: 0.37; acc: 0.88
Batch: 260; loss: 0.14; acc: 0.95
Batch: 280; loss: 0.26; acc: 0.92
Batch: 300; loss: 0.21; acc: 0.95
Batch: 320; loss: 0.2; acc: 0.95
Batch: 340; loss: 0.16; acc: 0.94
Batch: 360; loss: 0.32; acc: 0.91
Batch: 380; loss: 0.25; acc: 0.92
Batch: 400; loss: 0.11; acc: 0.95
Batch: 420; loss: 0.31; acc: 0.92
Batch: 440; loss: 0.19; acc: 0.94
Batch: 460; loss: 0.18; acc: 0.91
Batch: 480; loss: 0.3; acc: 0.86
Batch: 500; loss: 0.14; acc: 0.97
Batch: 520; loss: 0.28; acc: 0.91
Batch: 540; loss: 0.23; acc: 0.97
Batch: 560; loss: 0.18; acc: 0.94
Batch: 580; loss: 0.07; acc: 0.98
Batch: 600; loss: 0.28; acc: 0.88
Batch: 620; loss: 0.1; acc: 0.98
Batch: 640; loss: 0.15; acc: 0.97
Batch: 660; loss: 0.18; acc: 0.92
Batch: 680; loss: 0.24; acc: 0.95
Batch: 700; loss: 0.39; acc: 0.88
Batch: 720; loss: 0.11; acc: 0.95
Batch: 740; loss: 0.31; acc: 0.94
Batch: 760; loss: 0.26; acc: 0.94
Batch: 780; loss: 0.12; acc: 0.97
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.9771266781608574e-05
1.1535037629073486e-05
Batch: 0; loss: 0.21; acc: 0.91
Batch: 20; loss: 0.3; acc: 0.92
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.21; acc: 0.95
Batch: 120; loss: 0.37; acc: 0.88
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.20316311327894782; val_accuracy: 0.9425756369426752 

The current subspace-distance is: 1.1535037629073486e-05 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.34; acc: 0.94
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.14; acc: 0.95
Batch: 80; loss: 0.66; acc: 0.89
Batch: 100; loss: 0.19; acc: 0.97
Batch: 120; loss: 0.29; acc: 0.88
Batch: 140; loss: 0.18; acc: 0.94
Batch: 160; loss: 0.17; acc: 0.94
Batch: 180; loss: 0.15; acc: 0.94
Batch: 200; loss: 0.21; acc: 0.92
Batch: 220; loss: 0.37; acc: 0.89
Batch: 240; loss: 0.27; acc: 0.92
Batch: 260; loss: 0.24; acc: 0.94
Batch: 280; loss: 0.2; acc: 0.94
Batch: 300; loss: 0.39; acc: 0.88
Batch: 320; loss: 0.41; acc: 0.91
Batch: 340; loss: 0.24; acc: 0.94
Batch: 360; loss: 0.1; acc: 0.95
Batch: 380; loss: 0.09; acc: 0.95
Batch: 400; loss: 0.18; acc: 0.98
Batch: 420; loss: 0.28; acc: 0.88
Batch: 440; loss: 0.1; acc: 0.95
Batch: 460; loss: 0.22; acc: 0.94
Batch: 480; loss: 0.17; acc: 0.91
Batch: 500; loss: 0.15; acc: 0.97
Batch: 520; loss: 0.33; acc: 0.92
Batch: 540; loss: 0.21; acc: 0.91
Batch: 560; loss: 0.26; acc: 0.88
Batch: 580; loss: 0.48; acc: 0.84
Batch: 600; loss: 0.2; acc: 0.95
Batch: 620; loss: 0.22; acc: 0.92
Batch: 640; loss: 0.15; acc: 0.97
Batch: 660; loss: 0.12; acc: 0.97
Batch: 680; loss: 0.07; acc: 0.97
Batch: 700; loss: 0.25; acc: 0.92
Batch: 720; loss: 0.34; acc: 0.91
Batch: 740; loss: 0.39; acc: 0.91
Batch: 760; loss: 0.34; acc: 0.91
Batch: 780; loss: 0.14; acc: 0.95
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.9583374271169305e-05
1.0590834790491499e-05
Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.26; acc: 0.95
Batch: 80; loss: 0.13; acc: 0.94
Batch: 100; loss: 0.23; acc: 0.95
Batch: 120; loss: 0.38; acc: 0.89
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.20549924187599475; val_accuracy: 0.940187101910828 

The current subspace-distance is: 1.0590834790491499e-05 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.26; acc: 0.92
Batch: 20; loss: 0.15; acc: 0.94
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.15; acc: 0.91
Batch: 120; loss: 0.12; acc: 0.98
Batch: 140; loss: 0.15; acc: 0.98
Batch: 160; loss: 0.21; acc: 0.92
Batch: 180; loss: 0.22; acc: 0.94
Batch: 200; loss: 0.18; acc: 0.94
Batch: 220; loss: 0.2; acc: 0.92
Batch: 240; loss: 0.12; acc: 0.97
Batch: 260; loss: 0.22; acc: 0.95
Batch: 280; loss: 0.26; acc: 0.89
Batch: 300; loss: 0.41; acc: 0.92
Batch: 320; loss: 0.2; acc: 0.95
Batch: 340; loss: 0.24; acc: 0.91
Batch: 360; loss: 0.18; acc: 0.94
Batch: 380; loss: 0.17; acc: 0.94
Batch: 400; loss: 0.09; acc: 0.98
Batch: 420; loss: 0.08; acc: 0.97
Batch: 440; loss: 0.29; acc: 0.92
Batch: 460; loss: 0.22; acc: 0.95
Batch: 480; loss: 0.1; acc: 0.97
Batch: 500; loss: 0.21; acc: 0.92
Batch: 520; loss: 0.1; acc: 0.97
Batch: 540; loss: 0.25; acc: 0.92
Batch: 560; loss: 0.08; acc: 0.97
Batch: 580; loss: 0.23; acc: 0.94
Batch: 600; loss: 0.16; acc: 0.92
Batch: 620; loss: 0.14; acc: 0.97
Batch: 640; loss: 0.39; acc: 0.88
Batch: 660; loss: 0.21; acc: 0.92
Batch: 680; loss: 0.39; acc: 0.88
Batch: 700; loss: 0.15; acc: 0.95
Batch: 720; loss: 0.21; acc: 0.97
Batch: 740; loss: 0.31; acc: 0.91
Batch: 760; loss: 0.09; acc: 0.97
Batch: 780; loss: 0.21; acc: 0.95
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

3.1024897907627746e-05
1.1651757631625514e-05
Batch: 0; loss: 0.24; acc: 0.91
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.27; acc: 0.94
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.95
Batch: 120; loss: 0.36; acc: 0.89
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.2022675391120516; val_accuracy: 0.9418789808917197 

The current subspace-distance is: 1.1651757631625514e-05 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.21; acc: 0.95
Batch: 20; loss: 0.38; acc: 0.91
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.23; acc: 0.91
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.37; acc: 0.91
Batch: 120; loss: 0.26; acc: 0.91
Batch: 140; loss: 0.46; acc: 0.91
Batch: 160; loss: 0.15; acc: 0.95
Batch: 180; loss: 0.23; acc: 0.92
Batch: 200; loss: 0.24; acc: 0.92
Batch: 220; loss: 0.23; acc: 0.95
Batch: 240; loss: 0.2; acc: 0.92
Batch: 260; loss: 0.18; acc: 0.95
Batch: 280; loss: 0.56; acc: 0.94
Batch: 300; loss: 0.06; acc: 0.98
Batch: 320; loss: 0.16; acc: 0.95
Batch: 340; loss: 0.14; acc: 0.95
Batch: 360; loss: 0.54; acc: 0.94
Batch: 380; loss: 0.27; acc: 0.88
Batch: 400; loss: 0.25; acc: 0.92
Batch: 420; loss: 0.19; acc: 0.91
Batch: 440; loss: 0.09; acc: 0.97
Batch: 460; loss: 0.29; acc: 0.92
Batch: 480; loss: 0.1; acc: 0.95
Batch: 500; loss: 0.1; acc: 0.97
Batch: 520; loss: 0.2; acc: 0.95
Batch: 540; loss: 0.15; acc: 0.95
Batch: 560; loss: 0.27; acc: 0.94
Batch: 580; loss: 0.27; acc: 0.94
Batch: 600; loss: 0.16; acc: 0.95
Batch: 620; loss: 0.06; acc: 1.0
Batch: 640; loss: 0.21; acc: 0.95
Batch: 660; loss: 0.15; acc: 0.97
Batch: 680; loss: 0.14; acc: 0.94
Batch: 700; loss: 0.37; acc: 0.89
Batch: 720; loss: 0.24; acc: 0.94
Batch: 740; loss: 0.12; acc: 0.97
Batch: 760; loss: 0.12; acc: 0.95
Batch: 780; loss: 0.12; acc: 0.94
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.8523274522740394e-05
1.0229227882518899e-05
Batch: 0; loss: 0.21; acc: 0.91
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.25; acc: 0.95
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.95
Batch: 120; loss: 0.38; acc: 0.89
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.2010995216050725; val_accuracy: 0.9425756369426752 

The current subspace-distance is: 1.0229227882518899e-05 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.32; acc: 0.89
Batch: 20; loss: 0.27; acc: 0.92
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.27; acc: 0.94
Batch: 80; loss: 0.36; acc: 0.83
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.45; acc: 0.83
Batch: 140; loss: 0.26; acc: 0.95
Batch: 160; loss: 0.37; acc: 0.92
Batch: 180; loss: 0.17; acc: 0.95
Batch: 200; loss: 0.5; acc: 0.94
Batch: 220; loss: 0.16; acc: 0.95
Batch: 240; loss: 0.19; acc: 0.94
Batch: 260; loss: 0.17; acc: 0.95
Batch: 280; loss: 0.15; acc: 0.95
Batch: 300; loss: 0.21; acc: 0.95
Batch: 320; loss: 0.41; acc: 0.92
Batch: 340; loss: 0.14; acc: 0.95
Batch: 360; loss: 0.26; acc: 0.92
Batch: 380; loss: 0.08; acc: 0.97
Batch: 400; loss: 0.19; acc: 0.91
Batch: 420; loss: 0.13; acc: 0.97
Batch: 440; loss: 0.25; acc: 0.92
Batch: 460; loss: 0.14; acc: 0.95
Batch: 480; loss: 0.14; acc: 0.94
Batch: 500; loss: 0.3; acc: 0.92
Batch: 520; loss: 0.21; acc: 0.92
Batch: 540; loss: 0.17; acc: 0.94
Batch: 560; loss: 0.14; acc: 0.97
Batch: 580; loss: 0.18; acc: 0.91
Batch: 600; loss: 0.29; acc: 0.91
Batch: 620; loss: 0.2; acc: 0.92
Batch: 640; loss: 0.15; acc: 0.95
Batch: 660; loss: 0.52; acc: 0.86
Batch: 680; loss: 0.2; acc: 0.92
Batch: 700; loss: 0.26; acc: 0.95
Batch: 720; loss: 0.36; acc: 0.92
Batch: 740; loss: 0.19; acc: 0.92
Batch: 760; loss: 0.14; acc: 0.95
Batch: 780; loss: 0.38; acc: 0.88
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.9024138711974956e-05
1.0919090527750086e-05
Batch: 0; loss: 0.23; acc: 0.91
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.26; acc: 0.95
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.97
Batch: 120; loss: 0.37; acc: 0.89
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.20109593963167469; val_accuracy: 0.9415804140127388 

The current subspace-distance is: 1.0919090527750086e-05 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.29; acc: 0.94
Batch: 20; loss: 0.53; acc: 0.95
Batch: 40; loss: 0.34; acc: 0.92
Batch: 60; loss: 0.15; acc: 0.95
Batch: 80; loss: 0.1; acc: 0.98
Batch: 100; loss: 0.12; acc: 0.94
Batch: 120; loss: 0.21; acc: 0.94
Batch: 140; loss: 0.18; acc: 0.91
Batch: 160; loss: 0.15; acc: 0.95
Batch: 180; loss: 0.36; acc: 0.89
Batch: 200; loss: 0.11; acc: 0.98
Batch: 220; loss: 0.28; acc: 0.88
Batch: 240; loss: 0.33; acc: 0.89
Batch: 260; loss: 0.2; acc: 0.98
Batch: 280; loss: 0.19; acc: 0.94
Batch: 300; loss: 0.29; acc: 0.88
Batch: 320; loss: 0.19; acc: 0.94
Batch: 340; loss: 0.18; acc: 0.95
Batch: 360; loss: 0.17; acc: 0.95
Batch: 380; loss: 0.21; acc: 0.92
Batch: 400; loss: 0.13; acc: 0.97
Batch: 420; loss: 0.24; acc: 0.94
Batch: 440; loss: 0.09; acc: 0.95
Batch: 460; loss: 0.32; acc: 0.91
Batch: 480; loss: 0.2; acc: 0.95
Batch: 500; loss: 0.18; acc: 0.97
Batch: 520; loss: 0.39; acc: 0.92
Batch: 540; loss: 0.23; acc: 0.91
Batch: 560; loss: 0.13; acc: 0.97
Batch: 580; loss: 0.46; acc: 0.88
Batch: 600; loss: 0.26; acc: 0.89
Batch: 620; loss: 0.18; acc: 0.92
Batch: 640; loss: 0.06; acc: 0.98
Batch: 660; loss: 0.12; acc: 0.94
Batch: 680; loss: 0.26; acc: 0.88
Batch: 700; loss: 0.1; acc: 0.97
Batch: 720; loss: 0.28; acc: 0.94
Batch: 740; loss: 0.16; acc: 0.94
Batch: 760; loss: 0.22; acc: 0.94
Batch: 780; loss: 0.13; acc: 0.98
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.899197170336265e-05
1.1007494322257116e-05
Batch: 0; loss: 0.22; acc: 0.91
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.26; acc: 0.95
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.37; acc: 0.88
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.20069144856018625; val_accuracy: 0.9424761146496815 

The current subspace-distance is: 1.1007494322257116e-05 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.15; acc: 0.94
Batch: 20; loss: 0.36; acc: 0.94
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.54; acc: 0.91
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.35; acc: 0.89
Batch: 120; loss: 0.45; acc: 0.92
Batch: 140; loss: 0.3; acc: 0.92
Batch: 160; loss: 0.23; acc: 0.95
Batch: 180; loss: 0.29; acc: 0.89
Batch: 200; loss: 0.2; acc: 0.92
Batch: 220; loss: 0.11; acc: 0.95
Batch: 240; loss: 0.33; acc: 0.86
Batch: 260; loss: 0.16; acc: 0.94
Batch: 280; loss: 0.4; acc: 0.92
Batch: 300; loss: 0.23; acc: 0.92
Batch: 320; loss: 0.22; acc: 0.94
Batch: 340; loss: 0.26; acc: 0.95
Batch: 360; loss: 0.21; acc: 0.94
Batch: 380; loss: 0.31; acc: 0.91
Batch: 400; loss: 0.35; acc: 0.89
Batch: 420; loss: 0.19; acc: 0.95
Batch: 440; loss: 0.35; acc: 0.94
Batch: 460; loss: 0.15; acc: 0.98
Batch: 480; loss: 0.48; acc: 0.89
Batch: 500; loss: 0.64; acc: 0.91
Batch: 520; loss: 0.35; acc: 0.88
Batch: 540; loss: 0.21; acc: 0.91
Batch: 560; loss: 0.16; acc: 0.95
Batch: 580; loss: 0.44; acc: 0.88
Batch: 600; loss: 0.15; acc: 0.95
Batch: 620; loss: 0.29; acc: 0.91
Batch: 640; loss: 0.28; acc: 0.91
Batch: 660; loss: 0.25; acc: 0.94
Batch: 680; loss: 0.21; acc: 0.95
Batch: 700; loss: 0.22; acc: 0.91
Batch: 720; loss: 0.21; acc: 0.94
Batch: 740; loss: 0.35; acc: 0.84
Batch: 760; loss: 0.18; acc: 0.95
Batch: 780; loss: 0.09; acc: 0.98
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

3.1269599276129156e-05
1.1025729691027664e-05
Batch: 0; loss: 0.22; acc: 0.91
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.26; acc: 0.95
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.95
Batch: 120; loss: 0.37; acc: 0.88
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.20082990122828515; val_accuracy: 0.9423765923566879 

The current subspace-distance is: 1.1025729691027664e-05 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.14; acc: 0.98
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.4; acc: 0.92
Batch: 80; loss: 0.11; acc: 0.98
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.19; acc: 0.92
Batch: 140; loss: 0.12; acc: 0.97
Batch: 160; loss: 0.17; acc: 0.94
Batch: 180; loss: 0.06; acc: 1.0
Batch: 200; loss: 0.17; acc: 0.95
Batch: 220; loss: 0.07; acc: 1.0
Batch: 240; loss: 0.48; acc: 0.84
Batch: 260; loss: 0.44; acc: 0.94
Batch: 280; loss: 0.51; acc: 0.86
Batch: 300; loss: 0.15; acc: 0.95
Batch: 320; loss: 0.21; acc: 0.91
Batch: 340; loss: 0.13; acc: 0.95
Batch: 360; loss: 0.2; acc: 0.92
Batch: 380; loss: 0.1; acc: 0.98
Batch: 400; loss: 0.06; acc: 0.98
Batch: 420; loss: 0.22; acc: 0.95
Batch: 440; loss: 0.26; acc: 0.91
Batch: 460; loss: 0.11; acc: 0.95
Batch: 480; loss: 0.23; acc: 0.94
Batch: 500; loss: 0.08; acc: 0.98
Batch: 520; loss: 0.12; acc: 0.97
Batch: 540; loss: 0.24; acc: 0.95
Batch: 560; loss: 0.05; acc: 1.0
Batch: 580; loss: 0.19; acc: 0.89
Batch: 600; loss: 0.21; acc: 0.97
Batch: 620; loss: 0.27; acc: 0.94
Batch: 640; loss: 0.19; acc: 0.94
Batch: 660; loss: 0.17; acc: 0.92
Batch: 680; loss: 0.29; acc: 0.95
Batch: 700; loss: 0.28; acc: 0.95
Batch: 720; loss: 0.32; acc: 0.92
Batch: 740; loss: 0.2; acc: 0.92
Batch: 760; loss: 0.25; acc: 0.89
Batch: 780; loss: 0.16; acc: 0.95
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.899093487940263e-05
1.0130453119927552e-05
Batch: 0; loss: 0.22; acc: 0.89
Batch: 20; loss: 0.28; acc: 0.92
Batch: 40; loss: 0.07; acc: 1.0
Batch: 60; loss: 0.25; acc: 0.95
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.38; acc: 0.88
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.20198799052815528; val_accuracy: 0.9426751592356688 

The current subspace-distance is: 1.0130453119927552e-05 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.15; acc: 0.94
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.25; acc: 0.89
Batch: 80; loss: 0.31; acc: 0.94
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.49; acc: 0.89
Batch: 140; loss: 0.22; acc: 0.94
Batch: 160; loss: 0.23; acc: 0.92
Batch: 180; loss: 0.09; acc: 0.98
Batch: 200; loss: 0.3; acc: 0.91
Batch: 220; loss: 0.37; acc: 0.95
Batch: 240; loss: 0.12; acc: 0.97
Batch: 260; loss: 0.14; acc: 0.94
Batch: 280; loss: 0.35; acc: 0.94
Batch: 300; loss: 0.32; acc: 0.89
Batch: 320; loss: 0.56; acc: 0.91
Batch: 340; loss: 0.15; acc: 0.94
Batch: 360; loss: 0.42; acc: 0.92
Batch: 380; loss: 0.33; acc: 0.89
Batch: 400; loss: 0.16; acc: 0.94
Batch: 420; loss: 0.32; acc: 0.91
Batch: 440; loss: 0.2; acc: 0.95
Batch: 460; loss: 0.24; acc: 0.95
Batch: 480; loss: 0.23; acc: 0.95
Batch: 500; loss: 0.18; acc: 0.95
Batch: 520; loss: 0.26; acc: 0.94
Batch: 540; loss: 0.56; acc: 0.89
Batch: 560; loss: 0.32; acc: 0.91
Batch: 580; loss: 0.19; acc: 0.94
Batch: 600; loss: 0.1; acc: 0.98
Batch: 620; loss: 0.53; acc: 0.92
Batch: 640; loss: 0.19; acc: 0.95
Batch: 660; loss: 0.34; acc: 0.91
Batch: 680; loss: 0.12; acc: 0.95
Batch: 700; loss: 0.3; acc: 0.92
Batch: 720; loss: 0.27; acc: 0.92
Batch: 740; loss: 0.12; acc: 0.95
Batch: 760; loss: 0.28; acc: 0.91
Batch: 780; loss: 0.18; acc: 0.97
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.9037142667220905e-05
1.0623230082273949e-05
Batch: 0; loss: 0.22; acc: 0.91
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.25; acc: 0.95
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.37; acc: 0.89
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.20215324041949714; val_accuracy: 0.9419785031847133 

The current subspace-distance is: 1.0623230082273949e-05 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.27; acc: 0.92
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.18; acc: 0.95
Batch: 80; loss: 0.36; acc: 0.92
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.11; acc: 0.97
Batch: 140; loss: 0.29; acc: 0.94
Batch: 160; loss: 0.21; acc: 0.95
Batch: 180; loss: 0.3; acc: 0.92
Batch: 200; loss: 0.21; acc: 0.95
Batch: 220; loss: 0.23; acc: 0.95
Batch: 240; loss: 0.04; acc: 0.98
Batch: 260; loss: 0.29; acc: 0.91
Batch: 280; loss: 0.08; acc: 0.98
Batch: 300; loss: 0.1; acc: 0.98
Batch: 320; loss: 0.24; acc: 0.91
Batch: 340; loss: 0.17; acc: 0.92
Batch: 360; loss: 0.22; acc: 0.94
Batch: 380; loss: 0.17; acc: 0.95
Batch: 400; loss: 0.12; acc: 0.95
Batch: 420; loss: 0.43; acc: 0.92
Batch: 440; loss: 0.1; acc: 0.98
Batch: 460; loss: 0.14; acc: 0.94
Batch: 480; loss: 0.11; acc: 0.98
Batch: 500; loss: 0.11; acc: 0.95
Batch: 520; loss: 0.16; acc: 0.94
Batch: 540; loss: 0.25; acc: 0.88
Batch: 560; loss: 0.13; acc: 0.95
Batch: 580; loss: 0.17; acc: 0.97
Batch: 600; loss: 0.21; acc: 0.94
Batch: 620; loss: 0.23; acc: 0.91
Batch: 640; loss: 0.16; acc: 0.94
Batch: 660; loss: 0.19; acc: 0.92
Batch: 680; loss: 0.39; acc: 0.88
Batch: 700; loss: 0.27; acc: 0.92
Batch: 720; loss: 0.15; acc: 0.92
Batch: 740; loss: 0.23; acc: 0.91
Batch: 760; loss: 0.19; acc: 0.98
Batch: 780; loss: 0.23; acc: 0.94
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.9429027563310228e-05
1.0069054951600265e-05
Batch: 0; loss: 0.22; acc: 0.91
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.26; acc: 0.94
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.95
Batch: 120; loss: 0.37; acc: 0.88
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.20114490930821485; val_accuracy: 0.9425756369426752 

The current subspace-distance is: 1.0069054951600265e-05 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.16; acc: 0.97
Batch: 20; loss: 0.19; acc: 0.92
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.31; acc: 0.91
Batch: 80; loss: 0.39; acc: 0.91
Batch: 100; loss: 0.22; acc: 0.95
Batch: 120; loss: 0.15; acc: 0.95
Batch: 140; loss: 0.26; acc: 0.92
Batch: 160; loss: 0.21; acc: 0.92
Batch: 180; loss: 0.28; acc: 0.94
Batch: 200; loss: 0.34; acc: 0.92
Batch: 220; loss: 0.14; acc: 0.94
Batch: 240; loss: 0.12; acc: 0.97
Batch: 260; loss: 0.3; acc: 0.91
Batch: 280; loss: 0.3; acc: 0.95
Batch: 300; loss: 0.11; acc: 0.97
Batch: 320; loss: 0.18; acc: 0.95
Batch: 340; loss: 0.11; acc: 0.98
Batch: 360; loss: 0.18; acc: 0.94
Batch: 380; loss: 0.2; acc: 0.92
Batch: 400; loss: 0.21; acc: 0.92
Batch: 420; loss: 0.29; acc: 0.92
Batch: 440; loss: 0.15; acc: 0.97
Batch: 460; loss: 0.25; acc: 0.94
Batch: 480; loss: 0.28; acc: 0.97
Batch: 500; loss: 0.35; acc: 0.88
Batch: 520; loss: 0.15; acc: 0.95
Batch: 540; loss: 0.38; acc: 0.88
Batch: 560; loss: 0.35; acc: 0.91
Batch: 580; loss: 0.17; acc: 0.94
Batch: 600; loss: 0.28; acc: 0.95
Batch: 620; loss: 0.21; acc: 0.92
Batch: 640; loss: 0.23; acc: 0.95
Batch: 660; loss: 0.07; acc: 1.0
Batch: 680; loss: 0.1; acc: 0.97
Batch: 700; loss: 0.19; acc: 0.92
Batch: 720; loss: 0.11; acc: 0.95
Batch: 740; loss: 0.24; acc: 0.92
Batch: 760; loss: 0.29; acc: 0.89
Batch: 780; loss: 0.22; acc: 0.91
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.907388079620432e-05
1.0093101991515141e-05
Batch: 0; loss: 0.22; acc: 0.91
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.26; acc: 0.94
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.37; acc: 0.88
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.20065561458942996; val_accuracy: 0.9421775477707006 

The current subspace-distance is: 1.0093101991515141e-05 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.17; acc: 0.92
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.17; acc: 0.94
Batch: 80; loss: 0.3; acc: 0.94
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.16; acc: 0.97
Batch: 140; loss: 0.32; acc: 0.92
Batch: 160; loss: 0.24; acc: 0.92
Batch: 180; loss: 0.26; acc: 0.92
Batch: 200; loss: 0.34; acc: 0.89
Batch: 220; loss: 0.2; acc: 0.92
Batch: 240; loss: 0.15; acc: 0.95
Batch: 260; loss: 0.18; acc: 0.95
Batch: 280; loss: 0.42; acc: 0.91
Batch: 300; loss: 0.18; acc: 0.95
Batch: 320; loss: 0.15; acc: 0.97
Batch: 340; loss: 0.42; acc: 0.89
Batch: 360; loss: 0.25; acc: 0.91
Batch: 380; loss: 0.13; acc: 0.95
Batch: 400; loss: 0.22; acc: 0.92
Batch: 420; loss: 0.37; acc: 0.95
Batch: 440; loss: 0.18; acc: 0.97
Batch: 460; loss: 0.27; acc: 0.95
Batch: 480; loss: 0.13; acc: 0.94
Batch: 500; loss: 0.26; acc: 0.92
Batch: 520; loss: 0.31; acc: 0.89
Batch: 540; loss: 0.29; acc: 0.91
Batch: 560; loss: 0.3; acc: 0.92
Batch: 580; loss: 0.13; acc: 0.98
Batch: 600; loss: 0.26; acc: 0.92
Batch: 620; loss: 0.11; acc: 0.95
Batch: 640; loss: 0.35; acc: 0.88
Batch: 660; loss: 0.11; acc: 0.97
Batch: 680; loss: 0.28; acc: 0.95
Batch: 700; loss: 0.1; acc: 0.97
Batch: 720; loss: 0.23; acc: 0.92
Batch: 740; loss: 0.17; acc: 0.94
Batch: 760; loss: 0.33; acc: 0.92
Batch: 780; loss: 0.3; acc: 0.92
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.8880727768409997e-05
1.189427166536916e-05
Batch: 0; loss: 0.23; acc: 0.89
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.26; acc: 0.95
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.39; acc: 0.89
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.20222549823818692; val_accuracy: 0.9421775477707006 

The current subspace-distance is: 1.189427166536916e-05 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.35; acc: 0.89
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.1; acc: 0.98
Batch: 80; loss: 0.38; acc: 0.91
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.24; acc: 0.94
Batch: 140; loss: 0.32; acc: 0.91
Batch: 160; loss: 0.31; acc: 0.91
Batch: 180; loss: 0.06; acc: 0.98
Batch: 200; loss: 0.34; acc: 0.88
Batch: 220; loss: 0.33; acc: 0.91
Batch: 240; loss: 0.23; acc: 0.94
Batch: 260; loss: 0.21; acc: 0.94
Batch: 280; loss: 0.27; acc: 0.91
Batch: 300; loss: 0.15; acc: 0.95
Batch: 320; loss: 0.24; acc: 0.92
Batch: 340; loss: 0.19; acc: 0.89
Batch: 360; loss: 0.31; acc: 0.91
Batch: 380; loss: 0.33; acc: 0.94
Batch: 400; loss: 0.22; acc: 0.91
Batch: 420; loss: 0.23; acc: 0.95
Batch: 440; loss: 0.15; acc: 0.94
Batch: 460; loss: 0.24; acc: 0.97
Batch: 480; loss: 0.26; acc: 0.89
Batch: 500; loss: 0.13; acc: 0.97
Batch: 520; loss: 0.2; acc: 0.94
Batch: 540; loss: 0.25; acc: 0.92
Batch: 560; loss: 0.42; acc: 0.91
Batch: 580; loss: 0.29; acc: 0.92
Batch: 600; loss: 0.35; acc: 0.88
Batch: 620; loss: 0.2; acc: 0.94
Batch: 640; loss: 0.17; acc: 0.95
Batch: 660; loss: 0.25; acc: 0.91
Batch: 680; loss: 0.16; acc: 0.92
Batch: 700; loss: 0.28; acc: 0.94
Batch: 720; loss: 0.14; acc: 0.95
Batch: 740; loss: 0.32; acc: 0.91
Batch: 760; loss: 0.19; acc: 0.94
Batch: 780; loss: 0.31; acc: 0.91
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.8713711799355224e-05
1.0545858458499424e-05
Batch: 0; loss: 0.23; acc: 0.91
Batch: 20; loss: 0.3; acc: 0.92
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.26; acc: 0.94
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.95
Batch: 120; loss: 0.36; acc: 0.88
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.20132045533247056; val_accuracy: 0.9419785031847133 

The current subspace-distance is: 1.0545858458499424e-05 

plots/subspace_training/reg_lenet_3/2020-01-22 20:51:04/d_dim_180_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
nonzero elements in E: 40209
elements in E: 8548100
fraction nonzero: 0.004703852318058984
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.31; acc: 0.08
Batch: 20; loss: 2.29; acc: 0.05
Batch: 40; loss: 2.3; acc: 0.09
Batch: 60; loss: 2.3; acc: 0.02
Batch: 80; loss: 2.3; acc: 0.08
Batch: 100; loss: 2.3; acc: 0.12
Batch: 120; loss: 2.3; acc: 0.11
Batch: 140; loss: 2.32; acc: 0.08
Batch: 160; loss: 2.3; acc: 0.08
Batch: 180; loss: 2.3; acc: 0.11
Batch: 200; loss: 2.29; acc: 0.14
Batch: 220; loss: 2.31; acc: 0.06
Batch: 240; loss: 2.31; acc: 0.05
Batch: 260; loss: 2.3; acc: 0.09
Batch: 280; loss: 2.29; acc: 0.05
Batch: 300; loss: 2.29; acc: 0.05
Batch: 320; loss: 2.3; acc: 0.05
Batch: 340; loss: 2.29; acc: 0.05
Batch: 360; loss: 2.28; acc: 0.16
Batch: 380; loss: 2.3; acc: 0.06
Batch: 400; loss: 2.29; acc: 0.17
Batch: 420; loss: 2.31; acc: 0.12
Batch: 440; loss: 2.29; acc: 0.17
Batch: 460; loss: 2.29; acc: 0.19
Batch: 480; loss: 2.28; acc: 0.16
Batch: 500; loss: 2.27; acc: 0.2
Batch: 520; loss: 2.27; acc: 0.16
Batch: 540; loss: 2.26; acc: 0.27
Batch: 560; loss: 2.27; acc: 0.19
Batch: 580; loss: 2.26; acc: 0.19
Batch: 600; loss: 2.26; acc: 0.2
Batch: 620; loss: 2.23; acc: 0.31
Batch: 640; loss: 2.24; acc: 0.28
Batch: 660; loss: 2.24; acc: 0.19
Batch: 680; loss: 2.28; acc: 0.06
Batch: 700; loss: 2.25; acc: 0.12
Batch: 720; loss: 2.24; acc: 0.17
Batch: 740; loss: 2.18; acc: 0.23
Batch: 760; loss: 2.24; acc: 0.14
Batch: 780; loss: 2.22; acc: 0.2
Train Epoch over. train_loss: 2.28; train_accuracy: 0.13 

6.332623797788983e-06
1.8243782733406988e-06
Batch: 0; loss: 2.17; acc: 0.23
Batch: 20; loss: 2.21; acc: 0.16
Batch: 40; loss: 2.14; acc: 0.3
Batch: 60; loss: 2.18; acc: 0.22
Batch: 80; loss: 2.14; acc: 0.25
Batch: 100; loss: 2.17; acc: 0.25
Batch: 120; loss: 2.2; acc: 0.22
Batch: 140; loss: 2.18; acc: 0.25
Val Epoch over. val_loss: 2.179091852941331; val_accuracy: 0.229796974522293 

The current subspace-distance is: 1.8243782733406988e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 2.21; acc: 0.19
Batch: 20; loss: 2.15; acc: 0.39
Batch: 40; loss: 2.13; acc: 0.39
Batch: 60; loss: 2.02; acc: 0.5
Batch: 80; loss: 2.04; acc: 0.38
Batch: 100; loss: 2.02; acc: 0.41
Batch: 120; loss: 1.74; acc: 0.56
Batch: 140; loss: 1.54; acc: 0.62
Batch: 160; loss: 1.3; acc: 0.62
Batch: 180; loss: 1.18; acc: 0.73
Batch: 200; loss: 1.47; acc: 0.58
Batch: 220; loss: 1.07; acc: 0.69
Batch: 240; loss: 0.82; acc: 0.73
Batch: 260; loss: 1.13; acc: 0.58
Batch: 280; loss: 1.01; acc: 0.67
Batch: 300; loss: 0.74; acc: 0.77
Batch: 320; loss: 0.72; acc: 0.77
Batch: 340; loss: 0.84; acc: 0.75
Batch: 360; loss: 0.67; acc: 0.78
Batch: 380; loss: 0.72; acc: 0.81
Batch: 400; loss: 0.59; acc: 0.78
Batch: 420; loss: 0.83; acc: 0.67
Batch: 440; loss: 0.78; acc: 0.72
Batch: 460; loss: 0.94; acc: 0.69
Batch: 480; loss: 0.53; acc: 0.8
Batch: 500; loss: 0.87; acc: 0.69
Batch: 520; loss: 0.44; acc: 0.86
Batch: 540; loss: 0.32; acc: 0.89
Batch: 560; loss: 0.41; acc: 0.86
Batch: 580; loss: 0.48; acc: 0.83
Batch: 600; loss: 0.81; acc: 0.78
Batch: 620; loss: 0.42; acc: 0.92
Batch: 640; loss: 0.53; acc: 0.84
Batch: 660; loss: 0.9; acc: 0.69
Batch: 680; loss: 0.48; acc: 0.86
Batch: 700; loss: 0.57; acc: 0.75
Batch: 720; loss: 0.58; acc: 0.81
Batch: 740; loss: 0.65; acc: 0.86
Batch: 760; loss: 0.67; acc: 0.8
Batch: 780; loss: 0.65; acc: 0.8
Train Epoch over. train_loss: 0.98; train_accuracy: 0.7 

1.7967102394322865e-05
6.324201876850566e-06
Batch: 0; loss: 0.73; acc: 0.7
Batch: 20; loss: 1.09; acc: 0.59
Batch: 40; loss: 0.77; acc: 0.72
Batch: 60; loss: 1.17; acc: 0.67
Batch: 80; loss: 0.68; acc: 0.81
Batch: 100; loss: 0.99; acc: 0.72
Batch: 120; loss: 0.95; acc: 0.7
Batch: 140; loss: 1.02; acc: 0.62
Val Epoch over. val_loss: 1.0544993567998242; val_accuracy: 0.660828025477707 

The current subspace-distance is: 6.324201876850566e-06 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 1.07; acc: 0.61
Batch: 20; loss: 0.4; acc: 0.88
Batch: 40; loss: 0.34; acc: 0.89
Batch: 60; loss: 0.37; acc: 0.89
Batch: 80; loss: 0.64; acc: 0.78
Batch: 100; loss: 0.65; acc: 0.8
Batch: 120; loss: 0.67; acc: 0.84
Batch: 140; loss: 0.56; acc: 0.81
Batch: 160; loss: 0.43; acc: 0.86
Batch: 180; loss: 0.46; acc: 0.81
Batch: 200; loss: 0.53; acc: 0.88
Batch: 220; loss: 0.53; acc: 0.84
Batch: 240; loss: 0.64; acc: 0.83
Batch: 260; loss: 0.52; acc: 0.83
Batch: 280; loss: 0.35; acc: 0.91
Batch: 300; loss: 0.34; acc: 0.91
Batch: 320; loss: 0.54; acc: 0.89
Batch: 340; loss: 0.38; acc: 0.88
Batch: 360; loss: 0.39; acc: 0.89
Batch: 380; loss: 0.54; acc: 0.86
Batch: 400; loss: 0.39; acc: 0.88
Batch: 420; loss: 0.61; acc: 0.83
Batch: 440; loss: 0.4; acc: 0.89
Batch: 460; loss: 0.54; acc: 0.84
Batch: 480; loss: 0.53; acc: 0.81
Batch: 500; loss: 0.42; acc: 0.84
Batch: 520; loss: 0.33; acc: 0.89
Batch: 540; loss: 0.33; acc: 0.88
Batch: 560; loss: 0.53; acc: 0.83
Batch: 580; loss: 0.45; acc: 0.89
Batch: 600; loss: 0.41; acc: 0.89
Batch: 620; loss: 0.75; acc: 0.73
Batch: 640; loss: 0.32; acc: 0.89
Batch: 660; loss: 0.54; acc: 0.83
Batch: 680; loss: 0.35; acc: 0.89
Batch: 700; loss: 0.74; acc: 0.75
Batch: 720; loss: 0.26; acc: 0.91
Batch: 740; loss: 0.42; acc: 0.84
Batch: 760; loss: 0.41; acc: 0.86
Batch: 780; loss: 0.33; acc: 0.88
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

2.19710600504186e-05
8.363155757251661e-06
Batch: 0; loss: 0.37; acc: 0.86
Batch: 20; loss: 0.48; acc: 0.83
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.44; acc: 0.88
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.34; acc: 0.91
Batch: 120; loss: 0.68; acc: 0.75
Batch: 140; loss: 0.19; acc: 0.97
Val Epoch over. val_loss: 0.3568255415862533; val_accuracy: 0.8922173566878981 

The current subspace-distance is: 8.363155757251661e-06 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.37; acc: 0.83
Batch: 20; loss: 0.35; acc: 0.94
Batch: 40; loss: 0.39; acc: 0.89
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.34; acc: 0.89
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.47; acc: 0.84
Batch: 140; loss: 0.3; acc: 0.86
Batch: 160; loss: 0.31; acc: 0.83
Batch: 180; loss: 0.49; acc: 0.83
Batch: 200; loss: 0.26; acc: 0.92
Batch: 220; loss: 0.64; acc: 0.84
Batch: 240; loss: 0.48; acc: 0.83
Batch: 260; loss: 0.28; acc: 0.92
Batch: 280; loss: 0.5; acc: 0.88
Batch: 300; loss: 0.56; acc: 0.88
Batch: 320; loss: 0.38; acc: 0.88
Batch: 340; loss: 0.4; acc: 0.92
Batch: 360; loss: 0.61; acc: 0.81
Batch: 380; loss: 0.3; acc: 0.91
Batch: 400; loss: 0.49; acc: 0.84
Batch: 420; loss: 0.51; acc: 0.81
Batch: 440; loss: 0.08; acc: 0.98
Batch: 460; loss: 0.19; acc: 0.94
Batch: 480; loss: 0.39; acc: 0.92
Batch: 500; loss: 0.2; acc: 0.91
Batch: 520; loss: 0.37; acc: 0.88
Batch: 540; loss: 0.29; acc: 0.91
Batch: 560; loss: 0.43; acc: 0.86
Batch: 580; loss: 0.46; acc: 0.86
Batch: 600; loss: 0.25; acc: 0.91
Batch: 620; loss: 0.42; acc: 0.84
Batch: 640; loss: 0.41; acc: 0.89
Batch: 660; loss: 0.51; acc: 0.84
Batch: 680; loss: 0.41; acc: 0.91
Batch: 700; loss: 0.26; acc: 0.91
Batch: 720; loss: 0.44; acc: 0.84
Batch: 740; loss: 0.4; acc: 0.92
Batch: 760; loss: 0.34; acc: 0.92
Batch: 780; loss: 0.23; acc: 0.92
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

2.3167216568253934e-05
7.902568540885113e-06
Batch: 0; loss: 0.36; acc: 0.83
Batch: 20; loss: 0.49; acc: 0.8
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.43; acc: 0.84
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.37; acc: 0.89
Batch: 120; loss: 0.57; acc: 0.75
Batch: 140; loss: 0.18; acc: 0.94
Val Epoch over. val_loss: 0.3626483176022198; val_accuracy: 0.8847531847133758 

The current subspace-distance is: 7.902568540885113e-06 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.42; acc: 0.86
Batch: 20; loss: 0.47; acc: 0.84
Batch: 40; loss: 0.58; acc: 0.83
Batch: 60; loss: 0.46; acc: 0.86
Batch: 80; loss: 0.5; acc: 0.88
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.36; acc: 0.89
Batch: 140; loss: 0.32; acc: 0.89
Batch: 160; loss: 0.13; acc: 0.97
Batch: 180; loss: 0.22; acc: 0.92
Batch: 200; loss: 0.33; acc: 0.89
Batch: 220; loss: 0.35; acc: 0.89
Batch: 240; loss: 0.35; acc: 0.86
Batch: 260; loss: 0.38; acc: 0.88
Batch: 280; loss: 0.31; acc: 0.89
Batch: 300; loss: 0.16; acc: 0.92
Batch: 320; loss: 0.14; acc: 0.98
Batch: 340; loss: 0.31; acc: 0.89
Batch: 360; loss: 0.61; acc: 0.86
Batch: 380; loss: 0.21; acc: 0.95
Batch: 400; loss: 0.56; acc: 0.8
Batch: 420; loss: 0.23; acc: 0.91
Batch: 440; loss: 0.27; acc: 0.86
Batch: 460; loss: 0.34; acc: 0.88
Batch: 480; loss: 0.33; acc: 0.88
Batch: 500; loss: 0.26; acc: 0.88
Batch: 520; loss: 0.23; acc: 0.95
Batch: 540; loss: 0.32; acc: 0.89
Batch: 560; loss: 0.44; acc: 0.88
Batch: 580; loss: 0.3; acc: 0.91
Batch: 600; loss: 0.24; acc: 0.92
Batch: 620; loss: 0.27; acc: 0.89
Batch: 640; loss: 0.24; acc: 0.89
Batch: 660; loss: 0.64; acc: 0.83
Batch: 680; loss: 0.38; acc: 0.91
Batch: 700; loss: 0.26; acc: 0.89
Batch: 720; loss: 0.27; acc: 0.94
Batch: 740; loss: 0.37; acc: 0.94
Batch: 760; loss: 0.18; acc: 0.98
Batch: 780; loss: 0.28; acc: 0.92
Train Epoch over. train_loss: 0.34; train_accuracy: 0.9 

2.4077604393824004e-05
7.754038051643874e-06
Batch: 0; loss: 0.32; acc: 0.92
Batch: 20; loss: 0.63; acc: 0.77
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.39; acc: 0.88
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.71; acc: 0.75
Batch: 140; loss: 0.32; acc: 0.86
Val Epoch over. val_loss: 0.37020495961046523; val_accuracy: 0.8844546178343949 

The current subspace-distance is: 7.754038051643874e-06 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.46; acc: 0.81
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.55; acc: 0.83
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.26; acc: 0.92
Batch: 100; loss: 0.45; acc: 0.86
Batch: 120; loss: 0.39; acc: 0.88
Batch: 140; loss: 0.32; acc: 0.89
Batch: 160; loss: 0.4; acc: 0.89
Batch: 180; loss: 0.2; acc: 0.95
Batch: 200; loss: 0.35; acc: 0.91
Batch: 220; loss: 0.25; acc: 0.94
Batch: 240; loss: 0.46; acc: 0.88
Batch: 260; loss: 0.27; acc: 0.94
Batch: 280; loss: 0.32; acc: 0.89
Batch: 300; loss: 0.36; acc: 0.89
Batch: 320; loss: 0.36; acc: 0.92
Batch: 340; loss: 0.25; acc: 0.94
Batch: 360; loss: 0.51; acc: 0.81
Batch: 380; loss: 0.54; acc: 0.83
Batch: 400; loss: 0.28; acc: 0.91
Batch: 420; loss: 0.2; acc: 0.92
Batch: 440; loss: 0.32; acc: 0.92
Batch: 460; loss: 0.31; acc: 0.88
Batch: 480; loss: 0.27; acc: 0.89
Batch: 500; loss: 0.23; acc: 0.91
Batch: 520; loss: 0.3; acc: 0.89
Batch: 540; loss: 0.27; acc: 0.91
Batch: 560; loss: 0.25; acc: 0.94
Batch: 580; loss: 0.23; acc: 0.92
Batch: 600; loss: 0.26; acc: 0.89
Batch: 620; loss: 0.21; acc: 0.89
Batch: 640; loss: 0.3; acc: 0.91
Batch: 660; loss: 0.54; acc: 0.88
Batch: 680; loss: 0.14; acc: 0.94
Batch: 700; loss: 0.21; acc: 0.92
Batch: 720; loss: 0.61; acc: 0.81
Batch: 740; loss: 0.19; acc: 0.94
Batch: 760; loss: 0.35; acc: 0.91
Batch: 780; loss: 0.29; acc: 0.94
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.6117530069313943e-05
8.348029041371774e-06
Batch: 0; loss: 0.22; acc: 0.89
Batch: 20; loss: 0.38; acc: 0.86
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.14; acc: 0.98
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.48; acc: 0.83
Batch: 140; loss: 0.1; acc: 0.98
Val Epoch over. val_loss: 0.29509909749980184; val_accuracy: 0.9109275477707006 

The current subspace-distance is: 8.348029041371774e-06 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.53; acc: 0.8
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.32; acc: 0.88
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.24; acc: 0.92
Batch: 120; loss: 0.13; acc: 0.98
Batch: 140; loss: 0.29; acc: 0.94
Batch: 160; loss: 0.52; acc: 0.8
Batch: 180; loss: 0.33; acc: 0.86
Batch: 200; loss: 0.49; acc: 0.86
Batch: 220; loss: 0.27; acc: 0.91
Batch: 240; loss: 0.31; acc: 0.88
Batch: 260; loss: 0.18; acc: 0.94
Batch: 280; loss: 0.26; acc: 0.89
Batch: 300; loss: 0.39; acc: 0.91
Batch: 320; loss: 0.33; acc: 0.88
Batch: 340; loss: 0.2; acc: 0.94
Batch: 360; loss: 0.36; acc: 0.91
Batch: 380; loss: 0.36; acc: 0.88
Batch: 400; loss: 0.26; acc: 0.88
Batch: 420; loss: 0.46; acc: 0.81
Batch: 440; loss: 0.34; acc: 0.89
Batch: 460; loss: 0.17; acc: 0.94
Batch: 480; loss: 0.24; acc: 0.94
Batch: 500; loss: 0.13; acc: 0.95
Batch: 520; loss: 0.2; acc: 0.95
Batch: 540; loss: 0.28; acc: 0.92
Batch: 560; loss: 0.19; acc: 0.95
Batch: 580; loss: 0.25; acc: 0.91
Batch: 600; loss: 0.16; acc: 0.92
Batch: 620; loss: 0.25; acc: 0.95
Batch: 640; loss: 0.44; acc: 0.86
Batch: 660; loss: 0.24; acc: 0.95
Batch: 680; loss: 0.44; acc: 0.91
Batch: 700; loss: 0.34; acc: 0.91
Batch: 720; loss: 0.31; acc: 0.91
Batch: 740; loss: 0.11; acc: 0.95
Batch: 760; loss: 0.27; acc: 0.94
Batch: 780; loss: 0.17; acc: 0.95
Train Epoch over. train_loss: 0.3; train_accuracy: 0.9 

2.632807445479557e-05
8.634264304419048e-06
Batch: 0; loss: 0.26; acc: 0.92
Batch: 20; loss: 0.31; acc: 0.88
Batch: 40; loss: 0.1; acc: 0.98
Batch: 60; loss: 0.5; acc: 0.86
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.5; acc: 0.88
Batch: 140; loss: 0.18; acc: 0.95
Val Epoch over. val_loss: 0.2823755773626695; val_accuracy: 0.9120222929936306 

The current subspace-distance is: 8.634264304419048e-06 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.52; acc: 0.84
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.2; acc: 0.91
Batch: 60; loss: 0.31; acc: 0.94
Batch: 80; loss: 0.41; acc: 0.89
Batch: 100; loss: 0.33; acc: 0.89
Batch: 120; loss: 0.3; acc: 0.91
Batch: 140; loss: 0.22; acc: 0.91
Batch: 160; loss: 0.28; acc: 0.92
Batch: 180; loss: 0.1; acc: 0.97
Batch: 200; loss: 0.15; acc: 0.97
Batch: 220; loss: 0.41; acc: 0.88
Batch: 240; loss: 0.27; acc: 0.91
Batch: 260; loss: 0.24; acc: 0.92
Batch: 280; loss: 0.38; acc: 0.84
Batch: 300; loss: 0.42; acc: 0.81
Batch: 320; loss: 0.38; acc: 0.86
Batch: 340; loss: 0.47; acc: 0.89
Batch: 360; loss: 0.13; acc: 0.97
Batch: 380; loss: 0.17; acc: 0.95
Batch: 400; loss: 0.38; acc: 0.83
Batch: 420; loss: 0.28; acc: 0.91
Batch: 440; loss: 0.33; acc: 0.88
Batch: 460; loss: 0.2; acc: 0.91
Batch: 480; loss: 0.23; acc: 0.91
Batch: 500; loss: 0.31; acc: 0.92
Batch: 520; loss: 0.41; acc: 0.89
Batch: 540; loss: 0.29; acc: 0.89
Batch: 560; loss: 0.1; acc: 0.97
Batch: 580; loss: 0.36; acc: 0.88
Batch: 600; loss: 0.47; acc: 0.89
Batch: 620; loss: 0.48; acc: 0.88
Batch: 640; loss: 0.11; acc: 0.97
Batch: 660; loss: 0.32; acc: 0.91
Batch: 680; loss: 0.26; acc: 0.92
Batch: 700; loss: 0.44; acc: 0.86
Batch: 720; loss: 0.3; acc: 0.89
Batch: 740; loss: 0.44; acc: 0.92
Batch: 760; loss: 0.13; acc: 0.95
Batch: 780; loss: 0.23; acc: 0.92
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.7049798518419266e-05
8.547238394385204e-06
Batch: 0; loss: 0.28; acc: 0.89
Batch: 20; loss: 0.48; acc: 0.86
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.49; acc: 0.88
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.24; acc: 0.88
Batch: 120; loss: 0.69; acc: 0.78
Batch: 140; loss: 0.15; acc: 0.98
Val Epoch over. val_loss: 0.30409352913214144; val_accuracy: 0.9042595541401274 

The current subspace-distance is: 8.547238394385204e-06 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.33; acc: 0.91
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.49; acc: 0.84
Batch: 80; loss: 0.38; acc: 0.88
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.28; acc: 0.89
Batch: 140; loss: 0.39; acc: 0.89
Batch: 160; loss: 0.43; acc: 0.88
Batch: 180; loss: 0.38; acc: 0.89
Batch: 200; loss: 0.21; acc: 0.94
Batch: 220; loss: 0.38; acc: 0.89
Batch: 240; loss: 0.15; acc: 0.95
Batch: 260; loss: 0.34; acc: 0.89
Batch: 280; loss: 0.34; acc: 0.91
Batch: 300; loss: 0.3; acc: 0.89
Batch: 320; loss: 0.28; acc: 0.92
Batch: 340; loss: 0.29; acc: 0.88
Batch: 360; loss: 0.4; acc: 0.86
Batch: 380; loss: 0.08; acc: 1.0
Batch: 400; loss: 0.28; acc: 0.91
Batch: 420; loss: 0.12; acc: 0.97
Batch: 440; loss: 0.25; acc: 0.94
Batch: 460; loss: 0.13; acc: 0.95
Batch: 480; loss: 0.33; acc: 0.91
Batch: 500; loss: 0.44; acc: 0.86
Batch: 520; loss: 0.36; acc: 0.92
Batch: 540; loss: 0.34; acc: 0.91
Batch: 560; loss: 0.29; acc: 0.91
Batch: 580; loss: 0.3; acc: 0.92
Batch: 600; loss: 0.25; acc: 0.91
Batch: 620; loss: 0.36; acc: 0.91
Batch: 640; loss: 0.31; acc: 0.91
Batch: 660; loss: 0.55; acc: 0.86
Batch: 680; loss: 0.53; acc: 0.88
Batch: 700; loss: 0.31; acc: 0.94
Batch: 720; loss: 0.3; acc: 0.91
Batch: 740; loss: 0.34; acc: 0.94
Batch: 760; loss: 0.2; acc: 0.94
Batch: 780; loss: 0.24; acc: 0.88
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

2.8239996026968583e-05
8.798853741609491e-06
Batch: 0; loss: 0.26; acc: 0.92
Batch: 20; loss: 0.49; acc: 0.83
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.55; acc: 0.81
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.31; acc: 0.86
Batch: 120; loss: 0.55; acc: 0.83
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.2843556179172674; val_accuracy: 0.910031847133758 

The current subspace-distance is: 8.798853741609491e-06 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.45; acc: 0.91
Batch: 60; loss: 0.2; acc: 0.92
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.3; acc: 0.88
Batch: 120; loss: 0.32; acc: 0.91
Batch: 140; loss: 0.48; acc: 0.86
Batch: 160; loss: 0.27; acc: 0.94
Batch: 180; loss: 0.11; acc: 0.95
Batch: 200; loss: 0.22; acc: 0.91
Batch: 220; loss: 0.5; acc: 0.83
Batch: 240; loss: 0.27; acc: 0.92
Batch: 260; loss: 0.34; acc: 0.86
Batch: 280; loss: 0.24; acc: 0.91
Batch: 300; loss: 0.09; acc: 0.98
Batch: 320; loss: 0.51; acc: 0.84
Batch: 340; loss: 0.24; acc: 0.89
Batch: 360; loss: 0.16; acc: 0.94
Batch: 380; loss: 0.26; acc: 0.92
Batch: 400; loss: 0.35; acc: 0.89
Batch: 420; loss: 0.2; acc: 0.92
Batch: 440; loss: 0.29; acc: 0.91
Batch: 460; loss: 0.12; acc: 0.97
Batch: 480; loss: 0.21; acc: 0.91
Batch: 500; loss: 0.18; acc: 0.94
Batch: 520; loss: 0.15; acc: 0.95
Batch: 540; loss: 0.28; acc: 0.94
Batch: 560; loss: 0.25; acc: 0.91
Batch: 580; loss: 0.27; acc: 0.92
Batch: 600; loss: 0.13; acc: 0.97
Batch: 620; loss: 0.46; acc: 0.86
Batch: 640; loss: 0.25; acc: 0.91
Batch: 660; loss: 0.38; acc: 0.89
Batch: 680; loss: 0.13; acc: 0.97
Batch: 700; loss: 0.34; acc: 0.89
Batch: 720; loss: 0.41; acc: 0.88
Batch: 740; loss: 0.22; acc: 0.91
Batch: 760; loss: 0.17; acc: 0.95
Batch: 780; loss: 0.41; acc: 0.86
Train Epoch over. train_loss: 0.27; train_accuracy: 0.91 

2.7279053028905764e-05
9.60003035288537e-06
Batch: 0; loss: 0.31; acc: 0.89
Batch: 20; loss: 0.46; acc: 0.84
Batch: 40; loss: 0.27; acc: 0.91
Batch: 60; loss: 0.64; acc: 0.75
Batch: 80; loss: 0.26; acc: 0.89
Batch: 100; loss: 0.35; acc: 0.86
Batch: 120; loss: 0.5; acc: 0.83
Batch: 140; loss: 0.15; acc: 0.95
Val Epoch over. val_loss: 0.3463179834519222; val_accuracy: 0.886843152866242 

The current subspace-distance is: 9.60003035288537e-06 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.36; acc: 0.88
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.36; acc: 0.92
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.24; acc: 0.91
Batch: 120; loss: 0.2; acc: 0.95
Batch: 140; loss: 0.17; acc: 0.92
Batch: 160; loss: 0.25; acc: 0.91
Batch: 180; loss: 0.32; acc: 0.89
Batch: 200; loss: 0.26; acc: 0.94
Batch: 220; loss: 0.17; acc: 0.94
Batch: 240; loss: 0.15; acc: 0.94
Batch: 260; loss: 0.28; acc: 0.91
Batch: 280; loss: 0.15; acc: 0.95
Batch: 300; loss: 0.09; acc: 0.97
Batch: 320; loss: 0.24; acc: 0.94
Batch: 340; loss: 0.17; acc: 0.95
Batch: 360; loss: 0.27; acc: 0.94
Batch: 380; loss: 0.29; acc: 0.89
Batch: 400; loss: 0.43; acc: 0.91
Batch: 420; loss: 0.15; acc: 0.95
Batch: 440; loss: 0.19; acc: 0.91
Batch: 460; loss: 0.23; acc: 0.92
Batch: 480; loss: 0.14; acc: 0.92
Batch: 500; loss: 0.21; acc: 0.92
Batch: 520; loss: 0.2; acc: 0.94
Batch: 540; loss: 0.31; acc: 0.89
Batch: 560; loss: 0.26; acc: 0.92
Batch: 580; loss: 0.41; acc: 0.86
Batch: 600; loss: 0.3; acc: 0.91
Batch: 620; loss: 0.3; acc: 0.94
Batch: 640; loss: 0.23; acc: 0.94
Batch: 660; loss: 0.36; acc: 0.92
Batch: 680; loss: 0.49; acc: 0.88
Batch: 700; loss: 0.09; acc: 0.97
Batch: 720; loss: 0.12; acc: 0.95
Batch: 740; loss: 0.29; acc: 0.91
Batch: 760; loss: 0.34; acc: 0.88
Batch: 780; loss: 0.16; acc: 0.92
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

2.8101247153244913e-05
8.523188625986222e-06
Batch: 0; loss: 0.19; acc: 0.95
Batch: 20; loss: 0.39; acc: 0.88
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.37; acc: 0.89
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.17; acc: 0.97
Batch: 120; loss: 0.57; acc: 0.84
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.22514078384087344; val_accuracy: 0.9304339171974523 

The current subspace-distance is: 8.523188625986222e-06 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.31; acc: 0.91
Batch: 20; loss: 0.13; acc: 0.97
Batch: 40; loss: 0.33; acc: 0.91
Batch: 60; loss: 0.28; acc: 0.94
Batch: 80; loss: 0.34; acc: 0.91
Batch: 100; loss: 0.12; acc: 0.97
Batch: 120; loss: 0.18; acc: 0.98
Batch: 140; loss: 0.23; acc: 0.94
Batch: 160; loss: 0.31; acc: 0.88
Batch: 180; loss: 0.15; acc: 0.97
Batch: 200; loss: 0.21; acc: 0.95
Batch: 220; loss: 0.19; acc: 0.94
Batch: 240; loss: 0.16; acc: 0.94
Batch: 260; loss: 0.13; acc: 0.97
Batch: 280; loss: 0.21; acc: 0.94
Batch: 300; loss: 0.13; acc: 0.94
Batch: 320; loss: 0.21; acc: 0.94
Batch: 340; loss: 0.18; acc: 0.95
Batch: 360; loss: 0.38; acc: 0.84
Batch: 380; loss: 0.36; acc: 0.89
Batch: 400; loss: 0.2; acc: 0.94
Batch: 420; loss: 0.32; acc: 0.86
Batch: 440; loss: 0.38; acc: 0.91
Batch: 460; loss: 0.31; acc: 0.86
Batch: 480; loss: 0.26; acc: 0.92
Batch: 500; loss: 0.42; acc: 0.89
Batch: 520; loss: 0.32; acc: 0.89
Batch: 540; loss: 0.27; acc: 0.88
Batch: 560; loss: 0.34; acc: 0.92
Batch: 580; loss: 0.28; acc: 0.94
Batch: 600; loss: 0.26; acc: 0.94
Batch: 620; loss: 0.22; acc: 0.94
Batch: 640; loss: 0.31; acc: 0.88
Batch: 660; loss: 0.16; acc: 0.95
Batch: 680; loss: 0.42; acc: 0.88
Batch: 700; loss: 0.17; acc: 0.94
Batch: 720; loss: 0.19; acc: 0.95
Batch: 740; loss: 0.4; acc: 0.89
Batch: 760; loss: 0.48; acc: 0.88
Batch: 780; loss: 0.2; acc: 0.94
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

2.69934389507398e-05
8.902886293071788e-06
Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.35; acc: 0.84
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.42; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.48; acc: 0.86
Batch: 140; loss: 0.12; acc: 0.95
Val Epoch over. val_loss: 0.2195487544652383; val_accuracy: 0.9321257961783439 

The current subspace-distance is: 8.902886293071788e-06 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.31; acc: 0.91
Batch: 20; loss: 0.22; acc: 0.91
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.23; acc: 0.89
Batch: 120; loss: 0.27; acc: 0.92
Batch: 140; loss: 0.21; acc: 0.95
Batch: 160; loss: 0.38; acc: 0.86
Batch: 180; loss: 0.28; acc: 0.91
Batch: 200; loss: 0.17; acc: 0.98
Batch: 220; loss: 0.14; acc: 0.97
Batch: 240; loss: 0.16; acc: 0.94
Batch: 260; loss: 0.08; acc: 0.98
Batch: 280; loss: 0.19; acc: 0.94
Batch: 300; loss: 0.25; acc: 0.92
Batch: 320; loss: 0.26; acc: 0.92
Batch: 340; loss: 0.17; acc: 0.95
Batch: 360; loss: 0.13; acc: 0.97
Batch: 380; loss: 0.26; acc: 0.94
Batch: 400; loss: 0.26; acc: 0.91
Batch: 420; loss: 0.12; acc: 0.95
Batch: 440; loss: 0.36; acc: 0.89
Batch: 460; loss: 0.14; acc: 0.95
Batch: 480; loss: 0.12; acc: 0.95
Batch: 500; loss: 0.22; acc: 0.94
Batch: 520; loss: 0.25; acc: 0.92
Batch: 540; loss: 0.33; acc: 0.91
Batch: 560; loss: 0.17; acc: 0.97
Batch: 580; loss: 0.34; acc: 0.89
Batch: 600; loss: 0.31; acc: 0.88
Batch: 620; loss: 0.32; acc: 0.94
Batch: 640; loss: 0.2; acc: 0.94
Batch: 660; loss: 0.2; acc: 0.94
Batch: 680; loss: 0.21; acc: 0.91
Batch: 700; loss: 0.53; acc: 0.83
Batch: 720; loss: 0.14; acc: 0.95
Batch: 740; loss: 0.21; acc: 0.94
Batch: 760; loss: 0.21; acc: 0.92
Batch: 780; loss: 0.4; acc: 0.89
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

2.847531868610531e-05
8.8967881310964e-06
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.32; acc: 0.86
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.41; acc: 0.88
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.48; acc: 0.84
Batch: 140; loss: 0.09; acc: 0.98
Val Epoch over. val_loss: 0.215007582620071; val_accuracy: 0.9339171974522293 

The current subspace-distance is: 8.8967881310964e-06 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.29; acc: 0.89
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.34; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.24; acc: 0.89
Batch: 120; loss: 0.23; acc: 0.94
Batch: 140; loss: 0.38; acc: 0.84
Batch: 160; loss: 0.31; acc: 0.91
Batch: 180; loss: 0.16; acc: 0.95
Batch: 200; loss: 0.19; acc: 0.94
Batch: 220; loss: 0.47; acc: 0.89
Batch: 240; loss: 0.15; acc: 0.95
Batch: 260; loss: 0.15; acc: 0.95
Batch: 280; loss: 0.15; acc: 0.92
Batch: 300; loss: 0.28; acc: 0.89
Batch: 320; loss: 0.25; acc: 0.92
Batch: 340; loss: 0.31; acc: 0.94
Batch: 360; loss: 0.35; acc: 0.89
Batch: 380; loss: 0.11; acc: 0.97
Batch: 400; loss: 0.3; acc: 0.86
Batch: 420; loss: 0.22; acc: 0.94
Batch: 440; loss: 0.27; acc: 0.92
Batch: 460; loss: 0.17; acc: 0.95
Batch: 480; loss: 0.31; acc: 0.88
Batch: 500; loss: 0.29; acc: 0.94
Batch: 520; loss: 0.23; acc: 0.92
Batch: 540; loss: 0.28; acc: 0.94
Batch: 560; loss: 0.67; acc: 0.83
Batch: 580; loss: 0.22; acc: 0.92
Batch: 600; loss: 0.25; acc: 0.94
Batch: 620; loss: 0.33; acc: 0.92
Batch: 640; loss: 0.26; acc: 0.92
Batch: 660; loss: 0.22; acc: 0.94
Batch: 680; loss: 0.3; acc: 0.94
Batch: 700; loss: 0.23; acc: 0.92
Batch: 720; loss: 0.19; acc: 0.92
Batch: 740; loss: 0.19; acc: 0.94
Batch: 760; loss: 0.24; acc: 0.94
Batch: 780; loss: 0.39; acc: 0.89
Train Epoch over. train_loss: 0.24; train_accuracy: 0.92 

2.773307278403081e-05
8.614539183326997e-06
Batch: 0; loss: 0.2; acc: 0.92
Batch: 20; loss: 0.34; acc: 0.88
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.42; acc: 0.89
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.2; acc: 0.92
Batch: 120; loss: 0.49; acc: 0.84
Batch: 140; loss: 0.09; acc: 0.95
Val Epoch over. val_loss: 0.22081904538023245; val_accuracy: 0.9317277070063694 

The current subspace-distance is: 8.614539183326997e-06 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.23; acc: 0.94
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.31; acc: 0.92
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.21; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.16; acc: 0.94
Batch: 140; loss: 0.27; acc: 0.92
Batch: 160; loss: 0.28; acc: 0.94
Batch: 180; loss: 0.29; acc: 0.92
Batch: 200; loss: 0.3; acc: 0.91
Batch: 220; loss: 0.25; acc: 0.91
Batch: 240; loss: 0.26; acc: 0.92
Batch: 260; loss: 0.18; acc: 0.89
Batch: 280; loss: 0.11; acc: 0.95
Batch: 300; loss: 0.34; acc: 0.92
Batch: 320; loss: 0.33; acc: 0.91
Batch: 340; loss: 0.28; acc: 0.91
Batch: 360; loss: 0.36; acc: 0.89
Batch: 380; loss: 0.31; acc: 0.88
Batch: 400; loss: 0.28; acc: 0.92
Batch: 420; loss: 0.37; acc: 0.89
Batch: 440; loss: 0.17; acc: 0.95
Batch: 460; loss: 0.53; acc: 0.88
Batch: 480; loss: 0.27; acc: 0.92
Batch: 500; loss: 0.23; acc: 0.91
Batch: 520; loss: 0.32; acc: 0.92
Batch: 540; loss: 0.13; acc: 0.97
Batch: 560; loss: 0.17; acc: 0.97
Batch: 580; loss: 0.24; acc: 0.92
Batch: 600; loss: 0.16; acc: 0.94
Batch: 620; loss: 0.26; acc: 0.94
Batch: 640; loss: 0.18; acc: 0.92
Batch: 660; loss: 0.28; acc: 0.91
Batch: 680; loss: 0.14; acc: 0.94
Batch: 700; loss: 0.17; acc: 0.95
Batch: 720; loss: 0.28; acc: 0.88
Batch: 740; loss: 0.12; acc: 0.97
Batch: 760; loss: 0.21; acc: 0.91
Batch: 780; loss: 0.12; acc: 0.97
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

2.734657573455479e-05
9.19182366487803e-06
Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.34; acc: 0.88
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.43; acc: 0.92
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.19; acc: 0.92
Batch: 120; loss: 0.54; acc: 0.81
Batch: 140; loss: 0.1; acc: 0.92
Val Epoch over. val_loss: 0.22393085563163848; val_accuracy: 0.9324243630573248 

The current subspace-distance is: 9.19182366487803e-06 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.28; acc: 0.91
Batch: 20; loss: 0.31; acc: 0.89
Batch: 40; loss: 0.34; acc: 0.88
Batch: 60; loss: 0.16; acc: 0.97
Batch: 80; loss: 0.15; acc: 0.92
Batch: 100; loss: 0.28; acc: 0.89
Batch: 120; loss: 0.47; acc: 0.84
Batch: 140; loss: 0.21; acc: 0.94
Batch: 160; loss: 0.41; acc: 0.86
Batch: 180; loss: 0.3; acc: 0.92
Batch: 200; loss: 0.25; acc: 0.86
Batch: 220; loss: 0.19; acc: 0.95
Batch: 240; loss: 0.34; acc: 0.91
Batch: 260; loss: 0.19; acc: 0.95
Batch: 280; loss: 0.38; acc: 0.89
Batch: 300; loss: 0.21; acc: 0.95
Batch: 320; loss: 0.47; acc: 0.84
Batch: 340; loss: 0.37; acc: 0.91
Batch: 360; loss: 0.38; acc: 0.86
Batch: 380; loss: 0.17; acc: 0.95
Batch: 400; loss: 0.4; acc: 0.91
Batch: 420; loss: 0.3; acc: 0.95
Batch: 440; loss: 0.35; acc: 0.89
Batch: 460; loss: 0.17; acc: 0.97
Batch: 480; loss: 0.19; acc: 0.97
Batch: 500; loss: 0.55; acc: 0.88
Batch: 520; loss: 0.21; acc: 0.94
Batch: 540; loss: 0.14; acc: 0.95
Batch: 560; loss: 0.3; acc: 0.88
Batch: 580; loss: 0.22; acc: 0.94
Batch: 600; loss: 0.3; acc: 0.89
Batch: 620; loss: 0.18; acc: 0.95
Batch: 640; loss: 0.24; acc: 0.92
Batch: 660; loss: 0.21; acc: 0.94
Batch: 680; loss: 0.09; acc: 0.97
Batch: 700; loss: 0.31; acc: 0.91
Batch: 720; loss: 0.16; acc: 0.95
Batch: 740; loss: 0.23; acc: 0.88
Batch: 760; loss: 0.15; acc: 0.95
Batch: 780; loss: 0.31; acc: 0.92
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

2.7837457309942693e-05
9.086960744753014e-06
Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.32; acc: 0.89
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.44; acc: 0.88
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.54; acc: 0.81
Batch: 140; loss: 0.1; acc: 0.94
Val Epoch over. val_loss: 0.222902318759329; val_accuracy: 0.9343152866242038 

The current subspace-distance is: 9.086960744753014e-06 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.17; acc: 0.92
Batch: 20; loss: 0.24; acc: 0.91
Batch: 40; loss: 0.31; acc: 0.91
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.36; acc: 0.91
Batch: 100; loss: 0.26; acc: 0.89
Batch: 120; loss: 0.25; acc: 0.91
Batch: 140; loss: 0.19; acc: 0.94
Batch: 160; loss: 0.39; acc: 0.88
Batch: 180; loss: 0.36; acc: 0.86
Batch: 200; loss: 0.28; acc: 0.91
Batch: 220; loss: 0.17; acc: 0.95
Batch: 240; loss: 0.5; acc: 0.81
Batch: 260; loss: 0.23; acc: 0.94
Batch: 280; loss: 0.19; acc: 0.97
Batch: 300; loss: 0.32; acc: 0.91
Batch: 320; loss: 0.17; acc: 0.91
Batch: 340; loss: 0.15; acc: 0.94
Batch: 360; loss: 0.27; acc: 0.92
Batch: 380; loss: 0.37; acc: 0.88
Batch: 400; loss: 0.33; acc: 0.92
Batch: 420; loss: 0.28; acc: 0.94
Batch: 440; loss: 0.2; acc: 0.92
Batch: 460; loss: 0.23; acc: 0.91
Batch: 480; loss: 0.3; acc: 0.91
Batch: 500; loss: 0.29; acc: 0.91
Batch: 520; loss: 0.14; acc: 0.97
Batch: 540; loss: 0.3; acc: 0.92
Batch: 560; loss: 0.42; acc: 0.92
Batch: 580; loss: 0.2; acc: 0.94
Batch: 600; loss: 0.19; acc: 0.94
Batch: 620; loss: 0.22; acc: 0.92
Batch: 640; loss: 0.47; acc: 0.86
Batch: 660; loss: 0.2; acc: 0.95
Batch: 680; loss: 0.32; acc: 0.92
Batch: 700; loss: 0.1; acc: 0.97
Batch: 720; loss: 0.15; acc: 0.94
Batch: 740; loss: 0.36; acc: 0.95
Batch: 760; loss: 0.19; acc: 0.94
Batch: 780; loss: 0.39; acc: 0.88
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

2.8984968594159e-05
9.1638503363356e-06
Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.3; acc: 0.89
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.4; acc: 0.89
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.21; acc: 0.95
Batch: 120; loss: 0.54; acc: 0.81
Batch: 140; loss: 0.13; acc: 0.95
Val Epoch over. val_loss: 0.2187276004463624; val_accuracy: 0.9361066878980892 

The current subspace-distance is: 9.1638503363356e-06 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.19; acc: 0.92
Batch: 40; loss: 0.2; acc: 0.91
Batch: 60; loss: 0.26; acc: 0.94
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.3; acc: 0.89
Batch: 120; loss: 0.28; acc: 0.94
Batch: 140; loss: 0.14; acc: 0.95
Batch: 160; loss: 0.17; acc: 0.95
Batch: 180; loss: 0.35; acc: 0.88
Batch: 200; loss: 0.19; acc: 0.94
Batch: 220; loss: 0.18; acc: 0.94
Batch: 240; loss: 0.31; acc: 0.92
Batch: 260; loss: 0.24; acc: 0.94
Batch: 280; loss: 0.24; acc: 0.94
Batch: 300; loss: 0.26; acc: 0.95
Batch: 320; loss: 0.26; acc: 0.91
Batch: 340; loss: 0.19; acc: 0.92
Batch: 360; loss: 0.1; acc: 0.97
Batch: 380; loss: 0.12; acc: 0.95
Batch: 400; loss: 0.29; acc: 0.92
Batch: 420; loss: 0.15; acc: 0.97
Batch: 440; loss: 0.3; acc: 0.94
Batch: 460; loss: 0.24; acc: 0.89
Batch: 480; loss: 0.1; acc: 0.98
Batch: 500; loss: 0.21; acc: 0.94
Batch: 520; loss: 0.28; acc: 0.94
Batch: 540; loss: 0.22; acc: 0.91
Batch: 560; loss: 0.26; acc: 0.89
Batch: 580; loss: 0.13; acc: 0.95
Batch: 600; loss: 0.26; acc: 0.92
Batch: 620; loss: 0.19; acc: 0.92
Batch: 640; loss: 0.1; acc: 0.97
Batch: 660; loss: 0.14; acc: 0.97
Batch: 680; loss: 0.18; acc: 0.91
Batch: 700; loss: 0.37; acc: 0.92
Batch: 720; loss: 0.22; acc: 0.94
Batch: 740; loss: 0.12; acc: 0.97
Batch: 760; loss: 0.16; acc: 0.94
Batch: 780; loss: 0.21; acc: 0.92
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

2.773551932477858e-05
9.894121831166558e-06
Batch: 0; loss: 0.2; acc: 0.92
Batch: 20; loss: 0.3; acc: 0.89
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.08; acc: 0.95
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.49; acc: 0.81
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.21261122874963057; val_accuracy: 0.9354100318471338 

The current subspace-distance is: 9.894121831166558e-06 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.31; acc: 0.89
Batch: 20; loss: 0.25; acc: 0.91
Batch: 40; loss: 0.29; acc: 0.91
Batch: 60; loss: 0.42; acc: 0.92
Batch: 80; loss: 0.39; acc: 0.89
Batch: 100; loss: 0.63; acc: 0.86
Batch: 120; loss: 0.06; acc: 0.98
Batch: 140; loss: 0.27; acc: 0.88
Batch: 160; loss: 0.25; acc: 0.94
Batch: 180; loss: 0.24; acc: 0.94
Batch: 200; loss: 0.37; acc: 0.91
Batch: 220; loss: 0.31; acc: 0.91
Batch: 240; loss: 0.36; acc: 0.94
Batch: 260; loss: 0.4; acc: 0.86
Batch: 280; loss: 0.52; acc: 0.88
Batch: 300; loss: 0.29; acc: 0.89
Batch: 320; loss: 0.32; acc: 0.84
Batch: 340; loss: 0.25; acc: 0.92
Batch: 360; loss: 0.11; acc: 0.97
Batch: 380; loss: 0.13; acc: 0.95
Batch: 400; loss: 0.22; acc: 0.92
Batch: 420; loss: 0.14; acc: 0.98
Batch: 440; loss: 0.16; acc: 0.92
Batch: 460; loss: 0.16; acc: 0.92
Batch: 480; loss: 0.36; acc: 0.92
Batch: 500; loss: 0.14; acc: 0.97
Batch: 520; loss: 0.41; acc: 0.88
Batch: 540; loss: 0.22; acc: 0.95
Batch: 560; loss: 0.21; acc: 0.95
Batch: 580; loss: 0.21; acc: 0.94
Batch: 600; loss: 0.13; acc: 0.95
Batch: 620; loss: 0.32; acc: 0.88
Batch: 640; loss: 0.29; acc: 0.91
Batch: 660; loss: 0.13; acc: 0.97
Batch: 680; loss: 0.31; acc: 0.89
Batch: 700; loss: 0.15; acc: 0.94
Batch: 720; loss: 0.21; acc: 0.94
Batch: 740; loss: 0.14; acc: 0.97
Batch: 760; loss: 0.11; acc: 0.97
Batch: 780; loss: 0.27; acc: 0.94
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

2.8321848731138743e-05
1.1215192898816895e-05
Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.31; acc: 0.89
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.38; acc: 0.92
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.55; acc: 0.83
Batch: 140; loss: 0.1; acc: 0.94
Val Epoch over. val_loss: 0.2114316659510895; val_accuracy: 0.9338176751592356 

The current subspace-distance is: 1.1215192898816895e-05 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.16; acc: 0.97
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.3; acc: 0.91
Batch: 60; loss: 0.12; acc: 0.94
Batch: 80; loss: 0.29; acc: 0.91
Batch: 100; loss: 0.24; acc: 0.89
Batch: 120; loss: 0.16; acc: 0.97
Batch: 140; loss: 0.2; acc: 0.97
Batch: 160; loss: 0.34; acc: 0.84
Batch: 180; loss: 0.15; acc: 0.92
Batch: 200; loss: 0.26; acc: 0.88
Batch: 220; loss: 0.31; acc: 0.91
Batch: 240; loss: 0.21; acc: 0.92
Batch: 260; loss: 0.28; acc: 0.91
Batch: 280; loss: 0.22; acc: 0.95
Batch: 300; loss: 0.29; acc: 0.92
Batch: 320; loss: 0.34; acc: 0.92
Batch: 340; loss: 0.17; acc: 0.91
Batch: 360; loss: 0.24; acc: 0.92
Batch: 380; loss: 0.31; acc: 0.91
Batch: 400; loss: 0.16; acc: 0.95
Batch: 420; loss: 0.13; acc: 0.97
Batch: 440; loss: 0.22; acc: 0.94
Batch: 460; loss: 0.28; acc: 0.95
Batch: 480; loss: 0.17; acc: 0.94
Batch: 500; loss: 0.17; acc: 0.94
Batch: 520; loss: 0.16; acc: 0.92
Batch: 540; loss: 0.13; acc: 0.95
Batch: 560; loss: 0.26; acc: 0.95
Batch: 580; loss: 0.09; acc: 1.0
Batch: 600; loss: 0.45; acc: 0.91
Batch: 620; loss: 0.26; acc: 0.91
Batch: 640; loss: 0.21; acc: 0.94
Batch: 660; loss: 0.13; acc: 0.95
Batch: 680; loss: 0.2; acc: 0.95
Batch: 700; loss: 0.21; acc: 0.97
Batch: 720; loss: 0.34; acc: 0.92
Batch: 740; loss: 0.16; acc: 0.95
Batch: 760; loss: 0.27; acc: 0.94
Batch: 780; loss: 0.21; acc: 0.89
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

2.7974878321401775e-05
9.709679943625815e-06
Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.43; acc: 0.89
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.21; acc: 0.92
Batch: 120; loss: 0.47; acc: 0.84
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.2157237947841359; val_accuracy: 0.9326234076433121 

The current subspace-distance is: 9.709679943625815e-06 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.42; acc: 0.89
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.26; acc: 0.89
Batch: 80; loss: 0.37; acc: 0.92
Batch: 100; loss: 0.14; acc: 0.97
Batch: 120; loss: 0.22; acc: 0.94
Batch: 140; loss: 0.21; acc: 0.91
Batch: 160; loss: 0.17; acc: 0.95
Batch: 180; loss: 0.22; acc: 0.94
Batch: 200; loss: 0.13; acc: 0.94
Batch: 220; loss: 0.17; acc: 0.94
Batch: 240; loss: 0.11; acc: 0.97
Batch: 260; loss: 0.19; acc: 0.97
Batch: 280; loss: 0.21; acc: 0.91
Batch: 300; loss: 0.19; acc: 0.95
Batch: 320; loss: 0.19; acc: 0.95
Batch: 340; loss: 0.14; acc: 0.91
Batch: 360; loss: 0.11; acc: 0.97
Batch: 380; loss: 0.21; acc: 0.92
Batch: 400; loss: 0.28; acc: 0.89
Batch: 420; loss: 0.18; acc: 0.95
Batch: 440; loss: 0.14; acc: 0.95
Batch: 460; loss: 0.07; acc: 1.0
Batch: 480; loss: 0.33; acc: 0.91
Batch: 500; loss: 0.15; acc: 0.94
Batch: 520; loss: 0.12; acc: 0.97
Batch: 540; loss: 0.19; acc: 0.92
Batch: 560; loss: 0.29; acc: 0.91
Batch: 580; loss: 0.14; acc: 0.95
Batch: 600; loss: 0.35; acc: 0.86
Batch: 620; loss: 0.45; acc: 0.88
Batch: 640; loss: 0.21; acc: 0.94
Batch: 660; loss: 0.23; acc: 0.91
Batch: 680; loss: 0.24; acc: 0.92
Batch: 700; loss: 0.11; acc: 0.97
Batch: 720; loss: 0.32; acc: 0.92
Batch: 740; loss: 0.2; acc: 0.92
Batch: 760; loss: 0.3; acc: 0.86
Batch: 780; loss: 0.23; acc: 0.89
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.925622175098397e-05
1.0076859325636178e-05
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.28; acc: 0.88
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.41; acc: 0.91
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.52; acc: 0.84
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.2036553113750971; val_accuracy: 0.9371019108280255 

The current subspace-distance is: 1.0076859325636178e-05 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.29; acc: 0.94
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.12; acc: 0.95
Batch: 80; loss: 0.14; acc: 0.94
Batch: 100; loss: 0.08; acc: 0.98
Batch: 120; loss: 0.44; acc: 0.88
Batch: 140; loss: 0.16; acc: 0.94
Batch: 160; loss: 0.11; acc: 0.97
Batch: 180; loss: 0.21; acc: 0.94
Batch: 200; loss: 0.46; acc: 0.89
Batch: 220; loss: 0.05; acc: 1.0
Batch: 240; loss: 0.31; acc: 0.95
Batch: 260; loss: 0.23; acc: 0.94
Batch: 280; loss: 0.17; acc: 0.95
Batch: 300; loss: 0.23; acc: 0.92
Batch: 320; loss: 0.19; acc: 0.94
Batch: 340; loss: 0.11; acc: 0.97
Batch: 360; loss: 0.17; acc: 0.92
Batch: 380; loss: 0.3; acc: 0.94
Batch: 400; loss: 0.15; acc: 0.95
Batch: 420; loss: 0.24; acc: 0.91
Batch: 440; loss: 0.34; acc: 0.94
Batch: 460; loss: 0.25; acc: 0.94
Batch: 480; loss: 0.11; acc: 0.98
Batch: 500; loss: 0.15; acc: 0.94
Batch: 520; loss: 0.21; acc: 0.95
Batch: 540; loss: 0.29; acc: 0.89
Batch: 560; loss: 0.24; acc: 0.92
Batch: 580; loss: 0.32; acc: 0.89
Batch: 600; loss: 0.09; acc: 0.98
Batch: 620; loss: 0.14; acc: 0.94
Batch: 640; loss: 0.13; acc: 0.98
Batch: 660; loss: 0.29; acc: 0.92
Batch: 680; loss: 0.16; acc: 0.97
Batch: 700; loss: 0.09; acc: 0.97
Batch: 720; loss: 0.26; acc: 0.92
Batch: 740; loss: 0.13; acc: 0.95
Batch: 760; loss: 0.17; acc: 0.97
Batch: 780; loss: 0.15; acc: 0.97
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.8458216547733173e-05
7.804058441251982e-06
Batch: 0; loss: 0.15; acc: 0.94
Batch: 20; loss: 0.31; acc: 0.88
Batch: 40; loss: 0.07; acc: 1.0
Batch: 60; loss: 0.43; acc: 0.91
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.58; acc: 0.83
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.20696629446213413; val_accuracy: 0.9373009554140127 

The current subspace-distance is: 7.804058441251982e-06 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.09; acc: 0.98
Batch: 20; loss: 0.22; acc: 0.95
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.38; acc: 0.91
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.53; acc: 0.89
Batch: 140; loss: 0.17; acc: 0.92
Batch: 160; loss: 0.28; acc: 0.89
Batch: 180; loss: 0.3; acc: 0.94
Batch: 200; loss: 0.34; acc: 0.92
Batch: 220; loss: 0.09; acc: 0.98
Batch: 240; loss: 0.34; acc: 0.86
Batch: 260; loss: 0.38; acc: 0.86
Batch: 280; loss: 0.16; acc: 0.94
Batch: 300; loss: 0.1; acc: 0.97
Batch: 320; loss: 0.38; acc: 0.88
Batch: 340; loss: 0.22; acc: 0.88
Batch: 360; loss: 0.22; acc: 0.92
Batch: 380; loss: 0.31; acc: 0.92
Batch: 400; loss: 0.29; acc: 0.91
Batch: 420; loss: 0.17; acc: 0.94
Batch: 440; loss: 0.79; acc: 0.83
Batch: 460; loss: 0.18; acc: 0.94
Batch: 480; loss: 0.27; acc: 0.92
Batch: 500; loss: 0.31; acc: 0.88
Batch: 520; loss: 0.33; acc: 0.92
Batch: 540; loss: 0.18; acc: 0.92
Batch: 560; loss: 0.35; acc: 0.89
Batch: 580; loss: 0.21; acc: 0.94
Batch: 600; loss: 0.23; acc: 0.94
Batch: 620; loss: 0.29; acc: 0.91
Batch: 640; loss: 0.26; acc: 0.94
Batch: 660; loss: 0.25; acc: 0.94
Batch: 680; loss: 0.1; acc: 0.98
Batch: 700; loss: 0.14; acc: 0.95
Batch: 720; loss: 0.29; acc: 0.88
Batch: 740; loss: 0.36; acc: 0.91
Batch: 760; loss: 0.12; acc: 0.98
Batch: 780; loss: 0.42; acc: 0.88
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.7573492843657732e-05
8.726709893380757e-06
Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.06; acc: 1.0
Batch: 60; loss: 0.42; acc: 0.91
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.51; acc: 0.83
Batch: 140; loss: 0.09; acc: 0.95
Val Epoch over. val_loss: 0.20770313438906032; val_accuracy: 0.9370023885350318 

The current subspace-distance is: 8.726709893380757e-06 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.27; acc: 0.92
Batch: 20; loss: 0.2; acc: 0.97
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.35; acc: 0.95
Batch: 80; loss: 0.22; acc: 0.95
Batch: 100; loss: 0.08; acc: 0.98
Batch: 120; loss: 0.17; acc: 0.92
Batch: 140; loss: 0.18; acc: 0.95
Batch: 160; loss: 0.23; acc: 0.89
Batch: 180; loss: 0.22; acc: 0.92
Batch: 200; loss: 0.11; acc: 0.95
Batch: 220; loss: 0.27; acc: 0.91
Batch: 240; loss: 0.17; acc: 0.94
Batch: 260; loss: 0.28; acc: 0.92
Batch: 280; loss: 0.15; acc: 0.95
Batch: 300; loss: 0.18; acc: 0.95
Batch: 320; loss: 0.11; acc: 0.97
Batch: 340; loss: 0.35; acc: 0.91
Batch: 360; loss: 0.22; acc: 0.91
Batch: 380; loss: 0.36; acc: 0.91
Batch: 400; loss: 0.29; acc: 0.91
Batch: 420; loss: 0.27; acc: 0.89
Batch: 440; loss: 0.17; acc: 0.95
Batch: 460; loss: 0.16; acc: 0.92
Batch: 480; loss: 0.3; acc: 0.92
Batch: 500; loss: 0.26; acc: 0.92
Batch: 520; loss: 0.05; acc: 1.0
Batch: 540; loss: 0.11; acc: 0.98
Batch: 560; loss: 0.16; acc: 0.94
Batch: 580; loss: 0.22; acc: 0.89
Batch: 600; loss: 0.24; acc: 0.92
Batch: 620; loss: 0.16; acc: 0.92
Batch: 640; loss: 0.4; acc: 0.88
Batch: 660; loss: 0.22; acc: 0.92
Batch: 680; loss: 0.19; acc: 0.94
Batch: 700; loss: 0.23; acc: 0.94
Batch: 720; loss: 0.1; acc: 0.94
Batch: 740; loss: 0.26; acc: 0.92
Batch: 760; loss: 0.13; acc: 0.95
Batch: 780; loss: 0.33; acc: 0.92
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.750239582383074e-05
9.815534212975763e-06
Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.41; acc: 0.91
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.55; acc: 0.83
Batch: 140; loss: 0.1; acc: 0.94
Val Epoch over. val_loss: 0.20239966056624037; val_accuracy: 0.9384952229299363 

The current subspace-distance is: 9.815534212975763e-06 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.37; acc: 0.89
Batch: 40; loss: 0.33; acc: 0.92
Batch: 60; loss: 0.24; acc: 0.92
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.09; acc: 0.97
Batch: 140; loss: 0.18; acc: 0.95
Batch: 160; loss: 0.17; acc: 0.95
Batch: 180; loss: 0.31; acc: 0.89
Batch: 200; loss: 0.12; acc: 0.97
Batch: 220; loss: 0.25; acc: 0.95
Batch: 240; loss: 0.15; acc: 0.95
Batch: 260; loss: 0.13; acc: 0.97
Batch: 280; loss: 0.12; acc: 0.95
Batch: 300; loss: 0.15; acc: 0.95
Batch: 320; loss: 0.12; acc: 0.94
Batch: 340; loss: 0.13; acc: 0.95
Batch: 360; loss: 0.17; acc: 0.92
Batch: 380; loss: 0.32; acc: 0.91
Batch: 400; loss: 0.24; acc: 0.94
Batch: 420; loss: 0.14; acc: 0.95
Batch: 440; loss: 0.18; acc: 0.92
Batch: 460; loss: 0.46; acc: 0.88
Batch: 480; loss: 0.11; acc: 0.98
Batch: 500; loss: 0.25; acc: 0.95
Batch: 520; loss: 0.16; acc: 0.94
Batch: 540; loss: 0.29; acc: 0.91
Batch: 560; loss: 0.07; acc: 0.98
Batch: 580; loss: 0.1; acc: 0.98
Batch: 600; loss: 0.17; acc: 0.95
Batch: 620; loss: 0.16; acc: 0.97
Batch: 640; loss: 0.16; acc: 0.98
Batch: 660; loss: 0.27; acc: 0.89
Batch: 680; loss: 0.29; acc: 0.95
Batch: 700; loss: 0.06; acc: 0.98
Batch: 720; loss: 0.15; acc: 0.95
Batch: 740; loss: 0.17; acc: 0.94
Batch: 760; loss: 0.35; acc: 0.92
Batch: 780; loss: 0.15; acc: 0.95
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.9481911042239517e-05
9.143680472334381e-06
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.3; acc: 0.89
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.41; acc: 0.91
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.22; acc: 0.95
Batch: 120; loss: 0.59; acc: 0.81
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.2081496732629788; val_accuracy: 0.9375995222929936 

The current subspace-distance is: 9.143680472334381e-06 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.15; acc: 0.94
Batch: 20; loss: 0.32; acc: 0.86
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.29; acc: 0.94
Batch: 80; loss: 0.4; acc: 0.86
Batch: 100; loss: 0.21; acc: 0.92
Batch: 120; loss: 0.08; acc: 0.98
Batch: 140; loss: 0.24; acc: 0.94
Batch: 160; loss: 0.24; acc: 0.89
Batch: 180; loss: 0.19; acc: 0.92
Batch: 200; loss: 0.28; acc: 0.91
Batch: 220; loss: 0.38; acc: 0.89
Batch: 240; loss: 0.14; acc: 0.95
Batch: 260; loss: 0.25; acc: 0.92
Batch: 280; loss: 0.24; acc: 0.92
Batch: 300; loss: 0.25; acc: 0.92
Batch: 320; loss: 0.11; acc: 0.97
Batch: 340; loss: 0.17; acc: 0.94
Batch: 360; loss: 0.22; acc: 0.91
Batch: 380; loss: 0.12; acc: 0.92
Batch: 400; loss: 0.12; acc: 0.97
Batch: 420; loss: 0.21; acc: 0.94
Batch: 440; loss: 0.13; acc: 0.94
Batch: 460; loss: 0.34; acc: 0.92
Batch: 480; loss: 0.21; acc: 0.97
Batch: 500; loss: 0.23; acc: 0.92
Batch: 520; loss: 0.23; acc: 0.94
Batch: 540; loss: 0.22; acc: 0.92
Batch: 560; loss: 0.21; acc: 0.95
Batch: 580; loss: 0.18; acc: 0.95
Batch: 600; loss: 0.26; acc: 0.89
Batch: 620; loss: 0.13; acc: 0.95
Batch: 640; loss: 0.34; acc: 0.94
Batch: 660; loss: 0.33; acc: 0.91
Batch: 680; loss: 0.14; acc: 0.95
Batch: 700; loss: 0.15; acc: 0.94
Batch: 720; loss: 0.29; acc: 0.92
Batch: 740; loss: 0.11; acc: 0.98
Batch: 760; loss: 0.33; acc: 0.88
Batch: 780; loss: 0.05; acc: 1.0
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.7510184736456722e-05
8.287879609270021e-06
Batch: 0; loss: 0.11; acc: 0.95
Batch: 20; loss: 0.25; acc: 0.88
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.41; acc: 0.91
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.53; acc: 0.84
Batch: 140; loss: 0.07; acc: 1.0
Val Epoch over. val_loss: 0.20081067320172954; val_accuracy: 0.9368033439490446 

The current subspace-distance is: 8.287879609270021e-06 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.11; acc: 0.95
Batch: 40; loss: 0.32; acc: 0.89
Batch: 60; loss: 0.49; acc: 0.86
Batch: 80; loss: 0.41; acc: 0.88
Batch: 100; loss: 0.11; acc: 0.97
Batch: 120; loss: 0.15; acc: 0.95
Batch: 140; loss: 0.16; acc: 0.97
Batch: 160; loss: 0.32; acc: 0.89
Batch: 180; loss: 0.13; acc: 0.92
Batch: 200; loss: 0.14; acc: 0.94
Batch: 220; loss: 0.34; acc: 0.91
Batch: 240; loss: 0.12; acc: 0.95
Batch: 260; loss: 0.24; acc: 0.95
Batch: 280; loss: 0.3; acc: 0.89
Batch: 300; loss: 0.26; acc: 0.95
Batch: 320; loss: 0.31; acc: 0.92
Batch: 340; loss: 0.15; acc: 0.94
Batch: 360; loss: 0.13; acc: 0.95
Batch: 380; loss: 0.39; acc: 0.88
Batch: 400; loss: 0.11; acc: 0.97
Batch: 420; loss: 0.45; acc: 0.86
Batch: 440; loss: 0.14; acc: 0.95
Batch: 460; loss: 0.27; acc: 0.92
Batch: 480; loss: 0.19; acc: 0.92
Batch: 500; loss: 0.4; acc: 0.86
Batch: 520; loss: 0.17; acc: 0.95
Batch: 540; loss: 0.2; acc: 0.95
Batch: 560; loss: 0.27; acc: 0.89
Batch: 580; loss: 0.36; acc: 0.92
Batch: 600; loss: 0.19; acc: 0.92
Batch: 620; loss: 0.3; acc: 0.89
Batch: 640; loss: 0.15; acc: 0.94
Batch: 660; loss: 0.29; acc: 0.94
Batch: 680; loss: 0.28; acc: 0.92
Batch: 700; loss: 0.25; acc: 0.88
Batch: 720; loss: 0.3; acc: 0.91
Batch: 740; loss: 0.24; acc: 0.91
Batch: 760; loss: 0.29; acc: 0.94
Batch: 780; loss: 0.11; acc: 0.98
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.7643936846288852e-05
8.565074494981673e-06
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.26; acc: 0.92
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.4; acc: 0.91
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.56; acc: 0.81
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.20342238370779972; val_accuracy: 0.9372014331210191 

The current subspace-distance is: 8.565074494981673e-06 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.22; acc: 0.95
Batch: 20; loss: 0.24; acc: 0.95
Batch: 40; loss: 0.23; acc: 0.92
Batch: 60; loss: 0.37; acc: 0.88
Batch: 80; loss: 0.2; acc: 0.89
Batch: 100; loss: 0.11; acc: 0.98
Batch: 120; loss: 0.27; acc: 0.94
Batch: 140; loss: 0.39; acc: 0.91
Batch: 160; loss: 0.33; acc: 0.92
Batch: 180; loss: 0.22; acc: 0.89
Batch: 200; loss: 0.05; acc: 0.98
Batch: 220; loss: 0.19; acc: 0.95
Batch: 240; loss: 0.17; acc: 0.94
Batch: 260; loss: 0.32; acc: 0.89
Batch: 280; loss: 0.16; acc: 0.98
Batch: 300; loss: 0.36; acc: 0.91
Batch: 320; loss: 0.1; acc: 0.97
Batch: 340; loss: 0.28; acc: 0.94
Batch: 360; loss: 0.33; acc: 0.94
Batch: 380; loss: 0.22; acc: 0.92
Batch: 400; loss: 0.24; acc: 0.92
Batch: 420; loss: 0.37; acc: 0.91
Batch: 440; loss: 0.15; acc: 0.95
Batch: 460; loss: 0.2; acc: 0.97
Batch: 480; loss: 0.13; acc: 0.98
Batch: 500; loss: 0.35; acc: 0.94
Batch: 520; loss: 0.22; acc: 0.89
Batch: 540; loss: 0.3; acc: 0.92
Batch: 560; loss: 0.23; acc: 0.92
Batch: 580; loss: 0.19; acc: 0.92
Batch: 600; loss: 0.25; acc: 0.91
Batch: 620; loss: 0.21; acc: 0.91
Batch: 640; loss: 0.05; acc: 1.0
Batch: 660; loss: 0.45; acc: 0.83
Batch: 680; loss: 0.16; acc: 0.95
Batch: 700; loss: 0.25; acc: 0.92
Batch: 720; loss: 0.1; acc: 0.97
Batch: 740; loss: 0.4; acc: 0.91
Batch: 760; loss: 0.36; acc: 0.86
Batch: 780; loss: 0.64; acc: 0.89
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.8128668418503366e-05
8.81194955582032e-06
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.26; acc: 0.92
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.42; acc: 0.89
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.53; acc: 0.84
Batch: 140; loss: 0.08; acc: 0.97
Val Epoch over. val_loss: 0.2032760072997801; val_accuracy: 0.9379976114649682 

The current subspace-distance is: 8.81194955582032e-06 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.15; acc: 0.97
Batch: 40; loss: 0.18; acc: 0.92
Batch: 60; loss: 0.16; acc: 0.97
Batch: 80; loss: 0.25; acc: 0.91
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.15; acc: 0.94
Batch: 140; loss: 0.19; acc: 0.95
Batch: 160; loss: 0.14; acc: 0.95
Batch: 180; loss: 0.19; acc: 0.92
Batch: 200; loss: 0.13; acc: 0.95
Batch: 220; loss: 0.28; acc: 0.92
Batch: 240; loss: 0.2; acc: 0.94
Batch: 260; loss: 0.6; acc: 0.83
Batch: 280; loss: 0.32; acc: 0.89
Batch: 300; loss: 0.24; acc: 0.92
Batch: 320; loss: 0.2; acc: 0.94
Batch: 340; loss: 0.21; acc: 0.92
Batch: 360; loss: 0.25; acc: 0.89
Batch: 380; loss: 0.44; acc: 0.86
Batch: 400; loss: 0.16; acc: 0.95
Batch: 420; loss: 0.24; acc: 0.92
Batch: 440; loss: 0.39; acc: 0.84
Batch: 460; loss: 0.18; acc: 0.94
Batch: 480; loss: 0.13; acc: 0.95
Batch: 500; loss: 0.09; acc: 0.98
Batch: 520; loss: 0.2; acc: 0.92
Batch: 540; loss: 0.1; acc: 0.95
Batch: 560; loss: 0.23; acc: 0.92
Batch: 580; loss: 0.28; acc: 0.89
Batch: 600; loss: 0.18; acc: 0.94
Batch: 620; loss: 0.09; acc: 0.98
Batch: 640; loss: 0.11; acc: 0.98
Batch: 660; loss: 0.11; acc: 0.95
Batch: 680; loss: 0.31; acc: 0.91
Batch: 700; loss: 0.21; acc: 0.92
Batch: 720; loss: 0.24; acc: 0.94
Batch: 740; loss: 0.13; acc: 0.97
Batch: 760; loss: 0.22; acc: 0.94
Batch: 780; loss: 0.16; acc: 0.94
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.8785501854144968e-05
8.916813385440037e-06
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.27; acc: 0.86
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.46; acc: 0.91
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.58; acc: 0.84
Batch: 140; loss: 0.09; acc: 0.95
Val Epoch over. val_loss: 0.21262255605239017; val_accuracy: 0.9350119426751592 

The current subspace-distance is: 8.916813385440037e-06 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.27; acc: 0.91
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.28; acc: 0.89
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.18; acc: 0.92
Batch: 140; loss: 0.08; acc: 0.97
Batch: 160; loss: 0.32; acc: 0.92
Batch: 180; loss: 0.29; acc: 0.91
Batch: 200; loss: 0.09; acc: 0.97
Batch: 220; loss: 0.31; acc: 0.84
Batch: 240; loss: 0.15; acc: 0.92
Batch: 260; loss: 0.09; acc: 0.97
Batch: 280; loss: 0.13; acc: 0.97
Batch: 300; loss: 0.26; acc: 0.92
Batch: 320; loss: 0.42; acc: 0.89
Batch: 340; loss: 0.2; acc: 0.94
Batch: 360; loss: 0.15; acc: 0.95
Batch: 380; loss: 0.26; acc: 0.92
Batch: 400; loss: 0.31; acc: 0.91
Batch: 420; loss: 0.11; acc: 0.97
Batch: 440; loss: 0.7; acc: 0.86
Batch: 460; loss: 0.27; acc: 0.91
Batch: 480; loss: 0.1; acc: 0.94
Batch: 500; loss: 0.15; acc: 0.95
Batch: 520; loss: 0.23; acc: 0.92
Batch: 540; loss: 0.15; acc: 0.94
Batch: 560; loss: 0.16; acc: 0.95
Batch: 580; loss: 0.43; acc: 0.89
Batch: 600; loss: 0.16; acc: 0.95
Batch: 620; loss: 0.38; acc: 0.92
Batch: 640; loss: 0.36; acc: 0.88
Batch: 660; loss: 0.13; acc: 0.97
Batch: 680; loss: 0.25; acc: 0.95
Batch: 700; loss: 0.25; acc: 0.94
Batch: 720; loss: 0.2; acc: 0.94
Batch: 740; loss: 0.16; acc: 0.94
Batch: 760; loss: 0.12; acc: 0.97
Batch: 780; loss: 0.19; acc: 0.92
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.8517462851596065e-05
9.926475286192726e-06
Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.42; acc: 0.91
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.57; acc: 0.83
Batch: 140; loss: 0.06; acc: 1.0
Val Epoch over. val_loss: 0.20075240883098286; val_accuracy: 0.9379976114649682 

The current subspace-distance is: 9.926475286192726e-06 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.21; acc: 0.91
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.2; acc: 0.89
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.31; acc: 0.89
Batch: 140; loss: 0.48; acc: 0.84
Batch: 160; loss: 0.21; acc: 0.91
Batch: 180; loss: 0.13; acc: 0.94
Batch: 200; loss: 0.31; acc: 0.89
Batch: 220; loss: 0.22; acc: 0.95
Batch: 240; loss: 0.19; acc: 0.95
Batch: 260; loss: 0.29; acc: 0.95
Batch: 280; loss: 0.17; acc: 0.94
Batch: 300; loss: 0.44; acc: 0.92
Batch: 320; loss: 0.19; acc: 0.92
Batch: 340; loss: 0.15; acc: 0.95
Batch: 360; loss: 0.2; acc: 0.95
Batch: 380; loss: 0.1; acc: 0.97
Batch: 400; loss: 0.1; acc: 0.98
Batch: 420; loss: 0.21; acc: 0.91
Batch: 440; loss: 0.37; acc: 0.92
Batch: 460; loss: 0.49; acc: 0.91
Batch: 480; loss: 0.05; acc: 1.0
Batch: 500; loss: 0.18; acc: 0.95
Batch: 520; loss: 0.26; acc: 0.94
Batch: 540; loss: 0.19; acc: 0.94
Batch: 560; loss: 0.27; acc: 0.92
Batch: 580; loss: 0.22; acc: 0.95
Batch: 600; loss: 0.33; acc: 0.84
Batch: 620; loss: 0.18; acc: 0.92
Batch: 640; loss: 0.35; acc: 0.89
Batch: 660; loss: 0.21; acc: 0.95
Batch: 680; loss: 0.11; acc: 0.95
Batch: 700; loss: 0.29; acc: 0.89
Batch: 720; loss: 0.24; acc: 0.92
Batch: 740; loss: 0.21; acc: 0.91
Batch: 760; loss: 0.34; acc: 0.88
Batch: 780; loss: 0.13; acc: 0.94
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.9210645152488723e-05
9.470518307352904e-06
Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.25; acc: 0.89
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.43; acc: 0.91
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.55; acc: 0.84
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.1981757237653064; val_accuracy: 0.939390923566879 

The current subspace-distance is: 9.470518307352904e-06 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.26; acc: 0.94
Batch: 40; loss: 0.27; acc: 0.91
Batch: 60; loss: 0.2; acc: 0.92
Batch: 80; loss: 0.22; acc: 0.92
Batch: 100; loss: 0.24; acc: 0.91
Batch: 120; loss: 0.21; acc: 0.91
Batch: 140; loss: 0.29; acc: 0.89
Batch: 160; loss: 0.12; acc: 0.97
Batch: 180; loss: 0.16; acc: 0.95
Batch: 200; loss: 0.28; acc: 0.88
Batch: 220; loss: 0.24; acc: 0.92
Batch: 240; loss: 0.09; acc: 0.98
Batch: 260; loss: 0.06; acc: 1.0
Batch: 280; loss: 0.32; acc: 0.94
Batch: 300; loss: 0.87; acc: 0.84
Batch: 320; loss: 0.19; acc: 0.91
Batch: 340; loss: 0.39; acc: 0.92
Batch: 360; loss: 0.19; acc: 0.98
Batch: 380; loss: 0.14; acc: 0.94
Batch: 400; loss: 0.11; acc: 0.98
Batch: 420; loss: 0.36; acc: 0.91
Batch: 440; loss: 0.15; acc: 0.95
Batch: 460; loss: 0.15; acc: 0.94
Batch: 480; loss: 0.11; acc: 0.95
Batch: 500; loss: 0.32; acc: 0.91
Batch: 520; loss: 0.22; acc: 0.95
Batch: 540; loss: 0.11; acc: 0.98
Batch: 560; loss: 0.2; acc: 0.95
Batch: 580; loss: 0.18; acc: 0.94
Batch: 600; loss: 0.17; acc: 0.94
Batch: 620; loss: 0.37; acc: 0.84
Batch: 640; loss: 0.15; acc: 0.95
Batch: 660; loss: 0.1; acc: 0.95
Batch: 680; loss: 0.28; acc: 0.92
Batch: 700; loss: 0.18; acc: 0.92
Batch: 720; loss: 0.19; acc: 0.95
Batch: 740; loss: 0.11; acc: 0.97
Batch: 760; loss: 0.22; acc: 0.95
Batch: 780; loss: 0.22; acc: 0.95
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.8493204808910377e-05
1.0476239367562812e-05
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.26; acc: 0.92
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.42; acc: 0.91
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.56; acc: 0.84
Batch: 140; loss: 0.07; acc: 1.0
Val Epoch over. val_loss: 0.2001027756246032; val_accuracy: 0.9372014331210191 

The current subspace-distance is: 1.0476239367562812e-05 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.11; acc: 0.95
Batch: 20; loss: 0.39; acc: 0.84
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.16; acc: 0.92
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.24; acc: 0.94
Batch: 140; loss: 0.16; acc: 0.95
Batch: 160; loss: 0.12; acc: 0.95
Batch: 180; loss: 0.33; acc: 0.89
Batch: 200; loss: 0.09; acc: 0.98
Batch: 220; loss: 0.27; acc: 0.94
Batch: 240; loss: 0.4; acc: 0.83
Batch: 260; loss: 0.27; acc: 0.92
Batch: 280; loss: 0.11; acc: 0.97
Batch: 300; loss: 0.17; acc: 0.92
Batch: 320; loss: 0.15; acc: 0.95
Batch: 340; loss: 0.21; acc: 0.95
Batch: 360; loss: 0.16; acc: 0.95
Batch: 380; loss: 0.1; acc: 0.97
Batch: 400; loss: 0.27; acc: 0.92
Batch: 420; loss: 0.26; acc: 0.89
Batch: 440; loss: 0.23; acc: 0.92
Batch: 460; loss: 0.15; acc: 0.95
Batch: 480; loss: 0.2; acc: 0.95
Batch: 500; loss: 0.23; acc: 0.91
Batch: 520; loss: 0.14; acc: 0.95
Batch: 540; loss: 0.17; acc: 0.97
Batch: 560; loss: 0.23; acc: 0.92
Batch: 580; loss: 0.28; acc: 0.92
Batch: 600; loss: 0.19; acc: 0.92
Batch: 620; loss: 0.35; acc: 0.92
Batch: 640; loss: 0.23; acc: 0.91
Batch: 660; loss: 0.17; acc: 0.92
Batch: 680; loss: 0.32; acc: 0.94
Batch: 700; loss: 0.16; acc: 0.94
Batch: 720; loss: 0.27; acc: 0.92
Batch: 740; loss: 0.17; acc: 0.95
Batch: 760; loss: 0.22; acc: 0.92
Batch: 780; loss: 0.23; acc: 0.94
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.8840076993219554e-05
9.863955710898153e-06
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.42; acc: 0.91
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.54; acc: 0.84
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.19886019636111654; val_accuracy: 0.9379976114649682 

The current subspace-distance is: 9.863955710898153e-06 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.17; acc: 0.92
Batch: 20; loss: 0.27; acc: 0.94
Batch: 40; loss: 0.28; acc: 0.91
Batch: 60; loss: 0.28; acc: 0.89
Batch: 80; loss: 0.15; acc: 0.94
Batch: 100; loss: 0.38; acc: 0.89
Batch: 120; loss: 0.14; acc: 0.92
Batch: 140; loss: 0.21; acc: 0.91
Batch: 160; loss: 0.2; acc: 0.97
Batch: 180; loss: 0.12; acc: 0.95
Batch: 200; loss: 0.25; acc: 0.94
Batch: 220; loss: 0.27; acc: 0.95
Batch: 240; loss: 0.18; acc: 0.95
Batch: 260; loss: 0.14; acc: 0.95
Batch: 280; loss: 0.27; acc: 0.95
Batch: 300; loss: 0.21; acc: 0.94
Batch: 320; loss: 0.32; acc: 0.84
Batch: 340; loss: 0.25; acc: 0.91
Batch: 360; loss: 0.08; acc: 0.98
Batch: 380; loss: 0.13; acc: 0.95
Batch: 400; loss: 0.22; acc: 0.92
Batch: 420; loss: 0.2; acc: 0.94
Batch: 440; loss: 0.3; acc: 0.92
Batch: 460; loss: 0.14; acc: 0.95
Batch: 480; loss: 0.11; acc: 0.95
Batch: 500; loss: 0.1; acc: 0.97
Batch: 520; loss: 0.14; acc: 0.97
Batch: 540; loss: 0.2; acc: 0.92
Batch: 560; loss: 0.28; acc: 0.92
Batch: 580; loss: 0.14; acc: 0.97
Batch: 600; loss: 0.2; acc: 0.91
Batch: 620; loss: 0.24; acc: 0.92
Batch: 640; loss: 0.07; acc: 0.98
Batch: 660; loss: 0.41; acc: 0.91
Batch: 680; loss: 0.14; acc: 0.98
Batch: 700; loss: 0.38; acc: 0.89
Batch: 720; loss: 0.07; acc: 0.98
Batch: 740; loss: 0.24; acc: 0.92
Batch: 760; loss: 0.12; acc: 0.97
Batch: 780; loss: 0.13; acc: 0.95
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.877355473174248e-05
8.565055395592935e-06
Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.25; acc: 0.89
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.43; acc: 0.91
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.53; acc: 0.84
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.19746972297786908; val_accuracy: 0.9395899681528662 

The current subspace-distance is: 8.565055395592935e-06 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.49; acc: 0.94
Batch: 20; loss: 0.2; acc: 0.95
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.21; acc: 0.94
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.29; acc: 0.92
Batch: 140; loss: 0.2; acc: 0.94
Batch: 160; loss: 0.22; acc: 0.94
Batch: 180; loss: 0.07; acc: 0.98
Batch: 200; loss: 0.33; acc: 0.86
Batch: 220; loss: 0.25; acc: 0.97
Batch: 240; loss: 0.23; acc: 0.91
Batch: 260; loss: 0.22; acc: 0.89
Batch: 280; loss: 0.44; acc: 0.91
Batch: 300; loss: 0.13; acc: 0.95
Batch: 320; loss: 0.3; acc: 0.88
Batch: 340; loss: 0.22; acc: 0.94
Batch: 360; loss: 0.23; acc: 0.94
Batch: 380; loss: 0.13; acc: 0.97
Batch: 400; loss: 0.19; acc: 0.92
Batch: 420; loss: 0.36; acc: 0.89
Batch: 440; loss: 0.34; acc: 0.91
Batch: 460; loss: 0.21; acc: 0.95
Batch: 480; loss: 0.35; acc: 0.94
Batch: 500; loss: 0.13; acc: 0.92
Batch: 520; loss: 0.33; acc: 0.89
Batch: 540; loss: 0.28; acc: 0.91
Batch: 560; loss: 0.08; acc: 0.97
Batch: 580; loss: 0.28; acc: 0.92
Batch: 600; loss: 0.16; acc: 0.95
Batch: 620; loss: 0.29; acc: 0.91
Batch: 640; loss: 0.54; acc: 0.83
Batch: 660; loss: 0.1; acc: 1.0
Batch: 680; loss: 0.1; acc: 0.98
Batch: 700; loss: 0.1; acc: 0.97
Batch: 720; loss: 0.26; acc: 0.91
Batch: 740; loss: 0.31; acc: 0.89
Batch: 760; loss: 0.26; acc: 0.91
Batch: 780; loss: 0.28; acc: 0.94
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.964362829516176e-05
1.0108709830092266e-05
Batch: 0; loss: 0.13; acc: 0.94
Batch: 20; loss: 0.25; acc: 0.91
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.43; acc: 0.91
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.53; acc: 0.84
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.19779690499803063; val_accuracy: 0.9387937898089171 

The current subspace-distance is: 1.0108709830092266e-05 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.26; acc: 0.91
Batch: 60; loss: 0.24; acc: 0.92
Batch: 80; loss: 0.06; acc: 1.0
Batch: 100; loss: 0.2; acc: 0.97
Batch: 120; loss: 0.17; acc: 0.97
Batch: 140; loss: 0.29; acc: 0.92
Batch: 160; loss: 0.14; acc: 0.95
Batch: 180; loss: 0.42; acc: 0.89
Batch: 200; loss: 0.15; acc: 0.95
Batch: 220; loss: 0.15; acc: 0.94
Batch: 240; loss: 0.25; acc: 0.92
Batch: 260; loss: 0.35; acc: 0.89
Batch: 280; loss: 0.28; acc: 0.92
Batch: 300; loss: 0.2; acc: 0.91
Batch: 320; loss: 0.31; acc: 0.89
Batch: 340; loss: 0.21; acc: 0.97
Batch: 360; loss: 0.29; acc: 0.88
Batch: 380; loss: 0.23; acc: 0.92
Batch: 400; loss: 0.07; acc: 0.98
Batch: 420; loss: 0.33; acc: 0.92
Batch: 440; loss: 0.21; acc: 0.95
Batch: 460; loss: 0.26; acc: 0.97
Batch: 480; loss: 0.31; acc: 0.91
Batch: 500; loss: 0.25; acc: 0.92
Batch: 520; loss: 0.22; acc: 0.92
Batch: 540; loss: 0.3; acc: 0.89
Batch: 560; loss: 0.2; acc: 0.95
Batch: 580; loss: 0.34; acc: 0.92
Batch: 600; loss: 0.29; acc: 0.94
Batch: 620; loss: 0.41; acc: 0.88
Batch: 640; loss: 0.41; acc: 0.89
Batch: 660; loss: 0.29; acc: 0.94
Batch: 680; loss: 0.09; acc: 0.98
Batch: 700; loss: 0.08; acc: 0.97
Batch: 720; loss: 0.16; acc: 0.95
Batch: 740; loss: 0.17; acc: 0.92
Batch: 760; loss: 0.28; acc: 0.91
Batch: 780; loss: 0.19; acc: 0.92
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.9774995709885843e-05
1.0416385521239135e-05
Batch: 0; loss: 0.13; acc: 0.94
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.43; acc: 0.91
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.55; acc: 0.84
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.201005875115182; val_accuracy: 0.9379976114649682 

The current subspace-distance is: 1.0416385521239135e-05 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.14; acc: 0.97
Batch: 20; loss: 0.19; acc: 0.95
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.31; acc: 0.94
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.24; acc: 0.91
Batch: 120; loss: 0.31; acc: 0.91
Batch: 140; loss: 0.14; acc: 0.95
Batch: 160; loss: 0.24; acc: 0.89
Batch: 180; loss: 0.13; acc: 0.95
Batch: 200; loss: 0.17; acc: 0.92
Batch: 220; loss: 0.17; acc: 0.94
Batch: 240; loss: 0.29; acc: 0.94
Batch: 260; loss: 0.2; acc: 0.95
Batch: 280; loss: 0.14; acc: 0.94
Batch: 300; loss: 0.23; acc: 0.92
Batch: 320; loss: 0.23; acc: 0.92
Batch: 340; loss: 0.42; acc: 0.84
Batch: 360; loss: 0.14; acc: 0.98
Batch: 380; loss: 0.25; acc: 0.94
Batch: 400; loss: 0.23; acc: 0.89
Batch: 420; loss: 0.27; acc: 0.94
Batch: 440; loss: 0.08; acc: 0.98
Batch: 460; loss: 0.18; acc: 0.94
Batch: 480; loss: 0.18; acc: 0.91
Batch: 500; loss: 0.24; acc: 0.94
Batch: 520; loss: 0.15; acc: 0.95
Batch: 540; loss: 0.19; acc: 0.94
Batch: 560; loss: 0.09; acc: 1.0
Batch: 580; loss: 0.26; acc: 0.91
Batch: 600; loss: 0.21; acc: 0.92
Batch: 620; loss: 0.15; acc: 0.95
Batch: 640; loss: 0.36; acc: 0.88
Batch: 660; loss: 0.22; acc: 0.92
Batch: 680; loss: 0.09; acc: 0.97
Batch: 700; loss: 0.28; acc: 0.94
Batch: 720; loss: 0.19; acc: 0.91
Batch: 740; loss: 0.26; acc: 0.92
Batch: 760; loss: 0.15; acc: 0.94
Batch: 780; loss: 0.22; acc: 0.94
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.9060074666631408e-05
8.514086403010879e-06
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.27; acc: 0.91
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.44; acc: 0.91
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.53; acc: 0.84
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.2003498880584149; val_accuracy: 0.9381966560509554 

The current subspace-distance is: 8.514086403010879e-06 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.14; acc: 0.94
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.2; acc: 0.91
Batch: 80; loss: 0.14; acc: 0.92
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.22; acc: 0.91
Batch: 140; loss: 0.32; acc: 0.89
Batch: 160; loss: 0.15; acc: 0.97
Batch: 180; loss: 0.08; acc: 0.98
Batch: 200; loss: 0.18; acc: 0.92
Batch: 220; loss: 0.27; acc: 0.92
Batch: 240; loss: 0.35; acc: 0.89
Batch: 260; loss: 0.12; acc: 0.92
Batch: 280; loss: 0.28; acc: 0.92
Batch: 300; loss: 0.33; acc: 0.92
Batch: 320; loss: 0.17; acc: 0.95
Batch: 340; loss: 0.2; acc: 0.95
Batch: 360; loss: 0.13; acc: 0.94
Batch: 380; loss: 0.2; acc: 0.94
Batch: 400; loss: 0.11; acc: 0.95
Batch: 420; loss: 0.32; acc: 0.94
Batch: 440; loss: 0.23; acc: 0.92
Batch: 460; loss: 0.14; acc: 0.95
Batch: 480; loss: 0.23; acc: 0.91
Batch: 500; loss: 0.16; acc: 0.95
Batch: 520; loss: 0.36; acc: 0.89
Batch: 540; loss: 0.25; acc: 0.91
Batch: 560; loss: 0.25; acc: 0.94
Batch: 580; loss: 0.17; acc: 0.97
Batch: 600; loss: 0.29; acc: 0.94
Batch: 620; loss: 0.12; acc: 0.97
Batch: 640; loss: 0.16; acc: 0.95
Batch: 660; loss: 0.13; acc: 0.95
Batch: 680; loss: 0.21; acc: 0.92
Batch: 700; loss: 0.43; acc: 0.86
Batch: 720; loss: 0.11; acc: 0.95
Batch: 740; loss: 0.28; acc: 0.91
Batch: 760; loss: 0.16; acc: 0.95
Batch: 780; loss: 0.18; acc: 0.94
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.877529368561227e-05
1.0195666618528776e-05
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.42; acc: 0.91
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.53; acc: 0.84
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.1994491826956439; val_accuracy: 0.9376990445859873 

The current subspace-distance is: 1.0195666618528776e-05 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.33; acc: 0.89
Batch: 20; loss: 0.37; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.1; acc: 0.98
Batch: 80; loss: 0.32; acc: 0.94
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.18; acc: 0.94
Batch: 140; loss: 0.25; acc: 0.92
Batch: 160; loss: 0.12; acc: 0.95
Batch: 180; loss: 0.2; acc: 0.94
Batch: 200; loss: 0.34; acc: 0.91
Batch: 220; loss: 0.12; acc: 0.98
Batch: 240; loss: 0.28; acc: 0.91
Batch: 260; loss: 0.35; acc: 0.88
Batch: 280; loss: 0.2; acc: 0.91
Batch: 300; loss: 0.41; acc: 0.91
Batch: 320; loss: 0.31; acc: 0.91
Batch: 340; loss: 0.33; acc: 0.94
Batch: 360; loss: 0.06; acc: 1.0
Batch: 380; loss: 0.15; acc: 0.94
Batch: 400; loss: 0.31; acc: 0.94
Batch: 420; loss: 0.31; acc: 0.92
Batch: 440; loss: 0.11; acc: 0.97
Batch: 460; loss: 0.23; acc: 0.91
Batch: 480; loss: 0.09; acc: 0.97
Batch: 500; loss: 0.13; acc: 0.95
Batch: 520; loss: 0.28; acc: 0.94
Batch: 540; loss: 0.12; acc: 0.94
Batch: 560; loss: 0.23; acc: 0.91
Batch: 580; loss: 0.29; acc: 0.94
Batch: 600; loss: 0.08; acc: 0.98
Batch: 620; loss: 0.19; acc: 0.89
Batch: 640; loss: 0.11; acc: 0.97
Batch: 660; loss: 0.19; acc: 0.94
Batch: 680; loss: 0.08; acc: 0.98
Batch: 700; loss: 0.26; acc: 0.92
Batch: 720; loss: 0.29; acc: 0.92
Batch: 740; loss: 0.42; acc: 0.86
Batch: 760; loss: 0.19; acc: 0.94
Batch: 780; loss: 0.22; acc: 0.92
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.857432446035091e-05
9.42464430409018e-06
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.27; acc: 0.91
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.44; acc: 0.91
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.57; acc: 0.83
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.2027355951203662; val_accuracy: 0.9370023885350318 

The current subspace-distance is: 9.42464430409018e-06 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.17; acc: 0.94
Batch: 20; loss: 0.35; acc: 0.89
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.18; acc: 0.95
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.12; acc: 0.97
Batch: 140; loss: 0.17; acc: 0.94
Batch: 160; loss: 0.41; acc: 0.89
Batch: 180; loss: 0.22; acc: 0.91
Batch: 200; loss: 0.18; acc: 0.95
Batch: 220; loss: 0.25; acc: 0.91
Batch: 240; loss: 0.25; acc: 0.95
Batch: 260; loss: 0.23; acc: 0.92
Batch: 280; loss: 0.19; acc: 0.97
Batch: 300; loss: 0.2; acc: 0.92
Batch: 320; loss: 0.2; acc: 0.92
Batch: 340; loss: 0.2; acc: 0.92
Batch: 360; loss: 0.21; acc: 0.94
Batch: 380; loss: 0.24; acc: 0.94
Batch: 400; loss: 0.19; acc: 0.95
Batch: 420; loss: 0.21; acc: 0.94
Batch: 440; loss: 0.31; acc: 0.91
Batch: 460; loss: 0.11; acc: 0.97
Batch: 480; loss: 0.16; acc: 0.97
Batch: 500; loss: 0.23; acc: 0.92
Batch: 520; loss: 0.13; acc: 0.97
Batch: 540; loss: 0.13; acc: 0.95
Batch: 560; loss: 0.09; acc: 0.97
Batch: 580; loss: 0.2; acc: 0.94
Batch: 600; loss: 0.32; acc: 0.92
Batch: 620; loss: 0.17; acc: 0.95
Batch: 640; loss: 0.15; acc: 0.97
Batch: 660; loss: 0.23; acc: 0.92
Batch: 680; loss: 0.28; acc: 0.91
Batch: 700; loss: 0.2; acc: 0.95
Batch: 720; loss: 0.13; acc: 0.94
Batch: 740; loss: 0.22; acc: 0.91
Batch: 760; loss: 0.07; acc: 1.0
Batch: 780; loss: 0.2; acc: 0.94
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.8324400773271918e-05
1.0726089385570958e-05
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.26; acc: 0.89
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.43; acc: 0.91
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.55; acc: 0.84
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.1992320180603653; val_accuracy: 0.93859474522293 

The current subspace-distance is: 1.0726089385570958e-05 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.14; acc: 0.98
Batch: 20; loss: 0.22; acc: 0.91
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.13; acc: 0.95
Batch: 80; loss: 0.22; acc: 0.97
Batch: 100; loss: 0.35; acc: 0.88
Batch: 120; loss: 0.27; acc: 0.92
Batch: 140; loss: 0.17; acc: 0.95
Batch: 160; loss: 0.36; acc: 0.89
Batch: 180; loss: 0.36; acc: 0.92
Batch: 200; loss: 0.17; acc: 0.94
Batch: 220; loss: 0.37; acc: 0.88
Batch: 240; loss: 0.21; acc: 0.92
Batch: 260; loss: 0.11; acc: 0.95
Batch: 280; loss: 0.3; acc: 0.92
Batch: 300; loss: 0.15; acc: 0.95
Batch: 320; loss: 0.21; acc: 0.97
Batch: 340; loss: 0.12; acc: 0.98
Batch: 360; loss: 0.45; acc: 0.94
Batch: 380; loss: 0.34; acc: 0.95
Batch: 400; loss: 0.3; acc: 0.92
Batch: 420; loss: 0.15; acc: 0.94
Batch: 440; loss: 0.26; acc: 0.92
Batch: 460; loss: 0.31; acc: 0.91
Batch: 480; loss: 0.09; acc: 0.98
Batch: 500; loss: 0.07; acc: 0.97
Batch: 520; loss: 0.15; acc: 0.94
Batch: 540; loss: 0.17; acc: 0.94
Batch: 560; loss: 0.36; acc: 0.91
Batch: 580; loss: 0.35; acc: 0.91
Batch: 600; loss: 0.27; acc: 0.94
Batch: 620; loss: 0.14; acc: 0.97
Batch: 640; loss: 0.2; acc: 0.92
Batch: 660; loss: 0.12; acc: 0.98
Batch: 680; loss: 0.12; acc: 0.97
Batch: 700; loss: 0.19; acc: 0.94
Batch: 720; loss: 0.26; acc: 0.91
Batch: 740; loss: 0.15; acc: 0.95
Batch: 760; loss: 0.11; acc: 0.97
Batch: 780; loss: 0.07; acc: 0.97
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.834293081832584e-05
1.0268382538924925e-05
Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.25; acc: 0.89
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.43; acc: 0.91
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.54; acc: 0.84
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.19755591373819453; val_accuracy: 0.9383957006369427 

The current subspace-distance is: 1.0268382538924925e-05 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.12; acc: 0.95
Batch: 40; loss: 0.33; acc: 0.94
Batch: 60; loss: 0.23; acc: 0.92
Batch: 80; loss: 0.42; acc: 0.89
Batch: 100; loss: 0.23; acc: 0.91
Batch: 120; loss: 0.41; acc: 0.86
Batch: 140; loss: 0.17; acc: 0.95
Batch: 160; loss: 0.31; acc: 0.92
Batch: 180; loss: 0.23; acc: 0.91
Batch: 200; loss: 0.21; acc: 0.97
Batch: 220; loss: 0.21; acc: 0.94
Batch: 240; loss: 0.16; acc: 0.94
Batch: 260; loss: 0.16; acc: 0.95
Batch: 280; loss: 0.16; acc: 0.95
Batch: 300; loss: 0.1; acc: 0.97
Batch: 320; loss: 0.25; acc: 0.89
Batch: 340; loss: 0.16; acc: 0.95
Batch: 360; loss: 0.19; acc: 0.95
Batch: 380; loss: 0.08; acc: 0.98
Batch: 400; loss: 0.37; acc: 0.89
Batch: 420; loss: 0.17; acc: 0.95
Batch: 440; loss: 0.3; acc: 0.89
Batch: 460; loss: 0.08; acc: 0.97
Batch: 480; loss: 0.11; acc: 0.97
Batch: 500; loss: 0.18; acc: 0.92
Batch: 520; loss: 0.32; acc: 0.88
Batch: 540; loss: 0.18; acc: 0.94
Batch: 560; loss: 0.28; acc: 0.94
Batch: 580; loss: 0.26; acc: 0.91
Batch: 600; loss: 0.27; acc: 0.95
Batch: 620; loss: 0.3; acc: 0.91
Batch: 640; loss: 0.16; acc: 0.95
Batch: 660; loss: 0.16; acc: 0.94
Batch: 680; loss: 0.14; acc: 0.97
Batch: 700; loss: 0.22; acc: 0.94
Batch: 720; loss: 0.31; acc: 0.88
Batch: 740; loss: 0.14; acc: 0.95
Batch: 760; loss: 0.13; acc: 0.97
Batch: 780; loss: 0.16; acc: 0.97
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.8981303330510855e-05
9.420400601811707e-06
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.26; acc: 0.89
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.43; acc: 0.91
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.53; acc: 0.84
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.19879124522398992; val_accuracy: 0.9378980891719745 

The current subspace-distance is: 9.420400601811707e-06 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.36; acc: 0.92
Batch: 20; loss: 0.41; acc: 0.91
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.23; acc: 0.92
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.21; acc: 0.92
Batch: 140; loss: 0.19; acc: 0.97
Batch: 160; loss: 0.16; acc: 0.94
Batch: 180; loss: 0.17; acc: 0.91
Batch: 200; loss: 0.26; acc: 0.91
Batch: 220; loss: 0.23; acc: 0.89
Batch: 240; loss: 0.3; acc: 0.91
Batch: 260; loss: 0.28; acc: 0.95
Batch: 280; loss: 0.14; acc: 0.94
Batch: 300; loss: 0.18; acc: 0.95
Batch: 320; loss: 0.15; acc: 0.94
Batch: 340; loss: 0.08; acc: 0.98
Batch: 360; loss: 0.17; acc: 0.97
Batch: 380; loss: 0.25; acc: 0.91
Batch: 400; loss: 0.11; acc: 0.97
Batch: 420; loss: 0.22; acc: 0.94
Batch: 440; loss: 0.11; acc: 0.95
Batch: 460; loss: 0.09; acc: 0.98
Batch: 480; loss: 0.21; acc: 0.94
Batch: 500; loss: 0.27; acc: 0.91
Batch: 520; loss: 0.35; acc: 0.94
Batch: 540; loss: 0.3; acc: 0.91
Batch: 560; loss: 0.12; acc: 0.95
Batch: 580; loss: 0.29; acc: 0.91
Batch: 600; loss: 0.23; acc: 0.89
Batch: 620; loss: 0.23; acc: 0.94
Batch: 640; loss: 0.09; acc: 0.97
Batch: 660; loss: 0.1; acc: 0.97
Batch: 680; loss: 0.27; acc: 0.89
Batch: 700; loss: 0.09; acc: 0.97
Batch: 720; loss: 0.42; acc: 0.91
Batch: 740; loss: 0.43; acc: 0.88
Batch: 760; loss: 0.18; acc: 0.92
Batch: 780; loss: 0.25; acc: 0.91
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.8764083253918216e-05
9.375381523568649e-06
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.26; acc: 0.89
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.43; acc: 0.91
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.55; acc: 0.84
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.199090705792995; val_accuracy: 0.9386942675159236 

The current subspace-distance is: 9.375381523568649e-06 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.28; acc: 0.89
Batch: 20; loss: 0.52; acc: 0.84
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.46; acc: 0.92
Batch: 80; loss: 0.25; acc: 0.89
Batch: 100; loss: 0.28; acc: 0.92
Batch: 120; loss: 0.2; acc: 0.94
Batch: 140; loss: 0.31; acc: 0.92
Batch: 160; loss: 0.19; acc: 0.92
Batch: 180; loss: 0.31; acc: 0.91
Batch: 200; loss: 0.28; acc: 0.91
Batch: 220; loss: 0.14; acc: 0.94
Batch: 240; loss: 0.29; acc: 0.91
Batch: 260; loss: 0.29; acc: 0.88
Batch: 280; loss: 0.24; acc: 0.94
Batch: 300; loss: 0.24; acc: 0.92
Batch: 320; loss: 0.2; acc: 0.95
Batch: 340; loss: 0.2; acc: 0.97
Batch: 360; loss: 0.17; acc: 0.95
Batch: 380; loss: 0.29; acc: 0.95
Batch: 400; loss: 0.35; acc: 0.89
Batch: 420; loss: 0.25; acc: 0.94
Batch: 440; loss: 0.3; acc: 0.89
Batch: 460; loss: 0.1; acc: 0.98
Batch: 480; loss: 0.27; acc: 0.91
Batch: 500; loss: 0.56; acc: 0.88
Batch: 520; loss: 0.14; acc: 0.95
Batch: 540; loss: 0.1; acc: 0.97
Batch: 560; loss: 0.17; acc: 0.95
Batch: 580; loss: 0.5; acc: 0.91
Batch: 600; loss: 0.28; acc: 0.91
Batch: 620; loss: 0.2; acc: 0.95
Batch: 640; loss: 0.3; acc: 0.86
Batch: 660; loss: 0.3; acc: 0.89
Batch: 680; loss: 0.18; acc: 0.92
Batch: 700; loss: 0.08; acc: 0.98
Batch: 720; loss: 0.23; acc: 0.95
Batch: 740; loss: 0.44; acc: 0.89
Batch: 760; loss: 0.18; acc: 0.95
Batch: 780; loss: 0.1; acc: 0.97
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.7807893275166862e-05
9.832808245846536e-06
Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.25; acc: 0.91
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.43; acc: 0.91
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.53; acc: 0.84
Batch: 140; loss: 0.07; acc: 1.0
Val Epoch over. val_loss: 0.19797321095777926; val_accuracy: 0.9399880573248408 

The current subspace-distance is: 9.832808245846536e-06 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.09; acc: 0.98
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.2; acc: 0.92
Batch: 60; loss: 0.23; acc: 0.91
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.19; acc: 0.94
Batch: 140; loss: 0.09; acc: 0.97
Batch: 160; loss: 0.09; acc: 0.97
Batch: 180; loss: 0.13; acc: 0.97
Batch: 200; loss: 0.28; acc: 0.94
Batch: 220; loss: 0.06; acc: 1.0
Batch: 240; loss: 0.32; acc: 0.89
Batch: 260; loss: 0.26; acc: 0.94
Batch: 280; loss: 0.24; acc: 0.91
Batch: 300; loss: 0.09; acc: 0.97
Batch: 320; loss: 0.28; acc: 0.89
Batch: 340; loss: 0.15; acc: 0.95
Batch: 360; loss: 0.14; acc: 0.97
Batch: 380; loss: 0.17; acc: 0.97
Batch: 400; loss: 0.11; acc: 0.97
Batch: 420; loss: 0.2; acc: 0.94
Batch: 440; loss: 0.27; acc: 0.89
Batch: 460; loss: 0.17; acc: 0.97
Batch: 480; loss: 0.25; acc: 0.94
Batch: 500; loss: 0.09; acc: 0.97
Batch: 520; loss: 0.14; acc: 0.94
Batch: 540; loss: 0.26; acc: 0.94
Batch: 560; loss: 0.06; acc: 0.98
Batch: 580; loss: 0.19; acc: 0.94
Batch: 600; loss: 0.33; acc: 0.92
Batch: 620; loss: 0.17; acc: 0.94
Batch: 640; loss: 0.34; acc: 0.92
Batch: 660; loss: 0.24; acc: 0.94
Batch: 680; loss: 0.3; acc: 0.94
Batch: 700; loss: 0.41; acc: 0.89
Batch: 720; loss: 0.39; acc: 0.88
Batch: 740; loss: 0.25; acc: 0.89
Batch: 760; loss: 0.2; acc: 0.97
Batch: 780; loss: 0.21; acc: 0.92
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.7783005862147547e-05
8.972447176347487e-06
Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.25; acc: 0.89
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.43; acc: 0.91
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.53; acc: 0.84
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.19805051353137204; val_accuracy: 0.9391918789808917 

The current subspace-distance is: 8.972447176347487e-06 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.22; acc: 0.95
Batch: 20; loss: 0.3; acc: 0.92
Batch: 40; loss: 0.23; acc: 0.92
Batch: 60; loss: 0.28; acc: 0.89
Batch: 80; loss: 0.16; acc: 0.92
Batch: 100; loss: 0.14; acc: 0.97
Batch: 120; loss: 0.25; acc: 0.94
Batch: 140; loss: 0.25; acc: 0.92
Batch: 160; loss: 0.18; acc: 0.92
Batch: 180; loss: 0.1; acc: 0.97
Batch: 200; loss: 0.14; acc: 0.95
Batch: 220; loss: 0.22; acc: 0.97
Batch: 240; loss: 0.08; acc: 0.98
Batch: 260; loss: 0.13; acc: 0.95
Batch: 280; loss: 0.28; acc: 0.94
Batch: 300; loss: 0.27; acc: 0.94
Batch: 320; loss: 0.46; acc: 0.94
Batch: 340; loss: 0.18; acc: 0.92
Batch: 360; loss: 0.21; acc: 0.91
Batch: 380; loss: 0.36; acc: 0.89
Batch: 400; loss: 0.13; acc: 0.97
Batch: 420; loss: 0.36; acc: 0.91
Batch: 440; loss: 0.12; acc: 0.97
Batch: 460; loss: 0.22; acc: 0.95
Batch: 480; loss: 0.21; acc: 0.95
Batch: 500; loss: 0.19; acc: 0.92
Batch: 520; loss: 0.24; acc: 0.92
Batch: 540; loss: 0.53; acc: 0.86
Batch: 560; loss: 0.2; acc: 0.92
Batch: 580; loss: 0.2; acc: 0.94
Batch: 600; loss: 0.13; acc: 0.97
Batch: 620; loss: 0.66; acc: 0.88
Batch: 640; loss: 0.19; acc: 0.95
Batch: 660; loss: 0.19; acc: 0.97
Batch: 680; loss: 0.1; acc: 0.97
Batch: 700; loss: 0.05; acc: 1.0
Batch: 720; loss: 0.16; acc: 0.92
Batch: 740; loss: 0.18; acc: 0.94
Batch: 760; loss: 0.4; acc: 0.91
Batch: 780; loss: 0.19; acc: 0.95
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.921601480920799e-05
9.87351631920319e-06
Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.25; acc: 0.91
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.42; acc: 0.91
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.54; acc: 0.84
Batch: 140; loss: 0.07; acc: 1.0
Val Epoch over. val_loss: 0.19955016288218225; val_accuracy: 0.9383957006369427 

The current subspace-distance is: 9.87351631920319e-06 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.14; acc: 0.94
Batch: 20; loss: 0.24; acc: 0.91
Batch: 40; loss: 0.22; acc: 0.92
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.28; acc: 0.89
Batch: 120; loss: 0.22; acc: 0.91
Batch: 140; loss: 0.37; acc: 0.89
Batch: 160; loss: 0.24; acc: 0.94
Batch: 180; loss: 0.17; acc: 0.97
Batch: 200; loss: 0.17; acc: 0.94
Batch: 220; loss: 0.25; acc: 0.92
Batch: 240; loss: 0.09; acc: 0.98
Batch: 260; loss: 0.32; acc: 0.94
Batch: 280; loss: 0.09; acc: 0.97
Batch: 300; loss: 0.13; acc: 0.95
Batch: 320; loss: 0.21; acc: 0.92
Batch: 340; loss: 0.37; acc: 0.91
Batch: 360; loss: 0.29; acc: 0.89
Batch: 380; loss: 0.24; acc: 0.94
Batch: 400; loss: 0.15; acc: 0.94
Batch: 420; loss: 0.29; acc: 0.89
Batch: 440; loss: 0.14; acc: 0.97
Batch: 460; loss: 0.15; acc: 0.95
Batch: 480; loss: 0.08; acc: 0.97
Batch: 500; loss: 0.11; acc: 0.95
Batch: 520; loss: 0.25; acc: 0.92
Batch: 540; loss: 0.23; acc: 0.91
Batch: 560; loss: 0.26; acc: 0.92
Batch: 580; loss: 0.11; acc: 0.95
Batch: 600; loss: 0.26; acc: 0.86
Batch: 620; loss: 0.17; acc: 0.98
Batch: 640; loss: 0.19; acc: 0.95
Batch: 660; loss: 0.14; acc: 0.92
Batch: 680; loss: 0.29; acc: 0.91
Batch: 700; loss: 0.37; acc: 0.92
Batch: 720; loss: 0.2; acc: 0.94
Batch: 740; loss: 0.23; acc: 0.95
Batch: 760; loss: 0.34; acc: 0.94
Batch: 780; loss: 0.2; acc: 0.95
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.917035817517899e-05
9.926514394464903e-06
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.25; acc: 0.91
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.44; acc: 0.91
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.54; acc: 0.84
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.19842260696326092; val_accuracy: 0.9390923566878981 

The current subspace-distance is: 9.926514394464903e-06 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.16; acc: 0.98
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.18; acc: 0.92
Batch: 100; loss: 0.21; acc: 0.94
Batch: 120; loss: 0.31; acc: 0.89
Batch: 140; loss: 0.33; acc: 0.89
Batch: 160; loss: 0.23; acc: 0.92
Batch: 180; loss: 0.25; acc: 0.92
Batch: 200; loss: 0.28; acc: 0.91
Batch: 220; loss: 0.2; acc: 0.95
Batch: 240; loss: 0.18; acc: 0.95
Batch: 260; loss: 0.31; acc: 0.92
Batch: 280; loss: 0.35; acc: 0.89
Batch: 300; loss: 0.28; acc: 0.95
Batch: 320; loss: 0.32; acc: 0.94
Batch: 340; loss: 0.1; acc: 0.98
Batch: 360; loss: 0.17; acc: 0.91
Batch: 380; loss: 0.23; acc: 0.94
Batch: 400; loss: 0.2; acc: 0.91
Batch: 420; loss: 0.26; acc: 0.91
Batch: 440; loss: 0.17; acc: 0.92
Batch: 460; loss: 0.18; acc: 0.92
Batch: 480; loss: 0.29; acc: 0.95
Batch: 500; loss: 0.37; acc: 0.92
Batch: 520; loss: 0.15; acc: 0.94
Batch: 540; loss: 0.23; acc: 0.92
Batch: 560; loss: 0.31; acc: 0.91
Batch: 580; loss: 0.12; acc: 0.97
Batch: 600; loss: 0.19; acc: 0.95
Batch: 620; loss: 0.17; acc: 0.97
Batch: 640; loss: 0.19; acc: 0.95
Batch: 660; loss: 0.07; acc: 0.97
Batch: 680; loss: 0.17; acc: 0.92
Batch: 700; loss: 0.27; acc: 0.91
Batch: 720; loss: 0.27; acc: 0.95
Batch: 740; loss: 0.15; acc: 0.95
Batch: 760; loss: 0.27; acc: 0.92
Batch: 780; loss: 0.17; acc: 0.95
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.9868695492041297e-05
9.306794709118549e-06
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.25; acc: 0.91
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.43; acc: 0.91
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.54; acc: 0.84
Batch: 140; loss: 0.07; acc: 1.0
Val Epoch over. val_loss: 0.1987592628949387; val_accuracy: 0.9380971337579618 

The current subspace-distance is: 9.306794709118549e-06 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.16; acc: 0.92
Batch: 20; loss: 0.2; acc: 0.92
Batch: 40; loss: 0.2; acc: 0.97
Batch: 60; loss: 0.11; acc: 0.95
Batch: 80; loss: 0.15; acc: 0.94
Batch: 100; loss: 0.09; acc: 0.98
Batch: 120; loss: 0.12; acc: 0.97
Batch: 140; loss: 0.21; acc: 0.94
Batch: 160; loss: 0.17; acc: 0.95
Batch: 180; loss: 0.15; acc: 0.95
Batch: 200; loss: 0.3; acc: 0.91
Batch: 220; loss: 0.29; acc: 0.92
Batch: 240; loss: 0.2; acc: 0.94
Batch: 260; loss: 0.17; acc: 0.95
Batch: 280; loss: 0.32; acc: 0.94
Batch: 300; loss: 0.14; acc: 0.97
Batch: 320; loss: 0.16; acc: 0.94
Batch: 340; loss: 0.47; acc: 0.84
Batch: 360; loss: 0.21; acc: 0.91
Batch: 380; loss: 0.16; acc: 0.94
Batch: 400; loss: 0.25; acc: 0.94
Batch: 420; loss: 0.06; acc: 1.0
Batch: 440; loss: 0.18; acc: 0.94
Batch: 460; loss: 0.16; acc: 0.94
Batch: 480; loss: 0.18; acc: 0.94
Batch: 500; loss: 0.15; acc: 0.95
Batch: 520; loss: 0.38; acc: 0.89
Batch: 540; loss: 0.23; acc: 0.92
Batch: 560; loss: 0.22; acc: 0.92
Batch: 580; loss: 0.1; acc: 0.97
Batch: 600; loss: 0.22; acc: 0.95
Batch: 620; loss: 0.16; acc: 0.95
Batch: 640; loss: 0.24; acc: 0.95
Batch: 660; loss: 0.11; acc: 0.97
Batch: 680; loss: 0.08; acc: 0.98
Batch: 700; loss: 0.18; acc: 0.94
Batch: 720; loss: 0.14; acc: 0.95
Batch: 740; loss: 0.2; acc: 0.97
Batch: 760; loss: 0.37; acc: 0.89
Batch: 780; loss: 0.43; acc: 0.88
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.8439662855817005e-05
7.812875082890969e-06
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.25; acc: 0.89
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.43; acc: 0.91
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.54; acc: 0.84
Batch: 140; loss: 0.07; acc: 1.0
Val Epoch over. val_loss: 0.19865483202182563; val_accuracy: 0.9386942675159236 

The current subspace-distance is: 7.812875082890969e-06 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.22; acc: 0.95
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.23; acc: 0.91
Batch: 80; loss: 0.41; acc: 0.91
Batch: 100; loss: 0.08; acc: 1.0
Batch: 120; loss: 0.13; acc: 0.97
Batch: 140; loss: 0.18; acc: 0.94
Batch: 160; loss: 0.27; acc: 0.92
Batch: 180; loss: 0.19; acc: 0.89
Batch: 200; loss: 0.17; acc: 0.95
Batch: 220; loss: 0.2; acc: 0.91
Batch: 240; loss: 0.33; acc: 0.94
Batch: 260; loss: 0.32; acc: 0.95
Batch: 280; loss: 0.11; acc: 0.95
Batch: 300; loss: 0.18; acc: 0.94
Batch: 320; loss: 0.14; acc: 0.94
Batch: 340; loss: 0.07; acc: 0.98
Batch: 360; loss: 0.27; acc: 0.92
Batch: 380; loss: 0.24; acc: 0.92
Batch: 400; loss: 0.24; acc: 0.92
Batch: 420; loss: 0.16; acc: 0.92
Batch: 440; loss: 0.12; acc: 0.95
Batch: 460; loss: 0.29; acc: 0.95
Batch: 480; loss: 0.27; acc: 0.91
Batch: 500; loss: 0.15; acc: 0.95
Batch: 520; loss: 0.19; acc: 0.92
Batch: 540; loss: 0.19; acc: 0.95
Batch: 560; loss: 0.36; acc: 0.91
Batch: 580; loss: 0.26; acc: 0.91
Batch: 600; loss: 0.31; acc: 0.92
Batch: 620; loss: 0.29; acc: 0.95
Batch: 640; loss: 0.15; acc: 0.95
Batch: 660; loss: 0.26; acc: 0.94
Batch: 680; loss: 0.17; acc: 0.95
Batch: 700; loss: 0.18; acc: 0.94
Batch: 720; loss: 0.05; acc: 1.0
Batch: 740; loss: 0.26; acc: 0.95
Batch: 760; loss: 0.14; acc: 0.95
Batch: 780; loss: 0.16; acc: 0.95
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.847607720468659e-05
9.812556527322158e-06
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.25; acc: 0.91
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.44; acc: 0.91
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.53; acc: 0.84
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.1984579032109042; val_accuracy: 0.9397890127388535 

The current subspace-distance is: 9.812556527322158e-06 

plots/subspace_training/reg_lenet_3/2020-01-22 20:51:04/d_dim_190_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
nonzero elements in E: 42354
elements in E: 8998000
fraction nonzero: 0.004707046010224494
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.31; acc: 0.08
Batch: 20; loss: 2.29; acc: 0.03
Batch: 40; loss: 2.3; acc: 0.08
Batch: 60; loss: 2.3; acc: 0.02
Batch: 80; loss: 2.3; acc: 0.06
Batch: 100; loss: 2.3; acc: 0.09
Batch: 120; loss: 2.3; acc: 0.09
Batch: 140; loss: 2.31; acc: 0.08
Batch: 160; loss: 2.3; acc: 0.06
Batch: 180; loss: 2.3; acc: 0.11
Batch: 200; loss: 2.29; acc: 0.16
Batch: 220; loss: 2.3; acc: 0.06
Batch: 240; loss: 2.3; acc: 0.05
Batch: 260; loss: 2.3; acc: 0.09
Batch: 280; loss: 2.28; acc: 0.05
Batch: 300; loss: 2.29; acc: 0.05
Batch: 320; loss: 2.29; acc: 0.08
Batch: 340; loss: 2.29; acc: 0.08
Batch: 360; loss: 2.28; acc: 0.19
Batch: 380; loss: 2.29; acc: 0.09
Batch: 400; loss: 2.29; acc: 0.19
Batch: 420; loss: 2.3; acc: 0.16
Batch: 440; loss: 2.28; acc: 0.22
Batch: 460; loss: 2.29; acc: 0.2
Batch: 480; loss: 2.28; acc: 0.2
Batch: 500; loss: 2.26; acc: 0.19
Batch: 520; loss: 2.26; acc: 0.25
Batch: 540; loss: 2.26; acc: 0.25
Batch: 560; loss: 2.26; acc: 0.11
Batch: 580; loss: 2.25; acc: 0.22
Batch: 600; loss: 2.25; acc: 0.25
Batch: 620; loss: 2.23; acc: 0.33
Batch: 640; loss: 2.24; acc: 0.36
Batch: 660; loss: 2.23; acc: 0.31
Batch: 680; loss: 2.26; acc: 0.17
Batch: 700; loss: 2.22; acc: 0.25
Batch: 720; loss: 2.2; acc: 0.36
Batch: 740; loss: 2.19; acc: 0.34
Batch: 760; loss: 2.19; acc: 0.25
Batch: 780; loss: 2.17; acc: 0.27
Train Epoch over. train_loss: 2.27; train_accuracy: 0.16 

6.731822850269964e-06
1.8379524817646598e-06
Batch: 0; loss: 2.1; acc: 0.31
Batch: 20; loss: 2.19; acc: 0.17
Batch: 40; loss: 2.07; acc: 0.39
Batch: 60; loss: 2.1; acc: 0.31
Batch: 80; loss: 2.08; acc: 0.44
Batch: 100; loss: 2.11; acc: 0.31
Batch: 120; loss: 2.16; acc: 0.22
Batch: 140; loss: 2.14; acc: 0.3
Val Epoch over. val_loss: 2.1204784599838744; val_accuracy: 0.306031050955414 

The current subspace-distance is: 1.8379524817646598e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 2.13; acc: 0.31
Batch: 20; loss: 2.08; acc: 0.34
Batch: 40; loss: 1.97; acc: 0.45
Batch: 60; loss: 1.75; acc: 0.53
Batch: 80; loss: 1.6; acc: 0.59
Batch: 100; loss: 1.72; acc: 0.45
Batch: 120; loss: 1.51; acc: 0.58
Batch: 140; loss: 1.05; acc: 0.67
Batch: 160; loss: 1.34; acc: 0.61
Batch: 180; loss: 1.01; acc: 0.69
Batch: 200; loss: 0.86; acc: 0.7
Batch: 220; loss: 1.22; acc: 0.66
Batch: 240; loss: 0.88; acc: 0.73
Batch: 260; loss: 0.98; acc: 0.7
Batch: 280; loss: 0.72; acc: 0.78
Batch: 300; loss: 0.58; acc: 0.84
Batch: 320; loss: 0.81; acc: 0.72
Batch: 340; loss: 1.07; acc: 0.67
Batch: 360; loss: 0.64; acc: 0.73
Batch: 380; loss: 0.52; acc: 0.88
Batch: 400; loss: 0.58; acc: 0.83
Batch: 420; loss: 0.78; acc: 0.73
Batch: 440; loss: 0.74; acc: 0.75
Batch: 460; loss: 0.81; acc: 0.67
Batch: 480; loss: 0.58; acc: 0.75
Batch: 500; loss: 0.78; acc: 0.81
Batch: 520; loss: 0.5; acc: 0.8
Batch: 540; loss: 0.39; acc: 0.91
Batch: 560; loss: 0.47; acc: 0.84
Batch: 580; loss: 0.71; acc: 0.77
Batch: 600; loss: 0.76; acc: 0.81
Batch: 620; loss: 0.41; acc: 0.94
Batch: 640; loss: 0.54; acc: 0.84
Batch: 660; loss: 0.68; acc: 0.78
Batch: 680; loss: 0.6; acc: 0.81
Batch: 700; loss: 0.71; acc: 0.75
Batch: 720; loss: 0.66; acc: 0.86
Batch: 740; loss: 0.61; acc: 0.83
Batch: 760; loss: 0.7; acc: 0.75
Batch: 780; loss: 0.43; acc: 0.84
Train Epoch over. train_loss: 0.92; train_accuracy: 0.71 

1.7057182049029507e-05
5.483625500346534e-06
Batch: 0; loss: 0.62; acc: 0.8
Batch: 20; loss: 1.13; acc: 0.61
Batch: 40; loss: 0.31; acc: 0.92
Batch: 60; loss: 0.84; acc: 0.75
Batch: 80; loss: 0.41; acc: 0.84
Batch: 100; loss: 0.56; acc: 0.89
Batch: 120; loss: 0.75; acc: 0.72
Batch: 140; loss: 0.53; acc: 0.8
Val Epoch over. val_loss: 0.6234596595642673; val_accuracy: 0.7936902866242038 

The current subspace-distance is: 5.483625500346534e-06 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.88; acc: 0.72
Batch: 20; loss: 0.47; acc: 0.89
Batch: 40; loss: 0.29; acc: 0.91
Batch: 60; loss: 0.37; acc: 0.89
Batch: 80; loss: 0.48; acc: 0.81
Batch: 100; loss: 0.54; acc: 0.81
Batch: 120; loss: 0.72; acc: 0.78
Batch: 140; loss: 0.56; acc: 0.84
Batch: 160; loss: 0.43; acc: 0.88
Batch: 180; loss: 0.37; acc: 0.88
Batch: 200; loss: 0.45; acc: 0.86
Batch: 220; loss: 0.58; acc: 0.81
Batch: 240; loss: 0.64; acc: 0.86
Batch: 260; loss: 0.48; acc: 0.83
Batch: 280; loss: 0.37; acc: 0.91
Batch: 300; loss: 0.35; acc: 0.88
Batch: 320; loss: 0.61; acc: 0.83
Batch: 340; loss: 0.48; acc: 0.86
Batch: 360; loss: 0.56; acc: 0.84
Batch: 380; loss: 0.45; acc: 0.89
Batch: 400; loss: 0.55; acc: 0.88
Batch: 420; loss: 0.41; acc: 0.84
Batch: 440; loss: 0.45; acc: 0.86
Batch: 460; loss: 0.81; acc: 0.77
Batch: 480; loss: 0.37; acc: 0.88
Batch: 500; loss: 0.44; acc: 0.84
Batch: 520; loss: 0.34; acc: 0.88
Batch: 540; loss: 0.42; acc: 0.88
Batch: 560; loss: 0.47; acc: 0.83
Batch: 580; loss: 0.5; acc: 0.86
Batch: 600; loss: 0.34; acc: 0.91
Batch: 620; loss: 0.67; acc: 0.77
Batch: 640; loss: 0.28; acc: 0.89
Batch: 660; loss: 0.42; acc: 0.88
Batch: 680; loss: 0.41; acc: 0.81
Batch: 700; loss: 0.69; acc: 0.77
Batch: 720; loss: 0.13; acc: 0.98
Batch: 740; loss: 0.22; acc: 0.94
Batch: 760; loss: 0.48; acc: 0.88
Batch: 780; loss: 0.39; acc: 0.89
Train Epoch over. train_loss: 0.46; train_accuracy: 0.86 

2.1786874640383758e-05
6.672235485893907e-06
Batch: 0; loss: 0.42; acc: 0.8
Batch: 20; loss: 0.58; acc: 0.81
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.56; acc: 0.81
Batch: 80; loss: 0.3; acc: 0.88
Batch: 100; loss: 0.5; acc: 0.88
Batch: 120; loss: 0.65; acc: 0.8
Batch: 140; loss: 0.23; acc: 0.92
Val Epoch over. val_loss: 0.40448003172115155; val_accuracy: 0.8725119426751592 

The current subspace-distance is: 6.672235485893907e-06 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.39; acc: 0.84
Batch: 20; loss: 0.43; acc: 0.89
Batch: 40; loss: 0.44; acc: 0.86
Batch: 60; loss: 0.36; acc: 0.89
Batch: 80; loss: 0.34; acc: 0.88
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.24; acc: 0.91
Batch: 140; loss: 0.35; acc: 0.88
Batch: 160; loss: 0.22; acc: 0.91
Batch: 180; loss: 0.46; acc: 0.84
Batch: 200; loss: 0.34; acc: 0.91
Batch: 220; loss: 0.42; acc: 0.86
Batch: 240; loss: 0.62; acc: 0.78
Batch: 260; loss: 0.39; acc: 0.84
Batch: 280; loss: 0.59; acc: 0.91
Batch: 300; loss: 0.5; acc: 0.81
Batch: 320; loss: 0.51; acc: 0.83
Batch: 340; loss: 0.41; acc: 0.92
Batch: 360; loss: 0.36; acc: 0.88
Batch: 380; loss: 0.39; acc: 0.91
Batch: 400; loss: 0.3; acc: 0.89
Batch: 420; loss: 0.48; acc: 0.86
Batch: 440; loss: 0.16; acc: 0.92
Batch: 460; loss: 0.22; acc: 0.88
Batch: 480; loss: 0.37; acc: 0.89
Batch: 500; loss: 0.32; acc: 0.91
Batch: 520; loss: 0.24; acc: 0.94
Batch: 540; loss: 0.49; acc: 0.81
Batch: 560; loss: 0.52; acc: 0.88
Batch: 580; loss: 0.4; acc: 0.91
Batch: 600; loss: 0.44; acc: 0.88
Batch: 620; loss: 0.35; acc: 0.84
Batch: 640; loss: 0.63; acc: 0.83
Batch: 660; loss: 0.45; acc: 0.89
Batch: 680; loss: 0.39; acc: 0.91
Batch: 700; loss: 0.27; acc: 0.91
Batch: 720; loss: 0.6; acc: 0.78
Batch: 740; loss: 0.38; acc: 0.91
Batch: 760; loss: 0.27; acc: 0.89
Batch: 780; loss: 0.21; acc: 0.94
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

2.2428757802117616e-05
6.446255156333791e-06
Batch: 0; loss: 0.48; acc: 0.88
Batch: 20; loss: 0.56; acc: 0.8
Batch: 40; loss: 0.24; acc: 0.92
Batch: 60; loss: 0.69; acc: 0.75
Batch: 80; loss: 0.29; acc: 0.89
Batch: 100; loss: 0.52; acc: 0.83
Batch: 120; loss: 0.46; acc: 0.89
Batch: 140; loss: 0.17; acc: 0.95
Val Epoch over. val_loss: 0.47658321161748496; val_accuracy: 0.8562898089171974 

The current subspace-distance is: 6.446255156333791e-06 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.52; acc: 0.89
Batch: 20; loss: 0.41; acc: 0.8
Batch: 40; loss: 0.4; acc: 0.86
Batch: 60; loss: 0.53; acc: 0.86
Batch: 80; loss: 0.55; acc: 0.83
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.28; acc: 0.89
Batch: 140; loss: 0.34; acc: 0.91
Batch: 160; loss: 0.16; acc: 0.95
Batch: 180; loss: 0.24; acc: 0.89
Batch: 200; loss: 0.22; acc: 0.92
Batch: 220; loss: 0.48; acc: 0.84
Batch: 240; loss: 0.28; acc: 0.92
Batch: 260; loss: 0.26; acc: 0.91
Batch: 280; loss: 0.44; acc: 0.91
Batch: 300; loss: 0.29; acc: 0.89
Batch: 320; loss: 0.3; acc: 0.89
Batch: 340; loss: 0.34; acc: 0.86
Batch: 360; loss: 0.42; acc: 0.88
Batch: 380; loss: 0.31; acc: 0.91
Batch: 400; loss: 0.42; acc: 0.92
Batch: 420; loss: 0.37; acc: 0.86
Batch: 440; loss: 0.41; acc: 0.88
Batch: 460; loss: 0.34; acc: 0.89
Batch: 480; loss: 0.46; acc: 0.83
Batch: 500; loss: 0.35; acc: 0.86
Batch: 520; loss: 0.25; acc: 0.91
Batch: 540; loss: 0.19; acc: 0.95
Batch: 560; loss: 0.49; acc: 0.83
Batch: 580; loss: 0.44; acc: 0.89
Batch: 600; loss: 0.34; acc: 0.91
Batch: 620; loss: 0.3; acc: 0.89
Batch: 640; loss: 0.33; acc: 0.89
Batch: 660; loss: 0.66; acc: 0.86
Batch: 680; loss: 0.36; acc: 0.91
Batch: 700; loss: 0.33; acc: 0.88
Batch: 720; loss: 0.21; acc: 0.92
Batch: 740; loss: 0.3; acc: 0.92
Batch: 760; loss: 0.28; acc: 0.89
Batch: 780; loss: 0.19; acc: 0.92
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

2.2799151338404045e-05
7.161785106291063e-06
Batch: 0; loss: 0.22; acc: 0.95
Batch: 20; loss: 0.55; acc: 0.83
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.37; acc: 0.89
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.35; acc: 0.88
Batch: 120; loss: 0.42; acc: 0.88
Batch: 140; loss: 0.19; acc: 0.95
Val Epoch over. val_loss: 0.3087214446940999; val_accuracy: 0.9072452229299363 

The current subspace-distance is: 7.161785106291063e-06 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.57; acc: 0.84
Batch: 20; loss: 0.27; acc: 0.92
Batch: 40; loss: 0.63; acc: 0.78
Batch: 60; loss: 0.46; acc: 0.83
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.31; acc: 0.89
Batch: 120; loss: 0.39; acc: 0.86
Batch: 140; loss: 0.44; acc: 0.88
Batch: 160; loss: 0.35; acc: 0.88
Batch: 180; loss: 0.2; acc: 0.95
Batch: 200; loss: 0.38; acc: 0.88
Batch: 220; loss: 0.26; acc: 0.95
Batch: 240; loss: 0.4; acc: 0.89
Batch: 260; loss: 0.33; acc: 0.92
Batch: 280; loss: 0.21; acc: 0.97
Batch: 300; loss: 0.54; acc: 0.84
Batch: 320; loss: 0.35; acc: 0.86
Batch: 340; loss: 0.35; acc: 0.89
Batch: 360; loss: 0.42; acc: 0.91
Batch: 380; loss: 0.71; acc: 0.8
Batch: 400; loss: 0.29; acc: 0.89
Batch: 420; loss: 0.18; acc: 0.95
Batch: 440; loss: 0.38; acc: 0.88
Batch: 460; loss: 0.18; acc: 0.97
Batch: 480; loss: 0.39; acc: 0.86
Batch: 500; loss: 0.41; acc: 0.91
Batch: 520; loss: 0.46; acc: 0.83
Batch: 540; loss: 0.36; acc: 0.89
Batch: 560; loss: 0.26; acc: 0.92
Batch: 580; loss: 0.32; acc: 0.91
Batch: 600; loss: 0.32; acc: 0.88
Batch: 620; loss: 0.31; acc: 0.89
Batch: 640; loss: 0.41; acc: 0.84
Batch: 660; loss: 0.56; acc: 0.84
Batch: 680; loss: 0.18; acc: 0.97
Batch: 700; loss: 0.2; acc: 0.94
Batch: 720; loss: 0.74; acc: 0.81
Batch: 740; loss: 0.25; acc: 0.92
Batch: 760; loss: 0.34; acc: 0.92
Batch: 780; loss: 0.37; acc: 0.91
Train Epoch over. train_loss: 0.34; train_accuracy: 0.9 

2.448662053211592e-05
7.270059086295078e-06
Batch: 0; loss: 0.48; acc: 0.89
Batch: 20; loss: 0.49; acc: 0.86
Batch: 40; loss: 0.33; acc: 0.91
Batch: 60; loss: 0.72; acc: 0.8
Batch: 80; loss: 0.43; acc: 0.86
Batch: 100; loss: 0.64; acc: 0.8
Batch: 120; loss: 0.72; acc: 0.81
Batch: 140; loss: 0.3; acc: 0.92
Val Epoch over. val_loss: 0.5323131353042687; val_accuracy: 0.8378781847133758 

The current subspace-distance is: 7.270059086295078e-06 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.92; acc: 0.78
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.36; acc: 0.88
Batch: 60; loss: 0.32; acc: 0.92
Batch: 80; loss: 0.26; acc: 0.94
Batch: 100; loss: 0.37; acc: 0.86
Batch: 120; loss: 0.28; acc: 0.91
Batch: 140; loss: 0.45; acc: 0.86
Batch: 160; loss: 0.46; acc: 0.84
Batch: 180; loss: 0.25; acc: 0.92
Batch: 200; loss: 0.51; acc: 0.83
Batch: 220; loss: 0.37; acc: 0.84
Batch: 240; loss: 0.4; acc: 0.81
Batch: 260; loss: 0.43; acc: 0.91
Batch: 280; loss: 0.13; acc: 0.95
Batch: 300; loss: 0.31; acc: 0.91
Batch: 320; loss: 0.26; acc: 0.91
Batch: 340; loss: 0.3; acc: 0.94
Batch: 360; loss: 0.25; acc: 0.94
Batch: 380; loss: 0.29; acc: 0.92
Batch: 400; loss: 0.24; acc: 0.92
Batch: 420; loss: 0.47; acc: 0.88
Batch: 440; loss: 0.41; acc: 0.88
Batch: 460; loss: 0.2; acc: 0.95
Batch: 480; loss: 0.47; acc: 0.89
Batch: 500; loss: 0.15; acc: 0.97
Batch: 520; loss: 0.18; acc: 0.94
Batch: 540; loss: 0.31; acc: 0.92
Batch: 560; loss: 0.27; acc: 0.91
Batch: 580; loss: 0.16; acc: 0.97
Batch: 600; loss: 0.14; acc: 0.94
Batch: 620; loss: 0.23; acc: 0.95
Batch: 640; loss: 0.61; acc: 0.84
Batch: 660; loss: 0.36; acc: 0.88
Batch: 680; loss: 0.27; acc: 0.89
Batch: 700; loss: 0.32; acc: 0.92
Batch: 720; loss: 0.31; acc: 0.92
Batch: 740; loss: 0.34; acc: 0.89
Batch: 760; loss: 0.35; acc: 0.94
Batch: 780; loss: 0.17; acc: 0.94
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.5568206183379516e-05
8.066312148002908e-06
Batch: 0; loss: 0.27; acc: 0.89
Batch: 20; loss: 0.47; acc: 0.83
Batch: 40; loss: 0.27; acc: 0.91
Batch: 60; loss: 0.45; acc: 0.83
Batch: 80; loss: 0.35; acc: 0.86
Batch: 100; loss: 0.41; acc: 0.91
Batch: 120; loss: 0.41; acc: 0.83
Batch: 140; loss: 0.29; acc: 0.92
Val Epoch over. val_loss: 0.38611052764259324; val_accuracy: 0.878781847133758 

The current subspace-distance is: 8.066312148002908e-06 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.58; acc: 0.86
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.28; acc: 0.92
Batch: 80; loss: 0.27; acc: 0.89
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.24; acc: 0.92
Batch: 140; loss: 0.48; acc: 0.84
Batch: 160; loss: 0.18; acc: 0.94
Batch: 180; loss: 0.24; acc: 0.92
Batch: 200; loss: 0.17; acc: 0.92
Batch: 220; loss: 0.41; acc: 0.84
Batch: 240; loss: 0.18; acc: 0.94
Batch: 260; loss: 0.32; acc: 0.92
Batch: 280; loss: 0.49; acc: 0.86
Batch: 300; loss: 0.35; acc: 0.88
Batch: 320; loss: 0.43; acc: 0.86
Batch: 340; loss: 0.36; acc: 0.86
Batch: 360; loss: 0.15; acc: 0.94
Batch: 380; loss: 0.13; acc: 0.97
Batch: 400; loss: 0.29; acc: 0.91
Batch: 420; loss: 0.15; acc: 0.95
Batch: 440; loss: 0.37; acc: 0.89
Batch: 460; loss: 0.17; acc: 0.94
Batch: 480; loss: 0.28; acc: 0.88
Batch: 500; loss: 0.28; acc: 0.88
Batch: 520; loss: 0.53; acc: 0.86
Batch: 540; loss: 0.25; acc: 0.92
Batch: 560; loss: 0.09; acc: 0.98
Batch: 580; loss: 0.51; acc: 0.86
Batch: 600; loss: 0.35; acc: 0.88
Batch: 620; loss: 0.35; acc: 0.88
Batch: 640; loss: 0.18; acc: 0.95
Batch: 660; loss: 0.33; acc: 0.91
Batch: 680; loss: 0.21; acc: 0.94
Batch: 700; loss: 0.35; acc: 0.88
Batch: 720; loss: 0.17; acc: 0.97
Batch: 740; loss: 0.33; acc: 0.89
Batch: 760; loss: 0.13; acc: 0.95
Batch: 780; loss: 0.23; acc: 0.92
Train Epoch over. train_loss: 0.31; train_accuracy: 0.91 

2.4680799469933845e-05
8.877497748471797e-06
Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.64; acc: 0.78
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.48; acc: 0.89
Batch: 80; loss: 0.42; acc: 0.88
Batch: 100; loss: 0.33; acc: 0.89
Batch: 120; loss: 0.52; acc: 0.86
Batch: 140; loss: 0.19; acc: 0.95
Val Epoch over. val_loss: 0.35123470318829936; val_accuracy: 0.8953025477707006 

The current subspace-distance is: 8.877497748471797e-06 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.55; acc: 0.81
Batch: 20; loss: 0.17; acc: 0.95
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.44; acc: 0.89
Batch: 80; loss: 0.38; acc: 0.88
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.38; acc: 0.89
Batch: 140; loss: 0.34; acc: 0.91
Batch: 160; loss: 0.2; acc: 0.92
Batch: 180; loss: 0.63; acc: 0.8
Batch: 200; loss: 0.21; acc: 0.91
Batch: 220; loss: 0.24; acc: 0.92
Batch: 240; loss: 0.26; acc: 0.91
Batch: 260; loss: 0.18; acc: 0.95
Batch: 280; loss: 0.33; acc: 0.89
Batch: 300; loss: 0.24; acc: 0.91
Batch: 320; loss: 0.26; acc: 0.91
Batch: 340; loss: 0.36; acc: 0.88
Batch: 360; loss: 0.49; acc: 0.89
Batch: 380; loss: 0.28; acc: 0.94
Batch: 400; loss: 0.33; acc: 0.91
Batch: 420; loss: 0.19; acc: 0.94
Batch: 440; loss: 0.29; acc: 0.94
Batch: 460; loss: 0.16; acc: 0.95
Batch: 480; loss: 0.3; acc: 0.91
Batch: 500; loss: 0.32; acc: 0.86
Batch: 520; loss: 0.35; acc: 0.89
Batch: 540; loss: 0.26; acc: 0.91
Batch: 560; loss: 0.38; acc: 0.88
Batch: 580; loss: 0.34; acc: 0.86
Batch: 600; loss: 0.42; acc: 0.86
Batch: 620; loss: 0.28; acc: 0.92
Batch: 640; loss: 0.24; acc: 0.92
Batch: 660; loss: 0.45; acc: 0.89
Batch: 680; loss: 0.64; acc: 0.89
Batch: 700; loss: 0.34; acc: 0.86
Batch: 720; loss: 0.28; acc: 0.88
Batch: 740; loss: 0.32; acc: 0.89
Batch: 760; loss: 0.18; acc: 0.95
Batch: 780; loss: 0.41; acc: 0.89
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.4484319510520436e-05
8.15635848994134e-06
Batch: 0; loss: 0.34; acc: 0.88
Batch: 20; loss: 0.55; acc: 0.83
Batch: 40; loss: 0.22; acc: 0.92
Batch: 60; loss: 0.45; acc: 0.86
Batch: 80; loss: 0.32; acc: 0.91
Batch: 100; loss: 0.39; acc: 0.88
Batch: 120; loss: 0.34; acc: 0.94
Batch: 140; loss: 0.12; acc: 0.95
Val Epoch over. val_loss: 0.3218031485511619; val_accuracy: 0.900577229299363 

The current subspace-distance is: 8.15635848994134e-06 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.35; acc: 0.91
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.35; acc: 0.86
Batch: 60; loss: 0.22; acc: 0.97
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.22; acc: 0.91
Batch: 120; loss: 0.26; acc: 0.89
Batch: 140; loss: 0.41; acc: 0.91
Batch: 160; loss: 0.18; acc: 0.94
Batch: 180; loss: 0.31; acc: 0.94
Batch: 200; loss: 0.12; acc: 0.95
Batch: 220; loss: 0.48; acc: 0.89
Batch: 240; loss: 0.31; acc: 0.88
Batch: 260; loss: 0.47; acc: 0.84
Batch: 280; loss: 0.25; acc: 0.92
Batch: 300; loss: 0.15; acc: 0.95
Batch: 320; loss: 0.45; acc: 0.84
Batch: 340; loss: 0.31; acc: 0.88
Batch: 360; loss: 0.28; acc: 0.92
Batch: 380; loss: 0.21; acc: 0.92
Batch: 400; loss: 0.28; acc: 0.88
Batch: 420; loss: 0.15; acc: 0.95
Batch: 440; loss: 0.32; acc: 0.91
Batch: 460; loss: 0.19; acc: 0.94
Batch: 480; loss: 0.16; acc: 0.92
Batch: 500; loss: 0.16; acc: 0.94
Batch: 520; loss: 0.23; acc: 0.95
Batch: 540; loss: 0.2; acc: 0.97
Batch: 560; loss: 0.27; acc: 0.91
Batch: 580; loss: 0.17; acc: 0.95
Batch: 600; loss: 0.21; acc: 0.94
Batch: 620; loss: 0.4; acc: 0.88
Batch: 640; loss: 0.15; acc: 0.97
Batch: 660; loss: 0.19; acc: 0.94
Batch: 680; loss: 0.32; acc: 0.89
Batch: 700; loss: 0.33; acc: 0.92
Batch: 720; loss: 0.31; acc: 0.89
Batch: 740; loss: 0.38; acc: 0.88
Batch: 760; loss: 0.13; acc: 0.95
Batch: 780; loss: 0.48; acc: 0.89
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.4869119442882948e-05
7.2301704676647205e-06
Batch: 0; loss: 0.29; acc: 0.95
Batch: 20; loss: 0.59; acc: 0.8
Batch: 40; loss: 0.23; acc: 0.92
Batch: 60; loss: 0.38; acc: 0.84
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.42; acc: 0.91
Batch: 120; loss: 0.35; acc: 0.91
Batch: 140; loss: 0.17; acc: 0.92
Val Epoch over. val_loss: 0.35827107829557864; val_accuracy: 0.8885350318471338 

The current subspace-distance is: 7.2301704676647205e-06 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.52; acc: 0.86
Batch: 20; loss: 0.17; acc: 0.95
Batch: 40; loss: 0.22; acc: 0.91
Batch: 60; loss: 0.19; acc: 0.97
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.18; acc: 0.92
Batch: 120; loss: 0.28; acc: 0.92
Batch: 140; loss: 0.26; acc: 0.94
Batch: 160; loss: 0.29; acc: 0.92
Batch: 180; loss: 0.23; acc: 0.92
Batch: 200; loss: 0.4; acc: 0.89
Batch: 220; loss: 0.22; acc: 0.91
Batch: 240; loss: 0.37; acc: 0.84
Batch: 260; loss: 0.33; acc: 0.91
Batch: 280; loss: 0.25; acc: 0.94
Batch: 300; loss: 0.32; acc: 0.91
Batch: 320; loss: 0.41; acc: 0.88
Batch: 340; loss: 0.18; acc: 0.91
Batch: 360; loss: 0.33; acc: 0.89
Batch: 380; loss: 0.2; acc: 0.95
Batch: 400; loss: 0.56; acc: 0.84
Batch: 420; loss: 0.16; acc: 0.95
Batch: 440; loss: 0.14; acc: 0.97
Batch: 460; loss: 0.24; acc: 0.92
Batch: 480; loss: 0.2; acc: 0.92
Batch: 500; loss: 0.13; acc: 0.98
Batch: 520; loss: 0.36; acc: 0.91
Batch: 540; loss: 0.24; acc: 0.94
Batch: 560; loss: 0.46; acc: 0.94
Batch: 580; loss: 0.17; acc: 0.95
Batch: 600; loss: 0.26; acc: 0.92
Batch: 620; loss: 0.32; acc: 0.88
Batch: 640; loss: 0.28; acc: 0.91
Batch: 660; loss: 0.27; acc: 0.88
Batch: 680; loss: 0.32; acc: 0.89
Batch: 700; loss: 0.09; acc: 0.97
Batch: 720; loss: 0.17; acc: 0.94
Batch: 740; loss: 0.21; acc: 0.94
Batch: 760; loss: 0.23; acc: 0.95
Batch: 780; loss: 0.32; acc: 0.88
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.5806701160036027e-05
8.354230885743164e-06
Batch: 0; loss: 0.2; acc: 0.97
Batch: 20; loss: 0.41; acc: 0.92
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.23; acc: 0.92
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.27; acc: 0.91
Batch: 120; loss: 0.42; acc: 0.84
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.2462777890217532; val_accuracy: 0.9272492038216561 

The current subspace-distance is: 8.354230885743164e-06 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.24; acc: 0.92
Batch: 20; loss: 0.32; acc: 0.88
Batch: 40; loss: 0.23; acc: 0.95
Batch: 60; loss: 0.27; acc: 0.91
Batch: 80; loss: 0.29; acc: 0.91
Batch: 100; loss: 0.21; acc: 0.95
Batch: 120; loss: 0.24; acc: 0.92
Batch: 140; loss: 0.25; acc: 0.92
Batch: 160; loss: 0.21; acc: 0.91
Batch: 180; loss: 0.21; acc: 0.97
Batch: 200; loss: 0.26; acc: 0.91
Batch: 220; loss: 0.19; acc: 0.95
Batch: 240; loss: 0.19; acc: 0.92
Batch: 260; loss: 0.15; acc: 0.95
Batch: 280; loss: 0.11; acc: 0.97
Batch: 300; loss: 0.12; acc: 0.97
Batch: 320; loss: 0.17; acc: 0.95
Batch: 340; loss: 0.31; acc: 0.89
Batch: 360; loss: 0.41; acc: 0.86
Batch: 380; loss: 0.28; acc: 0.94
Batch: 400; loss: 0.17; acc: 0.95
Batch: 420; loss: 0.27; acc: 0.92
Batch: 440; loss: 0.39; acc: 0.88
Batch: 460; loss: 0.37; acc: 0.88
Batch: 480; loss: 0.54; acc: 0.88
Batch: 500; loss: 0.42; acc: 0.86
Batch: 520; loss: 0.26; acc: 0.94
Batch: 540; loss: 0.31; acc: 0.91
Batch: 560; loss: 0.16; acc: 0.95
Batch: 580; loss: 0.24; acc: 0.91
Batch: 600; loss: 0.3; acc: 0.92
Batch: 620; loss: 0.38; acc: 0.91
Batch: 640; loss: 0.3; acc: 0.86
Batch: 660; loss: 0.3; acc: 0.89
Batch: 680; loss: 0.31; acc: 0.91
Batch: 700; loss: 0.22; acc: 0.91
Batch: 720; loss: 0.23; acc: 0.89
Batch: 740; loss: 0.46; acc: 0.88
Batch: 760; loss: 0.54; acc: 0.86
Batch: 780; loss: 0.26; acc: 0.89
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.594594297988806e-05
6.9013781285320874e-06
Batch: 0; loss: 0.25; acc: 0.95
Batch: 20; loss: 0.48; acc: 0.88
Batch: 40; loss: 0.2; acc: 0.91
Batch: 60; loss: 0.61; acc: 0.86
Batch: 80; loss: 0.45; acc: 0.88
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.43; acc: 0.86
Batch: 140; loss: 0.14; acc: 0.95
Val Epoch over. val_loss: 0.3491865486191337; val_accuracy: 0.8967953821656051 

The current subspace-distance is: 6.9013781285320874e-06 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.33; acc: 0.88
Batch: 20; loss: 0.34; acc: 0.91
Batch: 40; loss: 0.27; acc: 0.94
Batch: 60; loss: 0.12; acc: 0.97
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.34; acc: 0.88
Batch: 140; loss: 0.15; acc: 0.94
Batch: 160; loss: 0.38; acc: 0.86
Batch: 180; loss: 0.14; acc: 0.98
Batch: 200; loss: 0.24; acc: 0.95
Batch: 220; loss: 0.21; acc: 0.95
Batch: 240; loss: 0.26; acc: 0.94
Batch: 260; loss: 0.1; acc: 0.98
Batch: 280; loss: 0.31; acc: 0.89
Batch: 300; loss: 0.21; acc: 0.94
Batch: 320; loss: 0.3; acc: 0.94
Batch: 340; loss: 0.17; acc: 0.95
Batch: 360; loss: 0.18; acc: 0.94
Batch: 380; loss: 0.22; acc: 0.92
Batch: 400; loss: 0.26; acc: 0.91
Batch: 420; loss: 0.2; acc: 0.94
Batch: 440; loss: 0.22; acc: 0.94
Batch: 460; loss: 0.26; acc: 0.94
Batch: 480; loss: 0.21; acc: 0.97
Batch: 500; loss: 0.12; acc: 0.97
Batch: 520; loss: 0.16; acc: 0.95
Batch: 540; loss: 0.43; acc: 0.89
Batch: 560; loss: 0.12; acc: 0.97
Batch: 580; loss: 0.28; acc: 0.94
Batch: 600; loss: 0.16; acc: 0.94
Batch: 620; loss: 0.26; acc: 0.94
Batch: 640; loss: 0.16; acc: 0.95
Batch: 660; loss: 0.27; acc: 0.94
Batch: 680; loss: 0.21; acc: 0.95
Batch: 700; loss: 0.44; acc: 0.88
Batch: 720; loss: 0.17; acc: 0.95
Batch: 740; loss: 0.28; acc: 0.92
Batch: 760; loss: 0.25; acc: 0.91
Batch: 780; loss: 0.26; acc: 0.91
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.560126995376777e-05
7.794707926223055e-06
Batch: 0; loss: 0.23; acc: 0.94
Batch: 20; loss: 0.44; acc: 0.88
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.25; acc: 0.89
Batch: 80; loss: 0.26; acc: 0.92
Batch: 100; loss: 0.27; acc: 0.94
Batch: 120; loss: 0.51; acc: 0.83
Batch: 140; loss: 0.14; acc: 0.95
Val Epoch over. val_loss: 0.26809508294151846; val_accuracy: 0.9169984076433121 

The current subspace-distance is: 7.794707926223055e-06 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.41; acc: 0.89
Batch: 20; loss: 0.24; acc: 0.89
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.19; acc: 0.91
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.32; acc: 0.89
Batch: 120; loss: 0.36; acc: 0.94
Batch: 140; loss: 0.36; acc: 0.89
Batch: 160; loss: 0.34; acc: 0.91
Batch: 180; loss: 0.13; acc: 0.97
Batch: 200; loss: 0.32; acc: 0.92
Batch: 220; loss: 0.38; acc: 0.86
Batch: 240; loss: 0.14; acc: 0.95
Batch: 260; loss: 0.23; acc: 0.94
Batch: 280; loss: 0.26; acc: 0.89
Batch: 300; loss: 0.29; acc: 0.91
Batch: 320; loss: 0.24; acc: 0.91
Batch: 340; loss: 0.27; acc: 0.91
Batch: 360; loss: 0.46; acc: 0.88
Batch: 380; loss: 0.17; acc: 0.97
Batch: 400; loss: 0.45; acc: 0.83
Batch: 420; loss: 0.24; acc: 0.91
Batch: 440; loss: 0.22; acc: 0.94
Batch: 460; loss: 0.37; acc: 0.89
Batch: 480; loss: 0.27; acc: 0.95
Batch: 500; loss: 0.28; acc: 0.89
Batch: 520; loss: 0.17; acc: 0.97
Batch: 540; loss: 0.27; acc: 0.91
Batch: 560; loss: 0.48; acc: 0.89
Batch: 580; loss: 0.18; acc: 0.94
Batch: 600; loss: 0.3; acc: 0.91
Batch: 620; loss: 0.31; acc: 0.94
Batch: 640; loss: 0.27; acc: 0.91
Batch: 660; loss: 0.43; acc: 0.91
Batch: 680; loss: 0.65; acc: 0.8
Batch: 700; loss: 0.32; acc: 0.94
Batch: 720; loss: 0.2; acc: 0.95
Batch: 740; loss: 0.09; acc: 0.97
Batch: 760; loss: 0.15; acc: 0.95
Batch: 780; loss: 0.28; acc: 0.91
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.499463334970642e-05
7.384676791843958e-06
Batch: 0; loss: 0.21; acc: 0.97
Batch: 20; loss: 0.38; acc: 0.91
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.23; acc: 0.91
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.22; acc: 0.95
Batch: 120; loss: 0.42; acc: 0.86
Batch: 140; loss: 0.09; acc: 0.98
Val Epoch over. val_loss: 0.2465683425402945; val_accuracy: 0.9243630573248408 

The current subspace-distance is: 7.384676791843958e-06 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.06; acc: 0.98
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.33; acc: 0.89
Batch: 120; loss: 0.23; acc: 0.92
Batch: 140; loss: 0.25; acc: 0.92
Batch: 160; loss: 0.14; acc: 0.95
Batch: 180; loss: 0.3; acc: 0.89
Batch: 200; loss: 0.31; acc: 0.95
Batch: 220; loss: 0.29; acc: 0.91
Batch: 240; loss: 0.44; acc: 0.84
Batch: 260; loss: 0.22; acc: 0.91
Batch: 280; loss: 0.16; acc: 0.94
Batch: 300; loss: 0.36; acc: 0.88
Batch: 320; loss: 0.4; acc: 0.88
Batch: 340; loss: 0.28; acc: 0.92
Batch: 360; loss: 0.37; acc: 0.84
Batch: 380; loss: 0.27; acc: 0.92
Batch: 400; loss: 0.29; acc: 0.92
Batch: 420; loss: 0.29; acc: 0.94
Batch: 440; loss: 0.46; acc: 0.91
Batch: 460; loss: 0.45; acc: 0.83
Batch: 480; loss: 0.12; acc: 0.97
Batch: 500; loss: 0.18; acc: 0.92
Batch: 520; loss: 0.29; acc: 0.97
Batch: 540; loss: 0.25; acc: 0.95
Batch: 560; loss: 0.24; acc: 0.88
Batch: 580; loss: 0.14; acc: 0.97
Batch: 600; loss: 0.12; acc: 0.95
Batch: 620; loss: 0.15; acc: 0.97
Batch: 640; loss: 0.36; acc: 0.89
Batch: 660; loss: 0.33; acc: 0.92
Batch: 680; loss: 0.11; acc: 0.97
Batch: 700; loss: 0.28; acc: 0.92
Batch: 720; loss: 0.27; acc: 0.94
Batch: 740; loss: 0.13; acc: 0.94
Batch: 760; loss: 0.43; acc: 0.92
Batch: 780; loss: 0.19; acc: 0.95
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.6208264898741618e-05
7.224449291243218e-06
Batch: 0; loss: 0.19; acc: 0.95
Batch: 20; loss: 0.37; acc: 0.88
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.22; acc: 0.92
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.21; acc: 0.97
Batch: 120; loss: 0.43; acc: 0.86
Batch: 140; loss: 0.11; acc: 0.98
Val Epoch over. val_loss: 0.24013272884070494; val_accuracy: 0.9271496815286624 

The current subspace-distance is: 7.224449291243218e-06 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.33; acc: 0.89
Batch: 20; loss: 0.33; acc: 0.86
Batch: 40; loss: 0.2; acc: 0.97
Batch: 60; loss: 0.25; acc: 0.88
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.33; acc: 0.94
Batch: 120; loss: 0.6; acc: 0.81
Batch: 140; loss: 0.13; acc: 0.98
Batch: 160; loss: 0.38; acc: 0.88
Batch: 180; loss: 0.37; acc: 0.92
Batch: 200; loss: 0.27; acc: 0.95
Batch: 220; loss: 0.21; acc: 0.95
Batch: 240; loss: 0.22; acc: 0.94
Batch: 260; loss: 0.23; acc: 0.91
Batch: 280; loss: 0.49; acc: 0.91
Batch: 300; loss: 0.19; acc: 0.94
Batch: 320; loss: 0.3; acc: 0.89
Batch: 340; loss: 0.36; acc: 0.88
Batch: 360; loss: 0.17; acc: 0.94
Batch: 380; loss: 0.37; acc: 0.84
Batch: 400; loss: 0.18; acc: 0.97
Batch: 420; loss: 0.26; acc: 0.95
Batch: 440; loss: 0.32; acc: 0.94
Batch: 460; loss: 0.25; acc: 0.89
Batch: 480; loss: 0.27; acc: 0.88
Batch: 500; loss: 0.39; acc: 0.91
Batch: 520; loss: 0.1; acc: 0.97
Batch: 540; loss: 0.19; acc: 0.94
Batch: 560; loss: 0.36; acc: 0.95
Batch: 580; loss: 0.13; acc: 0.97
Batch: 600; loss: 0.16; acc: 0.95
Batch: 620; loss: 0.17; acc: 0.92
Batch: 640; loss: 0.31; acc: 0.91
Batch: 660; loss: 0.12; acc: 0.98
Batch: 680; loss: 0.14; acc: 0.95
Batch: 700; loss: 0.26; acc: 0.92
Batch: 720; loss: 0.2; acc: 0.92
Batch: 740; loss: 0.3; acc: 0.89
Batch: 760; loss: 0.32; acc: 0.92
Batch: 780; loss: 0.39; acc: 0.89
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.7026630050386302e-05
7.417597316816682e-06
Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.5; acc: 0.86
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.26; acc: 0.89
Batch: 80; loss: 0.31; acc: 0.88
Batch: 100; loss: 0.39; acc: 0.89
Batch: 120; loss: 0.62; acc: 0.83
Batch: 140; loss: 0.2; acc: 0.94
Val Epoch over. val_loss: 0.3250505464376917; val_accuracy: 0.8945063694267515 

The current subspace-distance is: 7.417597316816682e-06 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.19; acc: 0.95
Batch: 20; loss: 0.34; acc: 0.89
Batch: 40; loss: 0.47; acc: 0.86
Batch: 60; loss: 0.41; acc: 0.88
Batch: 80; loss: 0.31; acc: 0.91
Batch: 100; loss: 0.28; acc: 0.91
Batch: 120; loss: 0.33; acc: 0.89
Batch: 140; loss: 0.14; acc: 0.95
Batch: 160; loss: 0.55; acc: 0.86
Batch: 180; loss: 0.32; acc: 0.88
Batch: 200; loss: 0.32; acc: 0.91
Batch: 220; loss: 0.13; acc: 0.95
Batch: 240; loss: 0.37; acc: 0.88
Batch: 260; loss: 0.24; acc: 0.95
Batch: 280; loss: 0.18; acc: 0.95
Batch: 300; loss: 0.32; acc: 0.91
Batch: 320; loss: 0.24; acc: 0.89
Batch: 340; loss: 0.09; acc: 0.95
Batch: 360; loss: 0.4; acc: 0.83
Batch: 380; loss: 0.35; acc: 0.89
Batch: 400; loss: 0.38; acc: 0.89
Batch: 420; loss: 0.54; acc: 0.88
Batch: 440; loss: 0.33; acc: 0.92
Batch: 460; loss: 0.13; acc: 0.97
Batch: 480; loss: 0.35; acc: 0.91
Batch: 500; loss: 0.31; acc: 0.94
Batch: 520; loss: 0.27; acc: 0.92
Batch: 540; loss: 0.38; acc: 0.91
Batch: 560; loss: 0.42; acc: 0.89
Batch: 580; loss: 0.21; acc: 0.94
Batch: 600; loss: 0.23; acc: 0.94
Batch: 620; loss: 0.16; acc: 0.95
Batch: 640; loss: 0.43; acc: 0.89
Batch: 660; loss: 0.24; acc: 0.91
Batch: 680; loss: 0.22; acc: 0.91
Batch: 700; loss: 0.12; acc: 0.95
Batch: 720; loss: 0.17; acc: 0.94
Batch: 740; loss: 0.35; acc: 0.91
Batch: 760; loss: 0.23; acc: 0.92
Batch: 780; loss: 0.17; acc: 0.92
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.6301873731426895e-05
8.176234587153886e-06
Batch: 0; loss: 0.19; acc: 0.95
Batch: 20; loss: 0.4; acc: 0.91
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.21; acc: 0.94
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.43; acc: 0.86
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.24709717136849263; val_accuracy: 0.9290406050955414 

The current subspace-distance is: 8.176234587153886e-06 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.24; acc: 0.91
Batch: 20; loss: 0.2; acc: 0.95
Batch: 40; loss: 0.44; acc: 0.84
Batch: 60; loss: 0.27; acc: 0.94
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.25; acc: 0.91
Batch: 140; loss: 0.37; acc: 0.89
Batch: 160; loss: 0.27; acc: 0.89
Batch: 180; loss: 0.16; acc: 0.95
Batch: 200; loss: 0.28; acc: 0.94
Batch: 220; loss: 0.11; acc: 0.97
Batch: 240; loss: 0.27; acc: 0.88
Batch: 260; loss: 0.34; acc: 0.86
Batch: 280; loss: 0.3; acc: 0.94
Batch: 300; loss: 0.36; acc: 0.91
Batch: 320; loss: 0.22; acc: 0.92
Batch: 340; loss: 0.29; acc: 0.92
Batch: 360; loss: 0.19; acc: 0.92
Batch: 380; loss: 0.12; acc: 0.95
Batch: 400; loss: 0.2; acc: 0.92
Batch: 420; loss: 0.18; acc: 0.97
Batch: 440; loss: 0.21; acc: 0.97
Batch: 460; loss: 0.38; acc: 0.92
Batch: 480; loss: 0.15; acc: 0.94
Batch: 500; loss: 0.18; acc: 0.94
Batch: 520; loss: 0.24; acc: 0.89
Batch: 540; loss: 0.26; acc: 0.91
Batch: 560; loss: 0.21; acc: 0.92
Batch: 580; loss: 0.07; acc: 1.0
Batch: 600; loss: 0.25; acc: 0.92
Batch: 620; loss: 0.21; acc: 0.92
Batch: 640; loss: 0.41; acc: 0.92
Batch: 660; loss: 0.12; acc: 0.97
Batch: 680; loss: 0.1; acc: 0.97
Batch: 700; loss: 0.31; acc: 0.92
Batch: 720; loss: 0.14; acc: 0.94
Batch: 740; loss: 0.18; acc: 0.94
Batch: 760; loss: 0.08; acc: 0.97
Batch: 780; loss: 0.24; acc: 0.92
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.6084562705364078e-05
8.938432983995881e-06
Batch: 0; loss: 0.19; acc: 0.97
Batch: 20; loss: 0.4; acc: 0.91
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.2; acc: 0.92
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.28; acc: 0.92
Batch: 120; loss: 0.39; acc: 0.86
Batch: 140; loss: 0.09; acc: 0.98
Val Epoch over. val_loss: 0.25399421876782824; val_accuracy: 0.9238654458598726 

The current subspace-distance is: 8.938432983995881e-06 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.33; acc: 0.86
Batch: 20; loss: 0.28; acc: 0.91
Batch: 40; loss: 0.27; acc: 0.94
Batch: 60; loss: 0.23; acc: 0.92
Batch: 80; loss: 0.55; acc: 0.84
Batch: 100; loss: 0.48; acc: 0.84
Batch: 120; loss: 0.15; acc: 0.97
Batch: 140; loss: 0.19; acc: 0.91
Batch: 160; loss: 0.22; acc: 0.91
Batch: 180; loss: 0.34; acc: 0.89
Batch: 200; loss: 0.31; acc: 0.89
Batch: 220; loss: 0.4; acc: 0.89
Batch: 240; loss: 0.28; acc: 0.94
Batch: 260; loss: 0.55; acc: 0.88
Batch: 280; loss: 0.24; acc: 0.89
Batch: 300; loss: 0.4; acc: 0.83
Batch: 320; loss: 0.35; acc: 0.89
Batch: 340; loss: 0.28; acc: 0.92
Batch: 360; loss: 0.16; acc: 0.95
Batch: 380; loss: 0.25; acc: 0.92
Batch: 400; loss: 0.19; acc: 0.95
Batch: 420; loss: 0.27; acc: 0.92
Batch: 440; loss: 0.2; acc: 0.95
Batch: 460; loss: 0.15; acc: 0.92
Batch: 480; loss: 0.41; acc: 0.91
Batch: 500; loss: 0.28; acc: 0.94
Batch: 520; loss: 0.37; acc: 0.91
Batch: 540; loss: 0.27; acc: 0.92
Batch: 560; loss: 0.15; acc: 0.95
Batch: 580; loss: 0.27; acc: 0.92
Batch: 600; loss: 0.21; acc: 0.95
Batch: 620; loss: 0.28; acc: 0.91
Batch: 640; loss: 0.24; acc: 0.91
Batch: 660; loss: 0.08; acc: 0.97
Batch: 680; loss: 0.27; acc: 0.92
Batch: 700; loss: 0.16; acc: 0.94
Batch: 720; loss: 0.19; acc: 0.95
Batch: 740; loss: 0.17; acc: 0.95
Batch: 760; loss: 0.23; acc: 0.95
Batch: 780; loss: 0.24; acc: 0.95
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.6792948119691573e-05
7.75031639932422e-06
Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.43; acc: 0.84
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.22; acc: 0.92
Batch: 100; loss: 0.25; acc: 0.94
Batch: 120; loss: 0.46; acc: 0.84
Batch: 140; loss: 0.14; acc: 0.97
Val Epoch over. val_loss: 0.2668868340077294; val_accuracy: 0.9202826433121019 

The current subspace-distance is: 7.75031639932422e-06 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.21; acc: 0.91
Batch: 20; loss: 0.26; acc: 0.92
Batch: 40; loss: 0.17; acc: 0.97
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.24; acc: 0.91
Batch: 100; loss: 0.26; acc: 0.89
Batch: 120; loss: 0.25; acc: 0.89
Batch: 140; loss: 0.2; acc: 0.91
Batch: 160; loss: 0.41; acc: 0.88
Batch: 180; loss: 0.22; acc: 0.95
Batch: 200; loss: 0.28; acc: 0.88
Batch: 220; loss: 0.3; acc: 0.92
Batch: 240; loss: 0.18; acc: 0.94
Batch: 260; loss: 0.24; acc: 0.94
Batch: 280; loss: 0.23; acc: 0.94
Batch: 300; loss: 0.35; acc: 0.89
Batch: 320; loss: 0.36; acc: 0.91
Batch: 340; loss: 0.09; acc: 0.98
Batch: 360; loss: 0.35; acc: 0.86
Batch: 380; loss: 0.25; acc: 0.89
Batch: 400; loss: 0.2; acc: 0.92
Batch: 420; loss: 0.21; acc: 0.89
Batch: 440; loss: 0.29; acc: 0.94
Batch: 460; loss: 0.27; acc: 0.91
Batch: 480; loss: 0.18; acc: 0.94
Batch: 500; loss: 0.24; acc: 0.94
Batch: 520; loss: 0.31; acc: 0.86
Batch: 540; loss: 0.16; acc: 0.94
Batch: 560; loss: 0.3; acc: 0.92
Batch: 580; loss: 0.13; acc: 0.95
Batch: 600; loss: 0.19; acc: 0.92
Batch: 620; loss: 0.54; acc: 0.84
Batch: 640; loss: 0.18; acc: 0.94
Batch: 660; loss: 0.16; acc: 0.95
Batch: 680; loss: 0.42; acc: 0.88
Batch: 700; loss: 0.49; acc: 0.91
Batch: 720; loss: 0.45; acc: 0.84
Batch: 740; loss: 0.27; acc: 0.86
Batch: 760; loss: 0.43; acc: 0.88
Batch: 780; loss: 0.3; acc: 0.89
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

2.6932897526421584e-05
8.09297853265889e-06
Batch: 0; loss: 0.23; acc: 0.94
Batch: 20; loss: 0.35; acc: 0.88
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.2; acc: 0.92
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.33; acc: 0.91
Batch: 120; loss: 0.4; acc: 0.84
Batch: 140; loss: 0.2; acc: 0.92
Val Epoch over. val_loss: 0.30549491740241175; val_accuracy: 0.9038614649681529 

The current subspace-distance is: 8.09297853265889e-06 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.75; acc: 0.8
Batch: 20; loss: 0.2; acc: 0.92
Batch: 40; loss: 0.27; acc: 0.88
Batch: 60; loss: 0.3; acc: 0.88
Batch: 80; loss: 0.51; acc: 0.89
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.26; acc: 0.88
Batch: 140; loss: 0.26; acc: 0.89
Batch: 160; loss: 0.26; acc: 0.95
Batch: 180; loss: 0.3; acc: 0.89
Batch: 200; loss: 0.14; acc: 0.95
Batch: 220; loss: 0.11; acc: 0.98
Batch: 240; loss: 0.14; acc: 0.98
Batch: 260; loss: 0.33; acc: 0.92
Batch: 280; loss: 0.16; acc: 0.97
Batch: 300; loss: 0.11; acc: 0.98
Batch: 320; loss: 0.25; acc: 0.91
Batch: 340; loss: 0.2; acc: 0.92
Batch: 360; loss: 0.2; acc: 0.89
Batch: 380; loss: 0.21; acc: 0.95
Batch: 400; loss: 0.21; acc: 0.94
Batch: 420; loss: 0.19; acc: 0.91
Batch: 440; loss: 0.1; acc: 0.97
Batch: 460; loss: 0.11; acc: 0.97
Batch: 480; loss: 0.35; acc: 0.86
Batch: 500; loss: 0.23; acc: 0.91
Batch: 520; loss: 0.21; acc: 0.94
Batch: 540; loss: 0.19; acc: 0.94
Batch: 560; loss: 0.24; acc: 0.94
Batch: 580; loss: 0.19; acc: 0.95
Batch: 600; loss: 0.18; acc: 0.95
Batch: 620; loss: 0.21; acc: 0.91
Batch: 640; loss: 0.19; acc: 0.94
Batch: 660; loss: 0.23; acc: 0.92
Batch: 680; loss: 0.21; acc: 0.92
Batch: 700; loss: 0.19; acc: 0.95
Batch: 720; loss: 0.33; acc: 0.94
Batch: 740; loss: 0.15; acc: 0.94
Batch: 760; loss: 0.23; acc: 0.95
Batch: 780; loss: 0.19; acc: 0.92
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

2.5747387553565204e-05
8.161556252161972e-06
Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.32; acc: 0.89
Batch: 40; loss: 0.12; acc: 0.94
Batch: 60; loss: 0.18; acc: 0.95
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.22; acc: 0.95
Batch: 120; loss: 0.41; acc: 0.88
Batch: 140; loss: 0.09; acc: 0.98
Val Epoch over. val_loss: 0.235222593115963; val_accuracy: 0.9288415605095541 

The current subspace-distance is: 8.161556252161972e-06 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.27; acc: 0.88
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.07; acc: 0.97
Batch: 80; loss: 0.23; acc: 0.91
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.34; acc: 0.91
Batch: 140; loss: 0.16; acc: 0.95
Batch: 160; loss: 0.4; acc: 0.88
Batch: 180; loss: 0.11; acc: 0.97
Batch: 200; loss: 0.35; acc: 0.88
Batch: 220; loss: 0.1; acc: 0.95
Batch: 240; loss: 0.15; acc: 0.95
Batch: 260; loss: 0.14; acc: 0.94
Batch: 280; loss: 0.17; acc: 0.95
Batch: 300; loss: 0.32; acc: 0.88
Batch: 320; loss: 0.3; acc: 0.91
Batch: 340; loss: 0.06; acc: 0.98
Batch: 360; loss: 0.12; acc: 0.97
Batch: 380; loss: 0.25; acc: 0.92
Batch: 400; loss: 0.26; acc: 0.89
Batch: 420; loss: 0.19; acc: 0.95
Batch: 440; loss: 0.32; acc: 0.91
Batch: 460; loss: 0.28; acc: 0.88
Batch: 480; loss: 0.16; acc: 0.95
Batch: 500; loss: 0.18; acc: 0.95
Batch: 520; loss: 0.51; acc: 0.91
Batch: 540; loss: 0.27; acc: 0.89
Batch: 560; loss: 0.12; acc: 0.94
Batch: 580; loss: 0.27; acc: 0.89
Batch: 600; loss: 0.22; acc: 0.94
Batch: 620; loss: 0.21; acc: 0.94
Batch: 640; loss: 0.25; acc: 0.91
Batch: 660; loss: 0.16; acc: 0.94
Batch: 680; loss: 0.35; acc: 0.94
Batch: 700; loss: 0.19; acc: 0.92
Batch: 720; loss: 0.29; acc: 0.92
Batch: 740; loss: 0.13; acc: 0.95
Batch: 760; loss: 0.26; acc: 0.89
Batch: 780; loss: 0.2; acc: 0.95
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

2.7503117962623946e-05
8.451221219729632e-06
Batch: 0; loss: 0.18; acc: 0.97
Batch: 20; loss: 0.34; acc: 0.92
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.18; acc: 0.97
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.22; acc: 0.97
Batch: 120; loss: 0.41; acc: 0.86
Batch: 140; loss: 0.1; acc: 0.98
Val Epoch over. val_loss: 0.23200063653005537; val_accuracy: 0.9300358280254777 

The current subspace-distance is: 8.451221219729632e-06 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.24; acc: 0.95
Batch: 20; loss: 0.17; acc: 0.95
Batch: 40; loss: 0.33; acc: 0.83
Batch: 60; loss: 0.28; acc: 0.92
Batch: 80; loss: 0.29; acc: 0.91
Batch: 100; loss: 0.2; acc: 0.89
Batch: 120; loss: 0.46; acc: 0.84
Batch: 140; loss: 0.12; acc: 0.97
Batch: 160; loss: 0.22; acc: 0.92
Batch: 180; loss: 0.3; acc: 0.95
Batch: 200; loss: 0.26; acc: 0.88
Batch: 220; loss: 0.17; acc: 0.95
Batch: 240; loss: 0.19; acc: 0.95
Batch: 260; loss: 0.26; acc: 0.94
Batch: 280; loss: 0.06; acc: 0.98
Batch: 300; loss: 0.15; acc: 0.95
Batch: 320; loss: 0.25; acc: 0.95
Batch: 340; loss: 0.25; acc: 0.89
Batch: 360; loss: 0.21; acc: 0.89
Batch: 380; loss: 0.2; acc: 0.95
Batch: 400; loss: 0.31; acc: 0.91
Batch: 420; loss: 0.25; acc: 0.92
Batch: 440; loss: 0.68; acc: 0.83
Batch: 460; loss: 0.12; acc: 0.98
Batch: 480; loss: 0.16; acc: 0.94
Batch: 500; loss: 0.11; acc: 0.97
Batch: 520; loss: 0.33; acc: 0.92
Batch: 540; loss: 0.15; acc: 0.95
Batch: 560; loss: 0.26; acc: 0.89
Batch: 580; loss: 0.23; acc: 0.92
Batch: 600; loss: 0.27; acc: 0.89
Batch: 620; loss: 0.21; acc: 0.94
Batch: 640; loss: 0.28; acc: 0.89
Batch: 660; loss: 0.17; acc: 0.94
Batch: 680; loss: 0.18; acc: 0.92
Batch: 700; loss: 0.29; acc: 0.92
Batch: 720; loss: 0.17; acc: 0.95
Batch: 740; loss: 0.15; acc: 0.92
Batch: 760; loss: 0.09; acc: 0.98
Batch: 780; loss: 0.29; acc: 0.92
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

2.6009007342508994e-05
8.039161912165582e-06
Batch: 0; loss: 0.17; acc: 0.97
Batch: 20; loss: 0.33; acc: 0.89
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.23; acc: 0.95
Batch: 120; loss: 0.41; acc: 0.86
Batch: 140; loss: 0.11; acc: 0.98
Val Epoch over. val_loss: 0.23408232547437688; val_accuracy: 0.9312300955414012 

The current subspace-distance is: 8.039161912165582e-06 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.31; acc: 0.91
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.36; acc: 0.92
Batch: 60; loss: 0.32; acc: 0.92
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.14; acc: 0.97
Batch: 120; loss: 0.11; acc: 0.95
Batch: 140; loss: 0.2; acc: 0.94
Batch: 160; loss: 0.24; acc: 0.92
Batch: 180; loss: 0.29; acc: 0.92
Batch: 200; loss: 0.14; acc: 0.98
Batch: 220; loss: 0.47; acc: 0.88
Batch: 240; loss: 0.2; acc: 0.91
Batch: 260; loss: 0.37; acc: 0.92
Batch: 280; loss: 0.19; acc: 0.91
Batch: 300; loss: 0.19; acc: 0.95
Batch: 320; loss: 0.08; acc: 0.98
Batch: 340; loss: 0.33; acc: 0.94
Batch: 360; loss: 0.33; acc: 0.92
Batch: 380; loss: 0.27; acc: 0.95
Batch: 400; loss: 0.22; acc: 0.91
Batch: 420; loss: 0.32; acc: 0.89
Batch: 440; loss: 0.17; acc: 0.95
Batch: 460; loss: 0.22; acc: 0.92
Batch: 480; loss: 0.21; acc: 0.94
Batch: 500; loss: 0.21; acc: 0.94
Batch: 520; loss: 0.08; acc: 0.97
Batch: 540; loss: 0.19; acc: 0.94
Batch: 560; loss: 0.16; acc: 0.94
Batch: 580; loss: 0.26; acc: 0.91
Batch: 600; loss: 0.27; acc: 0.88
Batch: 620; loss: 0.28; acc: 0.91
Batch: 640; loss: 0.44; acc: 0.88
Batch: 660; loss: 0.24; acc: 0.89
Batch: 680; loss: 0.25; acc: 0.94
Batch: 700; loss: 0.13; acc: 0.97
Batch: 720; loss: 0.16; acc: 0.92
Batch: 740; loss: 0.25; acc: 0.94
Batch: 760; loss: 0.23; acc: 0.95
Batch: 780; loss: 0.42; acc: 0.84
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

2.667296757863369e-05
7.711192665738054e-06
Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.4; acc: 0.88
Batch: 140; loss: 0.1; acc: 0.98
Val Epoch over. val_loss: 0.22574172059821476; val_accuracy: 0.9328224522292994 

The current subspace-distance is: 7.711192665738054e-06 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.3; acc: 0.94
Batch: 20; loss: 0.31; acc: 0.92
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.28; acc: 0.94
Batch: 80; loss: 0.24; acc: 0.91
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.16; acc: 0.97
Batch: 140; loss: 0.14; acc: 0.98
Batch: 160; loss: 0.22; acc: 0.95
Batch: 180; loss: 0.25; acc: 0.95
Batch: 200; loss: 0.11; acc: 0.97
Batch: 220; loss: 0.14; acc: 0.92
Batch: 240; loss: 0.26; acc: 0.91
Batch: 260; loss: 0.1; acc: 0.97
Batch: 280; loss: 0.24; acc: 0.94
Batch: 300; loss: 0.2; acc: 0.92
Batch: 320; loss: 0.18; acc: 0.94
Batch: 340; loss: 0.19; acc: 0.91
Batch: 360; loss: 0.23; acc: 0.91
Batch: 380; loss: 0.4; acc: 0.94
Batch: 400; loss: 0.17; acc: 0.92
Batch: 420; loss: 0.23; acc: 0.94
Batch: 440; loss: 0.19; acc: 0.94
Batch: 460; loss: 0.45; acc: 0.88
Batch: 480; loss: 0.16; acc: 0.94
Batch: 500; loss: 0.31; acc: 0.91
Batch: 520; loss: 0.16; acc: 0.94
Batch: 540; loss: 0.27; acc: 0.91
Batch: 560; loss: 0.15; acc: 0.98
Batch: 580; loss: 0.18; acc: 0.92
Batch: 600; loss: 0.34; acc: 0.91
Batch: 620; loss: 0.23; acc: 0.92
Batch: 640; loss: 0.27; acc: 0.94
Batch: 660; loss: 0.45; acc: 0.84
Batch: 680; loss: 0.32; acc: 0.92
Batch: 700; loss: 0.12; acc: 0.95
Batch: 720; loss: 0.13; acc: 0.92
Batch: 740; loss: 0.23; acc: 0.94
Batch: 760; loss: 0.31; acc: 0.91
Batch: 780; loss: 0.19; acc: 0.94
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

2.7059129934059456e-05
8.045758477237541e-06
Batch: 0; loss: 0.19; acc: 0.97
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.2; acc: 0.97
Batch: 120; loss: 0.42; acc: 0.89
Batch: 140; loss: 0.1; acc: 0.98
Val Epoch over. val_loss: 0.22954998382479902; val_accuracy: 0.9300358280254777 

The current subspace-distance is: 8.045758477237541e-06 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.19; acc: 0.92
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.16; acc: 0.97
Batch: 80; loss: 0.39; acc: 0.92
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.12; acc: 0.95
Batch: 140; loss: 0.2; acc: 0.97
Batch: 160; loss: 0.17; acc: 0.94
Batch: 180; loss: 0.23; acc: 0.92
Batch: 200; loss: 0.38; acc: 0.88
Batch: 220; loss: 0.31; acc: 0.88
Batch: 240; loss: 0.19; acc: 0.94
Batch: 260; loss: 0.28; acc: 0.92
Batch: 280; loss: 0.16; acc: 0.94
Batch: 300; loss: 0.23; acc: 0.91
Batch: 320; loss: 0.23; acc: 0.91
Batch: 340; loss: 0.19; acc: 0.92
Batch: 360; loss: 0.19; acc: 0.92
Batch: 380; loss: 0.22; acc: 0.94
Batch: 400; loss: 0.14; acc: 0.95
Batch: 420; loss: 0.27; acc: 0.94
Batch: 440; loss: 0.17; acc: 0.94
Batch: 460; loss: 0.24; acc: 0.88
Batch: 480; loss: 0.19; acc: 0.94
Batch: 500; loss: 0.17; acc: 0.92
Batch: 520; loss: 0.19; acc: 0.95
Batch: 540; loss: 0.2; acc: 0.95
Batch: 560; loss: 0.21; acc: 0.91
Batch: 580; loss: 0.24; acc: 0.94
Batch: 600; loss: 0.25; acc: 0.95
Batch: 620; loss: 0.21; acc: 0.92
Batch: 640; loss: 0.31; acc: 0.92
Batch: 660; loss: 0.19; acc: 0.92
Batch: 680; loss: 0.17; acc: 0.94
Batch: 700; loss: 0.22; acc: 0.94
Batch: 720; loss: 0.21; acc: 0.94
Batch: 740; loss: 0.23; acc: 0.95
Batch: 760; loss: 0.27; acc: 0.95
Batch: 780; loss: 0.08; acc: 0.98
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.654715171956923e-05
7.909394298621919e-06
Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.29; acc: 0.95
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.94
Batch: 80; loss: 0.22; acc: 0.95
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.4; acc: 0.86
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.227639739727898; val_accuracy: 0.9303343949044586 

The current subspace-distance is: 7.909394298621919e-06 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.14; acc: 0.94
Batch: 20; loss: 0.36; acc: 0.88
Batch: 40; loss: 0.26; acc: 0.92
Batch: 60; loss: 0.24; acc: 0.91
Batch: 80; loss: 0.27; acc: 0.91
Batch: 100; loss: 0.13; acc: 0.94
Batch: 120; loss: 0.19; acc: 0.94
Batch: 140; loss: 0.16; acc: 0.92
Batch: 160; loss: 0.47; acc: 0.86
Batch: 180; loss: 0.21; acc: 0.95
Batch: 200; loss: 0.3; acc: 0.89
Batch: 220; loss: 0.2; acc: 0.94
Batch: 240; loss: 0.25; acc: 0.92
Batch: 260; loss: 0.21; acc: 0.94
Batch: 280; loss: 0.3; acc: 0.86
Batch: 300; loss: 0.23; acc: 0.92
Batch: 320; loss: 0.23; acc: 0.91
Batch: 340; loss: 0.21; acc: 0.94
Batch: 360; loss: 0.14; acc: 0.94
Batch: 380; loss: 0.26; acc: 0.94
Batch: 400; loss: 0.13; acc: 0.97
Batch: 420; loss: 0.16; acc: 0.94
Batch: 440; loss: 0.1; acc: 0.98
Batch: 460; loss: 0.28; acc: 0.91
Batch: 480; loss: 0.15; acc: 0.94
Batch: 500; loss: 0.28; acc: 0.94
Batch: 520; loss: 0.14; acc: 0.98
Batch: 540; loss: 0.31; acc: 0.91
Batch: 560; loss: 0.19; acc: 0.95
Batch: 580; loss: 0.36; acc: 0.89
Batch: 600; loss: 0.24; acc: 0.91
Batch: 620; loss: 0.41; acc: 0.94
Batch: 640; loss: 0.27; acc: 0.92
Batch: 660; loss: 0.52; acc: 0.89
Batch: 680; loss: 0.29; acc: 0.94
Batch: 700; loss: 0.31; acc: 0.89
Batch: 720; loss: 0.24; acc: 0.91
Batch: 740; loss: 0.26; acc: 0.91
Batch: 760; loss: 0.25; acc: 0.92
Batch: 780; loss: 0.13; acc: 0.94
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.6458345018909313e-05
7.5177445069130044e-06
Batch: 0; loss: 0.17; acc: 0.97
Batch: 20; loss: 0.31; acc: 0.89
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.18; acc: 0.95
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.2; acc: 0.97
Batch: 120; loss: 0.44; acc: 0.84
Batch: 140; loss: 0.09; acc: 0.98
Val Epoch over. val_loss: 0.2298806379697505; val_accuracy: 0.9320262738853503 

The current subspace-distance is: 7.5177445069130044e-06 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.29; acc: 0.92
Batch: 20; loss: 0.24; acc: 0.97
Batch: 40; loss: 0.25; acc: 0.91
Batch: 60; loss: 0.33; acc: 0.92
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.07; acc: 0.98
Batch: 140; loss: 0.24; acc: 0.94
Batch: 160; loss: 0.16; acc: 0.92
Batch: 180; loss: 0.32; acc: 0.88
Batch: 200; loss: 0.12; acc: 0.95
Batch: 220; loss: 0.29; acc: 0.89
Batch: 240; loss: 0.24; acc: 0.91
Batch: 260; loss: 0.31; acc: 0.92
Batch: 280; loss: 0.09; acc: 0.98
Batch: 300; loss: 0.4; acc: 0.91
Batch: 320; loss: 0.04; acc: 1.0
Batch: 340; loss: 0.32; acc: 0.91
Batch: 360; loss: 0.35; acc: 0.89
Batch: 380; loss: 0.3; acc: 0.89
Batch: 400; loss: 0.28; acc: 0.91
Batch: 420; loss: 0.29; acc: 0.94
Batch: 440; loss: 0.36; acc: 0.92
Batch: 460; loss: 0.3; acc: 0.89
Batch: 480; loss: 0.18; acc: 0.98
Batch: 500; loss: 0.23; acc: 0.95
Batch: 520; loss: 0.18; acc: 0.94
Batch: 540; loss: 0.31; acc: 0.86
Batch: 560; loss: 0.11; acc: 0.97
Batch: 580; loss: 0.24; acc: 0.92
Batch: 600; loss: 0.16; acc: 0.98
Batch: 620; loss: 0.14; acc: 0.97
Batch: 640; loss: 0.04; acc: 0.98
Batch: 660; loss: 0.53; acc: 0.88
Batch: 680; loss: 0.13; acc: 0.97
Batch: 700; loss: 0.25; acc: 0.92
Batch: 720; loss: 0.23; acc: 0.91
Batch: 740; loss: 0.29; acc: 0.91
Batch: 760; loss: 0.17; acc: 0.95
Batch: 780; loss: 0.41; acc: 0.95
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.711056004045531e-05
8.542891009710729e-06
Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.21; acc: 0.97
Batch: 120; loss: 0.4; acc: 0.88
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.22712657807074535; val_accuracy: 0.931031050955414 

The current subspace-distance is: 8.542891009710729e-06 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.23; acc: 0.94
Batch: 20; loss: 0.27; acc: 0.89
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.1; acc: 0.94
Batch: 100; loss: 0.12; acc: 0.97
Batch: 120; loss: 0.19; acc: 0.94
Batch: 140; loss: 0.17; acc: 0.95
Batch: 160; loss: 0.36; acc: 0.88
Batch: 180; loss: 0.19; acc: 0.95
Batch: 200; loss: 0.14; acc: 0.97
Batch: 220; loss: 0.24; acc: 0.94
Batch: 240; loss: 0.14; acc: 0.91
Batch: 260; loss: 0.63; acc: 0.81
Batch: 280; loss: 0.31; acc: 0.94
Batch: 300; loss: 0.13; acc: 0.95
Batch: 320; loss: 0.11; acc: 0.95
Batch: 340; loss: 0.1; acc: 0.95
Batch: 360; loss: 0.23; acc: 0.92
Batch: 380; loss: 0.23; acc: 0.92
Batch: 400; loss: 0.18; acc: 0.92
Batch: 420; loss: 0.28; acc: 0.91
Batch: 440; loss: 0.1; acc: 0.97
Batch: 460; loss: 0.21; acc: 0.89
Batch: 480; loss: 0.16; acc: 0.95
Batch: 500; loss: 0.09; acc: 0.97
Batch: 520; loss: 0.18; acc: 0.95
Batch: 540; loss: 0.11; acc: 0.98
Batch: 560; loss: 0.23; acc: 0.88
Batch: 580; loss: 0.18; acc: 0.92
Batch: 600; loss: 0.25; acc: 0.95
Batch: 620; loss: 0.27; acc: 0.89
Batch: 640; loss: 0.28; acc: 0.91
Batch: 660; loss: 0.1; acc: 0.94
Batch: 680; loss: 0.24; acc: 0.92
Batch: 700; loss: 0.17; acc: 0.94
Batch: 720; loss: 0.13; acc: 0.95
Batch: 740; loss: 0.19; acc: 0.91
Batch: 760; loss: 0.11; acc: 0.97
Batch: 780; loss: 0.22; acc: 0.92
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.7417218007030897e-05
7.380463557637995e-06
Batch: 0; loss: 0.18; acc: 0.97
Batch: 20; loss: 0.31; acc: 0.92
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.21; acc: 0.94
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.18; acc: 0.97
Batch: 120; loss: 0.41; acc: 0.88
Batch: 140; loss: 0.09; acc: 0.98
Val Epoch over. val_loss: 0.22470336293528795; val_accuracy: 0.9317277070063694 

The current subspace-distance is: 7.380463557637995e-06 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.17; acc: 0.97
Batch: 60; loss: 0.39; acc: 0.88
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.17; acc: 0.92
Batch: 120; loss: 0.16; acc: 0.92
Batch: 140; loss: 0.13; acc: 0.95
Batch: 160; loss: 0.19; acc: 0.92
Batch: 180; loss: 0.3; acc: 0.92
Batch: 200; loss: 0.11; acc: 0.95
Batch: 220; loss: 0.38; acc: 0.89
Batch: 240; loss: 0.09; acc: 0.97
Batch: 260; loss: 0.15; acc: 0.95
Batch: 280; loss: 0.08; acc: 0.98
Batch: 300; loss: 0.36; acc: 0.89
Batch: 320; loss: 0.18; acc: 0.91
Batch: 340; loss: 0.12; acc: 0.97
Batch: 360; loss: 0.3; acc: 0.91
Batch: 380; loss: 0.25; acc: 0.95
Batch: 400; loss: 0.29; acc: 0.95
Batch: 420; loss: 0.11; acc: 0.94
Batch: 440; loss: 0.52; acc: 0.89
Batch: 460; loss: 0.33; acc: 0.91
Batch: 480; loss: 0.19; acc: 0.94
Batch: 500; loss: 0.1; acc: 0.95
Batch: 520; loss: 0.22; acc: 0.95
Batch: 540; loss: 0.21; acc: 0.92
Batch: 560; loss: 0.25; acc: 0.92
Batch: 580; loss: 0.41; acc: 0.86
Batch: 600; loss: 0.18; acc: 0.94
Batch: 620; loss: 0.42; acc: 0.89
Batch: 640; loss: 0.36; acc: 0.86
Batch: 660; loss: 0.12; acc: 0.95
Batch: 680; loss: 0.25; acc: 0.89
Batch: 700; loss: 0.32; acc: 0.92
Batch: 720; loss: 0.18; acc: 0.95
Batch: 740; loss: 0.24; acc: 0.89
Batch: 760; loss: 0.15; acc: 0.94
Batch: 780; loss: 0.18; acc: 0.97
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.6322552002966404e-05
8.552293365937658e-06
Batch: 0; loss: 0.18; acc: 0.97
Batch: 20; loss: 0.28; acc: 0.91
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.18; acc: 0.95
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.41; acc: 0.84
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.22092530563188967; val_accuracy: 0.9323248407643312 

The current subspace-distance is: 8.552293365937658e-06 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.18; acc: 0.95
Batch: 80; loss: 0.23; acc: 0.91
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.38; acc: 0.92
Batch: 140; loss: 0.46; acc: 0.88
Batch: 160; loss: 0.36; acc: 0.86
Batch: 180; loss: 0.14; acc: 0.95
Batch: 200; loss: 0.32; acc: 0.91
Batch: 220; loss: 0.27; acc: 0.92
Batch: 240; loss: 0.33; acc: 0.92
Batch: 260; loss: 0.27; acc: 0.95
Batch: 280; loss: 0.26; acc: 0.92
Batch: 300; loss: 0.49; acc: 0.84
Batch: 320; loss: 0.15; acc: 0.94
Batch: 340; loss: 0.36; acc: 0.89
Batch: 360; loss: 0.18; acc: 0.97
Batch: 380; loss: 0.09; acc: 0.97
Batch: 400; loss: 0.15; acc: 0.94
Batch: 420; loss: 0.2; acc: 0.94
Batch: 440; loss: 0.22; acc: 0.91
Batch: 460; loss: 0.43; acc: 0.91
Batch: 480; loss: 0.12; acc: 0.95
Batch: 500; loss: 0.17; acc: 0.94
Batch: 520; loss: 0.31; acc: 0.92
Batch: 540; loss: 0.22; acc: 0.92
Batch: 560; loss: 0.23; acc: 0.91
Batch: 580; loss: 0.22; acc: 0.97
Batch: 600; loss: 0.55; acc: 0.84
Batch: 620; loss: 0.09; acc: 0.97
Batch: 640; loss: 0.36; acc: 0.91
Batch: 660; loss: 0.15; acc: 0.92
Batch: 680; loss: 0.17; acc: 0.94
Batch: 700; loss: 0.28; acc: 0.89
Batch: 720; loss: 0.27; acc: 0.92
Batch: 740; loss: 0.25; acc: 0.88
Batch: 760; loss: 0.27; acc: 0.91
Batch: 780; loss: 0.18; acc: 0.94
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.7865082302014343e-05
8.977859579317737e-06
Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.95
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.18; acc: 0.97
Batch: 120; loss: 0.39; acc: 0.88
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.21862067337960575; val_accuracy: 0.9344148089171974 

The current subspace-distance is: 8.977859579317737e-06 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.14; acc: 0.97
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.22; acc: 0.92
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.36; acc: 0.92
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.15; acc: 0.94
Batch: 140; loss: 0.47; acc: 0.84
Batch: 160; loss: 0.17; acc: 0.95
Batch: 180; loss: 0.06; acc: 0.98
Batch: 200; loss: 0.19; acc: 0.92
Batch: 220; loss: 0.41; acc: 0.89
Batch: 240; loss: 0.12; acc: 0.98
Batch: 260; loss: 0.2; acc: 0.94
Batch: 280; loss: 0.39; acc: 0.86
Batch: 300; loss: 0.59; acc: 0.86
Batch: 320; loss: 0.26; acc: 0.89
Batch: 340; loss: 0.37; acc: 0.92
Batch: 360; loss: 0.18; acc: 0.97
Batch: 380; loss: 0.14; acc: 0.97
Batch: 400; loss: 0.25; acc: 0.92
Batch: 420; loss: 0.19; acc: 0.92
Batch: 440; loss: 0.17; acc: 0.92
Batch: 460; loss: 0.29; acc: 0.94
Batch: 480; loss: 0.11; acc: 0.94
Batch: 500; loss: 0.3; acc: 0.89
Batch: 520; loss: 0.31; acc: 0.92
Batch: 540; loss: 0.22; acc: 0.95
Batch: 560; loss: 0.24; acc: 0.94
Batch: 580; loss: 0.14; acc: 0.94
Batch: 600; loss: 0.2; acc: 0.92
Batch: 620; loss: 0.54; acc: 0.86
Batch: 640; loss: 0.13; acc: 0.97
Batch: 660; loss: 0.13; acc: 0.95
Batch: 680; loss: 0.2; acc: 0.95
Batch: 700; loss: 0.12; acc: 0.98
Batch: 720; loss: 0.19; acc: 0.95
Batch: 740; loss: 0.17; acc: 0.95
Batch: 760; loss: 0.14; acc: 0.94
Batch: 780; loss: 0.24; acc: 0.92
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.6428760975250043e-05
7.860774530854542e-06
Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.94
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.18; acc: 0.97
Batch: 120; loss: 0.41; acc: 0.86
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.2197898300068014; val_accuracy: 0.9341162420382165 

The current subspace-distance is: 7.860774530854542e-06 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.13; acc: 0.94
Batch: 40; loss: 0.22; acc: 0.88
Batch: 60; loss: 0.12; acc: 0.97
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.19; acc: 0.91
Batch: 140; loss: 0.25; acc: 0.88
Batch: 160; loss: 0.13; acc: 0.97
Batch: 180; loss: 0.18; acc: 0.92
Batch: 200; loss: 0.19; acc: 0.92
Batch: 220; loss: 0.33; acc: 0.92
Batch: 240; loss: 0.48; acc: 0.88
Batch: 260; loss: 0.25; acc: 0.91
Batch: 280; loss: 0.27; acc: 0.94
Batch: 300; loss: 0.18; acc: 0.94
Batch: 320; loss: 0.31; acc: 0.91
Batch: 340; loss: 0.16; acc: 0.94
Batch: 360; loss: 0.17; acc: 0.92
Batch: 380; loss: 0.14; acc: 0.95
Batch: 400; loss: 0.19; acc: 0.94
Batch: 420; loss: 0.2; acc: 0.91
Batch: 440; loss: 0.15; acc: 0.95
Batch: 460; loss: 0.21; acc: 0.95
Batch: 480; loss: 0.24; acc: 0.94
Batch: 500; loss: 0.16; acc: 0.94
Batch: 520; loss: 0.1; acc: 1.0
Batch: 540; loss: 0.25; acc: 0.91
Batch: 560; loss: 0.2; acc: 0.91
Batch: 580; loss: 0.3; acc: 0.91
Batch: 600; loss: 0.16; acc: 0.88
Batch: 620; loss: 0.31; acc: 0.91
Batch: 640; loss: 0.24; acc: 0.94
Batch: 660; loss: 0.18; acc: 0.92
Batch: 680; loss: 0.33; acc: 0.84
Batch: 700; loss: 0.18; acc: 0.94
Batch: 720; loss: 0.33; acc: 0.89
Batch: 740; loss: 0.25; acc: 0.89
Batch: 760; loss: 0.18; acc: 0.94
Batch: 780; loss: 0.21; acc: 0.94
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.739190313150175e-05
8.419714504270814e-06
Batch: 0; loss: 0.17; acc: 0.97
Batch: 20; loss: 0.27; acc: 0.91
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.94
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.97
Batch: 120; loss: 0.39; acc: 0.86
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.2188528403877073; val_accuracy: 0.9339171974522293 

The current subspace-distance is: 8.419714504270814e-06 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.41; acc: 0.97
Batch: 40; loss: 0.28; acc: 0.94
Batch: 60; loss: 0.2; acc: 0.91
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.36; acc: 0.92
Batch: 120; loss: 0.26; acc: 0.94
Batch: 140; loss: 0.24; acc: 0.91
Batch: 160; loss: 0.2; acc: 0.92
Batch: 180; loss: 0.19; acc: 0.92
Batch: 200; loss: 0.22; acc: 0.91
Batch: 220; loss: 0.27; acc: 0.92
Batch: 240; loss: 0.11; acc: 0.97
Batch: 260; loss: 0.28; acc: 0.89
Batch: 280; loss: 0.1; acc: 0.97
Batch: 300; loss: 0.19; acc: 0.94
Batch: 320; loss: 0.2; acc: 0.91
Batch: 340; loss: 0.29; acc: 0.89
Batch: 360; loss: 0.2; acc: 0.89
Batch: 380; loss: 0.09; acc: 0.98
Batch: 400; loss: 0.27; acc: 0.92
Batch: 420; loss: 0.21; acc: 0.94
Batch: 440; loss: 0.26; acc: 0.94
Batch: 460; loss: 0.18; acc: 0.95
Batch: 480; loss: 0.06; acc: 1.0
Batch: 500; loss: 0.22; acc: 0.94
Batch: 520; loss: 0.13; acc: 0.97
Batch: 540; loss: 0.29; acc: 0.92
Batch: 560; loss: 0.16; acc: 0.97
Batch: 580; loss: 0.1; acc: 0.97
Batch: 600; loss: 0.22; acc: 0.92
Batch: 620; loss: 0.25; acc: 0.92
Batch: 640; loss: 0.18; acc: 0.94
Batch: 660; loss: 0.36; acc: 0.95
Batch: 680; loss: 0.17; acc: 0.98
Batch: 700; loss: 0.32; acc: 0.84
Batch: 720; loss: 0.05; acc: 1.0
Batch: 740; loss: 0.21; acc: 0.94
Batch: 760; loss: 0.25; acc: 0.95
Batch: 780; loss: 0.16; acc: 0.92
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.71004992100643e-05
8.449755114270374e-06
Batch: 0; loss: 0.18; acc: 0.97
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.94
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.18; acc: 0.97
Batch: 120; loss: 0.39; acc: 0.86
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2187542272079143; val_accuracy: 0.9341162420382165 

The current subspace-distance is: 8.449755114270374e-06 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.33; acc: 0.94
Batch: 20; loss: 0.21; acc: 0.91
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.25; acc: 0.92
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.16; acc: 0.97
Batch: 140; loss: 0.08; acc: 0.98
Batch: 160; loss: 0.19; acc: 0.94
Batch: 180; loss: 0.09; acc: 0.98
Batch: 200; loss: 0.25; acc: 0.94
Batch: 220; loss: 0.35; acc: 0.92
Batch: 240; loss: 0.3; acc: 0.91
Batch: 260; loss: 0.24; acc: 0.92
Batch: 280; loss: 0.38; acc: 0.89
Batch: 300; loss: 0.16; acc: 0.95
Batch: 320; loss: 0.31; acc: 0.91
Batch: 340; loss: 0.19; acc: 0.95
Batch: 360; loss: 0.2; acc: 0.94
Batch: 380; loss: 0.21; acc: 0.95
Batch: 400; loss: 0.27; acc: 0.92
Batch: 420; loss: 0.31; acc: 0.89
Batch: 440; loss: 0.35; acc: 0.88
Batch: 460; loss: 0.19; acc: 0.97
Batch: 480; loss: 0.27; acc: 0.91
Batch: 500; loss: 0.08; acc: 0.95
Batch: 520; loss: 0.18; acc: 0.94
Batch: 540; loss: 0.32; acc: 0.91
Batch: 560; loss: 0.14; acc: 0.95
Batch: 580; loss: 0.3; acc: 0.94
Batch: 600; loss: 0.15; acc: 0.94
Batch: 620; loss: 0.2; acc: 0.92
Batch: 640; loss: 0.4; acc: 0.91
Batch: 660; loss: 0.2; acc: 0.94
Batch: 680; loss: 0.15; acc: 0.94
Batch: 700; loss: 0.11; acc: 0.97
Batch: 720; loss: 0.24; acc: 0.91
Batch: 740; loss: 0.22; acc: 0.92
Batch: 760; loss: 0.24; acc: 0.92
Batch: 780; loss: 0.28; acc: 0.94
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.746989412116818e-05
7.880805242166389e-06
Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.28; acc: 0.92
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.94
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.18; acc: 0.97
Batch: 120; loss: 0.4; acc: 0.86
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.2168974183547269; val_accuracy: 0.9351114649681529 

The current subspace-distance is: 7.880805242166389e-06 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.25; acc: 0.94
Batch: 40; loss: 0.22; acc: 0.95
Batch: 60; loss: 0.24; acc: 0.92
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.1; acc: 0.98
Batch: 120; loss: 0.3; acc: 0.86
Batch: 140; loss: 0.18; acc: 0.98
Batch: 160; loss: 0.17; acc: 0.95
Batch: 180; loss: 0.27; acc: 0.94
Batch: 200; loss: 0.12; acc: 0.97
Batch: 220; loss: 0.06; acc: 0.98
Batch: 240; loss: 0.1; acc: 0.97
Batch: 260; loss: 0.18; acc: 0.97
Batch: 280; loss: 0.46; acc: 0.91
Batch: 300; loss: 0.34; acc: 0.88
Batch: 320; loss: 0.19; acc: 0.97
Batch: 340; loss: 0.2; acc: 0.92
Batch: 360; loss: 0.27; acc: 0.89
Batch: 380; loss: 0.28; acc: 0.92
Batch: 400; loss: 0.05; acc: 0.98
Batch: 420; loss: 0.22; acc: 0.92
Batch: 440; loss: 0.17; acc: 0.94
Batch: 460; loss: 0.19; acc: 0.92
Batch: 480; loss: 0.24; acc: 0.92
Batch: 500; loss: 0.35; acc: 0.92
Batch: 520; loss: 0.17; acc: 0.92
Batch: 540; loss: 0.24; acc: 0.91
Batch: 560; loss: 0.24; acc: 0.94
Batch: 580; loss: 0.39; acc: 0.88
Batch: 600; loss: 0.21; acc: 0.91
Batch: 620; loss: 0.44; acc: 0.89
Batch: 640; loss: 0.37; acc: 0.91
Batch: 660; loss: 0.2; acc: 0.92
Batch: 680; loss: 0.16; acc: 0.95
Batch: 700; loss: 0.09; acc: 0.95
Batch: 720; loss: 0.29; acc: 0.92
Batch: 740; loss: 0.09; acc: 0.98
Batch: 760; loss: 0.27; acc: 0.91
Batch: 780; loss: 0.29; acc: 0.88
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.6083831471623853e-05
7.845333129807841e-06
Batch: 0; loss: 0.17; acc: 0.97
Batch: 20; loss: 0.3; acc: 0.89
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.95
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.18; acc: 0.97
Batch: 120; loss: 0.41; acc: 0.89
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.22074464537725327; val_accuracy: 0.934812898089172 

The current subspace-distance is: 7.845333129807841e-06 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.32; acc: 0.92
Batch: 40; loss: 0.19; acc: 0.92
Batch: 60; loss: 0.37; acc: 0.86
Batch: 80; loss: 0.19; acc: 0.92
Batch: 100; loss: 0.19; acc: 0.91
Batch: 120; loss: 0.19; acc: 0.95
Batch: 140; loss: 0.13; acc: 0.95
Batch: 160; loss: 0.33; acc: 0.91
Batch: 180; loss: 0.25; acc: 0.94
Batch: 200; loss: 0.27; acc: 0.92
Batch: 220; loss: 0.28; acc: 0.89
Batch: 240; loss: 0.26; acc: 0.91
Batch: 260; loss: 0.23; acc: 0.91
Batch: 280; loss: 0.1; acc: 1.0
Batch: 300; loss: 0.2; acc: 0.94
Batch: 320; loss: 0.32; acc: 0.94
Batch: 340; loss: 0.48; acc: 0.84
Batch: 360; loss: 0.29; acc: 0.94
Batch: 380; loss: 0.13; acc: 0.95
Batch: 400; loss: 0.21; acc: 0.91
Batch: 420; loss: 0.16; acc: 0.91
Batch: 440; loss: 0.13; acc: 0.97
Batch: 460; loss: 0.21; acc: 0.94
Batch: 480; loss: 0.2; acc: 0.94
Batch: 500; loss: 0.19; acc: 0.95
Batch: 520; loss: 0.15; acc: 0.92
Batch: 540; loss: 0.22; acc: 0.94
Batch: 560; loss: 0.2; acc: 0.94
Batch: 580; loss: 0.24; acc: 0.95
Batch: 600; loss: 0.28; acc: 0.89
Batch: 620; loss: 0.14; acc: 0.94
Batch: 640; loss: 0.46; acc: 0.88
Batch: 660; loss: 0.15; acc: 0.95
Batch: 680; loss: 0.16; acc: 0.92
Batch: 700; loss: 0.37; acc: 0.91
Batch: 720; loss: 0.14; acc: 0.95
Batch: 740; loss: 0.11; acc: 0.95
Batch: 760; loss: 0.21; acc: 0.91
Batch: 780; loss: 0.22; acc: 0.92
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.673803646757733e-05
8.249120583059266e-06
Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.94
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.18; acc: 0.97
Batch: 120; loss: 0.4; acc: 0.86
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.21843210560311177; val_accuracy: 0.9349124203821656 

The current subspace-distance is: 8.249120583059266e-06 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.2; acc: 0.92
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.15; acc: 0.95
Batch: 80; loss: 0.22; acc: 0.92
Batch: 100; loss: 0.22; acc: 0.95
Batch: 120; loss: 0.25; acc: 0.92
Batch: 140; loss: 0.43; acc: 0.86
Batch: 160; loss: 0.2; acc: 0.89
Batch: 180; loss: 0.05; acc: 0.98
Batch: 200; loss: 0.17; acc: 0.94
Batch: 220; loss: 0.16; acc: 0.97
Batch: 240; loss: 0.36; acc: 0.91
Batch: 260; loss: 0.22; acc: 0.92
Batch: 280; loss: 0.2; acc: 0.95
Batch: 300; loss: 0.17; acc: 0.95
Batch: 320; loss: 0.15; acc: 0.95
Batch: 340; loss: 0.15; acc: 0.97
Batch: 360; loss: 0.29; acc: 0.97
Batch: 380; loss: 0.23; acc: 0.94
Batch: 400; loss: 0.12; acc: 0.94
Batch: 420; loss: 0.32; acc: 0.91
Batch: 440; loss: 0.19; acc: 0.92
Batch: 460; loss: 0.2; acc: 0.94
Batch: 480; loss: 0.15; acc: 0.95
Batch: 500; loss: 0.13; acc: 0.97
Batch: 520; loss: 0.28; acc: 0.88
Batch: 540; loss: 0.12; acc: 0.97
Batch: 560; loss: 0.24; acc: 0.95
Batch: 580; loss: 0.13; acc: 0.97
Batch: 600; loss: 0.27; acc: 0.86
Batch: 620; loss: 0.17; acc: 0.95
Batch: 640; loss: 0.08; acc: 0.97
Batch: 660; loss: 0.19; acc: 0.94
Batch: 680; loss: 0.23; acc: 0.91
Batch: 700; loss: 0.32; acc: 0.95
Batch: 720; loss: 0.17; acc: 0.95
Batch: 740; loss: 0.37; acc: 0.83
Batch: 760; loss: 0.15; acc: 0.95
Batch: 780; loss: 0.21; acc: 0.92
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.6425806936458685e-05
7.376622306765057e-06
Batch: 0; loss: 0.17; acc: 0.97
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.94
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.97
Batch: 120; loss: 0.41; acc: 0.86
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.21782407427954067; val_accuracy: 0.9327229299363057 

The current subspace-distance is: 7.376622306765057e-06 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.49; acc: 0.88
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.09; acc: 1.0
Batch: 80; loss: 0.42; acc: 0.92
Batch: 100; loss: 0.32; acc: 0.92
Batch: 120; loss: 0.23; acc: 0.89
Batch: 140; loss: 0.31; acc: 0.89
Batch: 160; loss: 0.12; acc: 0.97
Batch: 180; loss: 0.19; acc: 0.95
Batch: 200; loss: 0.22; acc: 0.94
Batch: 220; loss: 0.25; acc: 0.92
Batch: 240; loss: 0.21; acc: 0.91
Batch: 260; loss: 0.37; acc: 0.91
Batch: 280; loss: 0.13; acc: 0.97
Batch: 300; loss: 0.36; acc: 0.89
Batch: 320; loss: 0.17; acc: 0.95
Batch: 340; loss: 0.14; acc: 0.95
Batch: 360; loss: 0.14; acc: 0.95
Batch: 380; loss: 0.11; acc: 0.98
Batch: 400; loss: 0.15; acc: 0.98
Batch: 420; loss: 0.33; acc: 0.92
Batch: 440; loss: 0.07; acc: 0.97
Batch: 460; loss: 0.15; acc: 0.94
Batch: 480; loss: 0.13; acc: 0.95
Batch: 500; loss: 0.19; acc: 0.92
Batch: 520; loss: 0.18; acc: 0.92
Batch: 540; loss: 0.16; acc: 0.95
Batch: 560; loss: 0.29; acc: 0.91
Batch: 580; loss: 0.33; acc: 0.89
Batch: 600; loss: 0.15; acc: 0.95
Batch: 620; loss: 0.22; acc: 0.92
Batch: 640; loss: 0.17; acc: 0.94
Batch: 660; loss: 0.12; acc: 0.95
Batch: 680; loss: 0.12; acc: 0.97
Batch: 700; loss: 0.36; acc: 0.86
Batch: 720; loss: 0.12; acc: 0.95
Batch: 740; loss: 0.29; acc: 0.88
Batch: 760; loss: 0.22; acc: 0.94
Batch: 780; loss: 0.16; acc: 0.94
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.6982097551808693e-05
7.85534120950615e-06
Batch: 0; loss: 0.18; acc: 0.97
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.21; acc: 0.94
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.97
Batch: 120; loss: 0.43; acc: 0.88
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.22052601024888124; val_accuracy: 0.9325238853503185 

The current subspace-distance is: 7.85534120950615e-06 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.22; acc: 0.91
Batch: 20; loss: 0.2; acc: 0.92
Batch: 40; loss: 0.18; acc: 0.97
Batch: 60; loss: 0.24; acc: 0.91
Batch: 80; loss: 0.3; acc: 0.94
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.37; acc: 0.92
Batch: 140; loss: 0.28; acc: 0.92
Batch: 160; loss: 0.15; acc: 0.94
Batch: 180; loss: 0.13; acc: 0.97
Batch: 200; loss: 0.11; acc: 0.97
Batch: 220; loss: 0.14; acc: 0.98
Batch: 240; loss: 0.14; acc: 0.97
Batch: 260; loss: 0.15; acc: 0.94
Batch: 280; loss: 0.22; acc: 0.94
Batch: 300; loss: 0.2; acc: 0.94
Batch: 320; loss: 0.12; acc: 0.95
Batch: 340; loss: 0.26; acc: 0.88
Batch: 360; loss: 0.17; acc: 0.92
Batch: 380; loss: 0.11; acc: 0.97
Batch: 400; loss: 0.08; acc: 0.98
Batch: 420; loss: 0.14; acc: 0.94
Batch: 440; loss: 0.18; acc: 0.91
Batch: 460; loss: 0.19; acc: 0.95
Batch: 480; loss: 0.16; acc: 0.97
Batch: 500; loss: 0.2; acc: 0.89
Batch: 520; loss: 0.13; acc: 0.94
Batch: 540; loss: 0.04; acc: 1.0
Batch: 560; loss: 0.15; acc: 0.95
Batch: 580; loss: 0.23; acc: 0.91
Batch: 600; loss: 0.13; acc: 0.94
Batch: 620; loss: 0.32; acc: 0.92
Batch: 640; loss: 0.22; acc: 0.94
Batch: 660; loss: 0.23; acc: 0.95
Batch: 680; loss: 0.34; acc: 0.89
Batch: 700; loss: 0.35; acc: 0.91
Batch: 720; loss: 0.13; acc: 0.94
Batch: 740; loss: 0.17; acc: 0.95
Batch: 760; loss: 0.18; acc: 0.94
Batch: 780; loss: 0.14; acc: 0.95
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.6877725758822635e-05
7.2948282650031615e-06
Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.28; acc: 0.91
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.97
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.18; acc: 0.97
Batch: 120; loss: 0.39; acc: 0.89
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.21574846980203488; val_accuracy: 0.9368033439490446 

The current subspace-distance is: 7.2948282650031615e-06 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.2; acc: 0.94
Batch: 60; loss: 0.24; acc: 0.91
Batch: 80; loss: 0.26; acc: 0.95
Batch: 100; loss: 0.28; acc: 0.94
Batch: 120; loss: 0.24; acc: 0.94
Batch: 140; loss: 0.16; acc: 0.92
Batch: 160; loss: 0.22; acc: 0.92
Batch: 180; loss: 0.18; acc: 0.94
Batch: 200; loss: 0.22; acc: 0.95
Batch: 220; loss: 0.29; acc: 0.95
Batch: 240; loss: 0.21; acc: 0.89
Batch: 260; loss: 0.1; acc: 0.97
Batch: 280; loss: 0.49; acc: 0.86
Batch: 300; loss: 0.25; acc: 0.92
Batch: 320; loss: 0.18; acc: 0.95
Batch: 340; loss: 0.13; acc: 0.97
Batch: 360; loss: 0.29; acc: 0.94
Batch: 380; loss: 0.33; acc: 0.89
Batch: 400; loss: 0.28; acc: 0.94
Batch: 420; loss: 0.2; acc: 0.92
Batch: 440; loss: 0.38; acc: 0.89
Batch: 460; loss: 0.21; acc: 0.94
Batch: 480; loss: 0.14; acc: 0.95
Batch: 500; loss: 0.11; acc: 0.94
Batch: 520; loss: 0.33; acc: 0.94
Batch: 540; loss: 0.14; acc: 0.95
Batch: 560; loss: 0.2; acc: 0.92
Batch: 580; loss: 0.2; acc: 0.94
Batch: 600; loss: 0.18; acc: 0.92
Batch: 620; loss: 0.08; acc: 0.97
Batch: 640; loss: 0.15; acc: 0.97
Batch: 660; loss: 0.22; acc: 0.97
Batch: 680; loss: 0.11; acc: 0.98
Batch: 700; loss: 0.26; acc: 0.92
Batch: 720; loss: 0.34; acc: 0.89
Batch: 740; loss: 0.27; acc: 0.94
Batch: 760; loss: 0.05; acc: 1.0
Batch: 780; loss: 0.09; acc: 0.98
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.61094537563622e-05
7.415800155285979e-06
Batch: 0; loss: 0.17; acc: 0.97
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.95
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.97
Batch: 120; loss: 0.41; acc: 0.86
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.21579234092051436; val_accuracy: 0.9357085987261147 

The current subspace-distance is: 7.415800155285979e-06 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.17; acc: 0.95
Batch: 40; loss: 0.22; acc: 0.92
Batch: 60; loss: 0.21; acc: 0.91
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.25; acc: 0.91
Batch: 140; loss: 0.13; acc: 0.95
Batch: 160; loss: 0.33; acc: 0.89
Batch: 180; loss: 0.21; acc: 0.94
Batch: 200; loss: 0.24; acc: 0.95
Batch: 220; loss: 0.14; acc: 0.92
Batch: 240; loss: 0.2; acc: 0.91
Batch: 260; loss: 0.11; acc: 0.98
Batch: 280; loss: 0.2; acc: 0.91
Batch: 300; loss: 0.25; acc: 0.92
Batch: 320; loss: 0.2; acc: 0.94
Batch: 340; loss: 0.09; acc: 0.98
Batch: 360; loss: 0.22; acc: 0.94
Batch: 380; loss: 0.1; acc: 0.98
Batch: 400; loss: 0.26; acc: 0.89
Batch: 420; loss: 0.16; acc: 0.94
Batch: 440; loss: 0.39; acc: 0.89
Batch: 460; loss: 0.07; acc: 1.0
Batch: 480; loss: 0.29; acc: 0.95
Batch: 500; loss: 0.17; acc: 0.92
Batch: 520; loss: 0.32; acc: 0.89
Batch: 540; loss: 0.1; acc: 0.95
Batch: 560; loss: 0.17; acc: 0.94
Batch: 580; loss: 0.33; acc: 0.89
Batch: 600; loss: 0.31; acc: 0.94
Batch: 620; loss: 0.23; acc: 0.92
Batch: 640; loss: 0.17; acc: 0.95
Batch: 660; loss: 0.33; acc: 0.86
Batch: 680; loss: 0.14; acc: 0.95
Batch: 700; loss: 0.25; acc: 0.89
Batch: 720; loss: 0.17; acc: 0.94
Batch: 740; loss: 0.11; acc: 0.97
Batch: 760; loss: 0.14; acc: 0.95
Batch: 780; loss: 0.22; acc: 0.92
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.7354333724360913e-05
8.022834663279355e-06
Batch: 0; loss: 0.17; acc: 0.97
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.94
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.97
Batch: 120; loss: 0.4; acc: 0.86
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2180047612281362; val_accuracy: 0.9333200636942676 

The current subspace-distance is: 8.022834663279355e-06 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.41; acc: 0.92
Batch: 20; loss: 0.38; acc: 0.95
Batch: 40; loss: 0.31; acc: 0.94
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.11; acc: 0.97
Batch: 140; loss: 0.31; acc: 0.91
Batch: 160; loss: 0.1; acc: 0.97
Batch: 180; loss: 0.21; acc: 0.94
Batch: 200; loss: 0.16; acc: 0.95
Batch: 220; loss: 0.22; acc: 0.91
Batch: 240; loss: 0.38; acc: 0.89
Batch: 260; loss: 0.29; acc: 0.92
Batch: 280; loss: 0.13; acc: 0.95
Batch: 300; loss: 0.17; acc: 0.94
Batch: 320; loss: 0.19; acc: 0.91
Batch: 340; loss: 0.17; acc: 0.95
Batch: 360; loss: 0.19; acc: 0.92
Batch: 380; loss: 0.16; acc: 0.94
Batch: 400; loss: 0.24; acc: 0.89
Batch: 420; loss: 0.17; acc: 0.94
Batch: 440; loss: 0.2; acc: 0.95
Batch: 460; loss: 0.13; acc: 0.97
Batch: 480; loss: 0.14; acc: 0.94
Batch: 500; loss: 0.2; acc: 0.94
Batch: 520; loss: 0.62; acc: 0.88
Batch: 540; loss: 0.23; acc: 0.95
Batch: 560; loss: 0.12; acc: 0.95
Batch: 580; loss: 0.47; acc: 0.88
Batch: 600; loss: 0.21; acc: 0.92
Batch: 620; loss: 0.19; acc: 0.97
Batch: 640; loss: 0.08; acc: 0.98
Batch: 660; loss: 0.09; acc: 0.95
Batch: 680; loss: 0.29; acc: 0.91
Batch: 700; loss: 0.1; acc: 0.97
Batch: 720; loss: 0.24; acc: 0.92
Batch: 740; loss: 0.13; acc: 0.95
Batch: 760; loss: 0.2; acc: 0.94
Batch: 780; loss: 0.16; acc: 0.95
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.790302642097231e-05
8.73421140568098e-06
Batch: 0; loss: 0.17; acc: 0.97
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.94
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.97
Batch: 120; loss: 0.41; acc: 0.86
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.21515313203737235; val_accuracy: 0.9355095541401274 

The current subspace-distance is: 8.73421140568098e-06 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.16; acc: 0.94
Batch: 20; loss: 0.31; acc: 0.88
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.51; acc: 0.86
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.33; acc: 0.89
Batch: 120; loss: 0.19; acc: 0.94
Batch: 140; loss: 0.21; acc: 0.94
Batch: 160; loss: 0.29; acc: 0.94
Batch: 180; loss: 0.25; acc: 0.92
Batch: 200; loss: 0.29; acc: 0.94
Batch: 220; loss: 0.11; acc: 0.95
Batch: 240; loss: 0.28; acc: 0.94
Batch: 260; loss: 0.2; acc: 0.97
Batch: 280; loss: 0.3; acc: 0.89
Batch: 300; loss: 0.27; acc: 0.95
Batch: 320; loss: 0.35; acc: 0.88
Batch: 340; loss: 0.25; acc: 0.94
Batch: 360; loss: 0.3; acc: 0.91
Batch: 380; loss: 0.22; acc: 0.95
Batch: 400; loss: 0.38; acc: 0.88
Batch: 420; loss: 0.13; acc: 0.94
Batch: 440; loss: 0.16; acc: 0.92
Batch: 460; loss: 0.18; acc: 0.95
Batch: 480; loss: 0.34; acc: 0.89
Batch: 500; loss: 0.44; acc: 0.92
Batch: 520; loss: 0.23; acc: 0.94
Batch: 540; loss: 0.12; acc: 1.0
Batch: 560; loss: 0.19; acc: 0.95
Batch: 580; loss: 0.41; acc: 0.89
Batch: 600; loss: 0.26; acc: 0.92
Batch: 620; loss: 0.16; acc: 0.92
Batch: 640; loss: 0.23; acc: 0.91
Batch: 660; loss: 0.42; acc: 0.86
Batch: 680; loss: 0.12; acc: 0.95
Batch: 700; loss: 0.25; acc: 0.89
Batch: 720; loss: 0.2; acc: 0.98
Batch: 740; loss: 0.58; acc: 0.88
Batch: 760; loss: 0.19; acc: 0.97
Batch: 780; loss: 0.26; acc: 0.92
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.8064296202501282e-05
8.190680091502145e-06
Batch: 0; loss: 0.17; acc: 0.97
Batch: 20; loss: 0.29; acc: 0.89
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.19; acc: 0.97
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.18; acc: 0.97
Batch: 120; loss: 0.39; acc: 0.88
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.2148526090962492; val_accuracy: 0.9362062101910829 

The current subspace-distance is: 8.190680091502145e-06 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.13; acc: 0.98
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.15; acc: 0.94
Batch: 120; loss: 0.24; acc: 0.92
Batch: 140; loss: 0.09; acc: 0.97
Batch: 160; loss: 0.18; acc: 0.94
Batch: 180; loss: 0.11; acc: 0.97
Batch: 200; loss: 0.25; acc: 0.89
Batch: 220; loss: 0.11; acc: 0.97
Batch: 240; loss: 0.33; acc: 0.91
Batch: 260; loss: 0.23; acc: 0.94
Batch: 280; loss: 0.36; acc: 0.91
Batch: 300; loss: 0.22; acc: 0.89
Batch: 320; loss: 0.24; acc: 0.92
Batch: 340; loss: 0.1; acc: 0.97
Batch: 360; loss: 0.15; acc: 0.97
Batch: 380; loss: 0.14; acc: 0.97
Batch: 400; loss: 0.13; acc: 0.95
Batch: 420; loss: 0.22; acc: 0.95
Batch: 440; loss: 0.2; acc: 0.92
Batch: 460; loss: 0.09; acc: 0.98
Batch: 480; loss: 0.19; acc: 0.92
Batch: 500; loss: 0.18; acc: 0.94
Batch: 520; loss: 0.11; acc: 0.97
Batch: 540; loss: 0.23; acc: 0.95
Batch: 560; loss: 0.1; acc: 0.97
Batch: 580; loss: 0.13; acc: 0.98
Batch: 600; loss: 0.33; acc: 0.92
Batch: 620; loss: 0.09; acc: 1.0
Batch: 640; loss: 0.2; acc: 0.95
Batch: 660; loss: 0.42; acc: 0.88
Batch: 680; loss: 0.28; acc: 0.95
Batch: 700; loss: 0.13; acc: 0.95
Batch: 720; loss: 0.34; acc: 0.88
Batch: 740; loss: 0.22; acc: 0.92
Batch: 760; loss: 0.14; acc: 0.94
Batch: 780; loss: 0.2; acc: 0.91
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.7152360416948795e-05
8.535024790035095e-06
Batch: 0; loss: 0.16; acc: 0.97
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.95
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.18; acc: 0.97
Batch: 120; loss: 0.41; acc: 0.86
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.21528590781388768; val_accuracy: 0.935609076433121 

The current subspace-distance is: 8.535024790035095e-06 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.27; acc: 0.92
Batch: 40; loss: 0.27; acc: 0.91
Batch: 60; loss: 0.22; acc: 0.92
Batch: 80; loss: 0.31; acc: 0.92
Batch: 100; loss: 0.12; acc: 0.97
Batch: 120; loss: 0.29; acc: 0.91
Batch: 140; loss: 0.25; acc: 0.95
Batch: 160; loss: 0.34; acc: 0.92
Batch: 180; loss: 0.21; acc: 0.92
Batch: 200; loss: 0.18; acc: 0.95
Batch: 220; loss: 0.21; acc: 0.94
Batch: 240; loss: 0.17; acc: 0.97
Batch: 260; loss: 0.16; acc: 0.92
Batch: 280; loss: 0.28; acc: 0.91
Batch: 300; loss: 0.23; acc: 0.95
Batch: 320; loss: 0.45; acc: 0.92
Batch: 340; loss: 0.14; acc: 0.94
Batch: 360; loss: 0.45; acc: 0.92
Batch: 380; loss: 0.41; acc: 0.83
Batch: 400; loss: 0.15; acc: 0.94
Batch: 420; loss: 0.19; acc: 0.92
Batch: 440; loss: 0.16; acc: 0.94
Batch: 460; loss: 0.38; acc: 0.91
Batch: 480; loss: 0.46; acc: 0.86
Batch: 500; loss: 0.21; acc: 0.92
Batch: 520; loss: 0.28; acc: 0.89
Batch: 540; loss: 0.54; acc: 0.89
Batch: 560; loss: 0.13; acc: 0.97
Batch: 580; loss: 0.27; acc: 0.89
Batch: 600; loss: 0.07; acc: 1.0
Batch: 620; loss: 0.4; acc: 0.92
Batch: 640; loss: 0.17; acc: 0.92
Batch: 660; loss: 0.15; acc: 0.95
Batch: 680; loss: 0.14; acc: 0.95
Batch: 700; loss: 0.37; acc: 0.91
Batch: 720; loss: 0.15; acc: 0.94
Batch: 740; loss: 0.22; acc: 0.94
Batch: 760; loss: 0.27; acc: 0.92
Batch: 780; loss: 0.13; acc: 0.94
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.6960400646203198e-05
7.598277534270892e-06
Batch: 0; loss: 0.17; acc: 0.97
Batch: 20; loss: 0.28; acc: 0.91
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.94
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.97
Batch: 120; loss: 0.41; acc: 0.86
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2160645378101024; val_accuracy: 0.9336186305732485 

The current subspace-distance is: 7.598277534270892e-06 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.23; acc: 0.95
Batch: 60; loss: 0.19; acc: 0.92
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.34; acc: 0.91
Batch: 120; loss: 0.16; acc: 0.94
Batch: 140; loss: 0.21; acc: 0.92
Batch: 160; loss: 0.25; acc: 0.91
Batch: 180; loss: 0.15; acc: 0.94
Batch: 200; loss: 0.25; acc: 0.89
Batch: 220; loss: 0.15; acc: 0.97
Batch: 240; loss: 0.16; acc: 0.97
Batch: 260; loss: 0.26; acc: 0.89
Batch: 280; loss: 0.09; acc: 0.97
Batch: 300; loss: 0.19; acc: 0.91
Batch: 320; loss: 0.3; acc: 0.88
Batch: 340; loss: 0.18; acc: 0.94
Batch: 360; loss: 0.42; acc: 0.83
Batch: 380; loss: 0.12; acc: 0.95
Batch: 400; loss: 0.25; acc: 0.94
Batch: 420; loss: 0.34; acc: 0.91
Batch: 440; loss: 0.19; acc: 0.95
Batch: 460; loss: 0.3; acc: 0.92
Batch: 480; loss: 0.18; acc: 0.94
Batch: 500; loss: 0.13; acc: 0.95
Batch: 520; loss: 0.28; acc: 0.94
Batch: 540; loss: 0.13; acc: 0.97
Batch: 560; loss: 0.13; acc: 0.95
Batch: 580; loss: 0.15; acc: 0.92
Batch: 600; loss: 0.15; acc: 0.94
Batch: 620; loss: 0.33; acc: 0.91
Batch: 640; loss: 0.14; acc: 0.98
Batch: 660; loss: 0.12; acc: 0.95
Batch: 680; loss: 0.33; acc: 0.89
Batch: 700; loss: 0.28; acc: 0.91
Batch: 720; loss: 0.19; acc: 0.95
Batch: 740; loss: 0.2; acc: 0.94
Batch: 760; loss: 0.24; acc: 0.95
Batch: 780; loss: 0.22; acc: 0.97
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.6748733944259584e-05
7.982712304510642e-06
Batch: 0; loss: 0.17; acc: 0.97
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.95
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.97
Batch: 120; loss: 0.41; acc: 0.86
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.21425467328565895; val_accuracy: 0.9355095541401274 

The current subspace-distance is: 7.982712304510642e-06 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.2; acc: 0.91
Batch: 60; loss: 0.2; acc: 0.92
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.27; acc: 0.97
Batch: 120; loss: 0.3; acc: 0.86
Batch: 140; loss: 0.29; acc: 0.92
Batch: 160; loss: 0.4; acc: 0.88
Batch: 180; loss: 0.11; acc: 0.98
Batch: 200; loss: 0.21; acc: 0.94
Batch: 220; loss: 0.14; acc: 0.95
Batch: 240; loss: 0.14; acc: 0.97
Batch: 260; loss: 0.57; acc: 0.86
Batch: 280; loss: 0.25; acc: 0.89
Batch: 300; loss: 0.15; acc: 0.94
Batch: 320; loss: 0.3; acc: 0.92
Batch: 340; loss: 0.11; acc: 0.95
Batch: 360; loss: 0.16; acc: 0.94
Batch: 380; loss: 0.29; acc: 0.94
Batch: 400; loss: 0.12; acc: 0.95
Batch: 420; loss: 0.17; acc: 0.92
Batch: 440; loss: 0.14; acc: 0.94
Batch: 460; loss: 0.18; acc: 0.97
Batch: 480; loss: 0.24; acc: 0.89
Batch: 500; loss: 0.39; acc: 0.92
Batch: 520; loss: 0.13; acc: 0.97
Batch: 540; loss: 0.53; acc: 0.89
Batch: 560; loss: 0.41; acc: 0.91
Batch: 580; loss: 0.21; acc: 0.94
Batch: 600; loss: 0.38; acc: 0.89
Batch: 620; loss: 0.28; acc: 0.92
Batch: 640; loss: 0.08; acc: 0.97
Batch: 660; loss: 0.09; acc: 0.97
Batch: 680; loss: 0.11; acc: 0.97
Batch: 700; loss: 0.13; acc: 0.97
Batch: 720; loss: 0.2; acc: 0.92
Batch: 740; loss: 0.2; acc: 0.89
Batch: 760; loss: 0.17; acc: 0.94
Batch: 780; loss: 0.35; acc: 0.94
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.6810355848283507e-05
8.254967724496964e-06
Batch: 0; loss: 0.17; acc: 0.97
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.94
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.97
Batch: 120; loss: 0.41; acc: 0.86
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.215126088731418; val_accuracy: 0.9334195859872612 

The current subspace-distance is: 8.254967724496964e-06 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.26; acc: 0.89
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.39; acc: 0.91
Batch: 80; loss: 0.28; acc: 0.91
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.17; acc: 0.95
Batch: 140; loss: 0.18; acc: 0.95
Batch: 160; loss: 0.24; acc: 0.94
Batch: 180; loss: 0.27; acc: 0.88
Batch: 200; loss: 0.29; acc: 0.92
Batch: 220; loss: 0.24; acc: 0.89
Batch: 240; loss: 0.16; acc: 0.95
Batch: 260; loss: 0.1; acc: 0.97
Batch: 280; loss: 0.24; acc: 0.92
Batch: 300; loss: 0.27; acc: 0.89
Batch: 320; loss: 0.12; acc: 0.97
Batch: 340; loss: 0.38; acc: 0.84
Batch: 360; loss: 0.23; acc: 0.89
Batch: 380; loss: 0.27; acc: 0.92
Batch: 400; loss: 0.14; acc: 0.95
Batch: 420; loss: 0.28; acc: 0.94
Batch: 440; loss: 0.2; acc: 0.94
Batch: 460; loss: 0.16; acc: 0.92
Batch: 480; loss: 0.27; acc: 0.89
Batch: 500; loss: 0.3; acc: 0.92
Batch: 520; loss: 0.2; acc: 0.92
Batch: 540; loss: 0.21; acc: 0.94
Batch: 560; loss: 0.18; acc: 0.94
Batch: 580; loss: 0.11; acc: 0.95
Batch: 600; loss: 0.22; acc: 0.94
Batch: 620; loss: 0.13; acc: 0.95
Batch: 640; loss: 0.33; acc: 0.91
Batch: 660; loss: 0.11; acc: 0.97
Batch: 680; loss: 0.28; acc: 0.92
Batch: 700; loss: 0.19; acc: 0.92
Batch: 720; loss: 0.22; acc: 0.94
Batch: 740; loss: 0.16; acc: 0.95
Batch: 760; loss: 0.33; acc: 0.91
Batch: 780; loss: 0.26; acc: 0.92
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.648486952239182e-05
7.895407179603353e-06
Batch: 0; loss: 0.17; acc: 0.97
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.95
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.97
Batch: 120; loss: 0.41; acc: 0.86
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.21477463207901662; val_accuracy: 0.9354100318471338 

The current subspace-distance is: 7.895407179603353e-06 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.22; acc: 0.91
Batch: 40; loss: 0.32; acc: 0.89
Batch: 60; loss: 0.2; acc: 0.95
Batch: 80; loss: 0.31; acc: 0.92
Batch: 100; loss: 0.31; acc: 0.92
Batch: 120; loss: 0.19; acc: 0.92
Batch: 140; loss: 0.22; acc: 0.95
Batch: 160; loss: 0.26; acc: 0.94
Batch: 180; loss: 0.16; acc: 0.97
Batch: 200; loss: 0.24; acc: 0.89
Batch: 220; loss: 0.3; acc: 0.89
Batch: 240; loss: 0.18; acc: 0.94
Batch: 260; loss: 0.23; acc: 0.92
Batch: 280; loss: 0.1; acc: 0.97
Batch: 300; loss: 0.28; acc: 0.89
Batch: 320; loss: 0.15; acc: 0.92
Batch: 340; loss: 0.28; acc: 0.88
Batch: 360; loss: 0.31; acc: 0.89
Batch: 380; loss: 0.16; acc: 0.95
Batch: 400; loss: 0.31; acc: 0.84
Batch: 420; loss: 0.16; acc: 0.95
Batch: 440; loss: 0.13; acc: 0.97
Batch: 460; loss: 0.29; acc: 0.92
Batch: 480; loss: 0.26; acc: 0.92
Batch: 500; loss: 0.34; acc: 0.84
Batch: 520; loss: 0.16; acc: 0.94
Batch: 540; loss: 0.19; acc: 0.92
Batch: 560; loss: 0.44; acc: 0.89
Batch: 580; loss: 0.3; acc: 0.91
Batch: 600; loss: 0.23; acc: 0.95
Batch: 620; loss: 0.2; acc: 0.97
Batch: 640; loss: 0.25; acc: 0.95
Batch: 660; loss: 0.14; acc: 0.94
Batch: 680; loss: 0.42; acc: 0.91
Batch: 700; loss: 0.19; acc: 0.94
Batch: 720; loss: 0.11; acc: 0.97
Batch: 740; loss: 0.33; acc: 0.86
Batch: 760; loss: 0.15; acc: 0.95
Batch: 780; loss: 0.3; acc: 0.89
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.6891120796790347e-05
7.476491191482637e-06
Batch: 0; loss: 0.17; acc: 0.97
Batch: 20; loss: 0.28; acc: 0.91
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.94
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.18; acc: 0.97
Batch: 120; loss: 0.39; acc: 0.86
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.21502305493707868; val_accuracy: 0.935609076433121 

The current subspace-distance is: 7.476491191482637e-06 

plots/subspace_training/reg_lenet_3/2020-01-22 20:51:04/d_dim_200_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
nonzero elements in E: 53568
elements in E: 11247500
fraction nonzero: 0.004762658368526339
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.31; acc: 0.08
Batch: 20; loss: 2.29; acc: 0.05
Batch: 40; loss: 2.3; acc: 0.09
Batch: 60; loss: 2.3; acc: 0.02
Batch: 80; loss: 2.3; acc: 0.08
Batch: 100; loss: 2.29; acc: 0.12
Batch: 120; loss: 2.3; acc: 0.11
Batch: 140; loss: 2.31; acc: 0.08
Batch: 160; loss: 2.3; acc: 0.08
Batch: 180; loss: 2.29; acc: 0.11
Batch: 200; loss: 2.29; acc: 0.14
Batch: 220; loss: 2.3; acc: 0.06
Batch: 240; loss: 2.3; acc: 0.05
Batch: 260; loss: 2.29; acc: 0.09
Batch: 280; loss: 2.28; acc: 0.05
Batch: 300; loss: 2.28; acc: 0.05
Batch: 320; loss: 2.29; acc: 0.08
Batch: 340; loss: 2.28; acc: 0.06
Batch: 360; loss: 2.27; acc: 0.16
Batch: 380; loss: 2.28; acc: 0.14
Batch: 400; loss: 2.27; acc: 0.19
Batch: 420; loss: 2.28; acc: 0.11
Batch: 440; loss: 2.25; acc: 0.25
Batch: 460; loss: 2.25; acc: 0.22
Batch: 480; loss: 2.24; acc: 0.31
Batch: 500; loss: 2.2; acc: 0.41
Batch: 520; loss: 2.23; acc: 0.25
Batch: 540; loss: 2.15; acc: 0.36
Batch: 560; loss: 2.16; acc: 0.27
Batch: 580; loss: 2.11; acc: 0.36
Batch: 600; loss: 2.02; acc: 0.52
Batch: 620; loss: 1.81; acc: 0.62
Batch: 640; loss: 1.76; acc: 0.52
Batch: 660; loss: 1.45; acc: 0.55
Batch: 680; loss: 1.38; acc: 0.61
Batch: 700; loss: 1.27; acc: 0.56
Batch: 720; loss: 1.06; acc: 0.67
Batch: 740; loss: 1.02; acc: 0.66
Batch: 760; loss: 0.98; acc: 0.64
Batch: 780; loss: 0.93; acc: 0.67
Train Epoch over. train_loss: 2.05; train_accuracy: 0.25 

1.0106935405929107e-05
4.652843472285895e-06
Batch: 0; loss: 0.84; acc: 0.67
Batch: 20; loss: 1.06; acc: 0.59
Batch: 40; loss: 0.49; acc: 0.81
Batch: 60; loss: 0.8; acc: 0.75
Batch: 80; loss: 0.58; acc: 0.78
Batch: 100; loss: 0.74; acc: 0.73
Batch: 120; loss: 0.85; acc: 0.7
Batch: 140; loss: 0.73; acc: 0.73
Val Epoch over. val_loss: 0.7632692930804696; val_accuracy: 0.7507961783439491 

The current subspace-distance is: 4.652843472285895e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 0.89; acc: 0.72
Batch: 20; loss: 1.39; acc: 0.58
Batch: 40; loss: 0.73; acc: 0.8
Batch: 60; loss: 0.69; acc: 0.81
Batch: 80; loss: 0.66; acc: 0.83
Batch: 100; loss: 0.55; acc: 0.81
Batch: 120; loss: 0.76; acc: 0.75
Batch: 140; loss: 0.44; acc: 0.88
Batch: 160; loss: 0.6; acc: 0.8
Batch: 180; loss: 0.51; acc: 0.83
Batch: 200; loss: 0.41; acc: 0.83
Batch: 220; loss: 0.68; acc: 0.8
Batch: 240; loss: 0.48; acc: 0.88
Batch: 260; loss: 0.51; acc: 0.86
Batch: 280; loss: 0.51; acc: 0.89
Batch: 300; loss: 0.45; acc: 0.86
Batch: 320; loss: 0.43; acc: 0.86
Batch: 340; loss: 0.56; acc: 0.83
Batch: 360; loss: 0.37; acc: 0.88
Batch: 380; loss: 0.34; acc: 0.89
Batch: 400; loss: 0.34; acc: 0.88
Batch: 420; loss: 0.42; acc: 0.86
Batch: 440; loss: 0.78; acc: 0.78
Batch: 460; loss: 0.53; acc: 0.8
Batch: 480; loss: 0.25; acc: 0.92
Batch: 500; loss: 0.38; acc: 0.88
Batch: 520; loss: 0.25; acc: 0.94
Batch: 540; loss: 0.27; acc: 0.94
Batch: 560; loss: 0.35; acc: 0.91
Batch: 580; loss: 0.31; acc: 0.91
Batch: 600; loss: 0.53; acc: 0.81
Batch: 620; loss: 0.24; acc: 0.97
Batch: 640; loss: 0.45; acc: 0.84
Batch: 660; loss: 0.6; acc: 0.81
Batch: 680; loss: 0.57; acc: 0.78
Batch: 700; loss: 0.39; acc: 0.88
Batch: 720; loss: 0.35; acc: 0.89
Batch: 740; loss: 0.56; acc: 0.92
Batch: 760; loss: 0.62; acc: 0.83
Batch: 780; loss: 0.45; acc: 0.84
Train Epoch over. train_loss: 0.53; train_accuracy: 0.83 

1.947272539837286e-05
6.61378180666361e-06
Batch: 0; loss: 0.46; acc: 0.84
Batch: 20; loss: 0.51; acc: 0.81
Batch: 40; loss: 0.34; acc: 0.83
Batch: 60; loss: 0.77; acc: 0.77
Batch: 80; loss: 0.34; acc: 0.88
Batch: 100; loss: 0.56; acc: 0.86
Batch: 120; loss: 0.81; acc: 0.75
Batch: 140; loss: 0.32; acc: 0.86
Val Epoch over. val_loss: 0.45361905687364046; val_accuracy: 0.8557921974522293 

The current subspace-distance is: 6.61378180666361e-06 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.77; acc: 0.78
Batch: 20; loss: 0.27; acc: 0.91
Batch: 40; loss: 0.3; acc: 0.91
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.43; acc: 0.83
Batch: 100; loss: 0.47; acc: 0.86
Batch: 120; loss: 0.41; acc: 0.89
Batch: 140; loss: 0.4; acc: 0.86
Batch: 160; loss: 0.36; acc: 0.92
Batch: 180; loss: 0.34; acc: 0.91
Batch: 200; loss: 0.4; acc: 0.88
Batch: 220; loss: 0.48; acc: 0.84
Batch: 240; loss: 0.62; acc: 0.83
Batch: 260; loss: 0.45; acc: 0.86
Batch: 280; loss: 0.33; acc: 0.91
Batch: 300; loss: 0.36; acc: 0.89
Batch: 320; loss: 0.29; acc: 0.94
Batch: 340; loss: 0.39; acc: 0.84
Batch: 360; loss: 0.37; acc: 0.89
Batch: 380; loss: 0.33; acc: 0.94
Batch: 400; loss: 0.46; acc: 0.88
Batch: 420; loss: 0.45; acc: 0.88
Batch: 440; loss: 0.25; acc: 0.94
Batch: 460; loss: 0.36; acc: 0.91
Batch: 480; loss: 0.36; acc: 0.89
Batch: 500; loss: 0.57; acc: 0.81
Batch: 520; loss: 0.22; acc: 0.92
Batch: 540; loss: 0.27; acc: 0.94
Batch: 560; loss: 0.44; acc: 0.86
Batch: 580; loss: 0.34; acc: 0.86
Batch: 600; loss: 0.24; acc: 0.92
Batch: 620; loss: 0.55; acc: 0.84
Batch: 640; loss: 0.25; acc: 0.91
Batch: 660; loss: 0.41; acc: 0.86
Batch: 680; loss: 0.33; acc: 0.88
Batch: 700; loss: 0.36; acc: 0.86
Batch: 720; loss: 0.21; acc: 0.92
Batch: 740; loss: 0.41; acc: 0.91
Batch: 760; loss: 0.23; acc: 0.92
Batch: 780; loss: 0.26; acc: 0.92
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

2.2083901058067568e-05
6.931110874575097e-06
Batch: 0; loss: 0.21; acc: 0.92
Batch: 20; loss: 0.36; acc: 0.88
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.45; acc: 0.83
Batch: 80; loss: 0.22; acc: 0.95
Batch: 100; loss: 0.42; acc: 0.88
Batch: 120; loss: 0.59; acc: 0.77
Batch: 140; loss: 0.2; acc: 0.94
Val Epoch over. val_loss: 0.33569060318219435; val_accuracy: 0.8932125796178344 

The current subspace-distance is: 6.931110874575097e-06 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.36; acc: 0.91
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.42; acc: 0.88
Batch: 60; loss: 0.34; acc: 0.86
Batch: 80; loss: 0.32; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.22; acc: 0.91
Batch: 140; loss: 0.22; acc: 0.94
Batch: 160; loss: 0.23; acc: 0.91
Batch: 180; loss: 0.33; acc: 0.91
Batch: 200; loss: 0.28; acc: 0.95
Batch: 220; loss: 0.51; acc: 0.89
Batch: 240; loss: 0.43; acc: 0.89
Batch: 260; loss: 0.25; acc: 0.91
Batch: 280; loss: 0.7; acc: 0.88
Batch: 300; loss: 0.33; acc: 0.89
Batch: 320; loss: 0.34; acc: 0.92
Batch: 340; loss: 0.32; acc: 0.92
Batch: 360; loss: 0.35; acc: 0.92
Batch: 380; loss: 0.26; acc: 0.95
Batch: 400; loss: 0.32; acc: 0.91
Batch: 420; loss: 0.5; acc: 0.88
Batch: 440; loss: 0.14; acc: 0.97
Batch: 460; loss: 0.3; acc: 0.91
Batch: 480; loss: 0.32; acc: 0.89
Batch: 500; loss: 0.21; acc: 0.91
Batch: 520; loss: 0.25; acc: 0.92
Batch: 540; loss: 0.68; acc: 0.78
Batch: 560; loss: 0.41; acc: 0.84
Batch: 580; loss: 0.43; acc: 0.88
Batch: 600; loss: 0.32; acc: 0.91
Batch: 620; loss: 0.36; acc: 0.89
Batch: 640; loss: 0.27; acc: 0.92
Batch: 660; loss: 0.47; acc: 0.88
Batch: 680; loss: 0.29; acc: 0.94
Batch: 700; loss: 0.18; acc: 0.95
Batch: 720; loss: 0.29; acc: 0.86
Batch: 740; loss: 0.37; acc: 0.91
Batch: 760; loss: 0.28; acc: 0.91
Batch: 780; loss: 0.17; acc: 0.95
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

2.2551983420271426e-05
7.289558652701089e-06
Batch: 0; loss: 0.98; acc: 0.8
Batch: 20; loss: 0.84; acc: 0.73
Batch: 40; loss: 0.53; acc: 0.81
Batch: 60; loss: 0.92; acc: 0.75
Batch: 80; loss: 0.67; acc: 0.83
Batch: 100; loss: 0.85; acc: 0.83
Batch: 120; loss: 0.98; acc: 0.73
Batch: 140; loss: 0.56; acc: 0.84
Val Epoch over. val_loss: 0.9299665336396284; val_accuracy: 0.7565684713375797 

The current subspace-distance is: 7.289558652701089e-06 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 1.15; acc: 0.73
Batch: 20; loss: 0.38; acc: 0.88
Batch: 40; loss: 0.49; acc: 0.83
Batch: 60; loss: 0.37; acc: 0.88
Batch: 80; loss: 0.38; acc: 0.94
Batch: 100; loss: 0.16; acc: 0.97
Batch: 120; loss: 0.32; acc: 0.91
Batch: 140; loss: 0.31; acc: 0.91
Batch: 160; loss: 0.11; acc: 0.95
Batch: 180; loss: 0.12; acc: 0.98
Batch: 200; loss: 0.23; acc: 0.89
Batch: 220; loss: 0.18; acc: 0.94
Batch: 240; loss: 0.19; acc: 0.92
Batch: 260; loss: 0.22; acc: 0.92
Batch: 280; loss: 0.28; acc: 0.92
Batch: 300; loss: 0.25; acc: 0.91
Batch: 320; loss: 0.21; acc: 0.95
Batch: 340; loss: 0.21; acc: 0.88
Batch: 360; loss: 0.3; acc: 0.88
Batch: 380; loss: 0.16; acc: 0.95
Batch: 400; loss: 0.53; acc: 0.88
Batch: 420; loss: 0.31; acc: 0.91
Batch: 440; loss: 0.23; acc: 0.94
Batch: 460; loss: 0.31; acc: 0.91
Batch: 480; loss: 0.35; acc: 0.91
Batch: 500; loss: 0.29; acc: 0.88
Batch: 520; loss: 0.21; acc: 0.92
Batch: 540; loss: 0.24; acc: 0.94
Batch: 560; loss: 0.3; acc: 0.95
Batch: 580; loss: 0.37; acc: 0.89
Batch: 600; loss: 0.28; acc: 0.91
Batch: 620; loss: 0.18; acc: 0.92
Batch: 640; loss: 0.19; acc: 0.94
Batch: 660; loss: 0.72; acc: 0.77
Batch: 680; loss: 0.4; acc: 0.88
Batch: 700; loss: 0.42; acc: 0.83
Batch: 720; loss: 0.19; acc: 0.97
Batch: 740; loss: 0.18; acc: 0.94
Batch: 760; loss: 0.18; acc: 0.98
Batch: 780; loss: 0.19; acc: 0.95
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.4242863219114952e-05
7.470714990631677e-06
Batch: 0; loss: 0.35; acc: 0.88
Batch: 20; loss: 0.25; acc: 0.91
Batch: 40; loss: 0.32; acc: 0.86
Batch: 60; loss: 0.71; acc: 0.81
Batch: 80; loss: 0.17; acc: 0.91
Batch: 100; loss: 0.37; acc: 0.92
Batch: 120; loss: 0.6; acc: 0.84
Batch: 140; loss: 0.24; acc: 0.92
Val Epoch over. val_loss: 0.34010551490221813; val_accuracy: 0.8864450636942676 

The current subspace-distance is: 7.470714990631677e-06 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.43; acc: 0.86
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.39; acc: 0.86
Batch: 60; loss: 0.17; acc: 0.94
Batch: 80; loss: 0.22; acc: 0.92
Batch: 100; loss: 0.19; acc: 0.98
Batch: 120; loss: 0.35; acc: 0.94
Batch: 140; loss: 0.48; acc: 0.84
Batch: 160; loss: 0.31; acc: 0.88
Batch: 180; loss: 0.29; acc: 0.89
Batch: 200; loss: 0.3; acc: 0.91
Batch: 220; loss: 0.18; acc: 0.98
Batch: 240; loss: 0.25; acc: 0.95
Batch: 260; loss: 0.28; acc: 0.94
Batch: 280; loss: 0.15; acc: 0.94
Batch: 300; loss: 0.2; acc: 0.94
Batch: 320; loss: 0.17; acc: 0.95
Batch: 340; loss: 0.19; acc: 0.95
Batch: 360; loss: 0.37; acc: 0.89
Batch: 380; loss: 0.44; acc: 0.86
Batch: 400; loss: 0.12; acc: 0.98
Batch: 420; loss: 0.09; acc: 0.98
Batch: 440; loss: 0.37; acc: 0.83
Batch: 460; loss: 0.28; acc: 0.92
Batch: 480; loss: 0.25; acc: 0.94
Batch: 500; loss: 0.43; acc: 0.89
Batch: 520; loss: 0.34; acc: 0.89
Batch: 540; loss: 0.19; acc: 0.92
Batch: 560; loss: 0.18; acc: 0.97
Batch: 580; loss: 0.36; acc: 0.88
Batch: 600; loss: 0.14; acc: 0.94
Batch: 620; loss: 0.22; acc: 0.91
Batch: 640; loss: 0.31; acc: 0.89
Batch: 660; loss: 0.68; acc: 0.81
Batch: 680; loss: 0.15; acc: 0.94
Batch: 700; loss: 0.28; acc: 0.92
Batch: 720; loss: 0.41; acc: 0.91
Batch: 740; loss: 0.26; acc: 0.91
Batch: 760; loss: 0.5; acc: 0.88
Batch: 780; loss: 0.24; acc: 0.89
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.4742317691561766e-05
8.471709406876471e-06
Batch: 0; loss: 0.08; acc: 1.0
Batch: 20; loss: 0.14; acc: 0.97
Batch: 40; loss: 0.09; acc: 0.95
Batch: 60; loss: 0.28; acc: 0.92
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.2; acc: 0.97
Batch: 120; loss: 0.4; acc: 0.91
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.20942710688824107; val_accuracy: 0.9358081210191083 

The current subspace-distance is: 8.471709406876471e-06 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.46; acc: 0.88
Batch: 20; loss: 0.08; acc: 0.98
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.19; acc: 0.92
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.31; acc: 0.92
Batch: 120; loss: 0.2; acc: 0.92
Batch: 140; loss: 0.34; acc: 0.88
Batch: 160; loss: 0.3; acc: 0.91
Batch: 180; loss: 0.33; acc: 0.92
Batch: 200; loss: 0.66; acc: 0.84
Batch: 220; loss: 0.22; acc: 0.92
Batch: 240; loss: 0.31; acc: 0.89
Batch: 260; loss: 0.23; acc: 0.94
Batch: 280; loss: 0.17; acc: 0.94
Batch: 300; loss: 0.23; acc: 0.95
Batch: 320; loss: 0.17; acc: 0.94
Batch: 340; loss: 0.18; acc: 0.94
Batch: 360; loss: 0.22; acc: 0.94
Batch: 380; loss: 0.23; acc: 0.89
Batch: 400; loss: 0.31; acc: 0.94
Batch: 420; loss: 0.26; acc: 0.91
Batch: 440; loss: 0.36; acc: 0.89
Batch: 460; loss: 0.1; acc: 0.95
Batch: 480; loss: 0.15; acc: 0.95
Batch: 500; loss: 0.12; acc: 0.97
Batch: 520; loss: 0.14; acc: 0.94
Batch: 540; loss: 0.29; acc: 0.91
Batch: 560; loss: 0.16; acc: 0.92
Batch: 580; loss: 0.13; acc: 0.95
Batch: 600; loss: 0.27; acc: 0.92
Batch: 620; loss: 0.31; acc: 0.91
Batch: 640; loss: 0.24; acc: 0.95
Batch: 660; loss: 0.31; acc: 0.91
Batch: 680; loss: 0.2; acc: 0.97
Batch: 700; loss: 0.31; acc: 0.91
Batch: 720; loss: 0.19; acc: 0.94
Batch: 740; loss: 0.2; acc: 0.91
Batch: 760; loss: 0.18; acc: 0.95
Batch: 780; loss: 0.12; acc: 0.95
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.458984454278834e-05
7.886250386945903e-06
Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.13; acc: 0.97
Batch: 40; loss: 0.09; acc: 0.95
Batch: 60; loss: 0.31; acc: 0.91
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.18; acc: 0.97
Batch: 120; loss: 0.38; acc: 0.89
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.19583217460353664; val_accuracy: 0.9404856687898089 

The current subspace-distance is: 7.886250386945903e-06 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.39; acc: 0.88
Batch: 20; loss: 0.1; acc: 0.98
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.27; acc: 0.91
Batch: 80; loss: 0.45; acc: 0.89
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.23; acc: 0.94
Batch: 140; loss: 0.29; acc: 0.94
Batch: 160; loss: 0.17; acc: 0.95
Batch: 180; loss: 0.09; acc: 0.97
Batch: 200; loss: 0.18; acc: 0.94
Batch: 220; loss: 0.31; acc: 0.91
Batch: 240; loss: 0.22; acc: 0.92
Batch: 260; loss: 0.23; acc: 0.94
Batch: 280; loss: 0.45; acc: 0.89
Batch: 300; loss: 0.45; acc: 0.84
Batch: 320; loss: 0.21; acc: 0.95
Batch: 340; loss: 0.43; acc: 0.88
Batch: 360; loss: 0.13; acc: 0.97
Batch: 380; loss: 0.05; acc: 1.0
Batch: 400; loss: 0.42; acc: 0.88
Batch: 420; loss: 0.15; acc: 0.97
Batch: 440; loss: 0.33; acc: 0.91
Batch: 460; loss: 0.12; acc: 0.97
Batch: 480; loss: 0.13; acc: 0.94
Batch: 500; loss: 0.13; acc: 0.95
Batch: 520; loss: 0.24; acc: 0.94
Batch: 540; loss: 0.28; acc: 0.92
Batch: 560; loss: 0.05; acc: 1.0
Batch: 580; loss: 0.21; acc: 0.97
Batch: 600; loss: 0.72; acc: 0.81
Batch: 620; loss: 0.24; acc: 0.92
Batch: 640; loss: 0.04; acc: 1.0
Batch: 660; loss: 0.39; acc: 0.91
Batch: 680; loss: 0.2; acc: 0.94
Batch: 700; loss: 0.17; acc: 0.94
Batch: 720; loss: 0.13; acc: 0.95
Batch: 740; loss: 0.23; acc: 0.94
Batch: 760; loss: 0.18; acc: 0.94
Batch: 780; loss: 0.12; acc: 0.97
Train Epoch over. train_loss: 0.25; train_accuracy: 0.93 

2.6048188374261372e-05
8.61232456372818e-06
Batch: 0; loss: 0.29; acc: 0.92
Batch: 20; loss: 0.31; acc: 0.89
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.37; acc: 0.89
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.23; acc: 0.89
Batch: 120; loss: 0.59; acc: 0.83
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.24354938054635267; val_accuracy: 0.9238654458598726 

The current subspace-distance is: 8.61232456372818e-06 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.39; acc: 0.86
Batch: 20; loss: 0.17; acc: 0.95
Batch: 40; loss: 0.13; acc: 0.94
Batch: 60; loss: 0.42; acc: 0.88
Batch: 80; loss: 0.41; acc: 0.86
Batch: 100; loss: 0.1; acc: 0.98
Batch: 120; loss: 0.31; acc: 0.91
Batch: 140; loss: 0.34; acc: 0.89
Batch: 160; loss: 0.22; acc: 0.94
Batch: 180; loss: 0.38; acc: 0.86
Batch: 200; loss: 0.13; acc: 0.95
Batch: 220; loss: 0.28; acc: 0.92
Batch: 240; loss: 0.13; acc: 0.94
Batch: 260; loss: 0.1; acc: 0.97
Batch: 280; loss: 0.26; acc: 0.97
Batch: 300; loss: 0.28; acc: 0.91
Batch: 320; loss: 0.32; acc: 0.92
Batch: 340; loss: 0.35; acc: 0.91
Batch: 360; loss: 0.28; acc: 0.95
Batch: 380; loss: 0.16; acc: 0.94
Batch: 400; loss: 0.3; acc: 0.92
Batch: 420; loss: 0.1; acc: 0.98
Batch: 440; loss: 0.34; acc: 0.91
Batch: 460; loss: 0.17; acc: 0.97
Batch: 480; loss: 0.37; acc: 0.89
Batch: 500; loss: 0.41; acc: 0.91
Batch: 520; loss: 0.18; acc: 0.94
Batch: 540; loss: 0.28; acc: 0.94
Batch: 560; loss: 0.23; acc: 0.89
Batch: 580; loss: 0.31; acc: 0.89
Batch: 600; loss: 0.33; acc: 0.91
Batch: 620; loss: 0.17; acc: 0.94
Batch: 640; loss: 0.25; acc: 0.91
Batch: 660; loss: 0.41; acc: 0.91
Batch: 680; loss: 0.6; acc: 0.92
Batch: 700; loss: 0.32; acc: 0.89
Batch: 720; loss: 0.23; acc: 0.91
Batch: 740; loss: 0.08; acc: 1.0
Batch: 760; loss: 0.22; acc: 0.92
Batch: 780; loss: 0.18; acc: 0.94
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.6059475203510374e-05
8.040806278586388e-06
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.94
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.16; acc: 0.97
Batch: 120; loss: 0.35; acc: 0.89
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.1791997429007178; val_accuracy: 0.9450636942675159 

The current subspace-distance is: 8.040806278586388e-06 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.17; acc: 0.92
Batch: 20; loss: 0.14; acc: 0.92
Batch: 40; loss: 0.24; acc: 0.92
Batch: 60; loss: 0.17; acc: 0.94
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.25; acc: 0.91
Batch: 120; loss: 0.21; acc: 0.95
Batch: 140; loss: 0.38; acc: 0.91
Batch: 160; loss: 0.09; acc: 0.98
Batch: 180; loss: 0.2; acc: 0.92
Batch: 200; loss: 0.14; acc: 0.95
Batch: 220; loss: 0.39; acc: 0.88
Batch: 240; loss: 0.17; acc: 0.95
Batch: 260; loss: 0.2; acc: 0.91
Batch: 280; loss: 0.07; acc: 0.97
Batch: 300; loss: 0.07; acc: 0.97
Batch: 320; loss: 0.29; acc: 0.92
Batch: 340; loss: 0.2; acc: 0.97
Batch: 360; loss: 0.17; acc: 0.94
Batch: 380; loss: 0.18; acc: 0.92
Batch: 400; loss: 0.21; acc: 0.94
Batch: 420; loss: 0.19; acc: 0.94
Batch: 440; loss: 0.14; acc: 0.97
Batch: 460; loss: 0.12; acc: 0.97
Batch: 480; loss: 0.11; acc: 0.98
Batch: 500; loss: 0.1; acc: 0.98
Batch: 520; loss: 0.38; acc: 0.91
Batch: 540; loss: 0.14; acc: 0.97
Batch: 560; loss: 0.27; acc: 0.95
Batch: 580; loss: 0.28; acc: 0.88
Batch: 600; loss: 0.2; acc: 0.92
Batch: 620; loss: 0.54; acc: 0.89
Batch: 640; loss: 0.24; acc: 0.95
Batch: 660; loss: 0.28; acc: 0.92
Batch: 680; loss: 0.14; acc: 0.97
Batch: 700; loss: 0.32; acc: 0.91
Batch: 720; loss: 0.5; acc: 0.84
Batch: 740; loss: 0.33; acc: 0.86
Batch: 760; loss: 0.26; acc: 0.94
Batch: 780; loss: 0.35; acc: 0.88
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.7163072445546277e-05
9.301586942456197e-06
Batch: 0; loss: 0.37; acc: 0.86
Batch: 20; loss: 0.37; acc: 0.88
Batch: 40; loss: 0.13; acc: 0.94
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.41; acc: 0.92
Batch: 100; loss: 0.28; acc: 0.92
Batch: 120; loss: 0.49; acc: 0.78
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2999258179004025; val_accuracy: 0.9040605095541401 

The current subspace-distance is: 9.301586942456197e-06 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.4; acc: 0.92
Batch: 20; loss: 0.24; acc: 0.94
Batch: 40; loss: 0.27; acc: 0.95
Batch: 60; loss: 0.14; acc: 0.97
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.16; acc: 0.94
Batch: 120; loss: 0.21; acc: 0.94
Batch: 140; loss: 0.27; acc: 0.92
Batch: 160; loss: 0.1; acc: 0.95
Batch: 180; loss: 0.19; acc: 0.95
Batch: 200; loss: 0.21; acc: 0.94
Batch: 220; loss: 0.19; acc: 0.94
Batch: 240; loss: 0.29; acc: 0.89
Batch: 260; loss: 0.19; acc: 0.94
Batch: 280; loss: 0.17; acc: 0.94
Batch: 300; loss: 0.17; acc: 0.95
Batch: 320; loss: 0.27; acc: 0.94
Batch: 340; loss: 0.18; acc: 0.95
Batch: 360; loss: 0.22; acc: 0.94
Batch: 380; loss: 0.24; acc: 0.94
Batch: 400; loss: 0.45; acc: 0.91
Batch: 420; loss: 0.12; acc: 0.95
Batch: 440; loss: 0.11; acc: 0.97
Batch: 460; loss: 0.1; acc: 0.97
Batch: 480; loss: 0.09; acc: 0.97
Batch: 500; loss: 0.2; acc: 0.95
Batch: 520; loss: 0.28; acc: 0.92
Batch: 540; loss: 0.15; acc: 0.94
Batch: 560; loss: 0.24; acc: 0.95
Batch: 580; loss: 0.18; acc: 0.98
Batch: 600; loss: 0.07; acc: 0.98
Batch: 620; loss: 0.23; acc: 0.95
Batch: 640; loss: 0.1; acc: 0.95
Batch: 660; loss: 0.36; acc: 0.95
Batch: 680; loss: 0.41; acc: 0.89
Batch: 700; loss: 0.1; acc: 0.97
Batch: 720; loss: 0.23; acc: 0.91
Batch: 740; loss: 0.25; acc: 0.92
Batch: 760; loss: 0.26; acc: 0.91
Batch: 780; loss: 0.19; acc: 0.89
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

2.620667146402411e-05
8.138199518725742e-06
Batch: 0; loss: 0.11; acc: 0.98
Batch: 20; loss: 0.13; acc: 0.94
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.15; acc: 0.98
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.13; acc: 0.98
Batch: 120; loss: 0.33; acc: 0.88
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.165425356477499; val_accuracy: 0.9513335987261147 

The current subspace-distance is: 8.138199518725742e-06 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.23; acc: 0.95
Batch: 60; loss: 0.3; acc: 0.95
Batch: 80; loss: 0.33; acc: 0.92
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.14; acc: 0.97
Batch: 140; loss: 0.18; acc: 0.97
Batch: 160; loss: 0.19; acc: 0.95
Batch: 180; loss: 0.07; acc: 0.97
Batch: 200; loss: 0.26; acc: 0.92
Batch: 220; loss: 0.16; acc: 0.95
Batch: 240; loss: 0.17; acc: 0.92
Batch: 260; loss: 0.05; acc: 0.98
Batch: 280; loss: 0.05; acc: 1.0
Batch: 300; loss: 0.07; acc: 0.98
Batch: 320; loss: 0.16; acc: 0.92
Batch: 340; loss: 0.17; acc: 0.94
Batch: 360; loss: 0.34; acc: 0.92
Batch: 380; loss: 0.11; acc: 0.94
Batch: 400; loss: 0.12; acc: 0.97
Batch: 420; loss: 0.09; acc: 0.98
Batch: 440; loss: 0.25; acc: 0.92
Batch: 460; loss: 0.47; acc: 0.84
Batch: 480; loss: 0.2; acc: 0.97
Batch: 500; loss: 0.41; acc: 0.86
Batch: 520; loss: 0.18; acc: 0.94
Batch: 540; loss: 0.08; acc: 0.97
Batch: 560; loss: 0.22; acc: 0.97
Batch: 580; loss: 0.16; acc: 0.95
Batch: 600; loss: 0.17; acc: 0.94
Batch: 620; loss: 0.2; acc: 0.94
Batch: 640; loss: 0.2; acc: 0.94
Batch: 660; loss: 0.13; acc: 0.95
Batch: 680; loss: 0.24; acc: 0.91
Batch: 700; loss: 0.11; acc: 0.95
Batch: 720; loss: 0.24; acc: 0.97
Batch: 740; loss: 0.26; acc: 0.91
Batch: 760; loss: 0.37; acc: 0.86
Batch: 780; loss: 0.11; acc: 0.97
Train Epoch over. train_loss: 0.18; train_accuracy: 0.94 

2.6789515686687082e-05
9.280408448830713e-06
Batch: 0; loss: 0.19; acc: 0.92
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.26; acc: 0.89
Batch: 80; loss: 0.26; acc: 0.91
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.34; acc: 0.83
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.22530270761744992; val_accuracy: 0.9292396496815286 

The current subspace-distance is: 9.280408448830713e-06 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.14; acc: 0.94
Batch: 20; loss: 0.17; acc: 0.92
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.06; acc: 0.97
Batch: 80; loss: 0.26; acc: 0.95
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.31; acc: 0.92
Batch: 140; loss: 0.14; acc: 0.94
Batch: 160; loss: 0.23; acc: 0.95
Batch: 180; loss: 0.08; acc: 0.97
Batch: 200; loss: 0.22; acc: 0.98
Batch: 220; loss: 0.19; acc: 0.97
Batch: 240; loss: 0.1; acc: 0.98
Batch: 260; loss: 0.06; acc: 1.0
Batch: 280; loss: 0.14; acc: 0.95
Batch: 300; loss: 0.21; acc: 0.97
Batch: 320; loss: 0.33; acc: 0.92
Batch: 340; loss: 0.07; acc: 0.97
Batch: 360; loss: 0.21; acc: 0.92
Batch: 380; loss: 0.24; acc: 0.92
Batch: 400; loss: 0.17; acc: 0.94
Batch: 420; loss: 0.09; acc: 0.98
Batch: 440; loss: 0.19; acc: 0.94
Batch: 460; loss: 0.11; acc: 0.95
Batch: 480; loss: 0.13; acc: 0.97
Batch: 500; loss: 0.06; acc: 0.98
Batch: 520; loss: 0.17; acc: 0.95
Batch: 540; loss: 0.26; acc: 0.89
Batch: 560; loss: 0.06; acc: 1.0
Batch: 580; loss: 0.23; acc: 0.94
Batch: 600; loss: 0.15; acc: 0.95
Batch: 620; loss: 0.28; acc: 0.94
Batch: 640; loss: 0.23; acc: 0.91
Batch: 660; loss: 0.22; acc: 0.94
Batch: 680; loss: 0.24; acc: 0.91
Batch: 700; loss: 0.36; acc: 0.86
Batch: 720; loss: 0.15; acc: 0.95
Batch: 740; loss: 0.12; acc: 0.95
Batch: 760; loss: 0.48; acc: 0.89
Batch: 780; loss: 0.15; acc: 0.97
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

2.685679828573484e-05
8.913299097912386e-06
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.17; acc: 0.95
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.16; acc: 0.97
Batch: 80; loss: 0.15; acc: 0.92
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.37; acc: 0.86
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.17469670476427504; val_accuracy: 0.9451632165605095 

The current subspace-distance is: 8.913299097912386e-06 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.13; acc: 0.92
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.12; acc: 0.98
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.26; acc: 0.94
Batch: 140; loss: 0.14; acc: 0.97
Batch: 160; loss: 0.27; acc: 0.91
Batch: 180; loss: 0.06; acc: 0.98
Batch: 200; loss: 0.14; acc: 0.95
Batch: 220; loss: 0.3; acc: 0.92
Batch: 240; loss: 0.06; acc: 0.98
Batch: 260; loss: 0.12; acc: 0.97
Batch: 280; loss: 0.1; acc: 0.97
Batch: 300; loss: 0.29; acc: 0.89
Batch: 320; loss: 0.09; acc: 0.95
Batch: 340; loss: 0.23; acc: 0.94
Batch: 360; loss: 0.24; acc: 0.92
Batch: 380; loss: 0.09; acc: 0.95
Batch: 400; loss: 0.21; acc: 0.92
Batch: 420; loss: 0.18; acc: 0.95
Batch: 440; loss: 0.09; acc: 0.97
Batch: 460; loss: 0.12; acc: 0.94
Batch: 480; loss: 0.23; acc: 0.97
Batch: 500; loss: 0.26; acc: 0.95
Batch: 520; loss: 0.12; acc: 0.95
Batch: 540; loss: 0.21; acc: 0.95
Batch: 560; loss: 0.53; acc: 0.89
Batch: 580; loss: 0.2; acc: 0.95
Batch: 600; loss: 0.22; acc: 0.92
Batch: 620; loss: 0.26; acc: 0.92
Batch: 640; loss: 0.05; acc: 0.98
Batch: 660; loss: 0.17; acc: 0.94
Batch: 680; loss: 0.29; acc: 0.91
Batch: 700; loss: 0.11; acc: 0.95
Batch: 720; loss: 0.14; acc: 0.95
Batch: 740; loss: 0.04; acc: 1.0
Batch: 760; loss: 0.23; acc: 0.89
Batch: 780; loss: 0.22; acc: 0.92
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

2.684119863261003e-05
9.673060958448332e-06
Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.12; acc: 0.97
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.16; acc: 0.97
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.17; acc: 0.97
Batch: 120; loss: 0.3; acc: 0.86
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.1667062500669698; val_accuracy: 0.9486464968152867 

The current subspace-distance is: 9.673060958448332e-06 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.16; acc: 0.94
Batch: 20; loss: 0.07; acc: 0.97
Batch: 40; loss: 0.2; acc: 0.92
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.13; acc: 0.94
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.1; acc: 0.97
Batch: 140; loss: 0.09; acc: 0.95
Batch: 160; loss: 0.16; acc: 0.95
Batch: 180; loss: 0.3; acc: 0.86
Batch: 200; loss: 0.17; acc: 0.92
Batch: 220; loss: 0.24; acc: 0.91
Batch: 240; loss: 0.26; acc: 0.92
Batch: 260; loss: 0.21; acc: 0.92
Batch: 280; loss: 0.09; acc: 0.95
Batch: 300; loss: 0.21; acc: 0.95
Batch: 320; loss: 0.34; acc: 0.92
Batch: 340; loss: 0.12; acc: 0.97
Batch: 360; loss: 0.48; acc: 0.92
Batch: 380; loss: 0.23; acc: 0.95
Batch: 400; loss: 0.11; acc: 0.95
Batch: 420; loss: 0.14; acc: 0.98
Batch: 440; loss: 0.22; acc: 0.92
Batch: 460; loss: 0.28; acc: 0.91
Batch: 480; loss: 0.14; acc: 0.94
Batch: 500; loss: 0.13; acc: 0.95
Batch: 520; loss: 0.07; acc: 0.97
Batch: 540; loss: 0.06; acc: 0.98
Batch: 560; loss: 0.18; acc: 0.95
Batch: 580; loss: 0.14; acc: 0.92
Batch: 600; loss: 0.08; acc: 0.97
Batch: 620; loss: 0.08; acc: 0.98
Batch: 640; loss: 0.22; acc: 0.95
Batch: 660; loss: 0.2; acc: 0.94
Batch: 680; loss: 0.11; acc: 0.95
Batch: 700; loss: 0.11; acc: 0.97
Batch: 720; loss: 0.38; acc: 0.91
Batch: 740; loss: 0.2; acc: 0.92
Batch: 760; loss: 0.25; acc: 0.91
Batch: 780; loss: 0.13; acc: 0.97
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

2.75294623861555e-05
9.635972674004734e-06
Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.18; acc: 0.92
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.24; acc: 0.91
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.95
Batch: 120; loss: 0.39; acc: 0.86
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.22955699720580108; val_accuracy: 0.9290406050955414 

The current subspace-distance is: 9.635972674004734e-06 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.29; acc: 0.89
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.11; acc: 0.98
Batch: 80; loss: 0.3; acc: 0.95
Batch: 100; loss: 0.08; acc: 0.98
Batch: 120; loss: 0.15; acc: 0.92
Batch: 140; loss: 0.06; acc: 0.98
Batch: 160; loss: 0.23; acc: 0.91
Batch: 180; loss: 0.28; acc: 0.92
Batch: 200; loss: 0.19; acc: 0.94
Batch: 220; loss: 0.17; acc: 0.95
Batch: 240; loss: 0.09; acc: 0.95
Batch: 260; loss: 0.18; acc: 0.94
Batch: 280; loss: 0.19; acc: 0.95
Batch: 300; loss: 0.11; acc: 0.97
Batch: 320; loss: 0.27; acc: 0.89
Batch: 340; loss: 0.28; acc: 0.92
Batch: 360; loss: 0.12; acc: 0.94
Batch: 380; loss: 0.16; acc: 0.95
Batch: 400; loss: 0.18; acc: 0.95
Batch: 420; loss: 0.2; acc: 0.94
Batch: 440; loss: 0.18; acc: 0.91
Batch: 460; loss: 0.1; acc: 0.94
Batch: 480; loss: 0.13; acc: 0.94
Batch: 500; loss: 0.25; acc: 0.92
Batch: 520; loss: 0.08; acc: 0.95
Batch: 540; loss: 0.14; acc: 0.94
Batch: 560; loss: 0.12; acc: 0.95
Batch: 580; loss: 0.17; acc: 0.92
Batch: 600; loss: 0.21; acc: 0.91
Batch: 620; loss: 0.2; acc: 0.94
Batch: 640; loss: 0.17; acc: 0.94
Batch: 660; loss: 0.09; acc: 0.95
Batch: 680; loss: 0.15; acc: 0.94
Batch: 700; loss: 0.15; acc: 0.94
Batch: 720; loss: 0.19; acc: 0.94
Batch: 740; loss: 0.29; acc: 0.94
Batch: 760; loss: 0.13; acc: 0.94
Batch: 780; loss: 0.25; acc: 0.92
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

2.742816104728263e-05
9.051715096575208e-06
Batch: 0; loss: 0.21; acc: 0.91
Batch: 20; loss: 0.24; acc: 0.91
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.4; acc: 0.88
Batch: 80; loss: 0.28; acc: 0.91
Batch: 100; loss: 0.37; acc: 0.91
Batch: 120; loss: 0.49; acc: 0.88
Batch: 140; loss: 0.14; acc: 0.94
Val Epoch over. val_loss: 0.32534801381029144; val_accuracy: 0.9007762738853503 

The current subspace-distance is: 9.051715096575208e-06 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.24; acc: 0.92
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.19; acc: 0.92
Batch: 120; loss: 0.22; acc: 0.91
Batch: 140; loss: 0.12; acc: 0.97
Batch: 160; loss: 0.38; acc: 0.89
Batch: 180; loss: 0.26; acc: 0.89
Batch: 200; loss: 0.17; acc: 0.95
Batch: 220; loss: 0.1; acc: 0.97
Batch: 240; loss: 0.37; acc: 0.88
Batch: 260; loss: 0.1; acc: 0.95
Batch: 280; loss: 0.1; acc: 0.97
Batch: 300; loss: 0.24; acc: 0.92
Batch: 320; loss: 0.15; acc: 0.94
Batch: 340; loss: 0.09; acc: 0.97
Batch: 360; loss: 0.11; acc: 0.95
Batch: 380; loss: 0.14; acc: 0.95
Batch: 400; loss: 0.26; acc: 0.91
Batch: 420; loss: 0.21; acc: 0.92
Batch: 440; loss: 0.2; acc: 0.91
Batch: 460; loss: 0.07; acc: 0.98
Batch: 480; loss: 0.1; acc: 0.94
Batch: 500; loss: 0.14; acc: 0.97
Batch: 520; loss: 0.19; acc: 0.94
Batch: 540; loss: 0.22; acc: 0.95
Batch: 560; loss: 0.33; acc: 0.94
Batch: 580; loss: 0.11; acc: 0.95
Batch: 600; loss: 0.09; acc: 0.97
Batch: 620; loss: 0.11; acc: 0.95
Batch: 640; loss: 0.21; acc: 0.97
Batch: 660; loss: 0.18; acc: 0.95
Batch: 680; loss: 0.21; acc: 0.92
Batch: 700; loss: 0.04; acc: 1.0
Batch: 720; loss: 0.07; acc: 0.98
Batch: 740; loss: 0.15; acc: 0.95
Batch: 760; loss: 0.26; acc: 0.92
Batch: 780; loss: 0.18; acc: 0.95
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

2.725683771132026e-05
9.28930785448756e-06
Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.39; acc: 0.86
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.94
Batch: 80; loss: 0.1; acc: 0.94
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.52; acc: 0.86
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2610140863307722; val_accuracy: 0.9236664012738853 

The current subspace-distance is: 9.28930785448756e-06 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.33; acc: 0.94
Batch: 20; loss: 0.08; acc: 0.98
Batch: 40; loss: 0.2; acc: 0.91
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.03; acc: 1.0
Batch: 100; loss: 0.19; acc: 0.91
Batch: 120; loss: 0.08; acc: 0.95
Batch: 140; loss: 0.2; acc: 0.95
Batch: 160; loss: 0.29; acc: 0.94
Batch: 180; loss: 0.18; acc: 0.92
Batch: 200; loss: 0.17; acc: 0.95
Batch: 220; loss: 0.12; acc: 0.95
Batch: 240; loss: 0.13; acc: 0.95
Batch: 260; loss: 0.17; acc: 0.95
Batch: 280; loss: 0.29; acc: 0.92
Batch: 300; loss: 0.27; acc: 0.94
Batch: 320; loss: 0.12; acc: 0.97
Batch: 340; loss: 0.12; acc: 0.94
Batch: 360; loss: 0.09; acc: 0.97
Batch: 380; loss: 0.09; acc: 0.95
Batch: 400; loss: 0.14; acc: 0.92
Batch: 420; loss: 0.18; acc: 0.95
Batch: 440; loss: 0.21; acc: 0.95
Batch: 460; loss: 0.23; acc: 0.94
Batch: 480; loss: 0.1; acc: 0.97
Batch: 500; loss: 0.08; acc: 1.0
Batch: 520; loss: 0.15; acc: 0.95
Batch: 540; loss: 0.17; acc: 0.91
Batch: 560; loss: 0.22; acc: 0.94
Batch: 580; loss: 0.06; acc: 0.97
Batch: 600; loss: 0.2; acc: 0.95
Batch: 620; loss: 0.08; acc: 0.97
Batch: 640; loss: 0.36; acc: 0.91
Batch: 660; loss: 0.05; acc: 0.98
Batch: 680; loss: 0.05; acc: 0.98
Batch: 700; loss: 0.4; acc: 0.92
Batch: 720; loss: 0.13; acc: 0.95
Batch: 740; loss: 0.18; acc: 0.97
Batch: 760; loss: 0.07; acc: 0.98
Batch: 780; loss: 0.2; acc: 0.97
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

2.7316635168972425e-05
8.35042283142684e-06
Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.16; acc: 0.94
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.14; acc: 0.95
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.19; acc: 0.97
Batch: 120; loss: 0.35; acc: 0.88
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.18401632498309112; val_accuracy: 0.943968949044586 

The current subspace-distance is: 8.35042283142684e-06 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.35; acc: 0.92
Batch: 20; loss: 0.08; acc: 0.97
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.23; acc: 0.92
Batch: 80; loss: 0.26; acc: 0.89
Batch: 100; loss: 0.48; acc: 0.84
Batch: 120; loss: 0.03; acc: 1.0
Batch: 140; loss: 0.36; acc: 0.88
Batch: 160; loss: 0.06; acc: 0.98
Batch: 180; loss: 0.21; acc: 0.94
Batch: 200; loss: 0.19; acc: 0.94
Batch: 220; loss: 0.38; acc: 0.91
Batch: 240; loss: 0.24; acc: 0.94
Batch: 260; loss: 0.24; acc: 0.91
Batch: 280; loss: 0.16; acc: 0.92
Batch: 300; loss: 0.09; acc: 0.98
Batch: 320; loss: 0.22; acc: 0.92
Batch: 340; loss: 0.2; acc: 0.92
Batch: 360; loss: 0.14; acc: 0.95
Batch: 380; loss: 0.04; acc: 0.98
Batch: 400; loss: 0.14; acc: 0.92
Batch: 420; loss: 0.1; acc: 0.95
Batch: 440; loss: 0.11; acc: 0.97
Batch: 460; loss: 0.05; acc: 0.98
Batch: 480; loss: 0.21; acc: 0.94
Batch: 500; loss: 0.25; acc: 0.95
Batch: 520; loss: 0.23; acc: 0.94
Batch: 540; loss: 0.1; acc: 0.95
Batch: 560; loss: 0.06; acc: 0.97
Batch: 580; loss: 0.17; acc: 0.95
Batch: 600; loss: 0.13; acc: 0.97
Batch: 620; loss: 0.11; acc: 0.95
Batch: 640; loss: 0.1; acc: 0.95
Batch: 660; loss: 0.02; acc: 1.0
Batch: 680; loss: 0.24; acc: 0.86
Batch: 700; loss: 0.05; acc: 1.0
Batch: 720; loss: 0.22; acc: 0.97
Batch: 740; loss: 0.09; acc: 0.98
Batch: 760; loss: 0.12; acc: 0.97
Batch: 780; loss: 0.21; acc: 0.95
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

2.852366742445156e-05
9.339464668300934e-06
Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.17; acc: 0.92
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.13; acc: 0.97
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.21; acc: 0.97
Batch: 120; loss: 0.39; acc: 0.91
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.17956571812462654; val_accuracy: 0.9464570063694268 

The current subspace-distance is: 9.339464668300934e-06 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.06; acc: 0.98
Batch: 20; loss: 0.18; acc: 0.92
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.03; acc: 1.0
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.16; acc: 0.89
Batch: 120; loss: 0.17; acc: 0.95
Batch: 140; loss: 0.09; acc: 0.98
Batch: 160; loss: 0.1; acc: 0.97
Batch: 180; loss: 0.12; acc: 0.97
Batch: 200; loss: 0.06; acc: 0.97
Batch: 220; loss: 0.33; acc: 0.92
Batch: 240; loss: 0.31; acc: 0.89
Batch: 260; loss: 0.15; acc: 0.91
Batch: 280; loss: 0.24; acc: 0.94
Batch: 300; loss: 0.25; acc: 0.92
Batch: 320; loss: 0.2; acc: 0.94
Batch: 340; loss: 0.08; acc: 0.95
Batch: 360; loss: 0.15; acc: 0.97
Batch: 380; loss: 0.18; acc: 0.94
Batch: 400; loss: 0.19; acc: 0.94
Batch: 420; loss: 0.11; acc: 0.97
Batch: 440; loss: 0.2; acc: 0.94
Batch: 460; loss: 0.12; acc: 0.97
Batch: 480; loss: 0.18; acc: 0.97
Batch: 500; loss: 0.12; acc: 0.95
Batch: 520; loss: 0.29; acc: 0.94
Batch: 540; loss: 0.06; acc: 0.98
Batch: 560; loss: 0.22; acc: 0.94
Batch: 580; loss: 0.04; acc: 1.0
Batch: 600; loss: 0.37; acc: 0.91
Batch: 620; loss: 0.17; acc: 0.92
Batch: 640; loss: 0.1; acc: 0.97
Batch: 660; loss: 0.11; acc: 0.95
Batch: 680; loss: 0.17; acc: 0.94
Batch: 700; loss: 0.2; acc: 0.91
Batch: 720; loss: 0.1; acc: 0.98
Batch: 740; loss: 0.15; acc: 0.95
Batch: 760; loss: 0.42; acc: 0.92
Batch: 780; loss: 0.17; acc: 0.95
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

2.7097408747067675e-05
9.114512977248523e-06
Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.2; acc: 0.97
Batch: 120; loss: 0.31; acc: 0.86
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1543433975167335; val_accuracy: 0.9529259554140127 

The current subspace-distance is: 9.114512977248523e-06 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.1; acc: 0.97
Batch: 40; loss: 0.18; acc: 0.91
Batch: 60; loss: 0.15; acc: 0.97
Batch: 80; loss: 0.31; acc: 0.94
Batch: 100; loss: 0.21; acc: 0.94
Batch: 120; loss: 0.11; acc: 0.97
Batch: 140; loss: 0.15; acc: 0.97
Batch: 160; loss: 0.26; acc: 0.94
Batch: 180; loss: 0.18; acc: 0.92
Batch: 200; loss: 0.09; acc: 0.95
Batch: 220; loss: 0.14; acc: 0.98
Batch: 240; loss: 0.11; acc: 0.97
Batch: 260; loss: 0.16; acc: 0.92
Batch: 280; loss: 0.13; acc: 0.94
Batch: 300; loss: 0.05; acc: 0.98
Batch: 320; loss: 0.08; acc: 0.97
Batch: 340; loss: 0.19; acc: 0.94
Batch: 360; loss: 0.06; acc: 0.98
Batch: 380; loss: 0.21; acc: 0.92
Batch: 400; loss: 0.08; acc: 0.98
Batch: 420; loss: 0.06; acc: 0.97
Batch: 440; loss: 0.13; acc: 0.98
Batch: 460; loss: 0.05; acc: 0.98
Batch: 480; loss: 0.22; acc: 0.92
Batch: 500; loss: 0.15; acc: 0.94
Batch: 520; loss: 0.04; acc: 1.0
Batch: 540; loss: 0.1; acc: 0.98
Batch: 560; loss: 0.04; acc: 0.98
Batch: 580; loss: 0.07; acc: 0.95
Batch: 600; loss: 0.06; acc: 0.98
Batch: 620; loss: 0.16; acc: 0.95
Batch: 640; loss: 0.12; acc: 0.95
Batch: 660; loss: 0.19; acc: 0.94
Batch: 680; loss: 0.1; acc: 0.95
Batch: 700; loss: 0.05; acc: 0.98
Batch: 720; loss: 0.16; acc: 0.97
Batch: 740; loss: 0.19; acc: 0.91
Batch: 760; loss: 0.23; acc: 0.94
Batch: 780; loss: 0.26; acc: 0.94
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

2.882625449274201e-05
9.764883543539327e-06
Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.12; acc: 0.95
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.11; acc: 0.98
Batch: 80; loss: 0.11; acc: 0.94
Batch: 100; loss: 0.18; acc: 0.97
Batch: 120; loss: 0.28; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.15332464636511103; val_accuracy: 0.9535230891719745 

The current subspace-distance is: 9.764883543539327e-06 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.12; acc: 0.94
Batch: 20; loss: 0.13; acc: 0.97
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.04; acc: 0.98
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.19; acc: 0.95
Batch: 140; loss: 0.06; acc: 0.97
Batch: 160; loss: 0.25; acc: 0.92
Batch: 180; loss: 0.04; acc: 1.0
Batch: 200; loss: 0.26; acc: 0.92
Batch: 220; loss: 0.05; acc: 0.98
Batch: 240; loss: 0.08; acc: 0.98
Batch: 260; loss: 0.12; acc: 0.94
Batch: 280; loss: 0.18; acc: 0.91
Batch: 300; loss: 0.15; acc: 0.92
Batch: 320; loss: 0.29; acc: 0.91
Batch: 340; loss: 0.07; acc: 0.97
Batch: 360; loss: 0.08; acc: 0.97
Batch: 380; loss: 0.09; acc: 0.97
Batch: 400; loss: 0.17; acc: 0.94
Batch: 420; loss: 0.13; acc: 0.97
Batch: 440; loss: 0.19; acc: 0.92
Batch: 460; loss: 0.17; acc: 0.94
Batch: 480; loss: 0.15; acc: 0.92
Batch: 500; loss: 0.07; acc: 0.98
Batch: 520; loss: 0.27; acc: 0.94
Batch: 540; loss: 0.3; acc: 0.89
Batch: 560; loss: 0.13; acc: 0.95
Batch: 580; loss: 0.14; acc: 0.95
Batch: 600; loss: 0.07; acc: 0.98
Batch: 620; loss: 0.14; acc: 0.97
Batch: 640; loss: 0.17; acc: 0.91
Batch: 660; loss: 0.13; acc: 0.92
Batch: 680; loss: 0.15; acc: 0.95
Batch: 700; loss: 0.07; acc: 0.95
Batch: 720; loss: 0.22; acc: 0.91
Batch: 740; loss: 0.06; acc: 1.0
Batch: 760; loss: 0.24; acc: 0.94
Batch: 780; loss: 0.12; acc: 0.94
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

2.9313392587937415e-05
9.680478797235992e-06
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.09; acc: 0.98
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.1; acc: 0.98
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.19; acc: 0.97
Batch: 120; loss: 0.28; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14434607711377417; val_accuracy: 0.9580015923566879 

The current subspace-distance is: 9.680478797235992e-06 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.09; acc: 0.98
Batch: 20; loss: 0.23; acc: 0.94
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.32; acc: 0.92
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.46; acc: 0.89
Batch: 140; loss: 0.07; acc: 0.98
Batch: 160; loss: 0.1; acc: 0.97
Batch: 180; loss: 0.3; acc: 0.92
Batch: 200; loss: 0.14; acc: 0.95
Batch: 220; loss: 0.09; acc: 0.98
Batch: 240; loss: 0.25; acc: 0.92
Batch: 260; loss: 0.19; acc: 0.91
Batch: 280; loss: 0.15; acc: 0.94
Batch: 300; loss: 0.04; acc: 0.98
Batch: 320; loss: 0.24; acc: 0.94
Batch: 340; loss: 0.16; acc: 0.97
Batch: 360; loss: 0.09; acc: 0.98
Batch: 380; loss: 0.21; acc: 0.94
Batch: 400; loss: 0.17; acc: 0.91
Batch: 420; loss: 0.13; acc: 0.95
Batch: 440; loss: 0.52; acc: 0.84
Batch: 460; loss: 0.09; acc: 0.95
Batch: 480; loss: 0.13; acc: 0.95
Batch: 500; loss: 0.36; acc: 0.91
Batch: 520; loss: 0.31; acc: 0.94
Batch: 540; loss: 0.12; acc: 0.94
Batch: 560; loss: 0.24; acc: 0.94
Batch: 580; loss: 0.25; acc: 0.95
Batch: 600; loss: 0.11; acc: 0.97
Batch: 620; loss: 0.23; acc: 0.95
Batch: 640; loss: 0.08; acc: 0.95
Batch: 660; loss: 0.07; acc: 0.98
Batch: 680; loss: 0.09; acc: 0.98
Batch: 700; loss: 0.09; acc: 0.95
Batch: 720; loss: 0.31; acc: 0.89
Batch: 740; loss: 0.08; acc: 0.97
Batch: 760; loss: 0.09; acc: 0.97
Batch: 780; loss: 0.26; acc: 0.92
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

2.8760703571606427e-05
8.839465408527758e-06
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.12; acc: 0.97
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.1; acc: 0.98
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.21; acc: 0.97
Batch: 120; loss: 0.31; acc: 0.86
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.14840186451365994; val_accuracy: 0.9555135350318471 

The current subspace-distance is: 8.839465408527758e-06 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.36; acc: 0.92
Batch: 80; loss: 0.25; acc: 0.95
Batch: 100; loss: 0.07; acc: 0.98
Batch: 120; loss: 0.16; acc: 0.95
Batch: 140; loss: 0.14; acc: 0.97
Batch: 160; loss: 0.1; acc: 0.97
Batch: 180; loss: 0.22; acc: 0.94
Batch: 200; loss: 0.03; acc: 1.0
Batch: 220; loss: 0.29; acc: 0.91
Batch: 240; loss: 0.19; acc: 0.92
Batch: 260; loss: 0.2; acc: 0.92
Batch: 280; loss: 0.07; acc: 0.98
Batch: 300; loss: 0.27; acc: 0.91
Batch: 320; loss: 0.07; acc: 0.97
Batch: 340; loss: 0.13; acc: 0.97
Batch: 360; loss: 0.15; acc: 0.94
Batch: 380; loss: 0.09; acc: 0.98
Batch: 400; loss: 0.13; acc: 0.95
Batch: 420; loss: 0.19; acc: 0.95
Batch: 440; loss: 0.05; acc: 0.98
Batch: 460; loss: 0.07; acc: 0.95
Batch: 480; loss: 0.26; acc: 0.91
Batch: 500; loss: 0.06; acc: 0.98
Batch: 520; loss: 0.06; acc: 0.98
Batch: 540; loss: 0.26; acc: 0.94
Batch: 560; loss: 0.12; acc: 0.95
Batch: 580; loss: 0.1; acc: 0.97
Batch: 600; loss: 0.1; acc: 0.95
Batch: 620; loss: 0.13; acc: 0.97
Batch: 640; loss: 0.32; acc: 0.92
Batch: 660; loss: 0.15; acc: 0.92
Batch: 680; loss: 0.25; acc: 0.95
Batch: 700; loss: 0.1; acc: 0.97
Batch: 720; loss: 0.03; acc: 1.0
Batch: 740; loss: 0.14; acc: 0.94
Batch: 760; loss: 0.1; acc: 0.95
Batch: 780; loss: 0.2; acc: 0.95
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

2.918229984061327e-05
9.243654858437367e-06
Batch: 0; loss: 0.1; acc: 0.95
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.17; acc: 0.97
Batch: 120; loss: 0.27; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.15607964328140211; val_accuracy: 0.9514331210191083 

The current subspace-distance is: 9.243654858437367e-06 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.21; acc: 0.92
Batch: 20; loss: 0.23; acc: 0.89
Batch: 40; loss: 0.26; acc: 0.95
Batch: 60; loss: 0.14; acc: 0.94
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.11; acc: 0.97
Batch: 120; loss: 0.06; acc: 0.97
Batch: 140; loss: 0.16; acc: 0.95
Batch: 160; loss: 0.11; acc: 0.94
Batch: 180; loss: 0.09; acc: 0.95
Batch: 200; loss: 0.07; acc: 0.97
Batch: 220; loss: 0.24; acc: 0.94
Batch: 240; loss: 0.16; acc: 0.97
Batch: 260; loss: 0.08; acc: 0.97
Batch: 280; loss: 0.12; acc: 0.94
Batch: 300; loss: 0.05; acc: 0.98
Batch: 320; loss: 0.2; acc: 0.92
Batch: 340; loss: 0.12; acc: 0.97
Batch: 360; loss: 0.1; acc: 0.94
Batch: 380; loss: 0.2; acc: 0.95
Batch: 400; loss: 0.14; acc: 0.97
Batch: 420; loss: 0.13; acc: 0.95
Batch: 440; loss: 0.07; acc: 0.95
Batch: 460; loss: 0.35; acc: 0.88
Batch: 480; loss: 0.18; acc: 0.94
Batch: 500; loss: 0.21; acc: 0.94
Batch: 520; loss: 0.15; acc: 0.97
Batch: 540; loss: 0.34; acc: 0.94
Batch: 560; loss: 0.11; acc: 0.94
Batch: 580; loss: 0.2; acc: 0.91
Batch: 600; loss: 0.11; acc: 0.97
Batch: 620; loss: 0.21; acc: 0.92
Batch: 640; loss: 0.17; acc: 0.97
Batch: 660; loss: 0.19; acc: 0.92
Batch: 680; loss: 0.41; acc: 0.92
Batch: 700; loss: 0.13; acc: 0.97
Batch: 720; loss: 0.13; acc: 0.94
Batch: 740; loss: 0.08; acc: 0.97
Batch: 760; loss: 0.28; acc: 0.94
Batch: 780; loss: 0.14; acc: 0.94
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

2.8285903681535274e-05
9.022579433803912e-06
Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.12; acc: 0.94
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.1; acc: 0.98
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.19; acc: 0.97
Batch: 120; loss: 0.32; acc: 0.83
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.142105523639234; val_accuracy: 0.9566082802547771 

The current subspace-distance is: 9.022579433803912e-06 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.26; acc: 0.92
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.17; acc: 0.92
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.23; acc: 0.89
Batch: 120; loss: 0.04; acc: 0.98
Batch: 140; loss: 0.12; acc: 0.97
Batch: 160; loss: 0.15; acc: 0.92
Batch: 180; loss: 0.07; acc: 0.97
Batch: 200; loss: 0.11; acc: 0.95
Batch: 220; loss: 0.26; acc: 0.94
Batch: 240; loss: 0.13; acc: 0.95
Batch: 260; loss: 0.09; acc: 0.97
Batch: 280; loss: 0.2; acc: 0.95
Batch: 300; loss: 0.27; acc: 0.95
Batch: 320; loss: 0.13; acc: 0.95
Batch: 340; loss: 0.2; acc: 0.91
Batch: 360; loss: 0.16; acc: 0.92
Batch: 380; loss: 0.11; acc: 0.94
Batch: 400; loss: 0.16; acc: 0.92
Batch: 420; loss: 0.09; acc: 0.97
Batch: 440; loss: 0.08; acc: 0.97
Batch: 460; loss: 0.11; acc: 0.95
Batch: 480; loss: 0.17; acc: 0.97
Batch: 500; loss: 0.17; acc: 0.95
Batch: 520; loss: 0.11; acc: 0.95
Batch: 540; loss: 0.18; acc: 0.94
Batch: 560; loss: 0.09; acc: 0.97
Batch: 580; loss: 0.14; acc: 0.95
Batch: 600; loss: 0.07; acc: 0.98
Batch: 620; loss: 0.21; acc: 0.94
Batch: 640; loss: 0.19; acc: 0.97
Batch: 660; loss: 0.1; acc: 0.97
Batch: 680; loss: 0.07; acc: 0.95
Batch: 700; loss: 0.13; acc: 0.95
Batch: 720; loss: 0.12; acc: 0.98
Batch: 740; loss: 0.08; acc: 0.98
Batch: 760; loss: 0.24; acc: 0.92
Batch: 780; loss: 0.06; acc: 0.97
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

2.8489926990005188e-05
1.0345090231567156e-05
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.1; acc: 0.97
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.22; acc: 0.97
Batch: 120; loss: 0.34; acc: 0.84
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1457954454621312; val_accuracy: 0.9547173566878981 

The current subspace-distance is: 1.0345090231567156e-05 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.16; acc: 0.94
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.15; acc: 0.92
Batch: 60; loss: 0.28; acc: 0.95
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.08; acc: 0.98
Batch: 120; loss: 0.08; acc: 0.97
Batch: 140; loss: 0.16; acc: 0.92
Batch: 160; loss: 0.35; acc: 0.94
Batch: 180; loss: 0.11; acc: 0.95
Batch: 200; loss: 0.11; acc: 0.97
Batch: 220; loss: 0.11; acc: 0.95
Batch: 240; loss: 0.25; acc: 0.92
Batch: 260; loss: 0.18; acc: 0.92
Batch: 280; loss: 0.18; acc: 0.97
Batch: 300; loss: 0.04; acc: 1.0
Batch: 320; loss: 0.15; acc: 0.94
Batch: 340; loss: 0.09; acc: 0.97
Batch: 360; loss: 0.04; acc: 1.0
Batch: 380; loss: 0.28; acc: 0.91
Batch: 400; loss: 0.06; acc: 0.98
Batch: 420; loss: 0.28; acc: 0.94
Batch: 440; loss: 0.07; acc: 0.97
Batch: 460; loss: 0.39; acc: 0.94
Batch: 480; loss: 0.16; acc: 0.95
Batch: 500; loss: 0.16; acc: 0.95
Batch: 520; loss: 0.11; acc: 0.95
Batch: 540; loss: 0.13; acc: 0.94
Batch: 560; loss: 0.08; acc: 0.97
Batch: 580; loss: 0.28; acc: 0.92
Batch: 600; loss: 0.14; acc: 0.97
Batch: 620; loss: 0.37; acc: 0.91
Batch: 640; loss: 0.16; acc: 0.95
Batch: 660; loss: 0.26; acc: 0.94
Batch: 680; loss: 0.26; acc: 0.89
Batch: 700; loss: 0.2; acc: 0.94
Batch: 720; loss: 0.11; acc: 0.97
Batch: 740; loss: 0.15; acc: 0.94
Batch: 760; loss: 0.12; acc: 0.97
Batch: 780; loss: 0.25; acc: 0.92
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.8824713808717206e-05
9.116864021052606e-06
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.12; acc: 0.95
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.1; acc: 0.98
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.19; acc: 0.97
Batch: 120; loss: 0.35; acc: 0.83
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.1448135053513536; val_accuracy: 0.9561106687898089 

The current subspace-distance is: 9.116864021052606e-06 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.16; acc: 0.94
Batch: 20; loss: 0.15; acc: 0.94
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.22; acc: 0.91
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.08; acc: 0.97
Batch: 120; loss: 0.15; acc: 0.95
Batch: 140; loss: 0.31; acc: 0.91
Batch: 160; loss: 0.05; acc: 0.97
Batch: 180; loss: 0.29; acc: 0.94
Batch: 200; loss: 0.09; acc: 0.98
Batch: 220; loss: 0.07; acc: 0.97
Batch: 240; loss: 0.22; acc: 0.95
Batch: 260; loss: 0.27; acc: 0.92
Batch: 280; loss: 0.06; acc: 0.98
Batch: 300; loss: 0.25; acc: 0.91
Batch: 320; loss: 0.04; acc: 1.0
Batch: 340; loss: 0.17; acc: 0.97
Batch: 360; loss: 0.28; acc: 0.91
Batch: 380; loss: 0.26; acc: 0.92
Batch: 400; loss: 0.15; acc: 0.97
Batch: 420; loss: 0.17; acc: 0.97
Batch: 440; loss: 0.18; acc: 0.94
Batch: 460; loss: 0.28; acc: 0.91
Batch: 480; loss: 0.13; acc: 0.95
Batch: 500; loss: 0.22; acc: 0.95
Batch: 520; loss: 0.21; acc: 0.95
Batch: 540; loss: 0.27; acc: 0.89
Batch: 560; loss: 0.17; acc: 0.89
Batch: 580; loss: 0.15; acc: 0.97
Batch: 600; loss: 0.06; acc: 0.98
Batch: 620; loss: 0.06; acc: 0.98
Batch: 640; loss: 0.01; acc: 1.0
Batch: 660; loss: 0.2; acc: 0.97
Batch: 680; loss: 0.09; acc: 0.97
Batch: 700; loss: 0.29; acc: 0.86
Batch: 720; loss: 0.07; acc: 0.98
Batch: 740; loss: 0.23; acc: 0.92
Batch: 760; loss: 0.15; acc: 0.94
Batch: 780; loss: 0.49; acc: 0.91
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.9758437449345365e-05
8.90174851519987e-06
Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.09; acc: 0.97
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.17; acc: 0.98
Batch: 120; loss: 0.27; acc: 0.83
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14363426439891194; val_accuracy: 0.9580015923566879 

The current subspace-distance is: 8.90174851519987e-06 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.06; acc: 0.98
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.17; acc: 0.92
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.07; acc: 0.98
Batch: 120; loss: 0.11; acc: 0.97
Batch: 140; loss: 0.13; acc: 0.97
Batch: 160; loss: 0.14; acc: 0.95
Batch: 180; loss: 0.1; acc: 0.97
Batch: 200; loss: 0.18; acc: 0.95
Batch: 220; loss: 0.11; acc: 0.98
Batch: 240; loss: 0.09; acc: 0.95
Batch: 260; loss: 0.34; acc: 0.88
Batch: 280; loss: 0.12; acc: 0.95
Batch: 300; loss: 0.18; acc: 0.95
Batch: 320; loss: 0.09; acc: 0.97
Batch: 340; loss: 0.09; acc: 0.95
Batch: 360; loss: 0.14; acc: 0.95
Batch: 380; loss: 0.25; acc: 0.95
Batch: 400; loss: 0.1; acc: 0.95
Batch: 420; loss: 0.11; acc: 0.97
Batch: 440; loss: 0.24; acc: 0.95
Batch: 460; loss: 0.15; acc: 0.95
Batch: 480; loss: 0.09; acc: 0.95
Batch: 500; loss: 0.07; acc: 0.98
Batch: 520; loss: 0.08; acc: 0.98
Batch: 540; loss: 0.1; acc: 0.97
Batch: 560; loss: 0.14; acc: 0.95
Batch: 580; loss: 0.11; acc: 0.95
Batch: 600; loss: 0.18; acc: 0.92
Batch: 620; loss: 0.2; acc: 0.97
Batch: 640; loss: 0.29; acc: 0.95
Batch: 660; loss: 0.06; acc: 0.98
Batch: 680; loss: 0.17; acc: 0.95
Batch: 700; loss: 0.11; acc: 0.97
Batch: 720; loss: 0.03; acc: 1.0
Batch: 740; loss: 0.08; acc: 0.97
Batch: 760; loss: 0.07; acc: 0.98
Batch: 780; loss: 0.05; acc: 0.98
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.8683803975582123e-05
9.096953363041393e-06
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.22; acc: 0.95
Batch: 120; loss: 0.39; acc: 0.78
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.15017499995364506; val_accuracy: 0.9522292993630573 

The current subspace-distance is: 9.096953363041393e-06 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.09; acc: 0.98
Batch: 20; loss: 0.18; acc: 0.95
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.13; acc: 0.94
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.06; acc: 0.97
Batch: 120; loss: 0.09; acc: 0.97
Batch: 140; loss: 0.12; acc: 0.95
Batch: 160; loss: 0.11; acc: 0.97
Batch: 180; loss: 0.14; acc: 0.95
Batch: 200; loss: 0.04; acc: 0.98
Batch: 220; loss: 0.11; acc: 0.95
Batch: 240; loss: 0.12; acc: 0.95
Batch: 260; loss: 0.08; acc: 0.98
Batch: 280; loss: 0.05; acc: 0.98
Batch: 300; loss: 0.23; acc: 0.91
Batch: 320; loss: 0.2; acc: 0.94
Batch: 340; loss: 0.04; acc: 0.98
Batch: 360; loss: 0.19; acc: 0.97
Batch: 380; loss: 0.25; acc: 0.92
Batch: 400; loss: 0.12; acc: 0.94
Batch: 420; loss: 0.05; acc: 0.98
Batch: 440; loss: 0.38; acc: 0.94
Batch: 460; loss: 0.14; acc: 0.95
Batch: 480; loss: 0.05; acc: 0.98
Batch: 500; loss: 0.09; acc: 0.97
Batch: 520; loss: 0.09; acc: 0.97
Batch: 540; loss: 0.14; acc: 0.97
Batch: 560; loss: 0.08; acc: 0.97
Batch: 580; loss: 0.17; acc: 0.95
Batch: 600; loss: 0.13; acc: 0.95
Batch: 620; loss: 0.11; acc: 0.97
Batch: 640; loss: 0.28; acc: 0.91
Batch: 660; loss: 0.04; acc: 1.0
Batch: 680; loss: 0.25; acc: 0.94
Batch: 700; loss: 0.11; acc: 0.95
Batch: 720; loss: 0.15; acc: 0.94
Batch: 740; loss: 0.12; acc: 0.94
Batch: 760; loss: 0.11; acc: 0.94
Batch: 780; loss: 0.14; acc: 0.97
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.7594076527748257e-05
9.62507510848809e-06
Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.11; acc: 0.95
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.17; acc: 0.97
Batch: 120; loss: 0.3; acc: 0.86
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14256912035642155; val_accuracy: 0.9573049363057324 

The current subspace-distance is: 9.62507510848809e-06 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.14; acc: 0.95
Batch: 80; loss: 0.14; acc: 0.94
Batch: 100; loss: 0.08; acc: 0.97
Batch: 120; loss: 0.17; acc: 0.94
Batch: 140; loss: 0.48; acc: 0.88
Batch: 160; loss: 0.17; acc: 0.97
Batch: 180; loss: 0.15; acc: 0.95
Batch: 200; loss: 0.18; acc: 0.94
Batch: 220; loss: 0.1; acc: 0.98
Batch: 240; loss: 0.08; acc: 0.97
Batch: 260; loss: 0.06; acc: 0.97
Batch: 280; loss: 0.16; acc: 0.97
Batch: 300; loss: 0.2; acc: 0.94
Batch: 320; loss: 0.14; acc: 0.92
Batch: 340; loss: 0.21; acc: 0.92
Batch: 360; loss: 0.08; acc: 0.98
Batch: 380; loss: 0.07; acc: 0.97
Batch: 400; loss: 0.13; acc: 0.95
Batch: 420; loss: 0.27; acc: 0.92
Batch: 440; loss: 0.3; acc: 0.91
Batch: 460; loss: 0.24; acc: 0.91
Batch: 480; loss: 0.09; acc: 0.94
Batch: 500; loss: 0.06; acc: 0.97
Batch: 520; loss: 0.23; acc: 0.92
Batch: 540; loss: 0.14; acc: 0.95
Batch: 560; loss: 0.11; acc: 0.95
Batch: 580; loss: 0.16; acc: 0.98
Batch: 600; loss: 0.14; acc: 0.95
Batch: 620; loss: 0.06; acc: 1.0
Batch: 640; loss: 0.23; acc: 0.94
Batch: 660; loss: 0.04; acc: 0.98
Batch: 680; loss: 0.12; acc: 0.97
Batch: 700; loss: 0.1; acc: 0.95
Batch: 720; loss: 0.18; acc: 0.94
Batch: 740; loss: 0.12; acc: 0.97
Batch: 760; loss: 0.14; acc: 0.94
Batch: 780; loss: 0.2; acc: 0.92
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.887600385292899e-05
9.51584388531046e-06
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.11; acc: 0.98
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.1; acc: 0.98
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.19; acc: 0.97
Batch: 120; loss: 0.3; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.13902494648269786; val_accuracy: 0.957703025477707 

The current subspace-distance is: 9.51584388531046e-06 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.06; acc: 0.98
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.12; acc: 0.94
Batch: 80; loss: 0.24; acc: 0.92
Batch: 100; loss: 0.11; acc: 0.94
Batch: 120; loss: 0.16; acc: 0.97
Batch: 140; loss: 0.34; acc: 0.94
Batch: 160; loss: 0.04; acc: 1.0
Batch: 180; loss: 0.04; acc: 1.0
Batch: 200; loss: 0.18; acc: 0.95
Batch: 220; loss: 0.26; acc: 0.92
Batch: 240; loss: 0.07; acc: 0.97
Batch: 260; loss: 0.16; acc: 0.95
Batch: 280; loss: 0.28; acc: 0.94
Batch: 300; loss: 0.52; acc: 0.81
Batch: 320; loss: 0.08; acc: 0.97
Batch: 340; loss: 0.14; acc: 0.95
Batch: 360; loss: 0.16; acc: 0.97
Batch: 380; loss: 0.1; acc: 0.97
Batch: 400; loss: 0.08; acc: 0.95
Batch: 420; loss: 0.26; acc: 0.94
Batch: 440; loss: 0.15; acc: 0.95
Batch: 460; loss: 0.04; acc: 1.0
Batch: 480; loss: 0.05; acc: 1.0
Batch: 500; loss: 0.2; acc: 0.94
Batch: 520; loss: 0.13; acc: 0.95
Batch: 540; loss: 0.04; acc: 0.98
Batch: 560; loss: 0.18; acc: 0.97
Batch: 580; loss: 0.12; acc: 0.94
Batch: 600; loss: 0.13; acc: 0.98
Batch: 620; loss: 0.24; acc: 0.94
Batch: 640; loss: 0.07; acc: 0.98
Batch: 660; loss: 0.12; acc: 0.97
Batch: 680; loss: 0.12; acc: 0.97
Batch: 700; loss: 0.05; acc: 0.98
Batch: 720; loss: 0.08; acc: 0.98
Batch: 740; loss: 0.07; acc: 0.98
Batch: 760; loss: 0.1; acc: 0.92
Batch: 780; loss: 0.11; acc: 0.97
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.9166047170292586e-05
9.728044460644014e-06
Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.1; acc: 0.98
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.19; acc: 0.97
Batch: 120; loss: 0.33; acc: 0.81
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.14040752229796852; val_accuracy: 0.9576035031847133 

The current subspace-distance is: 9.728044460644014e-06 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.14; acc: 0.94
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.2; acc: 0.97
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.16; acc: 0.97
Batch: 120; loss: 0.11; acc: 0.95
Batch: 140; loss: 0.12; acc: 0.97
Batch: 160; loss: 0.08; acc: 0.97
Batch: 180; loss: 0.13; acc: 0.97
Batch: 200; loss: 0.05; acc: 0.98
Batch: 220; loss: 0.18; acc: 0.97
Batch: 240; loss: 0.31; acc: 0.94
Batch: 260; loss: 0.09; acc: 0.98
Batch: 280; loss: 0.15; acc: 0.92
Batch: 300; loss: 0.11; acc: 0.95
Batch: 320; loss: 0.18; acc: 0.92
Batch: 340; loss: 0.08; acc: 0.97
Batch: 360; loss: 0.03; acc: 1.0
Batch: 380; loss: 0.17; acc: 0.97
Batch: 400; loss: 0.16; acc: 0.95
Batch: 420; loss: 0.26; acc: 0.94
Batch: 440; loss: 0.28; acc: 0.95
Batch: 460; loss: 0.08; acc: 0.97
Batch: 480; loss: 0.05; acc: 0.98
Batch: 500; loss: 0.09; acc: 0.97
Batch: 520; loss: 0.06; acc: 0.98
Batch: 540; loss: 0.14; acc: 0.92
Batch: 560; loss: 0.08; acc: 0.97
Batch: 580; loss: 0.16; acc: 0.95
Batch: 600; loss: 0.19; acc: 0.91
Batch: 620; loss: 0.13; acc: 0.94
Batch: 640; loss: 0.19; acc: 0.94
Batch: 660; loss: 0.11; acc: 0.95
Batch: 680; loss: 0.23; acc: 0.94
Batch: 700; loss: 0.1; acc: 0.98
Batch: 720; loss: 0.15; acc: 0.94
Batch: 740; loss: 0.14; acc: 0.94
Batch: 760; loss: 0.09; acc: 0.95
Batch: 780; loss: 0.15; acc: 0.94
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.868893170671072e-05
9.749994205776602e-06
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.11; acc: 0.95
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.1; acc: 0.98
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.17; acc: 0.97
Batch: 120; loss: 0.28; acc: 0.86
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.13958715303403557; val_accuracy: 0.9584992038216561 

The current subspace-distance is: 9.749994205776602e-06 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.14; acc: 0.97
Batch: 20; loss: 0.27; acc: 0.97
Batch: 40; loss: 0.1; acc: 0.98
Batch: 60; loss: 0.14; acc: 0.95
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.12; acc: 0.97
Batch: 140; loss: 0.1; acc: 0.98
Batch: 160; loss: 0.15; acc: 0.92
Batch: 180; loss: 0.09; acc: 0.95
Batch: 200; loss: 0.24; acc: 0.95
Batch: 220; loss: 0.31; acc: 0.92
Batch: 240; loss: 0.06; acc: 0.97
Batch: 260; loss: 0.13; acc: 0.95
Batch: 280; loss: 0.03; acc: 1.0
Batch: 300; loss: 0.11; acc: 0.97
Batch: 320; loss: 0.38; acc: 0.86
Batch: 340; loss: 0.13; acc: 0.95
Batch: 360; loss: 0.03; acc: 1.0
Batch: 380; loss: 0.08; acc: 0.98
Batch: 400; loss: 0.28; acc: 0.94
Batch: 420; loss: 0.12; acc: 0.97
Batch: 440; loss: 0.16; acc: 0.92
Batch: 460; loss: 0.07; acc: 1.0
Batch: 480; loss: 0.02; acc: 1.0
Batch: 500; loss: 0.14; acc: 0.95
Batch: 520; loss: 0.07; acc: 0.98
Batch: 540; loss: 0.17; acc: 0.97
Batch: 560; loss: 0.13; acc: 0.95
Batch: 580; loss: 0.03; acc: 1.0
Batch: 600; loss: 0.11; acc: 0.97
Batch: 620; loss: 0.21; acc: 0.94
Batch: 640; loss: 0.08; acc: 0.97
Batch: 660; loss: 0.37; acc: 0.89
Batch: 680; loss: 0.07; acc: 0.98
Batch: 700; loss: 0.25; acc: 0.95
Batch: 720; loss: 0.05; acc: 1.0
Batch: 740; loss: 0.06; acc: 0.98
Batch: 760; loss: 0.1; acc: 0.98
Batch: 780; loss: 0.08; acc: 0.97
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.8382304662954994e-05
9.959627277567051e-06
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.1; acc: 0.98
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.19; acc: 0.98
Batch: 120; loss: 0.29; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.13986758066780247; val_accuracy: 0.9591958598726115 

The current subspace-distance is: 9.959627277567051e-06 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.36; acc: 0.95
Batch: 20; loss: 0.1; acc: 0.97
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.1; acc: 0.98
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.09; acc: 0.98
Batch: 120; loss: 0.14; acc: 0.97
Batch: 140; loss: 0.13; acc: 0.94
Batch: 160; loss: 0.1; acc: 0.97
Batch: 180; loss: 0.1; acc: 0.98
Batch: 200; loss: 0.12; acc: 0.94
Batch: 220; loss: 0.26; acc: 0.94
Batch: 240; loss: 0.19; acc: 0.92
Batch: 260; loss: 0.11; acc: 0.95
Batch: 280; loss: 0.22; acc: 0.92
Batch: 300; loss: 0.16; acc: 0.94
Batch: 320; loss: 0.13; acc: 0.94
Batch: 340; loss: 0.1; acc: 0.97
Batch: 360; loss: 0.14; acc: 0.94
Batch: 380; loss: 0.11; acc: 0.95
Batch: 400; loss: 0.09; acc: 0.97
Batch: 420; loss: 0.16; acc: 0.94
Batch: 440; loss: 0.22; acc: 0.94
Batch: 460; loss: 0.12; acc: 0.98
Batch: 480; loss: 0.17; acc: 0.94
Batch: 500; loss: 0.07; acc: 0.98
Batch: 520; loss: 0.16; acc: 0.95
Batch: 540; loss: 0.22; acc: 0.92
Batch: 560; loss: 0.08; acc: 0.98
Batch: 580; loss: 0.19; acc: 0.95
Batch: 600; loss: 0.17; acc: 0.95
Batch: 620; loss: 0.05; acc: 0.98
Batch: 640; loss: 0.19; acc: 0.94
Batch: 660; loss: 0.11; acc: 0.95
Batch: 680; loss: 0.13; acc: 0.95
Batch: 700; loss: 0.1; acc: 0.97
Batch: 720; loss: 0.31; acc: 0.91
Batch: 740; loss: 0.12; acc: 0.94
Batch: 760; loss: 0.18; acc: 0.91
Batch: 780; loss: 0.26; acc: 0.94
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.876272628782317e-05
9.541369763610419e-06
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.12; acc: 0.95
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.19; acc: 0.97
Batch: 120; loss: 0.27; acc: 0.86
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1422981055821203; val_accuracy: 0.9568073248407644 

The current subspace-distance is: 9.541369763610419e-06 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.05; acc: 0.98
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.19; acc: 0.91
Batch: 60; loss: 0.13; acc: 0.95
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.14; acc: 0.95
Batch: 140; loss: 0.1; acc: 0.97
Batch: 160; loss: 0.03; acc: 1.0
Batch: 180; loss: 0.21; acc: 0.91
Batch: 200; loss: 0.13; acc: 0.97
Batch: 220; loss: 0.05; acc: 0.98
Batch: 240; loss: 0.11; acc: 0.97
Batch: 260; loss: 0.11; acc: 0.98
Batch: 280; loss: 0.29; acc: 0.89
Batch: 300; loss: 0.36; acc: 0.88
Batch: 320; loss: 0.26; acc: 0.92
Batch: 340; loss: 0.17; acc: 0.95
Batch: 360; loss: 0.19; acc: 0.95
Batch: 380; loss: 0.09; acc: 0.97
Batch: 400; loss: 0.09; acc: 0.95
Batch: 420; loss: 0.17; acc: 0.94
Batch: 440; loss: 0.06; acc: 0.98
Batch: 460; loss: 0.22; acc: 0.97
Batch: 480; loss: 0.32; acc: 0.94
Batch: 500; loss: 0.14; acc: 0.94
Batch: 520; loss: 0.09; acc: 0.98
Batch: 540; loss: 0.3; acc: 0.91
Batch: 560; loss: 0.18; acc: 0.95
Batch: 580; loss: 0.26; acc: 0.92
Batch: 600; loss: 0.18; acc: 0.95
Batch: 620; loss: 0.14; acc: 0.95
Batch: 640; loss: 0.36; acc: 0.88
Batch: 660; loss: 0.24; acc: 0.94
Batch: 680; loss: 0.06; acc: 0.98
Batch: 700; loss: 0.05; acc: 1.0
Batch: 720; loss: 0.15; acc: 0.92
Batch: 740; loss: 0.13; acc: 0.97
Batch: 760; loss: 0.17; acc: 0.94
Batch: 780; loss: 0.14; acc: 0.95
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.7558298825169913e-05
9.45637839322444e-06
Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.12; acc: 0.98
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.18; acc: 0.97
Batch: 120; loss: 0.31; acc: 0.83
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.13936324533858116; val_accuracy: 0.9575039808917197 

The current subspace-distance is: 9.45637839322444e-06 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.15; acc: 0.94
Batch: 20; loss: 0.29; acc: 0.95
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.22; acc: 0.97
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.12; acc: 0.97
Batch: 120; loss: 0.18; acc: 0.97
Batch: 140; loss: 0.04; acc: 1.0
Batch: 160; loss: 0.13; acc: 0.94
Batch: 180; loss: 0.18; acc: 0.95
Batch: 200; loss: 0.19; acc: 0.94
Batch: 220; loss: 0.23; acc: 0.95
Batch: 240; loss: 0.08; acc: 0.97
Batch: 260; loss: 0.15; acc: 0.95
Batch: 280; loss: 0.08; acc: 0.98
Batch: 300; loss: 0.19; acc: 0.94
Batch: 320; loss: 0.24; acc: 0.94
Batch: 340; loss: 0.22; acc: 0.92
Batch: 360; loss: 0.07; acc: 0.98
Batch: 380; loss: 0.05; acc: 0.98
Batch: 400; loss: 0.06; acc: 0.98
Batch: 420; loss: 0.08; acc: 0.98
Batch: 440; loss: 0.07; acc: 0.98
Batch: 460; loss: 0.11; acc: 0.97
Batch: 480; loss: 0.17; acc: 0.95
Batch: 500; loss: 0.11; acc: 0.97
Batch: 520; loss: 0.19; acc: 0.91
Batch: 540; loss: 0.23; acc: 0.92
Batch: 560; loss: 0.06; acc: 0.98
Batch: 580; loss: 0.4; acc: 0.91
Batch: 600; loss: 0.26; acc: 0.92
Batch: 620; loss: 0.09; acc: 0.97
Batch: 640; loss: 0.24; acc: 0.95
Batch: 660; loss: 0.07; acc: 0.98
Batch: 680; loss: 0.05; acc: 0.98
Batch: 700; loss: 0.35; acc: 0.91
Batch: 720; loss: 0.14; acc: 0.97
Batch: 740; loss: 0.15; acc: 0.95
Batch: 760; loss: 0.15; acc: 0.94
Batch: 780; loss: 0.21; acc: 0.92
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.744824450928718e-05
9.281087841372937e-06
Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.14; acc: 0.94
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.1; acc: 0.98
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.19; acc: 0.97
Batch: 120; loss: 0.3; acc: 0.83
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14231521140333195; val_accuracy: 0.956906847133758 

The current subspace-distance is: 9.281087841372937e-06 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.06; acc: 0.98
Batch: 20; loss: 0.2; acc: 0.97
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.22; acc: 0.95
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.1; acc: 0.94
Batch: 120; loss: 0.15; acc: 0.95
Batch: 140; loss: 0.22; acc: 0.92
Batch: 160; loss: 0.1; acc: 0.97
Batch: 180; loss: 0.02; acc: 1.0
Batch: 200; loss: 0.13; acc: 0.97
Batch: 220; loss: 0.21; acc: 0.95
Batch: 240; loss: 0.37; acc: 0.91
Batch: 260; loss: 0.09; acc: 0.98
Batch: 280; loss: 0.16; acc: 0.92
Batch: 300; loss: 0.15; acc: 0.97
Batch: 320; loss: 0.08; acc: 0.95
Batch: 340; loss: 0.13; acc: 0.97
Batch: 360; loss: 0.22; acc: 0.95
Batch: 380; loss: 0.17; acc: 0.94
Batch: 400; loss: 0.07; acc: 0.97
Batch: 420; loss: 0.25; acc: 0.94
Batch: 440; loss: 0.2; acc: 0.94
Batch: 460; loss: 0.1; acc: 0.97
Batch: 480; loss: 0.08; acc: 0.97
Batch: 500; loss: 0.09; acc: 0.98
Batch: 520; loss: 0.19; acc: 0.94
Batch: 540; loss: 0.09; acc: 0.95
Batch: 560; loss: 0.14; acc: 0.94
Batch: 580; loss: 0.05; acc: 0.98
Batch: 600; loss: 0.2; acc: 0.92
Batch: 620; loss: 0.04; acc: 1.0
Batch: 640; loss: 0.11; acc: 0.95
Batch: 660; loss: 0.12; acc: 0.94
Batch: 680; loss: 0.12; acc: 0.95
Batch: 700; loss: 0.18; acc: 0.94
Batch: 720; loss: 0.12; acc: 0.97
Batch: 740; loss: 0.23; acc: 0.94
Batch: 760; loss: 0.08; acc: 0.97
Batch: 780; loss: 0.12; acc: 0.97
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.771308754745405e-05
8.72417695063632e-06
Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.12; acc: 0.97
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.1; acc: 0.98
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.18; acc: 0.97
Batch: 120; loss: 0.3; acc: 0.86
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.13931806084171983; val_accuracy: 0.9582006369426752 

The current subspace-distance is: 8.72417695063632e-06 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.25; acc: 0.92
Batch: 20; loss: 0.1; acc: 0.95
Batch: 40; loss: 0.05; acc: 1.0
Batch: 60; loss: 0.07; acc: 1.0
Batch: 80; loss: 0.27; acc: 0.94
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.22; acc: 0.91
Batch: 140; loss: 0.07; acc: 0.97
Batch: 160; loss: 0.03; acc: 1.0
Batch: 180; loss: 0.05; acc: 0.98
Batch: 200; loss: 0.12; acc: 0.97
Batch: 220; loss: 0.24; acc: 0.91
Batch: 240; loss: 0.14; acc: 0.94
Batch: 260; loss: 0.08; acc: 0.98
Batch: 280; loss: 0.08; acc: 0.98
Batch: 300; loss: 0.26; acc: 0.92
Batch: 320; loss: 0.1; acc: 0.97
Batch: 340; loss: 0.08; acc: 0.97
Batch: 360; loss: 0.03; acc: 0.98
Batch: 380; loss: 0.05; acc: 0.98
Batch: 400; loss: 0.12; acc: 0.98
Batch: 420; loss: 0.19; acc: 0.94
Batch: 440; loss: 0.03; acc: 0.98
Batch: 460; loss: 0.1; acc: 0.97
Batch: 480; loss: 0.12; acc: 0.97
Batch: 500; loss: 0.1; acc: 0.97
Batch: 520; loss: 0.26; acc: 0.94
Batch: 540; loss: 0.09; acc: 0.97
Batch: 560; loss: 0.22; acc: 0.91
Batch: 580; loss: 0.21; acc: 0.91
Batch: 600; loss: 0.13; acc: 0.95
Batch: 620; loss: 0.09; acc: 0.97
Batch: 640; loss: 0.15; acc: 0.94
Batch: 660; loss: 0.07; acc: 0.97
Batch: 680; loss: 0.07; acc: 0.97
Batch: 700; loss: 0.2; acc: 0.95
Batch: 720; loss: 0.25; acc: 0.94
Batch: 740; loss: 0.27; acc: 0.94
Batch: 760; loss: 0.11; acc: 0.97
Batch: 780; loss: 0.14; acc: 0.97
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.8419857699191198e-05
9.155529369309079e-06
Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.1; acc: 0.97
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.1; acc: 0.98
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.18; acc: 0.98
Batch: 120; loss: 0.29; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.13792917742186292; val_accuracy: 0.9597929936305732 

The current subspace-distance is: 9.155529369309079e-06 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.16; acc: 0.94
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.92
Batch: 80; loss: 0.05; acc: 1.0
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.16; acc: 0.94
Batch: 140; loss: 0.16; acc: 0.95
Batch: 160; loss: 0.25; acc: 0.92
Batch: 180; loss: 0.08; acc: 0.97
Batch: 200; loss: 0.08; acc: 0.97
Batch: 220; loss: 0.12; acc: 0.94
Batch: 240; loss: 0.13; acc: 0.95
Batch: 260; loss: 0.19; acc: 0.94
Batch: 280; loss: 0.19; acc: 0.97
Batch: 300; loss: 0.16; acc: 0.94
Batch: 320; loss: 0.14; acc: 0.94
Batch: 340; loss: 0.2; acc: 0.95
Batch: 360; loss: 0.11; acc: 0.95
Batch: 380; loss: 0.21; acc: 0.94
Batch: 400; loss: 0.07; acc: 0.97
Batch: 420; loss: 0.11; acc: 0.95
Batch: 440; loss: 0.11; acc: 0.94
Batch: 460; loss: 0.11; acc: 0.95
Batch: 480; loss: 0.07; acc: 0.98
Batch: 500; loss: 0.13; acc: 0.97
Batch: 520; loss: 0.07; acc: 0.98
Batch: 540; loss: 0.05; acc: 0.97
Batch: 560; loss: 0.04; acc: 0.98
Batch: 580; loss: 0.11; acc: 0.97
Batch: 600; loss: 0.06; acc: 0.98
Batch: 620; loss: 0.14; acc: 0.94
Batch: 640; loss: 0.03; acc: 1.0
Batch: 660; loss: 0.13; acc: 0.94
Batch: 680; loss: 0.26; acc: 0.95
Batch: 700; loss: 0.12; acc: 0.95
Batch: 720; loss: 0.28; acc: 0.92
Batch: 740; loss: 0.28; acc: 0.91
Batch: 760; loss: 0.13; acc: 0.97
Batch: 780; loss: 0.14; acc: 0.97
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.8003814804833382e-05
9.200453860103153e-06
Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.11; acc: 0.98
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.1; acc: 0.98
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.18; acc: 0.97
Batch: 120; loss: 0.29; acc: 0.84
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.13678332188042105; val_accuracy: 0.9589968152866242 

The current subspace-distance is: 9.200453860103153e-06 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.11; acc: 0.95
Batch: 20; loss: 0.31; acc: 0.94
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.12; acc: 0.97
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.94
Batch: 120; loss: 0.25; acc: 0.95
Batch: 140; loss: 0.1; acc: 0.95
Batch: 160; loss: 0.11; acc: 0.97
Batch: 180; loss: 0.17; acc: 0.94
Batch: 200; loss: 0.08; acc: 0.95
Batch: 220; loss: 0.2; acc: 0.94
Batch: 240; loss: 0.06; acc: 0.97
Batch: 260; loss: 0.06; acc: 0.97
Batch: 280; loss: 0.28; acc: 0.92
Batch: 300; loss: 0.05; acc: 0.98
Batch: 320; loss: 0.08; acc: 0.97
Batch: 340; loss: 0.04; acc: 0.98
Batch: 360; loss: 0.45; acc: 0.95
Batch: 380; loss: 0.28; acc: 0.94
Batch: 400; loss: 0.3; acc: 0.89
Batch: 420; loss: 0.13; acc: 0.95
Batch: 440; loss: 0.11; acc: 0.95
Batch: 460; loss: 0.13; acc: 0.95
Batch: 480; loss: 0.24; acc: 0.94
Batch: 500; loss: 0.05; acc: 0.98
Batch: 520; loss: 0.05; acc: 0.98
Batch: 540; loss: 0.15; acc: 0.95
Batch: 560; loss: 0.21; acc: 0.95
Batch: 580; loss: 0.15; acc: 0.95
Batch: 600; loss: 0.11; acc: 0.95
Batch: 620; loss: 0.05; acc: 0.98
Batch: 640; loss: 0.2; acc: 0.95
Batch: 660; loss: 0.13; acc: 0.94
Batch: 680; loss: 0.04; acc: 1.0
Batch: 700; loss: 0.21; acc: 0.95
Batch: 720; loss: 0.24; acc: 0.91
Batch: 740; loss: 0.11; acc: 0.94
Batch: 760; loss: 0.04; acc: 1.0
Batch: 780; loss: 0.06; acc: 0.98
Train Epoch over. train_loss: 0.15; train_accuracy: 0.96 

2.8409202059265226e-05
8.620288099336904e-06
Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.12; acc: 0.97
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.1; acc: 0.98
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.18; acc: 0.97
Batch: 120; loss: 0.31; acc: 0.81
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.13754048922164425; val_accuracy: 0.9583996815286624 

The current subspace-distance is: 8.620288099336904e-06 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.1; acc: 0.95
Batch: 20; loss: 0.16; acc: 0.94
Batch: 40; loss: 0.09; acc: 0.95
Batch: 60; loss: 0.03; acc: 1.0
Batch: 80; loss: 0.15; acc: 0.94
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.22; acc: 0.88
Batch: 140; loss: 0.11; acc: 0.95
Batch: 160; loss: 0.24; acc: 0.92
Batch: 180; loss: 0.14; acc: 0.92
Batch: 200; loss: 0.17; acc: 0.95
Batch: 220; loss: 0.08; acc: 0.97
Batch: 240; loss: 0.1; acc: 0.95
Batch: 260; loss: 0.06; acc: 0.97
Batch: 280; loss: 0.13; acc: 0.95
Batch: 300; loss: 0.07; acc: 1.0
Batch: 320; loss: 0.09; acc: 0.97
Batch: 340; loss: 0.1; acc: 0.98
Batch: 360; loss: 0.24; acc: 0.94
Batch: 380; loss: 0.02; acc: 1.0
Batch: 400; loss: 0.15; acc: 0.94
Batch: 420; loss: 0.07; acc: 0.98
Batch: 440; loss: 0.21; acc: 0.95
Batch: 460; loss: 0.07; acc: 0.97
Batch: 480; loss: 0.09; acc: 0.95
Batch: 500; loss: 0.14; acc: 0.97
Batch: 520; loss: 0.19; acc: 0.95
Batch: 540; loss: 0.18; acc: 0.95
Batch: 560; loss: 0.12; acc: 0.94
Batch: 580; loss: 0.21; acc: 0.91
Batch: 600; loss: 0.2; acc: 0.94
Batch: 620; loss: 0.08; acc: 0.97
Batch: 640; loss: 0.09; acc: 0.97
Batch: 660; loss: 0.25; acc: 0.92
Batch: 680; loss: 0.12; acc: 0.95
Batch: 700; loss: 0.19; acc: 0.97
Batch: 720; loss: 0.16; acc: 0.94
Batch: 740; loss: 0.09; acc: 0.97
Batch: 760; loss: 0.14; acc: 0.97
Batch: 780; loss: 0.11; acc: 0.97
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.825922092597466e-05
9.670604413258843e-06
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.12; acc: 0.97
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.1; acc: 0.98
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.18; acc: 0.97
Batch: 120; loss: 0.31; acc: 0.86
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.13825832262255583; val_accuracy: 0.9580015923566879 

The current subspace-distance is: 9.670604413258843e-06 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.26; acc: 0.94
Batch: 20; loss: 0.26; acc: 0.97
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.15; acc: 0.92
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.05; acc: 1.0
Batch: 120; loss: 0.08; acc: 0.97
Batch: 140; loss: 0.13; acc: 0.98
Batch: 160; loss: 0.1; acc: 0.97
Batch: 180; loss: 0.28; acc: 0.95
Batch: 200; loss: 0.14; acc: 0.95
Batch: 220; loss: 0.07; acc: 0.98
Batch: 240; loss: 0.33; acc: 0.94
Batch: 260; loss: 0.19; acc: 0.95
Batch: 280; loss: 0.1; acc: 0.97
Batch: 300; loss: 0.15; acc: 0.97
Batch: 320; loss: 0.19; acc: 0.94
Batch: 340; loss: 0.08; acc: 0.95
Batch: 360; loss: 0.22; acc: 0.94
Batch: 380; loss: 0.12; acc: 0.95
Batch: 400; loss: 0.13; acc: 0.95
Batch: 420; loss: 0.11; acc: 0.97
Batch: 440; loss: 0.11; acc: 0.94
Batch: 460; loss: 0.22; acc: 0.92
Batch: 480; loss: 0.06; acc: 0.97
Batch: 500; loss: 0.15; acc: 0.97
Batch: 520; loss: 0.35; acc: 0.92
Batch: 540; loss: 0.16; acc: 0.95
Batch: 560; loss: 0.17; acc: 0.97
Batch: 580; loss: 0.2; acc: 0.91
Batch: 600; loss: 0.11; acc: 0.97
Batch: 620; loss: 0.07; acc: 1.0
Batch: 640; loss: 0.08; acc: 0.98
Batch: 660; loss: 0.08; acc: 0.97
Batch: 680; loss: 0.13; acc: 0.95
Batch: 700; loss: 0.05; acc: 0.98
Batch: 720; loss: 0.24; acc: 0.92
Batch: 740; loss: 0.21; acc: 0.95
Batch: 760; loss: 0.07; acc: 0.98
Batch: 780; loss: 0.11; acc: 0.97
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.834277620422654e-05
9.245771252608392e-06
Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.11; acc: 0.98
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.1; acc: 0.98
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.18; acc: 0.97
Batch: 120; loss: 0.3; acc: 0.86
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.13694426920383598; val_accuracy: 0.9580015923566879 

The current subspace-distance is: 9.245771252608392e-06 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.16; acc: 0.92
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.41; acc: 0.94
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.16; acc: 0.92
Batch: 120; loss: 0.07; acc: 0.95
Batch: 140; loss: 0.24; acc: 0.95
Batch: 160; loss: 0.18; acc: 0.95
Batch: 180; loss: 0.16; acc: 0.94
Batch: 200; loss: 0.1; acc: 0.97
Batch: 220; loss: 0.1; acc: 0.97
Batch: 240; loss: 0.18; acc: 0.91
Batch: 260; loss: 0.14; acc: 0.95
Batch: 280; loss: 0.2; acc: 0.92
Batch: 300; loss: 0.11; acc: 0.97
Batch: 320; loss: 0.05; acc: 1.0
Batch: 340; loss: 0.17; acc: 0.94
Batch: 360; loss: 0.04; acc: 1.0
Batch: 380; loss: 0.16; acc: 0.95
Batch: 400; loss: 0.3; acc: 0.89
Batch: 420; loss: 0.18; acc: 0.94
Batch: 440; loss: 0.11; acc: 0.95
Batch: 460; loss: 0.12; acc: 0.95
Batch: 480; loss: 0.31; acc: 0.91
Batch: 500; loss: 0.23; acc: 0.95
Batch: 520; loss: 0.13; acc: 0.95
Batch: 540; loss: 0.05; acc: 0.98
Batch: 560; loss: 0.11; acc: 0.97
Batch: 580; loss: 0.28; acc: 0.92
Batch: 600; loss: 0.21; acc: 0.97
Batch: 620; loss: 0.09; acc: 0.97
Batch: 640; loss: 0.17; acc: 0.97
Batch: 660; loss: 0.26; acc: 0.89
Batch: 680; loss: 0.14; acc: 0.97
Batch: 700; loss: 0.11; acc: 0.97
Batch: 720; loss: 0.15; acc: 0.98
Batch: 740; loss: 0.39; acc: 0.88
Batch: 760; loss: 0.1; acc: 0.97
Batch: 780; loss: 0.05; acc: 0.98
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.8274269425310194e-05
1.031047577271238e-05
Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.12; acc: 0.97
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.1; acc: 0.98
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.18; acc: 0.97
Batch: 120; loss: 0.3; acc: 0.83
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.13798485226502086; val_accuracy: 0.9573049363057324 

The current subspace-distance is: 1.031047577271238e-05 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.04; acc: 1.0
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.16; acc: 0.94
Batch: 80; loss: 0.12; acc: 0.94
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.11; acc: 0.97
Batch: 140; loss: 0.12; acc: 0.97
Batch: 160; loss: 0.09; acc: 0.97
Batch: 180; loss: 0.04; acc: 0.98
Batch: 200; loss: 0.17; acc: 0.98
Batch: 220; loss: 0.07; acc: 0.95
Batch: 240; loss: 0.21; acc: 0.94
Batch: 260; loss: 0.27; acc: 0.95
Batch: 280; loss: 0.27; acc: 0.91
Batch: 300; loss: 0.11; acc: 0.98
Batch: 320; loss: 0.19; acc: 0.94
Batch: 340; loss: 0.01; acc: 1.0
Batch: 360; loss: 0.15; acc: 0.95
Batch: 380; loss: 0.08; acc: 0.98
Batch: 400; loss: 0.03; acc: 1.0
Batch: 420; loss: 0.1; acc: 0.95
Batch: 440; loss: 0.11; acc: 0.95
Batch: 460; loss: 0.17; acc: 0.94
Batch: 480; loss: 0.21; acc: 0.95
Batch: 500; loss: 0.08; acc: 0.97
Batch: 520; loss: 0.11; acc: 0.94
Batch: 540; loss: 0.2; acc: 0.97
Batch: 560; loss: 0.09; acc: 0.98
Batch: 580; loss: 0.08; acc: 0.97
Batch: 600; loss: 0.26; acc: 0.95
Batch: 620; loss: 0.03; acc: 1.0
Batch: 640; loss: 0.04; acc: 1.0
Batch: 660; loss: 0.18; acc: 0.94
Batch: 680; loss: 0.27; acc: 0.94
Batch: 700; loss: 0.07; acc: 1.0
Batch: 720; loss: 0.34; acc: 0.92
Batch: 740; loss: 0.17; acc: 0.95
Batch: 760; loss: 0.09; acc: 0.95
Batch: 780; loss: 0.22; acc: 0.94
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.8292126444284804e-05
9.01661223906558e-06
Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.12; acc: 0.97
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.1; acc: 0.98
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.18; acc: 0.97
Batch: 120; loss: 0.3; acc: 0.83
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1380494772723526; val_accuracy: 0.9580015923566879 

The current subspace-distance is: 9.01661223906558e-06 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.05; acc: 0.98
Batch: 20; loss: 0.15; acc: 0.94
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.17; acc: 0.97
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.1; acc: 0.95
Batch: 120; loss: 0.18; acc: 0.94
Batch: 140; loss: 0.07; acc: 1.0
Batch: 160; loss: 0.13; acc: 0.95
Batch: 180; loss: 0.08; acc: 0.95
Batch: 200; loss: 0.12; acc: 0.97
Batch: 220; loss: 0.14; acc: 0.97
Batch: 240; loss: 0.06; acc: 0.97
Batch: 260; loss: 0.14; acc: 0.94
Batch: 280; loss: 0.13; acc: 0.95
Batch: 300; loss: 0.27; acc: 0.92
Batch: 320; loss: 0.53; acc: 0.91
Batch: 340; loss: 0.05; acc: 0.98
Batch: 360; loss: 0.2; acc: 0.92
Batch: 380; loss: 0.12; acc: 0.97
Batch: 400; loss: 0.12; acc: 0.97
Batch: 420; loss: 0.17; acc: 0.95
Batch: 440; loss: 0.15; acc: 0.95
Batch: 460; loss: 0.22; acc: 0.92
Batch: 480; loss: 0.24; acc: 0.95
Batch: 500; loss: 0.23; acc: 0.91
Batch: 520; loss: 0.19; acc: 0.92
Batch: 540; loss: 0.5; acc: 0.88
Batch: 560; loss: 0.26; acc: 0.92
Batch: 580; loss: 0.13; acc: 0.95
Batch: 600; loss: 0.08; acc: 0.95
Batch: 620; loss: 0.15; acc: 0.95
Batch: 640; loss: 0.05; acc: 0.98
Batch: 660; loss: 0.07; acc: 1.0
Batch: 680; loss: 0.03; acc: 1.0
Batch: 700; loss: 0.13; acc: 0.95
Batch: 720; loss: 0.16; acc: 0.97
Batch: 740; loss: 0.08; acc: 0.97
Batch: 760; loss: 0.15; acc: 0.95
Batch: 780; loss: 0.09; acc: 0.97
Train Epoch over. train_loss: 0.15; train_accuracy: 0.96 

2.826168929459527e-05
8.698731107870117e-06
Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.13; acc: 0.97
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.1; acc: 0.98
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.17; acc: 0.97
Batch: 120; loss: 0.3; acc: 0.84
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.13824102894705573; val_accuracy: 0.9591958598726115 

The current subspace-distance is: 8.698731107870117e-06 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.17; acc: 0.97
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.15; acc: 0.95
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.06; acc: 0.97
Batch: 140; loss: 0.16; acc: 0.92
Batch: 160; loss: 0.12; acc: 0.94
Batch: 180; loss: 0.18; acc: 0.95
Batch: 200; loss: 0.21; acc: 0.92
Batch: 220; loss: 0.07; acc: 0.97
Batch: 240; loss: 0.04; acc: 0.98
Batch: 260; loss: 0.12; acc: 0.94
Batch: 280; loss: 0.09; acc: 0.95
Batch: 300; loss: 0.05; acc: 0.97
Batch: 320; loss: 0.22; acc: 0.92
Batch: 340; loss: 0.25; acc: 0.94
Batch: 360; loss: 0.13; acc: 0.97
Batch: 380; loss: 0.05; acc: 1.0
Batch: 400; loss: 0.04; acc: 1.0
Batch: 420; loss: 0.2; acc: 0.94
Batch: 440; loss: 0.09; acc: 0.95
Batch: 460; loss: 0.13; acc: 0.95
Batch: 480; loss: 0.06; acc: 0.98
Batch: 500; loss: 0.08; acc: 0.97
Batch: 520; loss: 0.18; acc: 0.95
Batch: 540; loss: 0.19; acc: 0.92
Batch: 560; loss: 0.05; acc: 1.0
Batch: 580; loss: 0.09; acc: 0.97
Batch: 600; loss: 0.08; acc: 0.98
Batch: 620; loss: 0.16; acc: 0.94
Batch: 640; loss: 0.1; acc: 0.95
Batch: 660; loss: 0.18; acc: 0.95
Batch: 680; loss: 0.21; acc: 0.92
Batch: 700; loss: 0.24; acc: 0.95
Batch: 720; loss: 0.1; acc: 0.95
Batch: 740; loss: 0.28; acc: 0.94
Batch: 760; loss: 0.24; acc: 0.97
Batch: 780; loss: 0.13; acc: 0.95
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.823933209583629e-05
9.177894753520377e-06
Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.12; acc: 0.97
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.1; acc: 0.98
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.17; acc: 0.97
Batch: 120; loss: 0.3; acc: 0.84
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.13712372334235035; val_accuracy: 0.9585987261146497 

The current subspace-distance is: 9.177894753520377e-06 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.29; acc: 0.95
Batch: 20; loss: 0.06; acc: 0.98
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.13; acc: 0.95
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.37; acc: 0.94
Batch: 120; loss: 0.15; acc: 0.97
Batch: 140; loss: 0.15; acc: 0.97
Batch: 160; loss: 0.11; acc: 0.97
Batch: 180; loss: 0.12; acc: 0.97
Batch: 200; loss: 0.1; acc: 0.98
Batch: 220; loss: 0.1; acc: 0.97
Batch: 240; loss: 0.15; acc: 0.97
Batch: 260; loss: 0.15; acc: 0.94
Batch: 280; loss: 0.06; acc: 1.0
Batch: 300; loss: 0.06; acc: 0.98
Batch: 320; loss: 0.2; acc: 0.92
Batch: 340; loss: 0.05; acc: 0.98
Batch: 360; loss: 0.18; acc: 0.92
Batch: 380; loss: 0.22; acc: 0.92
Batch: 400; loss: 0.12; acc: 0.95
Batch: 420; loss: 0.12; acc: 0.95
Batch: 440; loss: 0.05; acc: 0.98
Batch: 460; loss: 0.08; acc: 0.97
Batch: 480; loss: 0.16; acc: 0.97
Batch: 500; loss: 0.33; acc: 0.89
Batch: 520; loss: 0.08; acc: 0.98
Batch: 540; loss: 0.35; acc: 0.91
Batch: 560; loss: 0.25; acc: 0.94
Batch: 580; loss: 0.13; acc: 0.97
Batch: 600; loss: 0.29; acc: 0.95
Batch: 620; loss: 0.16; acc: 0.97
Batch: 640; loss: 0.07; acc: 0.95
Batch: 660; loss: 0.06; acc: 0.98
Batch: 680; loss: 0.19; acc: 0.94
Batch: 700; loss: 0.14; acc: 0.95
Batch: 720; loss: 0.23; acc: 0.94
Batch: 740; loss: 0.15; acc: 0.94
Batch: 760; loss: 0.17; acc: 0.92
Batch: 780; loss: 0.09; acc: 0.97
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.8809514333261177e-05
8.586484909756109e-06
Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.1; acc: 0.98
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.18; acc: 0.97
Batch: 120; loss: 0.31; acc: 0.84
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.13766924457944882; val_accuracy: 0.9582006369426752 

The current subspace-distance is: 8.586484909756109e-06 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.08; acc: 0.95
Batch: 20; loss: 0.14; acc: 0.94
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.12; acc: 0.95
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.04; acc: 0.98
Batch: 120; loss: 0.1; acc: 0.98
Batch: 140; loss: 0.1; acc: 0.97
Batch: 160; loss: 0.08; acc: 0.97
Batch: 180; loss: 0.15; acc: 0.95
Batch: 200; loss: 0.16; acc: 0.95
Batch: 220; loss: 0.11; acc: 0.97
Batch: 240; loss: 0.08; acc: 0.98
Batch: 260; loss: 0.15; acc: 0.95
Batch: 280; loss: 0.28; acc: 0.91
Batch: 300; loss: 0.16; acc: 0.95
Batch: 320; loss: 0.04; acc: 0.98
Batch: 340; loss: 0.33; acc: 0.91
Batch: 360; loss: 0.08; acc: 0.95
Batch: 380; loss: 0.21; acc: 0.94
Batch: 400; loss: 0.1; acc: 0.97
Batch: 420; loss: 0.23; acc: 0.97
Batch: 440; loss: 0.06; acc: 0.98
Batch: 460; loss: 0.2; acc: 0.92
Batch: 480; loss: 0.11; acc: 0.94
Batch: 500; loss: 0.21; acc: 0.91
Batch: 520; loss: 0.4; acc: 0.94
Batch: 540; loss: 0.26; acc: 0.92
Batch: 560; loss: 0.12; acc: 0.94
Batch: 580; loss: 0.05; acc: 0.98
Batch: 600; loss: 0.1; acc: 0.97
Batch: 620; loss: 0.06; acc: 0.98
Batch: 640; loss: 0.34; acc: 0.92
Batch: 660; loss: 0.13; acc: 0.97
Batch: 680; loss: 0.19; acc: 0.95
Batch: 700; loss: 0.05; acc: 0.98
Batch: 720; loss: 0.1; acc: 0.97
Batch: 740; loss: 0.07; acc: 0.97
Batch: 760; loss: 0.18; acc: 0.95
Batch: 780; loss: 0.3; acc: 0.92
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.858570405805949e-05
9.548246453050524e-06
Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.12; acc: 0.97
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.1; acc: 0.98
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.18; acc: 0.97
Batch: 120; loss: 0.31; acc: 0.83
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.13773749856527445; val_accuracy: 0.9586982484076433 

The current subspace-distance is: 9.548246453050524e-06 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.06; acc: 1.0
Batch: 20; loss: 0.11; acc: 0.94
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.08; acc: 0.97
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.09; acc: 0.98
Batch: 140; loss: 0.12; acc: 0.95
Batch: 160; loss: 0.13; acc: 0.97
Batch: 180; loss: 0.13; acc: 0.95
Batch: 200; loss: 0.26; acc: 0.94
Batch: 220; loss: 0.16; acc: 0.94
Batch: 240; loss: 0.19; acc: 0.94
Batch: 260; loss: 0.33; acc: 0.94
Batch: 280; loss: 0.12; acc: 0.97
Batch: 300; loss: 0.11; acc: 0.97
Batch: 320; loss: 0.1; acc: 0.97
Batch: 340; loss: 0.07; acc: 0.98
Batch: 360; loss: 0.23; acc: 0.89
Batch: 380; loss: 0.11; acc: 0.95
Batch: 400; loss: 0.36; acc: 0.88
Batch: 420; loss: 0.1; acc: 0.97
Batch: 440; loss: 0.19; acc: 0.92
Batch: 460; loss: 0.11; acc: 0.98
Batch: 480; loss: 0.13; acc: 0.95
Batch: 500; loss: 0.14; acc: 0.95
Batch: 520; loss: 0.22; acc: 0.94
Batch: 540; loss: 0.18; acc: 0.94
Batch: 560; loss: 0.44; acc: 0.91
Batch: 580; loss: 0.18; acc: 0.97
Batch: 600; loss: 0.09; acc: 0.98
Batch: 620; loss: 0.18; acc: 0.97
Batch: 640; loss: 0.06; acc: 1.0
Batch: 660; loss: 0.05; acc: 0.98
Batch: 680; loss: 0.11; acc: 0.97
Batch: 700; loss: 0.14; acc: 0.95
Batch: 720; loss: 0.07; acc: 0.97
Batch: 740; loss: 0.11; acc: 0.94
Batch: 760; loss: 0.11; acc: 0.97
Batch: 780; loss: 0.18; acc: 0.91
Train Epoch over. train_loss: 0.15; train_accuracy: 0.96 

2.8635669877985492e-05
9.23380230233306e-06
Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.12; acc: 0.98
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.1; acc: 0.98
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.19; acc: 0.97
Batch: 120; loss: 0.3; acc: 0.84
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.13789759403106513; val_accuracy: 0.9583996815286624 

The current subspace-distance is: 9.23380230233306e-06 

plots/subspace_training/reg_lenet_3/2020-01-22 20:51:04/d_dim_250_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
nonzero elements in E: 63428
elements in E: 13497000
fraction nonzero: 0.004699414684744758
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.31; acc: 0.08
Batch: 20; loss: 2.29; acc: 0.06
Batch: 40; loss: 2.3; acc: 0.11
Batch: 60; loss: 2.3; acc: 0.03
Batch: 80; loss: 2.3; acc: 0.08
Batch: 100; loss: 2.3; acc: 0.16
Batch: 120; loss: 2.3; acc: 0.12
Batch: 140; loss: 2.31; acc: 0.08
Batch: 160; loss: 2.3; acc: 0.09
Batch: 180; loss: 2.3; acc: 0.16
Batch: 200; loss: 2.29; acc: 0.14
Batch: 220; loss: 2.3; acc: 0.14
Batch: 240; loss: 2.3; acc: 0.09
Batch: 260; loss: 2.29; acc: 0.14
Batch: 280; loss: 2.28; acc: 0.19
Batch: 300; loss: 2.27; acc: 0.2
Batch: 320; loss: 2.27; acc: 0.16
Batch: 340; loss: 2.27; acc: 0.17
Batch: 360; loss: 2.26; acc: 0.23
Batch: 380; loss: 2.25; acc: 0.2
Batch: 400; loss: 2.24; acc: 0.3
Batch: 420; loss: 2.25; acc: 0.16
Batch: 440; loss: 2.17; acc: 0.38
Batch: 460; loss: 2.12; acc: 0.25
Batch: 480; loss: 2.0; acc: 0.42
Batch: 500; loss: 1.79; acc: 0.53
Batch: 520; loss: 1.58; acc: 0.48
Batch: 540; loss: 1.6; acc: 0.53
Batch: 560; loss: 1.02; acc: 0.66
Batch: 580; loss: 1.44; acc: 0.5
Batch: 600; loss: 0.84; acc: 0.72
Batch: 620; loss: 1.02; acc: 0.62
Batch: 640; loss: 0.95; acc: 0.67
Batch: 660; loss: 0.79; acc: 0.78
Batch: 680; loss: 1.01; acc: 0.61
Batch: 700; loss: 0.89; acc: 0.67
Batch: 720; loss: 0.43; acc: 0.86
Batch: 740; loss: 0.95; acc: 0.7
Batch: 760; loss: 0.83; acc: 0.75
Batch: 780; loss: 0.7; acc: 0.77
Train Epoch over. train_loss: 1.82; train_accuracy: 0.35 

1.105563023884315e-05
5.1544620873755775e-06
Batch: 0; loss: 0.64; acc: 0.78
Batch: 20; loss: 0.93; acc: 0.72
Batch: 40; loss: 0.38; acc: 0.86
Batch: 60; loss: 0.86; acc: 0.78
Batch: 80; loss: 0.5; acc: 0.86
Batch: 100; loss: 0.53; acc: 0.88
Batch: 120; loss: 1.17; acc: 0.64
Batch: 140; loss: 0.58; acc: 0.75
Val Epoch over. val_loss: 0.6390604862741603; val_accuracy: 0.7899084394904459 

The current subspace-distance is: 5.1544620873755775e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 0.7; acc: 0.72
Batch: 20; loss: 1.08; acc: 0.62
Batch: 40; loss: 0.53; acc: 0.8
Batch: 60; loss: 0.73; acc: 0.72
Batch: 80; loss: 0.57; acc: 0.91
Batch: 100; loss: 0.3; acc: 0.89
Batch: 120; loss: 0.67; acc: 0.8
Batch: 140; loss: 0.5; acc: 0.84
Batch: 160; loss: 0.55; acc: 0.84
Batch: 180; loss: 0.41; acc: 0.84
Batch: 200; loss: 0.5; acc: 0.86
Batch: 220; loss: 0.9; acc: 0.78
Batch: 240; loss: 0.43; acc: 0.92
Batch: 260; loss: 0.54; acc: 0.83
Batch: 280; loss: 0.4; acc: 0.89
Batch: 300; loss: 0.39; acc: 0.91
Batch: 320; loss: 0.5; acc: 0.84
Batch: 340; loss: 0.72; acc: 0.77
Batch: 360; loss: 0.4; acc: 0.89
Batch: 380; loss: 0.25; acc: 0.95
Batch: 400; loss: 0.36; acc: 0.91
Batch: 420; loss: 0.55; acc: 0.83
Batch: 440; loss: 0.62; acc: 0.78
Batch: 460; loss: 0.6; acc: 0.84
Batch: 480; loss: 0.32; acc: 0.89
Batch: 500; loss: 0.67; acc: 0.84
Batch: 520; loss: 0.22; acc: 0.94
Batch: 540; loss: 0.34; acc: 0.89
Batch: 560; loss: 0.36; acc: 0.89
Batch: 580; loss: 0.38; acc: 0.88
Batch: 600; loss: 0.34; acc: 0.91
Batch: 620; loss: 0.29; acc: 0.91
Batch: 640; loss: 0.53; acc: 0.81
Batch: 660; loss: 0.57; acc: 0.8
Batch: 680; loss: 0.44; acc: 0.89
Batch: 700; loss: 0.37; acc: 0.83
Batch: 720; loss: 0.67; acc: 0.81
Batch: 740; loss: 0.59; acc: 0.91
Batch: 760; loss: 0.49; acc: 0.88
Batch: 780; loss: 0.39; acc: 0.8
Train Epoch over. train_loss: 0.49; train_accuracy: 0.85 

1.9225955838919617e-05
5.447249805001775e-06
Batch: 0; loss: 0.93; acc: 0.72
Batch: 20; loss: 1.42; acc: 0.66
Batch: 40; loss: 0.44; acc: 0.83
Batch: 60; loss: 1.18; acc: 0.72
Batch: 80; loss: 0.72; acc: 0.8
Batch: 100; loss: 0.58; acc: 0.88
Batch: 120; loss: 1.15; acc: 0.69
Batch: 140; loss: 0.64; acc: 0.72
Val Epoch over. val_loss: 0.676419269696922; val_accuracy: 0.7875199044585988 

The current subspace-distance is: 5.447249805001775e-06 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.81; acc: 0.78
Batch: 20; loss: 0.33; acc: 0.92
Batch: 40; loss: 0.3; acc: 0.91
Batch: 60; loss: 0.43; acc: 0.86
Batch: 80; loss: 0.54; acc: 0.78
Batch: 100; loss: 0.59; acc: 0.81
Batch: 120; loss: 0.38; acc: 0.89
Batch: 140; loss: 0.48; acc: 0.86
Batch: 160; loss: 0.38; acc: 0.89
Batch: 180; loss: 0.45; acc: 0.91
Batch: 200; loss: 0.41; acc: 0.86
Batch: 220; loss: 0.41; acc: 0.86
Batch: 240; loss: 0.65; acc: 0.83
Batch: 260; loss: 0.45; acc: 0.88
Batch: 280; loss: 0.18; acc: 0.92
Batch: 300; loss: 0.22; acc: 0.95
Batch: 320; loss: 0.31; acc: 0.94
Batch: 340; loss: 0.22; acc: 0.95
Batch: 360; loss: 0.31; acc: 0.94
Batch: 380; loss: 0.34; acc: 0.94
Batch: 400; loss: 0.25; acc: 0.91
Batch: 420; loss: 0.37; acc: 0.88
Batch: 440; loss: 0.29; acc: 0.88
Batch: 460; loss: 0.41; acc: 0.84
Batch: 480; loss: 0.61; acc: 0.77
Batch: 500; loss: 0.45; acc: 0.8
Batch: 520; loss: 0.3; acc: 0.89
Batch: 540; loss: 0.27; acc: 0.91
Batch: 560; loss: 0.32; acc: 0.92
Batch: 580; loss: 0.39; acc: 0.84
Batch: 600; loss: 0.21; acc: 0.94
Batch: 620; loss: 0.49; acc: 0.81
Batch: 640; loss: 0.28; acc: 0.89
Batch: 660; loss: 0.33; acc: 0.91
Batch: 680; loss: 0.35; acc: 0.88
Batch: 700; loss: 0.25; acc: 0.91
Batch: 720; loss: 0.22; acc: 0.92
Batch: 740; loss: 0.29; acc: 0.94
Batch: 760; loss: 0.23; acc: 0.92
Batch: 780; loss: 0.19; acc: 0.92
Train Epoch over. train_loss: 0.34; train_accuracy: 0.89 

2.1288211428327486e-05
6.688606845273171e-06
Batch: 0; loss: 0.4; acc: 0.86
Batch: 20; loss: 0.64; acc: 0.8
Batch: 40; loss: 0.21; acc: 0.92
Batch: 60; loss: 0.86; acc: 0.8
Batch: 80; loss: 0.37; acc: 0.88
Batch: 100; loss: 0.53; acc: 0.86
Batch: 120; loss: 0.59; acc: 0.84
Batch: 140; loss: 0.19; acc: 0.94
Val Epoch over. val_loss: 0.4890279367471197; val_accuracy: 0.8518113057324841 

The current subspace-distance is: 6.688606845273171e-06 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.74; acc: 0.83
Batch: 20; loss: 0.48; acc: 0.88
Batch: 40; loss: 0.27; acc: 0.92
Batch: 60; loss: 0.2; acc: 0.97
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.2; acc: 0.95
Batch: 140; loss: 0.23; acc: 0.94
Batch: 160; loss: 0.42; acc: 0.86
Batch: 180; loss: 0.5; acc: 0.84
Batch: 200; loss: 0.18; acc: 0.95
Batch: 220; loss: 0.53; acc: 0.88
Batch: 240; loss: 0.41; acc: 0.91
Batch: 260; loss: 0.18; acc: 0.94
Batch: 280; loss: 0.39; acc: 0.92
Batch: 300; loss: 0.34; acc: 0.89
Batch: 320; loss: 0.4; acc: 0.88
Batch: 340; loss: 0.24; acc: 0.92
Batch: 360; loss: 0.17; acc: 0.94
Batch: 380; loss: 0.16; acc: 0.94
Batch: 400; loss: 0.35; acc: 0.84
Batch: 420; loss: 0.38; acc: 0.89
Batch: 440; loss: 0.28; acc: 0.92
Batch: 460; loss: 0.14; acc: 0.95
Batch: 480; loss: 0.37; acc: 0.91
Batch: 500; loss: 0.34; acc: 0.86
Batch: 520; loss: 0.24; acc: 0.91
Batch: 540; loss: 0.32; acc: 0.89
Batch: 560; loss: 0.42; acc: 0.86
Batch: 580; loss: 0.31; acc: 0.89
Batch: 600; loss: 0.29; acc: 0.94
Batch: 620; loss: 0.29; acc: 0.89
Batch: 640; loss: 0.43; acc: 0.91
Batch: 660; loss: 0.52; acc: 0.88
Batch: 680; loss: 0.26; acc: 0.89
Batch: 700; loss: 0.14; acc: 0.97
Batch: 720; loss: 0.42; acc: 0.88
Batch: 740; loss: 0.3; acc: 0.92
Batch: 760; loss: 0.21; acc: 0.95
Batch: 780; loss: 0.12; acc: 0.95
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.2075231754570268e-05
7.648923201486468e-06
Batch: 0; loss: 0.59; acc: 0.8
Batch: 20; loss: 1.09; acc: 0.66
Batch: 40; loss: 0.46; acc: 0.86
Batch: 60; loss: 1.09; acc: 0.72
Batch: 80; loss: 0.62; acc: 0.78
Batch: 100; loss: 0.72; acc: 0.78
Batch: 120; loss: 0.91; acc: 0.78
Batch: 140; loss: 0.4; acc: 0.83
Val Epoch over. val_loss: 0.8212638267665912; val_accuracy: 0.7566679936305732 

The current subspace-distance is: 7.648923201486468e-06 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.83; acc: 0.78
Batch: 20; loss: 0.26; acc: 0.94
Batch: 40; loss: 0.43; acc: 0.88
Batch: 60; loss: 0.35; acc: 0.91
Batch: 80; loss: 0.37; acc: 0.92
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.22; acc: 0.92
Batch: 140; loss: 0.33; acc: 0.89
Batch: 160; loss: 0.18; acc: 0.95
Batch: 180; loss: 0.12; acc: 0.98
Batch: 200; loss: 0.21; acc: 0.91
Batch: 220; loss: 0.34; acc: 0.94
Batch: 240; loss: 0.27; acc: 0.94
Batch: 260; loss: 0.19; acc: 0.89
Batch: 280; loss: 0.21; acc: 0.92
Batch: 300; loss: 0.16; acc: 0.94
Batch: 320; loss: 0.15; acc: 0.98
Batch: 340; loss: 0.12; acc: 0.97
Batch: 360; loss: 0.31; acc: 0.91
Batch: 380; loss: 0.12; acc: 0.95
Batch: 400; loss: 0.3; acc: 0.94
Batch: 420; loss: 0.26; acc: 0.92
Batch: 440; loss: 0.17; acc: 0.94
Batch: 460; loss: 0.24; acc: 0.91
Batch: 480; loss: 0.31; acc: 0.89
Batch: 500; loss: 0.15; acc: 0.92
Batch: 520; loss: 0.1; acc: 0.97
Batch: 540; loss: 0.19; acc: 0.92
Batch: 560; loss: 0.31; acc: 0.89
Batch: 580; loss: 0.34; acc: 0.91
Batch: 600; loss: 0.18; acc: 0.94
Batch: 620; loss: 0.23; acc: 0.91
Batch: 640; loss: 0.15; acc: 0.97
Batch: 660; loss: 0.6; acc: 0.81
Batch: 680; loss: 0.28; acc: 0.89
Batch: 700; loss: 0.24; acc: 0.91
Batch: 720; loss: 0.23; acc: 0.94
Batch: 740; loss: 0.16; acc: 0.97
Batch: 760; loss: 0.23; acc: 0.94
Batch: 780; loss: 0.15; acc: 0.94
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.3442877136403695e-05
7.273552910191938e-06
Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.41; acc: 0.89
Batch: 40; loss: 0.1; acc: 0.98
Batch: 60; loss: 0.39; acc: 0.92
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.38; acc: 0.91
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2550749838542027; val_accuracy: 0.9221735668789809 

The current subspace-distance is: 7.273552910191938e-06 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.3; acc: 0.88
Batch: 20; loss: 0.17; acc: 0.94
Batch: 40; loss: 0.22; acc: 0.92
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.2; acc: 0.92
Batch: 140; loss: 0.38; acc: 0.89
Batch: 160; loss: 0.31; acc: 0.92
Batch: 180; loss: 0.16; acc: 0.95
Batch: 200; loss: 0.23; acc: 0.91
Batch: 220; loss: 0.09; acc: 0.97
Batch: 240; loss: 0.34; acc: 0.94
Batch: 260; loss: 0.32; acc: 0.92
Batch: 280; loss: 0.15; acc: 0.94
Batch: 300; loss: 0.3; acc: 0.94
Batch: 320; loss: 0.26; acc: 0.88
Batch: 340; loss: 0.19; acc: 0.97
Batch: 360; loss: 0.42; acc: 0.84
Batch: 380; loss: 0.5; acc: 0.84
Batch: 400; loss: 0.12; acc: 0.95
Batch: 420; loss: 0.25; acc: 0.91
Batch: 440; loss: 0.2; acc: 0.94
Batch: 460; loss: 0.13; acc: 0.98
Batch: 480; loss: 0.17; acc: 0.95
Batch: 500; loss: 0.35; acc: 0.91
Batch: 520; loss: 0.22; acc: 0.94
Batch: 540; loss: 0.15; acc: 0.94
Batch: 560; loss: 0.22; acc: 0.94
Batch: 580; loss: 0.19; acc: 0.92
Batch: 600; loss: 0.16; acc: 0.95
Batch: 620; loss: 0.26; acc: 0.89
Batch: 640; loss: 0.19; acc: 0.94
Batch: 660; loss: 0.61; acc: 0.84
Batch: 680; loss: 0.1; acc: 0.97
Batch: 700; loss: 0.15; acc: 0.95
Batch: 720; loss: 0.56; acc: 0.84
Batch: 740; loss: 0.23; acc: 0.91
Batch: 760; loss: 0.28; acc: 0.91
Batch: 780; loss: 0.17; acc: 0.95
Train Epoch over. train_loss: 0.24; train_accuracy: 0.92 

2.470203980919905e-05
7.796669706294779e-06
Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.4; acc: 0.92
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.29; acc: 0.92
Batch: 140; loss: 0.08; acc: 0.97
Val Epoch over. val_loss: 0.25366168583084825; val_accuracy: 0.9250597133757962 

The current subspace-distance is: 7.796669706294779e-06 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.38; acc: 0.91
Batch: 20; loss: 0.11; acc: 0.94
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.2; acc: 0.92
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.18; acc: 0.95
Batch: 140; loss: 0.24; acc: 0.94
Batch: 160; loss: 0.31; acc: 0.86
Batch: 180; loss: 0.29; acc: 0.89
Batch: 200; loss: 0.39; acc: 0.88
Batch: 220; loss: 0.29; acc: 0.91
Batch: 240; loss: 0.23; acc: 0.88
Batch: 260; loss: 0.25; acc: 0.91
Batch: 280; loss: 0.16; acc: 0.95
Batch: 300; loss: 0.17; acc: 0.97
Batch: 320; loss: 0.12; acc: 0.95
Batch: 340; loss: 0.13; acc: 0.95
Batch: 360; loss: 0.31; acc: 0.91
Batch: 380; loss: 0.19; acc: 0.95
Batch: 400; loss: 0.13; acc: 0.94
Batch: 420; loss: 0.35; acc: 0.86
Batch: 440; loss: 0.45; acc: 0.86
Batch: 460; loss: 0.06; acc: 0.98
Batch: 480; loss: 0.13; acc: 0.95
Batch: 500; loss: 0.11; acc: 0.95
Batch: 520; loss: 0.12; acc: 0.94
Batch: 540; loss: 0.17; acc: 0.91
Batch: 560; loss: 0.16; acc: 0.95
Batch: 580; loss: 0.15; acc: 0.95
Batch: 600; loss: 0.1; acc: 0.94
Batch: 620; loss: 0.17; acc: 0.97
Batch: 640; loss: 0.44; acc: 0.91
Batch: 660; loss: 0.13; acc: 0.97
Batch: 680; loss: 0.21; acc: 0.94
Batch: 700; loss: 0.14; acc: 0.95
Batch: 720; loss: 0.27; acc: 0.92
Batch: 740; loss: 0.18; acc: 0.91
Batch: 760; loss: 0.18; acc: 0.95
Batch: 780; loss: 0.16; acc: 0.95
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.430431413813494e-05
7.959089089126792e-06
Batch: 0; loss: 0.13; acc: 0.94
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.52; acc: 0.86
Batch: 80; loss: 0.22; acc: 0.97
Batch: 100; loss: 0.31; acc: 0.88
Batch: 120; loss: 0.39; acc: 0.89
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.26372948772968; val_accuracy: 0.9217754777070064 

The current subspace-distance is: 7.959089089126792e-06 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.43; acc: 0.88
Batch: 20; loss: 0.06; acc: 0.97
Batch: 40; loss: 0.08; acc: 1.0
Batch: 60; loss: 0.24; acc: 0.92
Batch: 80; loss: 0.3; acc: 0.88
Batch: 100; loss: 0.1; acc: 0.98
Batch: 120; loss: 0.18; acc: 0.95
Batch: 140; loss: 0.17; acc: 0.92
Batch: 160; loss: 0.12; acc: 0.97
Batch: 180; loss: 0.09; acc: 0.95
Batch: 200; loss: 0.15; acc: 0.95
Batch: 220; loss: 0.35; acc: 0.91
Batch: 240; loss: 0.17; acc: 0.92
Batch: 260; loss: 0.16; acc: 0.97
Batch: 280; loss: 0.38; acc: 0.86
Batch: 300; loss: 0.18; acc: 0.94
Batch: 320; loss: 0.35; acc: 0.89
Batch: 340; loss: 0.22; acc: 0.92
Batch: 360; loss: 0.1; acc: 0.97
Batch: 380; loss: 0.05; acc: 0.98
Batch: 400; loss: 0.21; acc: 0.94
Batch: 420; loss: 0.17; acc: 0.94
Batch: 440; loss: 0.31; acc: 0.91
Batch: 460; loss: 0.21; acc: 0.94
Batch: 480; loss: 0.07; acc: 1.0
Batch: 500; loss: 0.21; acc: 0.94
Batch: 520; loss: 0.44; acc: 0.89
Batch: 540; loss: 0.25; acc: 0.92
Batch: 560; loss: 0.06; acc: 0.98
Batch: 580; loss: 0.19; acc: 0.95
Batch: 600; loss: 0.26; acc: 0.89
Batch: 620; loss: 0.22; acc: 0.92
Batch: 640; loss: 0.05; acc: 0.98
Batch: 660; loss: 0.25; acc: 0.95
Batch: 680; loss: 0.12; acc: 0.98
Batch: 700; loss: 0.24; acc: 0.91
Batch: 720; loss: 0.13; acc: 0.94
Batch: 740; loss: 0.24; acc: 0.94
Batch: 760; loss: 0.08; acc: 0.98
Batch: 780; loss: 0.21; acc: 0.92
Train Epoch over. train_loss: 0.21; train_accuracy: 0.93 

2.61541863437742e-05
8.283829629363026e-06
Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.34; acc: 0.89
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.37; acc: 0.89
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.28; acc: 0.91
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.21370570420934137; val_accuracy: 0.9351114649681529 

The current subspace-distance is: 8.283829629363026e-06 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.45; acc: 0.84
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.2; acc: 0.92
Batch: 60; loss: 0.43; acc: 0.91
Batch: 80; loss: 0.36; acc: 0.91
Batch: 100; loss: 0.08; acc: 0.97
Batch: 120; loss: 0.19; acc: 0.94
Batch: 140; loss: 0.19; acc: 0.92
Batch: 160; loss: 0.36; acc: 0.89
Batch: 180; loss: 0.3; acc: 0.91
Batch: 200; loss: 0.19; acc: 0.94
Batch: 220; loss: 0.25; acc: 0.91
Batch: 240; loss: 0.13; acc: 0.95
Batch: 260; loss: 0.17; acc: 0.94
Batch: 280; loss: 0.08; acc: 0.97
Batch: 300; loss: 0.15; acc: 0.95
Batch: 320; loss: 0.11; acc: 0.95
Batch: 340; loss: 0.14; acc: 0.95
Batch: 360; loss: 0.21; acc: 0.92
Batch: 380; loss: 0.12; acc: 0.95
Batch: 400; loss: 0.14; acc: 0.97
Batch: 420; loss: 0.33; acc: 0.89
Batch: 440; loss: 0.22; acc: 0.92
Batch: 460; loss: 0.13; acc: 0.97
Batch: 480; loss: 0.32; acc: 0.92
Batch: 500; loss: 0.22; acc: 0.95
Batch: 520; loss: 0.32; acc: 0.91
Batch: 540; loss: 0.22; acc: 0.92
Batch: 560; loss: 0.21; acc: 0.92
Batch: 580; loss: 0.15; acc: 0.95
Batch: 600; loss: 0.22; acc: 0.94
Batch: 620; loss: 0.21; acc: 0.94
Batch: 640; loss: 0.3; acc: 0.91
Batch: 660; loss: 0.2; acc: 0.91
Batch: 680; loss: 0.36; acc: 0.91
Batch: 700; loss: 0.24; acc: 0.86
Batch: 720; loss: 0.07; acc: 0.97
Batch: 740; loss: 0.25; acc: 0.95
Batch: 760; loss: 0.18; acc: 0.91
Batch: 780; loss: 0.18; acc: 0.98
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

2.659249003045261e-05
8.353607881872449e-06
Batch: 0; loss: 0.04; acc: 1.0
Batch: 20; loss: 0.23; acc: 0.94
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.39; acc: 0.88
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.36; acc: 0.86
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.18178069133572516; val_accuracy: 0.9442675159235668 

The current subspace-distance is: 8.353607881872449e-06 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.19; acc: 0.92
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.29; acc: 0.88
Batch: 60; loss: 0.13; acc: 0.94
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.32; acc: 0.86
Batch: 140; loss: 0.2; acc: 0.92
Batch: 160; loss: 0.08; acc: 0.95
Batch: 180; loss: 0.14; acc: 0.94
Batch: 200; loss: 0.26; acc: 0.94
Batch: 220; loss: 0.36; acc: 0.84
Batch: 240; loss: 0.15; acc: 0.94
Batch: 260; loss: 0.26; acc: 0.92
Batch: 280; loss: 0.18; acc: 0.92
Batch: 300; loss: 0.03; acc: 1.0
Batch: 320; loss: 0.2; acc: 0.94
Batch: 340; loss: 0.18; acc: 0.95
Batch: 360; loss: 0.17; acc: 0.94
Batch: 380; loss: 0.13; acc: 0.97
Batch: 400; loss: 0.08; acc: 0.97
Batch: 420; loss: 0.25; acc: 0.94
Batch: 440; loss: 0.09; acc: 0.95
Batch: 460; loss: 0.15; acc: 0.97
Batch: 480; loss: 0.11; acc: 0.95
Batch: 500; loss: 0.12; acc: 0.95
Batch: 520; loss: 0.15; acc: 0.97
Batch: 540; loss: 0.12; acc: 0.97
Batch: 560; loss: 0.19; acc: 0.98
Batch: 580; loss: 0.18; acc: 0.95
Batch: 600; loss: 0.07; acc: 0.98
Batch: 620; loss: 0.46; acc: 0.89
Batch: 640; loss: 0.21; acc: 0.94
Batch: 660; loss: 0.28; acc: 0.91
Batch: 680; loss: 0.18; acc: 0.95
Batch: 700; loss: 0.21; acc: 0.94
Batch: 720; loss: 0.31; acc: 0.88
Batch: 740; loss: 0.31; acc: 0.94
Batch: 760; loss: 0.11; acc: 0.95
Batch: 780; loss: 0.26; acc: 0.91
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

2.5983081286540255e-05
7.37785512683331e-06
Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.2; acc: 0.95
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.38; acc: 0.91
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.2; acc: 0.92
Batch: 120; loss: 0.29; acc: 0.94
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.17759210163146066; val_accuracy: 0.946656050955414 

The current subspace-distance is: 7.37785512683331e-06 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.19; acc: 0.95
Batch: 20; loss: 0.14; acc: 0.94
Batch: 40; loss: 0.18; acc: 0.97
Batch: 60; loss: 0.14; acc: 0.94
Batch: 80; loss: 0.03; acc: 1.0
Batch: 100; loss: 0.22; acc: 0.92
Batch: 120; loss: 0.17; acc: 0.95
Batch: 140; loss: 0.21; acc: 0.95
Batch: 160; loss: 0.09; acc: 0.98
Batch: 180; loss: 0.17; acc: 0.92
Batch: 200; loss: 0.33; acc: 0.92
Batch: 220; loss: 0.14; acc: 0.95
Batch: 240; loss: 0.19; acc: 0.94
Batch: 260; loss: 0.08; acc: 1.0
Batch: 280; loss: 0.12; acc: 0.95
Batch: 300; loss: 0.07; acc: 0.97
Batch: 320; loss: 0.33; acc: 0.91
Batch: 340; loss: 0.23; acc: 0.92
Batch: 360; loss: 0.24; acc: 0.94
Batch: 380; loss: 0.19; acc: 0.94
Batch: 400; loss: 0.17; acc: 0.94
Batch: 420; loss: 0.08; acc: 0.98
Batch: 440; loss: 0.16; acc: 0.92
Batch: 460; loss: 0.08; acc: 0.97
Batch: 480; loss: 0.2; acc: 0.92
Batch: 500; loss: 0.12; acc: 0.97
Batch: 520; loss: 0.19; acc: 0.89
Batch: 540; loss: 0.15; acc: 0.94
Batch: 560; loss: 0.18; acc: 0.92
Batch: 580; loss: 0.07; acc: 0.98
Batch: 600; loss: 0.18; acc: 0.95
Batch: 620; loss: 0.28; acc: 0.92
Batch: 640; loss: 0.11; acc: 0.94
Batch: 660; loss: 0.15; acc: 0.94
Batch: 680; loss: 0.43; acc: 0.91
Batch: 700; loss: 0.09; acc: 0.97
Batch: 720; loss: 0.07; acc: 0.97
Batch: 740; loss: 0.08; acc: 0.98
Batch: 760; loss: 0.12; acc: 0.97
Batch: 780; loss: 0.1; acc: 0.95
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

2.6300027457182296e-05
8.192148015950806e-06
Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.27; acc: 0.94
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.15; acc: 0.94
Batch: 120; loss: 0.33; acc: 0.88
Batch: 140; loss: 0.02; acc: 0.98
Val Epoch over. val_loss: 0.15200513473172098; val_accuracy: 0.9541202229299363 

The current subspace-distance is: 8.192148015950806e-06 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.11; acc: 0.95
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.21; acc: 0.94
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.07; acc: 1.0
Batch: 140; loss: 0.16; acc: 0.97
Batch: 160; loss: 0.13; acc: 0.94
Batch: 180; loss: 0.12; acc: 0.97
Batch: 200; loss: 0.11; acc: 0.98
Batch: 220; loss: 0.2; acc: 0.94
Batch: 240; loss: 0.09; acc: 0.98
Batch: 260; loss: 0.08; acc: 0.95
Batch: 280; loss: 0.06; acc: 0.97
Batch: 300; loss: 0.03; acc: 1.0
Batch: 320; loss: 0.09; acc: 0.97
Batch: 340; loss: 0.18; acc: 0.94
Batch: 360; loss: 0.37; acc: 0.94
Batch: 380; loss: 0.08; acc: 0.98
Batch: 400; loss: 0.04; acc: 1.0
Batch: 420; loss: 0.11; acc: 0.97
Batch: 440; loss: 0.28; acc: 0.94
Batch: 460; loss: 0.18; acc: 0.89
Batch: 480; loss: 0.16; acc: 0.97
Batch: 500; loss: 0.36; acc: 0.89
Batch: 520; loss: 0.21; acc: 0.94
Batch: 540; loss: 0.11; acc: 0.95
Batch: 560; loss: 0.26; acc: 0.95
Batch: 580; loss: 0.14; acc: 0.95
Batch: 600; loss: 0.17; acc: 0.92
Batch: 620; loss: 0.13; acc: 0.97
Batch: 640; loss: 0.12; acc: 0.97
Batch: 660; loss: 0.1; acc: 0.94
Batch: 680; loss: 0.12; acc: 0.98
Batch: 700; loss: 0.08; acc: 0.97
Batch: 720; loss: 0.11; acc: 0.97
Batch: 740; loss: 0.16; acc: 0.94
Batch: 760; loss: 0.2; acc: 0.94
Batch: 780; loss: 0.1; acc: 0.97
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

2.6887610147241503e-05
8.09142966318177e-06
Batch: 0; loss: 0.05; acc: 0.98
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.39; acc: 0.91
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.28; acc: 0.91
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.18399735566252357; val_accuracy: 0.9444665605095541 

The current subspace-distance is: 8.09142966318177e-06 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.11; acc: 0.95
Batch: 20; loss: 0.17; acc: 0.92
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.1; acc: 0.98
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.09; acc: 0.95
Batch: 120; loss: 0.22; acc: 0.94
Batch: 140; loss: 0.14; acc: 0.95
Batch: 160; loss: 0.22; acc: 0.95
Batch: 180; loss: 0.23; acc: 0.95
Batch: 200; loss: 0.19; acc: 0.97
Batch: 220; loss: 0.04; acc: 1.0
Batch: 240; loss: 0.06; acc: 1.0
Batch: 260; loss: 0.06; acc: 0.97
Batch: 280; loss: 0.19; acc: 0.95
Batch: 300; loss: 0.08; acc: 0.98
Batch: 320; loss: 0.14; acc: 0.95
Batch: 340; loss: 0.05; acc: 0.98
Batch: 360; loss: 0.13; acc: 0.97
Batch: 380; loss: 0.13; acc: 0.94
Batch: 400; loss: 0.09; acc: 0.95
Batch: 420; loss: 0.12; acc: 0.95
Batch: 440; loss: 0.19; acc: 0.95
Batch: 460; loss: 0.13; acc: 0.95
Batch: 480; loss: 0.11; acc: 0.97
Batch: 500; loss: 0.04; acc: 0.98
Batch: 520; loss: 0.13; acc: 0.95
Batch: 540; loss: 0.2; acc: 0.92
Batch: 560; loss: 0.08; acc: 0.98
Batch: 580; loss: 0.13; acc: 0.97
Batch: 600; loss: 0.24; acc: 0.95
Batch: 620; loss: 0.12; acc: 0.95
Batch: 640; loss: 0.1; acc: 0.97
Batch: 660; loss: 0.28; acc: 0.94
Batch: 680; loss: 0.12; acc: 0.95
Batch: 700; loss: 0.11; acc: 0.95
Batch: 720; loss: 0.07; acc: 0.97
Batch: 740; loss: 0.16; acc: 0.94
Batch: 760; loss: 0.28; acc: 0.94
Batch: 780; loss: 0.14; acc: 0.94
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

2.656308060977608e-05
8.552374310966115e-06
Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.18; acc: 0.95
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.28; acc: 0.92
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.15; acc: 0.92
Batch: 120; loss: 0.3; acc: 0.86
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1471231467072751; val_accuracy: 0.9571058917197452 

The current subspace-distance is: 8.552374310966115e-06 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.11; acc: 0.98
Batch: 20; loss: 0.16; acc: 0.94
Batch: 40; loss: 0.14; acc: 0.94
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.23; acc: 0.95
Batch: 140; loss: 0.25; acc: 0.92
Batch: 160; loss: 0.31; acc: 0.91
Batch: 180; loss: 0.05; acc: 1.0
Batch: 200; loss: 0.17; acc: 0.94
Batch: 220; loss: 0.16; acc: 0.94
Batch: 240; loss: 0.09; acc: 0.98
Batch: 260; loss: 0.06; acc: 0.97
Batch: 280; loss: 0.07; acc: 0.98
Batch: 300; loss: 0.18; acc: 0.95
Batch: 320; loss: 0.08; acc: 0.98
Batch: 340; loss: 0.2; acc: 0.92
Batch: 360; loss: 0.13; acc: 0.97
Batch: 380; loss: 0.05; acc: 0.97
Batch: 400; loss: 0.27; acc: 0.92
Batch: 420; loss: 0.11; acc: 0.95
Batch: 440; loss: 0.1; acc: 0.97
Batch: 460; loss: 0.17; acc: 0.94
Batch: 480; loss: 0.1; acc: 0.95
Batch: 500; loss: 0.24; acc: 0.94
Batch: 520; loss: 0.1; acc: 0.95
Batch: 540; loss: 0.11; acc: 0.97
Batch: 560; loss: 0.32; acc: 0.91
Batch: 580; loss: 0.16; acc: 0.94
Batch: 600; loss: 0.16; acc: 0.97
Batch: 620; loss: 0.24; acc: 0.94
Batch: 640; loss: 0.14; acc: 0.95
Batch: 660; loss: 0.28; acc: 0.91
Batch: 680; loss: 0.2; acc: 0.92
Batch: 700; loss: 0.19; acc: 0.95
Batch: 720; loss: 0.14; acc: 0.89
Batch: 740; loss: 0.04; acc: 1.0
Batch: 760; loss: 0.08; acc: 0.97
Batch: 780; loss: 0.19; acc: 0.94
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.6686735509429127e-05
7.571733476652298e-06
Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.05; acc: 0.97
Batch: 60; loss: 0.31; acc: 0.94
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.14; acc: 0.94
Batch: 120; loss: 0.31; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14965542764135986; val_accuracy: 0.9557125796178344 

The current subspace-distance is: 7.571733476652298e-06 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.05; acc: 0.98
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.07; acc: 0.98
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.14; acc: 0.94
Batch: 120; loss: 0.11; acc: 0.97
Batch: 140; loss: 0.11; acc: 0.97
Batch: 160; loss: 0.08; acc: 0.95
Batch: 180; loss: 0.14; acc: 0.92
Batch: 200; loss: 0.18; acc: 0.95
Batch: 220; loss: 0.16; acc: 0.95
Batch: 240; loss: 0.22; acc: 0.92
Batch: 260; loss: 0.2; acc: 0.92
Batch: 280; loss: 0.11; acc: 0.95
Batch: 300; loss: 0.11; acc: 0.97
Batch: 320; loss: 0.32; acc: 0.92
Batch: 340; loss: 0.14; acc: 0.95
Batch: 360; loss: 0.33; acc: 0.92
Batch: 380; loss: 0.18; acc: 0.95
Batch: 400; loss: 0.09; acc: 0.97
Batch: 420; loss: 0.11; acc: 0.94
Batch: 440; loss: 0.09; acc: 0.97
Batch: 460; loss: 0.24; acc: 0.94
Batch: 480; loss: 0.14; acc: 0.97
Batch: 500; loss: 0.14; acc: 0.95
Batch: 520; loss: 0.16; acc: 0.97
Batch: 540; loss: 0.05; acc: 0.98
Batch: 560; loss: 0.13; acc: 0.95
Batch: 580; loss: 0.1; acc: 0.97
Batch: 600; loss: 0.11; acc: 0.95
Batch: 620; loss: 0.09; acc: 0.97
Batch: 640; loss: 0.18; acc: 0.91
Batch: 660; loss: 0.11; acc: 0.95
Batch: 680; loss: 0.14; acc: 0.95
Batch: 700; loss: 0.12; acc: 0.94
Batch: 720; loss: 0.12; acc: 0.97
Batch: 740; loss: 0.08; acc: 0.98
Batch: 760; loss: 0.2; acc: 0.94
Batch: 780; loss: 0.1; acc: 0.97
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.7638363462756388e-05
8.549528502044268e-06
Batch: 0; loss: 0.04; acc: 0.97
Batch: 20; loss: 0.2; acc: 0.97
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.25; acc: 0.95
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.15; acc: 0.94
Batch: 120; loss: 0.32; acc: 0.84
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1481421565886136; val_accuracy: 0.9573049363057324 

The current subspace-distance is: 8.549528502044268e-06 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.08; acc: 0.98
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.32; acc: 0.88
Batch: 140; loss: 0.06; acc: 0.97
Batch: 160; loss: 0.25; acc: 0.92
Batch: 180; loss: 0.36; acc: 0.91
Batch: 200; loss: 0.21; acc: 0.94
Batch: 220; loss: 0.12; acc: 0.95
Batch: 240; loss: 0.06; acc: 0.98
Batch: 260; loss: 0.1; acc: 0.97
Batch: 280; loss: 0.29; acc: 0.94
Batch: 300; loss: 0.07; acc: 0.97
Batch: 320; loss: 0.17; acc: 0.92
Batch: 340; loss: 0.29; acc: 0.92
Batch: 360; loss: 0.06; acc: 1.0
Batch: 380; loss: 0.17; acc: 0.95
Batch: 400; loss: 0.28; acc: 0.91
Batch: 420; loss: 0.21; acc: 0.95
Batch: 440; loss: 0.11; acc: 0.98
Batch: 460; loss: 0.08; acc: 0.97
Batch: 480; loss: 0.16; acc: 0.97
Batch: 500; loss: 0.44; acc: 0.92
Batch: 520; loss: 0.03; acc: 1.0
Batch: 540; loss: 0.06; acc: 0.98
Batch: 560; loss: 0.11; acc: 0.97
Batch: 580; loss: 0.1; acc: 0.98
Batch: 600; loss: 0.19; acc: 0.91
Batch: 620; loss: 0.2; acc: 0.91
Batch: 640; loss: 0.14; acc: 0.94
Batch: 660; loss: 0.05; acc: 1.0
Batch: 680; loss: 0.05; acc: 0.97
Batch: 700; loss: 0.18; acc: 0.94
Batch: 720; loss: 0.1; acc: 0.97
Batch: 740; loss: 0.05; acc: 0.97
Batch: 760; loss: 0.23; acc: 0.97
Batch: 780; loss: 0.16; acc: 0.97
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.6402010917081498e-05
8.175512448360678e-06
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.15; acc: 0.97
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.3; acc: 0.94
Batch: 80; loss: 0.17; acc: 0.97
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.24; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.15915791450697145; val_accuracy: 0.95203025477707 

The current subspace-distance is: 8.175512448360678e-06 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.05; acc: 0.98
Batch: 20; loss: 0.12; acc: 0.98
Batch: 40; loss: 0.31; acc: 0.94
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.22; acc: 0.92
Batch: 100; loss: 0.41; acc: 0.94
Batch: 120; loss: 0.21; acc: 0.94
Batch: 140; loss: 0.06; acc: 1.0
Batch: 160; loss: 0.27; acc: 0.89
Batch: 180; loss: 0.33; acc: 0.88
Batch: 200; loss: 0.25; acc: 0.91
Batch: 220; loss: 0.08; acc: 0.95
Batch: 240; loss: 0.17; acc: 0.88
Batch: 260; loss: 0.1; acc: 0.98
Batch: 280; loss: 0.05; acc: 0.98
Batch: 300; loss: 0.13; acc: 0.97
Batch: 320; loss: 0.08; acc: 0.98
Batch: 340; loss: 0.06; acc: 0.98
Batch: 360; loss: 0.3; acc: 0.89
Batch: 380; loss: 0.18; acc: 0.94
Batch: 400; loss: 0.23; acc: 0.91
Batch: 420; loss: 0.25; acc: 0.95
Batch: 440; loss: 0.18; acc: 0.94
Batch: 460; loss: 0.1; acc: 0.95
Batch: 480; loss: 0.08; acc: 0.98
Batch: 500; loss: 0.13; acc: 0.97
Batch: 520; loss: 0.13; acc: 0.95
Batch: 540; loss: 0.26; acc: 0.94
Batch: 560; loss: 0.25; acc: 0.95
Batch: 580; loss: 0.19; acc: 0.92
Batch: 600; loss: 0.13; acc: 0.94
Batch: 620; loss: 0.15; acc: 0.95
Batch: 640; loss: 0.12; acc: 0.92
Batch: 660; loss: 0.1; acc: 0.97
Batch: 680; loss: 0.07; acc: 0.98
Batch: 700; loss: 0.04; acc: 0.98
Batch: 720; loss: 0.13; acc: 0.98
Batch: 740; loss: 0.17; acc: 0.94
Batch: 760; loss: 0.27; acc: 0.91
Batch: 780; loss: 0.21; acc: 0.91
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.698452772165183e-05
8.934667675930541e-06
Batch: 0; loss: 0.04; acc: 1.0
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.28; acc: 0.92
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.16; acc: 0.94
Batch: 120; loss: 0.27; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14753276271045587; val_accuracy: 0.9555135350318471 

The current subspace-distance is: 8.934667675930541e-06 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.12; acc: 0.92
Batch: 40; loss: 0.27; acc: 0.92
Batch: 60; loss: 0.11; acc: 0.98
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.12; acc: 0.92
Batch: 120; loss: 0.11; acc: 0.95
Batch: 140; loss: 0.3; acc: 0.91
Batch: 160; loss: 0.36; acc: 0.91
Batch: 180; loss: 0.16; acc: 0.95
Batch: 200; loss: 0.18; acc: 0.98
Batch: 220; loss: 0.06; acc: 0.98
Batch: 240; loss: 0.04; acc: 0.98
Batch: 260; loss: 0.19; acc: 0.92
Batch: 280; loss: 0.13; acc: 0.97
Batch: 300; loss: 0.23; acc: 0.95
Batch: 320; loss: 0.16; acc: 0.95
Batch: 340; loss: 0.16; acc: 0.94
Batch: 360; loss: 0.14; acc: 0.97
Batch: 380; loss: 0.08; acc: 0.98
Batch: 400; loss: 0.11; acc: 0.94
Batch: 420; loss: 0.12; acc: 0.97
Batch: 440; loss: 0.24; acc: 0.94
Batch: 460; loss: 0.25; acc: 0.91
Batch: 480; loss: 0.05; acc: 0.98
Batch: 500; loss: 0.08; acc: 0.98
Batch: 520; loss: 0.21; acc: 0.91
Batch: 540; loss: 0.06; acc: 0.98
Batch: 560; loss: 0.25; acc: 0.94
Batch: 580; loss: 0.11; acc: 0.95
Batch: 600; loss: 0.21; acc: 0.95
Batch: 620; loss: 0.14; acc: 0.95
Batch: 640; loss: 0.12; acc: 0.97
Batch: 660; loss: 0.07; acc: 0.97
Batch: 680; loss: 0.05; acc: 0.98
Batch: 700; loss: 0.27; acc: 0.94
Batch: 720; loss: 0.22; acc: 0.95
Batch: 740; loss: 0.14; acc: 0.95
Batch: 760; loss: 0.03; acc: 1.0
Batch: 780; loss: 0.12; acc: 0.97
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.6946221623802558e-05
8.372207048523705e-06
Batch: 0; loss: 0.05; acc: 0.98
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.14; acc: 0.94
Batch: 120; loss: 0.29; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1598585599641891; val_accuracy: 0.9517316878980892 

The current subspace-distance is: 8.372207048523705e-06 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.22; acc: 0.92
Batch: 20; loss: 0.08; acc: 0.98
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.09; acc: 0.98
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.52; acc: 0.86
Batch: 120; loss: 0.03; acc: 1.0
Batch: 140; loss: 0.38; acc: 0.84
Batch: 160; loss: 0.05; acc: 0.98
Batch: 180; loss: 0.25; acc: 0.92
Batch: 200; loss: 0.37; acc: 0.92
Batch: 220; loss: 0.33; acc: 0.94
Batch: 240; loss: 0.19; acc: 0.95
Batch: 260; loss: 0.38; acc: 0.89
Batch: 280; loss: 0.15; acc: 0.94
Batch: 300; loss: 0.19; acc: 0.94
Batch: 320; loss: 0.22; acc: 0.92
Batch: 340; loss: 0.11; acc: 0.97
Batch: 360; loss: 0.17; acc: 0.95
Batch: 380; loss: 0.07; acc: 0.98
Batch: 400; loss: 0.17; acc: 0.91
Batch: 420; loss: 0.07; acc: 0.98
Batch: 440; loss: 0.17; acc: 0.94
Batch: 460; loss: 0.07; acc: 0.97
Batch: 480; loss: 0.17; acc: 0.95
Batch: 500; loss: 0.23; acc: 0.95
Batch: 520; loss: 0.16; acc: 0.92
Batch: 540; loss: 0.11; acc: 0.95
Batch: 560; loss: 0.06; acc: 0.97
Batch: 580; loss: 0.13; acc: 0.97
Batch: 600; loss: 0.04; acc: 0.98
Batch: 620; loss: 0.08; acc: 0.98
Batch: 640; loss: 0.15; acc: 0.94
Batch: 660; loss: 0.03; acc: 0.98
Batch: 680; loss: 0.13; acc: 0.95
Batch: 700; loss: 0.08; acc: 0.97
Batch: 720; loss: 0.18; acc: 0.94
Batch: 740; loss: 0.06; acc: 0.98
Batch: 760; loss: 0.16; acc: 0.91
Batch: 780; loss: 0.09; acc: 0.95
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.7432459319243208e-05
8.038625310291536e-06
Batch: 0; loss: 0.05; acc: 0.98
Batch: 20; loss: 0.12; acc: 0.97
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.28; acc: 0.94
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.29; acc: 0.86
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14985343282389793; val_accuracy: 0.9557125796178344 

The current subspace-distance is: 8.038625310291536e-06 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.12; acc: 0.97
Batch: 40; loss: 0.24; acc: 0.97
Batch: 60; loss: 0.04; acc: 0.98
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.08; acc: 0.95
Batch: 140; loss: 0.07; acc: 0.97
Batch: 160; loss: 0.16; acc: 0.97
Batch: 180; loss: 0.14; acc: 0.94
Batch: 200; loss: 0.17; acc: 0.97
Batch: 220; loss: 0.1; acc: 0.97
Batch: 240; loss: 0.1; acc: 0.95
Batch: 260; loss: 0.16; acc: 0.97
Batch: 280; loss: 0.2; acc: 0.95
Batch: 300; loss: 0.17; acc: 0.95
Batch: 320; loss: 0.16; acc: 0.94
Batch: 340; loss: 0.12; acc: 0.95
Batch: 360; loss: 0.16; acc: 0.97
Batch: 380; loss: 0.16; acc: 0.94
Batch: 400; loss: 0.2; acc: 0.94
Batch: 420; loss: 0.18; acc: 0.95
Batch: 440; loss: 0.14; acc: 0.95
Batch: 460; loss: 0.25; acc: 0.94
Batch: 480; loss: 0.11; acc: 0.94
Batch: 500; loss: 0.13; acc: 0.95
Batch: 520; loss: 0.2; acc: 0.94
Batch: 540; loss: 0.08; acc: 0.97
Batch: 560; loss: 0.27; acc: 0.95
Batch: 580; loss: 0.03; acc: 1.0
Batch: 600; loss: 0.17; acc: 0.94
Batch: 620; loss: 0.25; acc: 0.92
Batch: 640; loss: 0.17; acc: 0.92
Batch: 660; loss: 0.12; acc: 0.97
Batch: 680; loss: 0.15; acc: 0.95
Batch: 700; loss: 0.17; acc: 0.95
Batch: 720; loss: 0.19; acc: 0.94
Batch: 740; loss: 0.13; acc: 0.97
Batch: 760; loss: 0.23; acc: 0.92
Batch: 780; loss: 0.09; acc: 0.97
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.6871528461924754e-05
8.957369573181495e-06
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.12; acc: 0.97
Batch: 40; loss: 0.04; acc: 0.97
Batch: 60; loss: 0.27; acc: 0.94
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.13; acc: 0.94
Batch: 120; loss: 0.17; acc: 0.94
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14171814479550737; val_accuracy: 0.9589968152866242 

The current subspace-distance is: 8.957369573181495e-06 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.23; acc: 0.92
Batch: 20; loss: 0.04; acc: 0.98
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.15; acc: 0.95
Batch: 80; loss: 0.18; acc: 0.97
Batch: 100; loss: 0.08; acc: 1.0
Batch: 120; loss: 0.15; acc: 0.95
Batch: 140; loss: 0.14; acc: 0.95
Batch: 160; loss: 0.1; acc: 0.97
Batch: 180; loss: 0.23; acc: 0.89
Batch: 200; loss: 0.07; acc: 0.97
Batch: 220; loss: 0.29; acc: 0.89
Batch: 240; loss: 0.02; acc: 1.0
Batch: 260; loss: 0.15; acc: 0.94
Batch: 280; loss: 0.13; acc: 0.92
Batch: 300; loss: 0.12; acc: 0.97
Batch: 320; loss: 0.22; acc: 0.94
Batch: 340; loss: 0.06; acc: 1.0
Batch: 360; loss: 0.06; acc: 0.98
Batch: 380; loss: 0.15; acc: 0.94
Batch: 400; loss: 0.08; acc: 0.98
Batch: 420; loss: 0.07; acc: 0.97
Batch: 440; loss: 0.09; acc: 0.97
Batch: 460; loss: 0.13; acc: 0.95
Batch: 480; loss: 0.16; acc: 0.94
Batch: 500; loss: 0.13; acc: 0.95
Batch: 520; loss: 0.14; acc: 0.95
Batch: 540; loss: 0.09; acc: 0.95
Batch: 560; loss: 0.1; acc: 0.98
Batch: 580; loss: 0.05; acc: 0.98
Batch: 600; loss: 0.11; acc: 0.97
Batch: 620; loss: 0.21; acc: 0.92
Batch: 640; loss: 0.1; acc: 0.95
Batch: 660; loss: 0.24; acc: 0.92
Batch: 680; loss: 0.12; acc: 0.97
Batch: 700; loss: 0.1; acc: 0.95
Batch: 720; loss: 0.15; acc: 0.94
Batch: 740; loss: 0.08; acc: 0.98
Batch: 760; loss: 0.11; acc: 0.97
Batch: 780; loss: 0.13; acc: 0.95
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

2.7196185328648426e-05
7.719268978689797e-06
Batch: 0; loss: 0.06; acc: 0.97
Batch: 20; loss: 0.14; acc: 0.97
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.26; acc: 0.94
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.12; acc: 0.94
Batch: 120; loss: 0.19; acc: 0.92
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1427059458794108; val_accuracy: 0.9588972929936306 

The current subspace-distance is: 7.719268978689797e-06 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.08; acc: 0.98
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.03; acc: 1.0
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.09; acc: 0.98
Batch: 120; loss: 0.17; acc: 0.95
Batch: 140; loss: 0.1; acc: 0.97
Batch: 160; loss: 0.08; acc: 0.97
Batch: 180; loss: 0.06; acc: 0.98
Batch: 200; loss: 0.29; acc: 0.89
Batch: 220; loss: 0.05; acc: 0.97
Batch: 240; loss: 0.03; acc: 1.0
Batch: 260; loss: 0.12; acc: 0.95
Batch: 280; loss: 0.09; acc: 0.95
Batch: 300; loss: 0.12; acc: 0.97
Batch: 320; loss: 0.2; acc: 0.94
Batch: 340; loss: 0.04; acc: 1.0
Batch: 360; loss: 0.09; acc: 0.97
Batch: 380; loss: 0.08; acc: 0.97
Batch: 400; loss: 0.05; acc: 1.0
Batch: 420; loss: 0.24; acc: 0.95
Batch: 440; loss: 0.11; acc: 0.98
Batch: 460; loss: 0.19; acc: 0.94
Batch: 480; loss: 0.06; acc: 0.98
Batch: 500; loss: 0.12; acc: 0.97
Batch: 520; loss: 0.18; acc: 0.95
Batch: 540; loss: 0.07; acc: 0.95
Batch: 560; loss: 0.07; acc: 0.98
Batch: 580; loss: 0.15; acc: 0.97
Batch: 600; loss: 0.16; acc: 0.95
Batch: 620; loss: 0.11; acc: 0.98
Batch: 640; loss: 0.19; acc: 0.91
Batch: 660; loss: 0.08; acc: 0.98
Batch: 680; loss: 0.19; acc: 0.95
Batch: 700; loss: 0.12; acc: 0.94
Batch: 720; loss: 0.09; acc: 0.98
Batch: 740; loss: 0.07; acc: 0.98
Batch: 760; loss: 0.26; acc: 0.94
Batch: 780; loss: 0.17; acc: 0.95
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

2.6766821974888444e-05
8.89411512616789e-06
Batch: 0; loss: 0.06; acc: 0.97
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.27; acc: 0.94
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.24; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14548141701491016; val_accuracy: 0.9579020700636943 

The current subspace-distance is: 8.89411512616789e-06 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.11; acc: 0.94
Batch: 20; loss: 0.13; acc: 0.97
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.15; acc: 0.95
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.23; acc: 0.94
Batch: 140; loss: 0.07; acc: 0.98
Batch: 160; loss: 0.07; acc: 0.97
Batch: 180; loss: 0.16; acc: 0.94
Batch: 200; loss: 0.12; acc: 0.97
Batch: 220; loss: 0.05; acc: 0.97
Batch: 240; loss: 0.1; acc: 0.97
Batch: 260; loss: 0.16; acc: 0.94
Batch: 280; loss: 0.08; acc: 0.97
Batch: 300; loss: 0.05; acc: 0.97
Batch: 320; loss: 0.13; acc: 0.95
Batch: 340; loss: 0.12; acc: 0.97
Batch: 360; loss: 0.16; acc: 0.95
Batch: 380; loss: 0.23; acc: 0.95
Batch: 400; loss: 0.11; acc: 0.94
Batch: 420; loss: 0.09; acc: 0.98
Batch: 440; loss: 0.35; acc: 0.91
Batch: 460; loss: 0.1; acc: 0.98
Batch: 480; loss: 0.11; acc: 0.97
Batch: 500; loss: 0.21; acc: 0.91
Batch: 520; loss: 0.17; acc: 0.95
Batch: 540; loss: 0.11; acc: 0.95
Batch: 560; loss: 0.16; acc: 0.94
Batch: 580; loss: 0.15; acc: 0.94
Batch: 600; loss: 0.13; acc: 0.95
Batch: 620; loss: 0.11; acc: 0.97
Batch: 640; loss: 0.06; acc: 0.97
Batch: 660; loss: 0.09; acc: 0.98
Batch: 680; loss: 0.14; acc: 0.92
Batch: 700; loss: 0.1; acc: 0.97
Batch: 720; loss: 0.13; acc: 0.97
Batch: 740; loss: 0.08; acc: 0.97
Batch: 760; loss: 0.06; acc: 0.98
Batch: 780; loss: 0.2; acc: 0.95
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

2.6460633307578973e-05
8.6264935816871e-06
Batch: 0; loss: 0.05; acc: 0.97
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.25; acc: 0.92
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.11; acc: 0.95
Batch: 120; loss: 0.17; acc: 0.95
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.13795835199724338; val_accuracy: 0.9592953821656051 

The current subspace-distance is: 8.6264935816871e-06 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.09; acc: 0.95
Batch: 40; loss: 0.14; acc: 0.94
Batch: 60; loss: 0.4; acc: 0.89
Batch: 80; loss: 0.29; acc: 0.94
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.08; acc: 0.97
Batch: 140; loss: 0.17; acc: 0.95
Batch: 160; loss: 0.11; acc: 0.95
Batch: 180; loss: 0.12; acc: 0.97
Batch: 200; loss: 0.05; acc: 0.98
Batch: 220; loss: 0.15; acc: 0.95
Batch: 240; loss: 0.12; acc: 0.95
Batch: 260; loss: 0.19; acc: 0.95
Batch: 280; loss: 0.08; acc: 0.98
Batch: 300; loss: 0.08; acc: 0.97
Batch: 320; loss: 0.03; acc: 1.0
Batch: 340; loss: 0.18; acc: 0.94
Batch: 360; loss: 0.1; acc: 0.95
Batch: 380; loss: 0.16; acc: 0.94
Batch: 400; loss: 0.15; acc: 0.95
Batch: 420; loss: 0.27; acc: 0.89
Batch: 440; loss: 0.17; acc: 0.95
Batch: 460; loss: 0.08; acc: 0.97
Batch: 480; loss: 0.2; acc: 0.94
Batch: 500; loss: 0.09; acc: 0.97
Batch: 520; loss: 0.11; acc: 0.95
Batch: 540; loss: 0.14; acc: 0.95
Batch: 560; loss: 0.1; acc: 0.95
Batch: 580; loss: 0.09; acc: 0.95
Batch: 600; loss: 0.15; acc: 0.94
Batch: 620; loss: 0.18; acc: 0.89
Batch: 640; loss: 0.33; acc: 0.92
Batch: 660; loss: 0.13; acc: 0.95
Batch: 680; loss: 0.15; acc: 0.94
Batch: 700; loss: 0.09; acc: 0.97
Batch: 720; loss: 0.14; acc: 0.97
Batch: 740; loss: 0.2; acc: 0.95
Batch: 760; loss: 0.09; acc: 0.97
Batch: 780; loss: 0.36; acc: 0.91
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

2.704852340684738e-05
8.499768227920868e-06
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.14; acc: 0.97
Batch: 40; loss: 0.04; acc: 0.97
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.1; acc: 0.94
Batch: 120; loss: 0.17; acc: 0.94
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1372524181938475; val_accuracy: 0.9590963375796179 

The current subspace-distance is: 8.499768227920868e-06 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.17; acc: 0.97
Batch: 40; loss: 0.08; acc: 0.94
Batch: 60; loss: 0.13; acc: 0.94
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.16; acc: 0.97
Batch: 120; loss: 0.13; acc: 0.98
Batch: 140; loss: 0.07; acc: 0.98
Batch: 160; loss: 0.2; acc: 0.95
Batch: 180; loss: 0.11; acc: 0.97
Batch: 200; loss: 0.09; acc: 0.97
Batch: 220; loss: 0.15; acc: 0.94
Batch: 240; loss: 0.13; acc: 0.97
Batch: 260; loss: 0.08; acc: 0.97
Batch: 280; loss: 0.08; acc: 0.97
Batch: 300; loss: 0.04; acc: 0.98
Batch: 320; loss: 0.11; acc: 0.95
Batch: 340; loss: 0.09; acc: 0.97
Batch: 360; loss: 0.06; acc: 0.98
Batch: 380; loss: 0.35; acc: 0.94
Batch: 400; loss: 0.19; acc: 0.97
Batch: 420; loss: 0.05; acc: 0.98
Batch: 440; loss: 0.08; acc: 0.98
Batch: 460; loss: 0.4; acc: 0.89
Batch: 480; loss: 0.14; acc: 0.97
Batch: 500; loss: 0.19; acc: 0.98
Batch: 520; loss: 0.16; acc: 0.94
Batch: 540; loss: 0.27; acc: 0.94
Batch: 560; loss: 0.07; acc: 0.98
Batch: 580; loss: 0.06; acc: 0.97
Batch: 600; loss: 0.14; acc: 0.94
Batch: 620; loss: 0.05; acc: 1.0
Batch: 640; loss: 0.08; acc: 0.98
Batch: 660; loss: 0.12; acc: 0.98
Batch: 680; loss: 0.23; acc: 0.94
Batch: 700; loss: 0.06; acc: 0.98
Batch: 720; loss: 0.04; acc: 1.0
Batch: 740; loss: 0.19; acc: 0.95
Batch: 760; loss: 0.16; acc: 0.95
Batch: 780; loss: 0.09; acc: 0.97
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

2.6616864488460124e-05
8.174069989763666e-06
Batch: 0; loss: 0.05; acc: 0.98
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.26; acc: 0.94
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.09; acc: 0.95
Batch: 120; loss: 0.18; acc: 0.92
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.13828146362760266; val_accuracy: 0.9581011146496815 

The current subspace-distance is: 8.174069989763666e-06 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.12; acc: 0.95
Batch: 40; loss: 0.05; acc: 0.97
Batch: 60; loss: 0.16; acc: 0.91
Batch: 80; loss: 0.31; acc: 0.94
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.02; acc: 1.0
Batch: 140; loss: 0.11; acc: 0.95
Batch: 160; loss: 0.13; acc: 0.98
Batch: 180; loss: 0.05; acc: 1.0
Batch: 200; loss: 0.14; acc: 0.98
Batch: 220; loss: 0.2; acc: 0.92
Batch: 240; loss: 0.16; acc: 0.92
Batch: 260; loss: 0.09; acc: 0.97
Batch: 280; loss: 0.03; acc: 0.98
Batch: 300; loss: 0.16; acc: 0.92
Batch: 320; loss: 0.05; acc: 0.98
Batch: 340; loss: 0.17; acc: 0.95
Batch: 360; loss: 0.12; acc: 0.95
Batch: 380; loss: 0.15; acc: 0.94
Batch: 400; loss: 0.07; acc: 0.98
Batch: 420; loss: 0.04; acc: 0.98
Batch: 440; loss: 0.05; acc: 0.98
Batch: 460; loss: 0.29; acc: 0.94
Batch: 480; loss: 0.05; acc: 0.98
Batch: 500; loss: 0.1; acc: 0.97
Batch: 520; loss: 0.16; acc: 0.95
Batch: 540; loss: 0.1; acc: 0.97
Batch: 560; loss: 0.2; acc: 0.92
Batch: 580; loss: 0.16; acc: 0.95
Batch: 600; loss: 0.14; acc: 0.95
Batch: 620; loss: 0.12; acc: 0.95
Batch: 640; loss: 0.3; acc: 0.92
Batch: 660; loss: 0.1; acc: 0.97
Batch: 680; loss: 0.07; acc: 0.95
Batch: 700; loss: 0.15; acc: 0.95
Batch: 720; loss: 0.09; acc: 0.98
Batch: 740; loss: 0.12; acc: 0.98
Batch: 760; loss: 0.27; acc: 0.94
Batch: 780; loss: 0.05; acc: 0.98
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

2.790889448078815e-05
8.648940820421558e-06
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.18; acc: 0.97
Batch: 40; loss: 0.05; acc: 0.97
Batch: 60; loss: 0.3; acc: 0.94
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.1; acc: 0.95
Batch: 120; loss: 0.21; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14948487324509652; val_accuracy: 0.9538216560509554 

The current subspace-distance is: 8.648940820421558e-06 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.07; acc: 0.97
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.21; acc: 0.97
Batch: 100; loss: 0.12; acc: 0.98
Batch: 120; loss: 0.09; acc: 0.97
Batch: 140; loss: 0.05; acc: 1.0
Batch: 160; loss: 0.25; acc: 0.91
Batch: 180; loss: 0.05; acc: 0.98
Batch: 200; loss: 0.11; acc: 0.97
Batch: 220; loss: 0.11; acc: 0.95
Batch: 240; loss: 0.14; acc: 0.92
Batch: 260; loss: 0.16; acc: 0.97
Batch: 280; loss: 0.17; acc: 0.95
Batch: 300; loss: 0.08; acc: 0.97
Batch: 320; loss: 0.2; acc: 0.95
Batch: 340; loss: 0.12; acc: 0.97
Batch: 360; loss: 0.14; acc: 0.95
Batch: 380; loss: 0.31; acc: 0.91
Batch: 400; loss: 0.04; acc: 0.98
Batch: 420; loss: 0.19; acc: 0.91
Batch: 440; loss: 0.04; acc: 0.98
Batch: 460; loss: 0.36; acc: 0.92
Batch: 480; loss: 0.14; acc: 0.97
Batch: 500; loss: 0.16; acc: 0.95
Batch: 520; loss: 0.08; acc: 0.97
Batch: 540; loss: 0.22; acc: 0.97
Batch: 560; loss: 0.21; acc: 0.94
Batch: 580; loss: 0.25; acc: 0.89
Batch: 600; loss: 0.06; acc: 0.97
Batch: 620; loss: 0.33; acc: 0.95
Batch: 640; loss: 0.08; acc: 0.97
Batch: 660; loss: 0.22; acc: 0.95
Batch: 680; loss: 0.28; acc: 0.91
Batch: 700; loss: 0.24; acc: 0.91
Batch: 720; loss: 0.25; acc: 0.94
Batch: 740; loss: 0.1; acc: 0.97
Batch: 760; loss: 0.22; acc: 0.94
Batch: 780; loss: 0.1; acc: 0.94
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

2.667324588401243e-05
8.430132766079623e-06
Batch: 0; loss: 0.06; acc: 0.97
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.04; acc: 0.97
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.15; acc: 0.95
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1426368276974198; val_accuracy: 0.9591958598726115 

The current subspace-distance is: 8.430132766079623e-06 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.17; acc: 0.97
Batch: 40; loss: 0.04; acc: 0.97
Batch: 60; loss: 0.19; acc: 0.92
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.12; acc: 0.95
Batch: 140; loss: 0.21; acc: 0.97
Batch: 160; loss: 0.23; acc: 0.91
Batch: 180; loss: 0.18; acc: 0.92
Batch: 200; loss: 0.08; acc: 0.97
Batch: 220; loss: 0.1; acc: 0.97
Batch: 240; loss: 0.18; acc: 0.95
Batch: 260; loss: 0.24; acc: 0.92
Batch: 280; loss: 0.04; acc: 0.98
Batch: 300; loss: 0.14; acc: 0.94
Batch: 320; loss: 0.05; acc: 0.98
Batch: 340; loss: 0.09; acc: 0.97
Batch: 360; loss: 0.19; acc: 0.94
Batch: 380; loss: 0.18; acc: 0.94
Batch: 400; loss: 0.11; acc: 0.97
Batch: 420; loss: 0.21; acc: 0.94
Batch: 440; loss: 0.22; acc: 0.94
Batch: 460; loss: 0.09; acc: 0.97
Batch: 480; loss: 0.27; acc: 0.95
Batch: 500; loss: 0.18; acc: 0.97
Batch: 520; loss: 0.17; acc: 0.94
Batch: 540; loss: 0.22; acc: 0.92
Batch: 560; loss: 0.21; acc: 0.95
Batch: 580; loss: 0.23; acc: 0.92
Batch: 600; loss: 0.07; acc: 0.98
Batch: 620; loss: 0.07; acc: 0.98
Batch: 640; loss: 0.01; acc: 1.0
Batch: 660; loss: 0.18; acc: 0.91
Batch: 680; loss: 0.03; acc: 1.0
Batch: 700; loss: 0.35; acc: 0.91
Batch: 720; loss: 0.11; acc: 0.97
Batch: 740; loss: 0.18; acc: 0.97
Batch: 760; loss: 0.22; acc: 0.92
Batch: 780; loss: 0.32; acc: 0.94
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

2.709630280151032e-05
7.952339728944935e-06
Batch: 0; loss: 0.05; acc: 0.98
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.26; acc: 0.94
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.16; acc: 0.95
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.13568104646957604; val_accuracy: 0.961484872611465 

The current subspace-distance is: 7.952339728944935e-06 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.06; acc: 0.98
Batch: 20; loss: 0.15; acc: 0.94
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.18; acc: 0.95
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.14; acc: 0.98
Batch: 120; loss: 0.12; acc: 0.94
Batch: 140; loss: 0.05; acc: 0.98
Batch: 160; loss: 0.11; acc: 0.92
Batch: 180; loss: 0.15; acc: 0.97
Batch: 200; loss: 0.09; acc: 0.98
Batch: 220; loss: 0.15; acc: 0.97
Batch: 240; loss: 0.11; acc: 0.97
Batch: 260; loss: 0.41; acc: 0.86
Batch: 280; loss: 0.27; acc: 0.94
Batch: 300; loss: 0.07; acc: 0.98
Batch: 320; loss: 0.05; acc: 0.98
Batch: 340; loss: 0.12; acc: 0.95
Batch: 360; loss: 0.17; acc: 0.95
Batch: 380; loss: 0.16; acc: 0.97
Batch: 400; loss: 0.28; acc: 0.94
Batch: 420; loss: 0.15; acc: 0.92
Batch: 440; loss: 0.22; acc: 0.92
Batch: 460; loss: 0.14; acc: 0.94
Batch: 480; loss: 0.05; acc: 0.98
Batch: 500; loss: 0.05; acc: 0.98
Batch: 520; loss: 0.07; acc: 0.98
Batch: 540; loss: 0.08; acc: 0.97
Batch: 560; loss: 0.09; acc: 0.97
Batch: 580; loss: 0.07; acc: 0.98
Batch: 600; loss: 0.14; acc: 0.95
Batch: 620; loss: 0.16; acc: 0.95
Batch: 640; loss: 0.22; acc: 0.95
Batch: 660; loss: 0.07; acc: 0.98
Batch: 680; loss: 0.08; acc: 0.97
Batch: 700; loss: 0.08; acc: 0.97
Batch: 720; loss: 0.07; acc: 0.97
Batch: 740; loss: 0.03; acc: 1.0
Batch: 760; loss: 0.02; acc: 1.0
Batch: 780; loss: 0.04; acc: 0.98
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

2.6019579308922403e-05
8.120783604681492e-06
Batch: 0; loss: 0.04; acc: 0.97
Batch: 20; loss: 0.14; acc: 0.97
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.27; acc: 0.95
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.11; acc: 0.95
Batch: 120; loss: 0.21; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.13724031809503864; val_accuracy: 0.9609872611464968 

The current subspace-distance is: 8.120783604681492e-06 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.13; acc: 0.97
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.05; acc: 1.0
Batch: 140; loss: 0.06; acc: 0.98
Batch: 160; loss: 0.13; acc: 0.95
Batch: 180; loss: 0.12; acc: 0.95
Batch: 200; loss: 0.05; acc: 0.98
Batch: 220; loss: 0.1; acc: 0.95
Batch: 240; loss: 0.12; acc: 0.97
Batch: 260; loss: 0.08; acc: 0.98
Batch: 280; loss: 0.05; acc: 0.97
Batch: 300; loss: 0.22; acc: 0.95
Batch: 320; loss: 0.16; acc: 0.94
Batch: 340; loss: 0.07; acc: 0.98
Batch: 360; loss: 0.17; acc: 0.95
Batch: 380; loss: 0.06; acc: 0.98
Batch: 400; loss: 0.05; acc: 0.98
Batch: 420; loss: 0.04; acc: 0.98
Batch: 440; loss: 0.36; acc: 0.92
Batch: 460; loss: 0.21; acc: 0.94
Batch: 480; loss: 0.02; acc: 1.0
Batch: 500; loss: 0.03; acc: 1.0
Batch: 520; loss: 0.1; acc: 0.98
Batch: 540; loss: 0.17; acc: 0.98
Batch: 560; loss: 0.1; acc: 0.97
Batch: 580; loss: 0.18; acc: 0.92
Batch: 600; loss: 0.12; acc: 0.97
Batch: 620; loss: 0.15; acc: 0.94
Batch: 640; loss: 0.16; acc: 0.94
Batch: 660; loss: 0.06; acc: 0.97
Batch: 680; loss: 0.12; acc: 0.98
Batch: 700; loss: 0.18; acc: 0.94
Batch: 720; loss: 0.05; acc: 0.98
Batch: 740; loss: 0.07; acc: 0.97
Batch: 760; loss: 0.06; acc: 0.97
Batch: 780; loss: 0.09; acc: 0.98
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

2.6763571440824308e-05
7.773538527544588e-06
Batch: 0; loss: 0.05; acc: 0.97
Batch: 20; loss: 0.12; acc: 0.95
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.11; acc: 0.95
Batch: 120; loss: 0.17; acc: 0.95
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.13416961915079195; val_accuracy: 0.9616839171974523 

The current subspace-distance is: 7.773538527544588e-06 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.17; acc: 0.95
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.09; acc: 0.97
Batch: 80; loss: 0.23; acc: 0.91
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.16; acc: 0.95
Batch: 140; loss: 0.39; acc: 0.92
Batch: 160; loss: 0.17; acc: 0.94
Batch: 180; loss: 0.12; acc: 0.97
Batch: 200; loss: 0.15; acc: 0.97
Batch: 220; loss: 0.1; acc: 0.97
Batch: 240; loss: 0.09; acc: 0.98
Batch: 260; loss: 0.15; acc: 0.95
Batch: 280; loss: 0.13; acc: 0.95
Batch: 300; loss: 0.31; acc: 0.92
Batch: 320; loss: 0.13; acc: 0.94
Batch: 340; loss: 0.1; acc: 0.97
Batch: 360; loss: 0.18; acc: 0.97
Batch: 380; loss: 0.05; acc: 0.98
Batch: 400; loss: 0.15; acc: 0.95
Batch: 420; loss: 0.24; acc: 0.95
Batch: 440; loss: 0.13; acc: 0.94
Batch: 460; loss: 0.32; acc: 0.92
Batch: 480; loss: 0.14; acc: 0.95
Batch: 500; loss: 0.05; acc: 0.97
Batch: 520; loss: 0.17; acc: 0.97
Batch: 540; loss: 0.11; acc: 0.97
Batch: 560; loss: 0.12; acc: 0.95
Batch: 580; loss: 0.13; acc: 0.95
Batch: 600; loss: 0.23; acc: 0.91
Batch: 620; loss: 0.06; acc: 0.97
Batch: 640; loss: 0.11; acc: 0.95
Batch: 660; loss: 0.1; acc: 0.98
Batch: 680; loss: 0.08; acc: 0.97
Batch: 700; loss: 0.12; acc: 0.97
Batch: 720; loss: 0.16; acc: 0.95
Batch: 740; loss: 0.13; acc: 0.94
Batch: 760; loss: 0.27; acc: 0.92
Batch: 780; loss: 0.1; acc: 0.97
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

2.7434542062110268e-05
8.216579772124533e-06
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.13; acc: 0.97
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.1; acc: 0.94
Batch: 120; loss: 0.18; acc: 0.91
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.13189848324960204; val_accuracy: 0.962281050955414 

The current subspace-distance is: 8.216579772124533e-06 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.1; acc: 0.95
Batch: 20; loss: 0.13; acc: 0.94
Batch: 40; loss: 0.1; acc: 0.95
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.11; acc: 0.94
Batch: 120; loss: 0.18; acc: 0.95
Batch: 140; loss: 0.15; acc: 0.97
Batch: 160; loss: 0.13; acc: 0.95
Batch: 180; loss: 0.03; acc: 0.98
Batch: 200; loss: 0.18; acc: 0.95
Batch: 220; loss: 0.25; acc: 0.95
Batch: 240; loss: 0.04; acc: 0.98
Batch: 260; loss: 0.11; acc: 0.95
Batch: 280; loss: 0.31; acc: 0.92
Batch: 300; loss: 0.45; acc: 0.88
Batch: 320; loss: 0.07; acc: 0.97
Batch: 340; loss: 0.2; acc: 0.95
Batch: 360; loss: 0.13; acc: 0.97
Batch: 380; loss: 0.04; acc: 1.0
Batch: 400; loss: 0.13; acc: 0.97
Batch: 420; loss: 0.16; acc: 0.94
Batch: 440; loss: 0.07; acc: 0.95
Batch: 460; loss: 0.07; acc: 0.98
Batch: 480; loss: 0.12; acc: 0.98
Batch: 500; loss: 0.2; acc: 0.95
Batch: 520; loss: 0.2; acc: 0.95
Batch: 540; loss: 0.04; acc: 1.0
Batch: 560; loss: 0.13; acc: 0.97
Batch: 580; loss: 0.09; acc: 0.98
Batch: 600; loss: 0.08; acc: 0.98
Batch: 620; loss: 0.23; acc: 0.91
Batch: 640; loss: 0.08; acc: 0.97
Batch: 660; loss: 0.17; acc: 0.95
Batch: 680; loss: 0.15; acc: 0.92
Batch: 700; loss: 0.05; acc: 0.98
Batch: 720; loss: 0.15; acc: 0.92
Batch: 740; loss: 0.15; acc: 0.97
Batch: 760; loss: 0.12; acc: 0.97
Batch: 780; loss: 0.08; acc: 0.98
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

2.7751979359891266e-05
9.382045391248539e-06
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.25; acc: 0.95
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.09; acc: 0.95
Batch: 120; loss: 0.18; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1313466299206588; val_accuracy: 0.9626791401273885 

The current subspace-distance is: 9.382045391248539e-06 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.04; acc: 0.98
Batch: 120; loss: 0.07; acc: 0.98
Batch: 140; loss: 0.2; acc: 0.95
Batch: 160; loss: 0.04; acc: 0.97
Batch: 180; loss: 0.1; acc: 0.95
Batch: 200; loss: 0.08; acc: 0.98
Batch: 220; loss: 0.13; acc: 0.95
Batch: 240; loss: 0.24; acc: 0.92
Batch: 260; loss: 0.08; acc: 0.98
Batch: 280; loss: 0.13; acc: 0.97
Batch: 300; loss: 0.12; acc: 0.97
Batch: 320; loss: 0.23; acc: 0.92
Batch: 340; loss: 0.15; acc: 0.97
Batch: 360; loss: 0.07; acc: 0.97
Batch: 380; loss: 0.21; acc: 0.94
Batch: 400; loss: 0.14; acc: 0.95
Batch: 420; loss: 0.15; acc: 0.95
Batch: 440; loss: 0.23; acc: 0.95
Batch: 460; loss: 0.09; acc: 0.97
Batch: 480; loss: 0.11; acc: 0.95
Batch: 500; loss: 0.18; acc: 0.94
Batch: 520; loss: 0.06; acc: 0.98
Batch: 540; loss: 0.08; acc: 0.98
Batch: 560; loss: 0.11; acc: 0.94
Batch: 580; loss: 0.33; acc: 0.95
Batch: 600; loss: 0.09; acc: 0.95
Batch: 620; loss: 0.18; acc: 0.95
Batch: 640; loss: 0.17; acc: 0.94
Batch: 660; loss: 0.26; acc: 0.94
Batch: 680; loss: 0.27; acc: 0.94
Batch: 700; loss: 0.08; acc: 0.95
Batch: 720; loss: 0.17; acc: 0.95
Batch: 740; loss: 0.14; acc: 0.94
Batch: 760; loss: 0.09; acc: 0.98
Batch: 780; loss: 0.14; acc: 0.94
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

2.7157304430147633e-05
9.070288797374815e-06
Batch: 0; loss: 0.05; acc: 0.98
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.09; acc: 0.95
Batch: 120; loss: 0.16; acc: 0.94
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.13215750330098117; val_accuracy: 0.9616839171974523 

The current subspace-distance is: 9.070288797374815e-06 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.08; acc: 0.97
Batch: 20; loss: 0.18; acc: 0.97
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.09; acc: 0.98
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.28; acc: 0.91
Batch: 120; loss: 0.17; acc: 0.95
Batch: 140; loss: 0.07; acc: 0.97
Batch: 160; loss: 0.19; acc: 0.95
Batch: 180; loss: 0.08; acc: 0.98
Batch: 200; loss: 0.14; acc: 0.97
Batch: 220; loss: 0.1; acc: 0.98
Batch: 240; loss: 0.09; acc: 0.97
Batch: 260; loss: 0.14; acc: 0.94
Batch: 280; loss: 0.02; acc: 1.0
Batch: 300; loss: 0.1; acc: 0.95
Batch: 320; loss: 0.34; acc: 0.91
Batch: 340; loss: 0.22; acc: 0.91
Batch: 360; loss: 0.1; acc: 0.98
Batch: 380; loss: 0.03; acc: 1.0
Batch: 400; loss: 0.17; acc: 0.94
Batch: 420; loss: 0.12; acc: 0.97
Batch: 440; loss: 0.18; acc: 0.92
Batch: 460; loss: 0.11; acc: 0.98
Batch: 480; loss: 0.02; acc: 1.0
Batch: 500; loss: 0.14; acc: 0.95
Batch: 520; loss: 0.16; acc: 0.97
Batch: 540; loss: 0.22; acc: 0.92
Batch: 560; loss: 0.21; acc: 0.94
Batch: 580; loss: 0.08; acc: 0.95
Batch: 600; loss: 0.09; acc: 0.97
Batch: 620; loss: 0.08; acc: 0.98
Batch: 640; loss: 0.02; acc: 1.0
Batch: 660; loss: 0.24; acc: 0.95
Batch: 680; loss: 0.08; acc: 0.98
Batch: 700; loss: 0.18; acc: 0.95
Batch: 720; loss: 0.04; acc: 0.98
Batch: 740; loss: 0.13; acc: 0.95
Batch: 760; loss: 0.13; acc: 0.94
Batch: 780; loss: 0.09; acc: 0.97
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

2.7322359528625384e-05
7.22257800589432e-06
Batch: 0; loss: 0.04; acc: 0.97
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.11; acc: 0.94
Batch: 120; loss: 0.17; acc: 0.94
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.13286557591929557; val_accuracy: 0.9616839171974523 

The current subspace-distance is: 7.22257800589432e-06 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.25; acc: 0.97
Batch: 20; loss: 0.06; acc: 1.0
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.13; acc: 0.94
Batch: 140; loss: 0.06; acc: 0.98
Batch: 160; loss: 0.21; acc: 0.95
Batch: 180; loss: 0.13; acc: 0.95
Batch: 200; loss: 0.15; acc: 0.97
Batch: 220; loss: 0.1; acc: 0.98
Batch: 240; loss: 0.17; acc: 0.94
Batch: 260; loss: 0.1; acc: 0.98
Batch: 280; loss: 0.26; acc: 0.91
Batch: 300; loss: 0.08; acc: 0.98
Batch: 320; loss: 0.15; acc: 0.95
Batch: 340; loss: 0.11; acc: 0.95
Batch: 360; loss: 0.14; acc: 0.94
Batch: 380; loss: 0.13; acc: 0.95
Batch: 400; loss: 0.22; acc: 0.94
Batch: 420; loss: 0.11; acc: 0.95
Batch: 440; loss: 0.25; acc: 0.94
Batch: 460; loss: 0.08; acc: 0.98
Batch: 480; loss: 0.13; acc: 0.94
Batch: 500; loss: 0.1; acc: 0.97
Batch: 520; loss: 0.08; acc: 0.98
Batch: 540; loss: 0.15; acc: 0.95
Batch: 560; loss: 0.02; acc: 1.0
Batch: 580; loss: 0.16; acc: 0.95
Batch: 600; loss: 0.28; acc: 0.94
Batch: 620; loss: 0.06; acc: 0.98
Batch: 640; loss: 0.19; acc: 0.92
Batch: 660; loss: 0.08; acc: 0.97
Batch: 680; loss: 0.07; acc: 0.97
Batch: 700; loss: 0.22; acc: 0.95
Batch: 720; loss: 0.13; acc: 0.95
Batch: 740; loss: 0.1; acc: 0.97
Batch: 760; loss: 0.18; acc: 0.95
Batch: 780; loss: 0.1; acc: 0.97
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

2.713991852942854e-05
8.926360351324547e-06
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.12; acc: 0.97
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.1; acc: 0.95
Batch: 120; loss: 0.16; acc: 0.92
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.13301530739019632; val_accuracy: 0.9615843949044586 

The current subspace-distance is: 8.926360351324547e-06 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.24; acc: 0.94
Batch: 40; loss: 0.25; acc: 0.91
Batch: 60; loss: 0.18; acc: 0.95
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.14; acc: 0.94
Batch: 120; loss: 0.13; acc: 0.94
Batch: 140; loss: 0.21; acc: 0.94
Batch: 160; loss: 0.14; acc: 0.94
Batch: 180; loss: 0.1; acc: 0.95
Batch: 200; loss: 0.05; acc: 0.98
Batch: 220; loss: 0.04; acc: 0.98
Batch: 240; loss: 0.12; acc: 0.94
Batch: 260; loss: 0.08; acc: 0.98
Batch: 280; loss: 0.11; acc: 0.95
Batch: 300; loss: 0.19; acc: 0.94
Batch: 320; loss: 0.22; acc: 0.94
Batch: 340; loss: 0.08; acc: 0.97
Batch: 360; loss: 0.2; acc: 0.95
Batch: 380; loss: 0.21; acc: 0.94
Batch: 400; loss: 0.03; acc: 0.98
Batch: 420; loss: 0.1; acc: 0.98
Batch: 440; loss: 0.06; acc: 0.98
Batch: 460; loss: 0.13; acc: 0.95
Batch: 480; loss: 0.13; acc: 0.98
Batch: 500; loss: 0.1; acc: 0.97
Batch: 520; loss: 0.04; acc: 0.98
Batch: 540; loss: 0.21; acc: 0.94
Batch: 560; loss: 0.06; acc: 0.97
Batch: 580; loss: 0.29; acc: 0.89
Batch: 600; loss: 0.34; acc: 0.92
Batch: 620; loss: 0.11; acc: 0.95
Batch: 640; loss: 0.23; acc: 0.89
Batch: 660; loss: 0.29; acc: 0.95
Batch: 680; loss: 0.12; acc: 0.97
Batch: 700; loss: 0.1; acc: 0.97
Batch: 720; loss: 0.17; acc: 0.95
Batch: 740; loss: 0.08; acc: 0.98
Batch: 760; loss: 0.07; acc: 0.98
Batch: 780; loss: 0.19; acc: 0.95
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

2.693721944524441e-05
8.972683644969948e-06
Batch: 0; loss: 0.05; acc: 0.98
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.24; acc: 0.95
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.08; acc: 0.97
Batch: 120; loss: 0.16; acc: 0.92
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1345119892744122; val_accuracy: 0.9623805732484076 

The current subspace-distance is: 8.972683644969948e-06 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.18; acc: 0.97
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.22; acc: 0.91
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.21; acc: 0.94
Batch: 140; loss: 0.07; acc: 0.98
Batch: 160; loss: 0.17; acc: 0.91
Batch: 180; loss: 0.12; acc: 0.98
Batch: 200; loss: 0.08; acc: 0.97
Batch: 220; loss: 0.14; acc: 0.94
Batch: 240; loss: 0.13; acc: 0.97
Batch: 260; loss: 0.08; acc: 0.97
Batch: 280; loss: 0.11; acc: 0.98
Batch: 300; loss: 0.12; acc: 0.92
Batch: 320; loss: 0.08; acc: 0.98
Batch: 340; loss: 0.23; acc: 0.94
Batch: 360; loss: 0.07; acc: 0.97
Batch: 380; loss: 0.07; acc: 0.98
Batch: 400; loss: 0.06; acc: 0.97
Batch: 420; loss: 0.04; acc: 0.98
Batch: 440; loss: 0.03; acc: 1.0
Batch: 460; loss: 0.14; acc: 0.97
Batch: 480; loss: 0.23; acc: 0.94
Batch: 500; loss: 0.08; acc: 0.95
Batch: 520; loss: 0.17; acc: 0.94
Batch: 540; loss: 0.19; acc: 0.94
Batch: 560; loss: 0.06; acc: 0.98
Batch: 580; loss: 0.16; acc: 0.98
Batch: 600; loss: 0.13; acc: 0.95
Batch: 620; loss: 0.08; acc: 0.98
Batch: 640; loss: 0.16; acc: 0.95
Batch: 660; loss: 0.1; acc: 0.98
Batch: 680; loss: 0.09; acc: 0.95
Batch: 700; loss: 0.23; acc: 0.94
Batch: 720; loss: 0.03; acc: 0.98
Batch: 740; loss: 0.03; acc: 1.0
Batch: 760; loss: 0.15; acc: 0.95
Batch: 780; loss: 0.06; acc: 1.0
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

2.723411853366997e-05
8.300351510115433e-06
Batch: 0; loss: 0.05; acc: 0.97
Batch: 20; loss: 0.13; acc: 0.97
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.1; acc: 0.95
Batch: 120; loss: 0.16; acc: 0.95
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.13260959523024074; val_accuracy: 0.962281050955414 

The current subspace-distance is: 8.300351510115433e-06 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.04; acc: 0.98
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.22; acc: 0.95
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.1; acc: 0.95
Batch: 120; loss: 0.14; acc: 0.97
Batch: 140; loss: 0.14; acc: 0.95
Batch: 160; loss: 0.15; acc: 0.95
Batch: 180; loss: 0.04; acc: 1.0
Batch: 200; loss: 0.14; acc: 0.97
Batch: 220; loss: 0.08; acc: 0.97
Batch: 240; loss: 0.09; acc: 0.97
Batch: 260; loss: 0.09; acc: 0.97
Batch: 280; loss: 0.1; acc: 0.98
Batch: 300; loss: 0.11; acc: 0.95
Batch: 320; loss: 0.07; acc: 0.97
Batch: 340; loss: 0.06; acc: 0.98
Batch: 360; loss: 0.09; acc: 0.95
Batch: 380; loss: 0.11; acc: 0.97
Batch: 400; loss: 0.08; acc: 0.97
Batch: 420; loss: 0.24; acc: 0.94
Batch: 440; loss: 0.12; acc: 0.94
Batch: 460; loss: 0.13; acc: 0.95
Batch: 480; loss: 0.19; acc: 0.92
Batch: 500; loss: 0.17; acc: 0.95
Batch: 520; loss: 0.23; acc: 0.92
Batch: 540; loss: 0.13; acc: 0.97
Batch: 560; loss: 0.15; acc: 0.95
Batch: 580; loss: 0.05; acc: 0.97
Batch: 600; loss: 0.15; acc: 0.95
Batch: 620; loss: 0.03; acc: 1.0
Batch: 640; loss: 0.07; acc: 0.98
Batch: 660; loss: 0.07; acc: 0.97
Batch: 680; loss: 0.11; acc: 0.95
Batch: 700; loss: 0.24; acc: 0.94
Batch: 720; loss: 0.09; acc: 0.98
Batch: 740; loss: 0.15; acc: 0.94
Batch: 760; loss: 0.14; acc: 0.97
Batch: 780; loss: 0.12; acc: 0.98
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

2.6561052436591126e-05
8.188109859474935e-06
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.15; acc: 0.97
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.26; acc: 0.94
Batch: 80; loss: 0.11; acc: 0.95
Batch: 100; loss: 0.08; acc: 0.95
Batch: 120; loss: 0.17; acc: 0.92
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.13353858382743636; val_accuracy: 0.9611863057324841 

The current subspace-distance is: 8.188109859474935e-06 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.28; acc: 0.94
Batch: 20; loss: 0.11; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.03; acc: 1.0
Batch: 80; loss: 0.22; acc: 0.92
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.21; acc: 0.92
Batch: 140; loss: 0.12; acc: 0.97
Batch: 160; loss: 0.1; acc: 0.94
Batch: 180; loss: 0.07; acc: 0.97
Batch: 200; loss: 0.18; acc: 0.94
Batch: 220; loss: 0.19; acc: 0.92
Batch: 240; loss: 0.08; acc: 0.98
Batch: 260; loss: 0.08; acc: 0.98
Batch: 280; loss: 0.05; acc: 1.0
Batch: 300; loss: 0.19; acc: 0.95
Batch: 320; loss: 0.11; acc: 0.94
Batch: 340; loss: 0.06; acc: 0.98
Batch: 360; loss: 0.1; acc: 0.95
Batch: 380; loss: 0.08; acc: 0.97
Batch: 400; loss: 0.08; acc: 0.98
Batch: 420; loss: 0.14; acc: 0.95
Batch: 440; loss: 0.03; acc: 0.98
Batch: 460; loss: 0.02; acc: 1.0
Batch: 480; loss: 0.06; acc: 0.95
Batch: 500; loss: 0.17; acc: 0.95
Batch: 520; loss: 0.3; acc: 0.92
Batch: 540; loss: 0.09; acc: 0.97
Batch: 560; loss: 0.2; acc: 0.95
Batch: 580; loss: 0.12; acc: 0.97
Batch: 600; loss: 0.06; acc: 1.0
Batch: 620; loss: 0.07; acc: 0.98
Batch: 640; loss: 0.1; acc: 0.95
Batch: 660; loss: 0.07; acc: 0.98
Batch: 680; loss: 0.03; acc: 0.98
Batch: 700; loss: 0.2; acc: 0.91
Batch: 720; loss: 0.19; acc: 0.95
Batch: 740; loss: 0.24; acc: 0.94
Batch: 760; loss: 0.21; acc: 0.94
Batch: 780; loss: 0.1; acc: 0.94
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

2.729038715187926e-05
8.138777047861367e-06
Batch: 0; loss: 0.05; acc: 0.97
Batch: 20; loss: 0.13; acc: 0.97
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.11; acc: 0.94
Batch: 120; loss: 0.17; acc: 0.94
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1321575993755061; val_accuracy: 0.9625796178343949 

The current subspace-distance is: 8.138777047861367e-06 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.06; acc: 0.98
Batch: 20; loss: 0.1; acc: 0.98
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.09; acc: 0.97
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.06; acc: 0.97
Batch: 120; loss: 0.06; acc: 0.97
Batch: 140; loss: 0.17; acc: 0.92
Batch: 160; loss: 0.17; acc: 0.94
Batch: 180; loss: 0.11; acc: 0.95
Batch: 200; loss: 0.08; acc: 0.95
Batch: 220; loss: 0.13; acc: 0.98
Batch: 240; loss: 0.14; acc: 0.97
Batch: 260; loss: 0.11; acc: 0.95
Batch: 280; loss: 0.16; acc: 0.92
Batch: 300; loss: 0.14; acc: 0.97
Batch: 320; loss: 0.09; acc: 0.97
Batch: 340; loss: 0.25; acc: 0.94
Batch: 360; loss: 0.05; acc: 1.0
Batch: 380; loss: 0.16; acc: 0.94
Batch: 400; loss: 0.07; acc: 0.98
Batch: 420; loss: 0.15; acc: 0.95
Batch: 440; loss: 0.1; acc: 0.97
Batch: 460; loss: 0.1; acc: 0.95
Batch: 480; loss: 0.09; acc: 0.97
Batch: 500; loss: 0.22; acc: 0.91
Batch: 520; loss: 0.03; acc: 1.0
Batch: 540; loss: 0.09; acc: 0.95
Batch: 560; loss: 0.01; acc: 1.0
Batch: 580; loss: 0.2; acc: 0.94
Batch: 600; loss: 0.16; acc: 0.94
Batch: 620; loss: 0.12; acc: 0.97
Batch: 640; loss: 0.13; acc: 0.97
Batch: 660; loss: 0.1; acc: 0.98
Batch: 680; loss: 0.23; acc: 0.94
Batch: 700; loss: 0.15; acc: 0.95
Batch: 720; loss: 0.09; acc: 0.97
Batch: 740; loss: 0.27; acc: 0.92
Batch: 760; loss: 0.07; acc: 0.98
Batch: 780; loss: 0.08; acc: 0.98
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

2.649206726346165e-05
8.467042789561674e-06
Batch: 0; loss: 0.05; acc: 0.97
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.1; acc: 0.95
Batch: 120; loss: 0.16; acc: 0.94
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.13138477805598525; val_accuracy: 0.9629777070063694 

The current subspace-distance is: 8.467042789561674e-06 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.05; acc: 1.0
Batch: 20; loss: 0.27; acc: 0.92
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.14; acc: 0.97
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.14; acc: 0.98
Batch: 120; loss: 0.15; acc: 0.94
Batch: 140; loss: 0.09; acc: 0.97
Batch: 160; loss: 0.08; acc: 0.95
Batch: 180; loss: 0.17; acc: 0.92
Batch: 200; loss: 0.16; acc: 0.95
Batch: 220; loss: 0.25; acc: 0.94
Batch: 240; loss: 0.13; acc: 0.95
Batch: 260; loss: 0.06; acc: 0.98
Batch: 280; loss: 0.17; acc: 0.97
Batch: 300; loss: 0.05; acc: 0.98
Batch: 320; loss: 0.06; acc: 0.98
Batch: 340; loss: 0.07; acc: 0.97
Batch: 360; loss: 0.25; acc: 0.95
Batch: 380; loss: 0.14; acc: 0.98
Batch: 400; loss: 0.25; acc: 0.92
Batch: 420; loss: 0.12; acc: 0.95
Batch: 440; loss: 0.2; acc: 0.92
Batch: 460; loss: 0.16; acc: 0.94
Batch: 480; loss: 0.06; acc: 0.97
Batch: 500; loss: 0.05; acc: 0.98
Batch: 520; loss: 0.1; acc: 0.97
Batch: 540; loss: 0.08; acc: 0.95
Batch: 560; loss: 0.15; acc: 0.94
Batch: 580; loss: 0.15; acc: 0.94
Batch: 600; loss: 0.1; acc: 0.97
Batch: 620; loss: 0.03; acc: 1.0
Batch: 640; loss: 0.05; acc: 0.98
Batch: 660; loss: 0.1; acc: 0.98
Batch: 680; loss: 0.09; acc: 0.94
Batch: 700; loss: 0.19; acc: 0.95
Batch: 720; loss: 0.23; acc: 0.91
Batch: 740; loss: 0.05; acc: 0.97
Batch: 760; loss: 0.02; acc: 1.0
Batch: 780; loss: 0.02; acc: 1.0
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

2.7270274586044252e-05
7.97522716311505e-06
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.13; acc: 0.97
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.24; acc: 0.95
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.09; acc: 0.95
Batch: 120; loss: 0.17; acc: 0.92
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1303901522165271; val_accuracy: 0.9629777070063694 

The current subspace-distance is: 7.97522716311505e-06 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.18; acc: 0.97
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.12; acc: 0.94
Batch: 120; loss: 0.29; acc: 0.94
Batch: 140; loss: 0.1; acc: 0.95
Batch: 160; loss: 0.29; acc: 0.92
Batch: 180; loss: 0.1; acc: 0.97
Batch: 200; loss: 0.09; acc: 0.98
Batch: 220; loss: 0.09; acc: 0.95
Batch: 240; loss: 0.14; acc: 0.97
Batch: 260; loss: 0.05; acc: 1.0
Batch: 280; loss: 0.03; acc: 1.0
Batch: 300; loss: 0.03; acc: 0.98
Batch: 320; loss: 0.22; acc: 0.91
Batch: 340; loss: 0.05; acc: 0.98
Batch: 360; loss: 0.12; acc: 0.97
Batch: 380; loss: 0.04; acc: 1.0
Batch: 400; loss: 0.2; acc: 0.89
Batch: 420; loss: 0.08; acc: 0.97
Batch: 440; loss: 0.1; acc: 0.97
Batch: 460; loss: 0.09; acc: 0.94
Batch: 480; loss: 0.07; acc: 0.97
Batch: 500; loss: 0.2; acc: 0.94
Batch: 520; loss: 0.37; acc: 0.91
Batch: 540; loss: 0.11; acc: 0.95
Batch: 560; loss: 0.11; acc: 0.95
Batch: 580; loss: 0.09; acc: 0.98
Batch: 600; loss: 0.19; acc: 0.94
Batch: 620; loss: 0.06; acc: 0.98
Batch: 640; loss: 0.16; acc: 0.97
Batch: 660; loss: 0.09; acc: 0.97
Batch: 680; loss: 0.11; acc: 0.95
Batch: 700; loss: 0.19; acc: 0.94
Batch: 720; loss: 0.12; acc: 0.95
Batch: 740; loss: 0.09; acc: 0.95
Batch: 760; loss: 0.15; acc: 0.95
Batch: 780; loss: 0.16; acc: 0.95
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

2.6852107112063095e-05
8.34403090266278e-06
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.13; acc: 0.97
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.09; acc: 0.95
Batch: 120; loss: 0.16; acc: 0.94
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.13047423628959687; val_accuracy: 0.961484872611465 

The current subspace-distance is: 8.34403090266278e-06 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.31; acc: 0.92
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.15; acc: 0.95
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.14; acc: 0.98
Batch: 120; loss: 0.11; acc: 0.92
Batch: 140; loss: 0.14; acc: 0.95
Batch: 160; loss: 0.08; acc: 0.97
Batch: 180; loss: 0.08; acc: 0.98
Batch: 200; loss: 0.1; acc: 0.92
Batch: 220; loss: 0.1; acc: 0.95
Batch: 240; loss: 0.24; acc: 0.95
Batch: 260; loss: 0.25; acc: 0.94
Batch: 280; loss: 0.08; acc: 0.98
Batch: 300; loss: 0.18; acc: 0.95
Batch: 320; loss: 0.05; acc: 0.98
Batch: 340; loss: 0.05; acc: 0.98
Batch: 360; loss: 0.05; acc: 0.98
Batch: 380; loss: 0.1; acc: 0.97
Batch: 400; loss: 0.07; acc: 0.97
Batch: 420; loss: 0.12; acc: 0.95
Batch: 440; loss: 0.07; acc: 0.98
Batch: 460; loss: 0.09; acc: 0.95
Batch: 480; loss: 0.05; acc: 0.98
Batch: 500; loss: 0.09; acc: 0.97
Batch: 520; loss: 0.2; acc: 0.94
Batch: 540; loss: 0.27; acc: 0.94
Batch: 560; loss: 0.12; acc: 0.95
Batch: 580; loss: 0.22; acc: 0.94
Batch: 600; loss: 0.14; acc: 0.95
Batch: 620; loss: 0.11; acc: 0.97
Batch: 640; loss: 0.07; acc: 0.97
Batch: 660; loss: 0.12; acc: 0.95
Batch: 680; loss: 0.12; acc: 0.97
Batch: 700; loss: 0.11; acc: 0.97
Batch: 720; loss: 0.22; acc: 0.92
Batch: 740; loss: 0.19; acc: 0.94
Batch: 760; loss: 0.22; acc: 0.95
Batch: 780; loss: 0.09; acc: 0.95
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

2.740198942774441e-05
7.984068361110985e-06
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.13; acc: 0.97
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.09; acc: 0.95
Batch: 120; loss: 0.16; acc: 0.94
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.13013046647712684; val_accuracy: 0.963077229299363 

The current subspace-distance is: 7.984068361110985e-06 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.11; acc: 0.98
Batch: 20; loss: 0.12; acc: 0.95
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.3; acc: 0.95
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.15; acc: 0.98
Batch: 140; loss: 0.27; acc: 0.95
Batch: 160; loss: 0.14; acc: 0.94
Batch: 180; loss: 0.19; acc: 0.91
Batch: 200; loss: 0.06; acc: 0.98
Batch: 220; loss: 0.09; acc: 0.97
Batch: 240; loss: 0.15; acc: 0.95
Batch: 260; loss: 0.21; acc: 0.94
Batch: 280; loss: 0.08; acc: 0.97
Batch: 300; loss: 0.12; acc: 0.95
Batch: 320; loss: 0.3; acc: 0.95
Batch: 340; loss: 0.13; acc: 0.98
Batch: 360; loss: 0.09; acc: 0.97
Batch: 380; loss: 0.13; acc: 0.95
Batch: 400; loss: 0.28; acc: 0.92
Batch: 420; loss: 0.09; acc: 0.97
Batch: 440; loss: 0.16; acc: 0.94
Batch: 460; loss: 0.08; acc: 0.98
Batch: 480; loss: 0.22; acc: 0.95
Batch: 500; loss: 0.31; acc: 0.92
Batch: 520; loss: 0.16; acc: 0.97
Batch: 540; loss: 0.07; acc: 0.97
Batch: 560; loss: 0.11; acc: 0.97
Batch: 580; loss: 0.23; acc: 0.94
Batch: 600; loss: 0.16; acc: 0.95
Batch: 620; loss: 0.04; acc: 0.98
Batch: 640; loss: 0.16; acc: 0.95
Batch: 660; loss: 0.15; acc: 0.95
Batch: 680; loss: 0.12; acc: 0.97
Batch: 700; loss: 0.06; acc: 0.97
Batch: 720; loss: 0.09; acc: 0.95
Batch: 740; loss: 0.28; acc: 0.91
Batch: 760; loss: 0.07; acc: 0.97
Batch: 780; loss: 0.06; acc: 0.98
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

2.7007143216906115e-05
8.282135240733624e-06
Batch: 0; loss: 0.04; acc: 0.97
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.24; acc: 0.95
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.09; acc: 0.95
Batch: 120; loss: 0.17; acc: 0.92
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1303495215667281; val_accuracy: 0.9637738853503185 

The current subspace-distance is: 8.282135240733624e-06 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.1; acc: 0.95
Batch: 20; loss: 0.05; acc: 0.98
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.14; acc: 0.97
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.11; acc: 0.98
Batch: 120; loss: 0.07; acc: 0.97
Batch: 140; loss: 0.12; acc: 0.97
Batch: 160; loss: 0.05; acc: 0.98
Batch: 180; loss: 0.09; acc: 0.95
Batch: 200; loss: 0.09; acc: 0.97
Batch: 220; loss: 0.04; acc: 0.98
Batch: 240; loss: 0.28; acc: 0.89
Batch: 260; loss: 0.23; acc: 0.95
Batch: 280; loss: 0.33; acc: 0.91
Batch: 300; loss: 0.13; acc: 0.94
Batch: 320; loss: 0.16; acc: 0.95
Batch: 340; loss: 0.06; acc: 0.98
Batch: 360; loss: 0.18; acc: 0.97
Batch: 380; loss: 0.05; acc: 0.97
Batch: 400; loss: 0.08; acc: 0.97
Batch: 420; loss: 0.15; acc: 0.97
Batch: 440; loss: 0.12; acc: 0.94
Batch: 460; loss: 0.08; acc: 0.97
Batch: 480; loss: 0.11; acc: 0.97
Batch: 500; loss: 0.08; acc: 0.98
Batch: 520; loss: 0.08; acc: 0.97
Batch: 540; loss: 0.06; acc: 0.98
Batch: 560; loss: 0.02; acc: 1.0
Batch: 580; loss: 0.1; acc: 0.97
Batch: 600; loss: 0.23; acc: 0.95
Batch: 620; loss: 0.11; acc: 0.95
Batch: 640; loss: 0.04; acc: 1.0
Batch: 660; loss: 0.22; acc: 0.92
Batch: 680; loss: 0.21; acc: 0.95
Batch: 700; loss: 0.11; acc: 0.95
Batch: 720; loss: 0.42; acc: 0.86
Batch: 740; loss: 0.27; acc: 0.92
Batch: 760; loss: 0.09; acc: 0.95
Batch: 780; loss: 0.18; acc: 0.94
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

2.6917332434095442e-05
8.520300980308093e-06
Batch: 0; loss: 0.04; acc: 0.97
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.24; acc: 0.95
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.09; acc: 0.95
Batch: 120; loss: 0.18; acc: 0.92
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.13058692935830468; val_accuracy: 0.9632762738853503 

The current subspace-distance is: 8.520300980308093e-06 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.07; acc: 0.95
Batch: 20; loss: 0.17; acc: 0.95
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.17; acc: 0.92
Batch: 140; loss: 0.09; acc: 0.95
Batch: 160; loss: 0.2; acc: 0.92
Batch: 180; loss: 0.06; acc: 0.97
Batch: 200; loss: 0.1; acc: 0.98
Batch: 220; loss: 0.06; acc: 0.97
Batch: 240; loss: 0.11; acc: 0.97
Batch: 260; loss: 0.08; acc: 0.97
Batch: 280; loss: 0.26; acc: 0.92
Batch: 300; loss: 0.3; acc: 0.91
Batch: 320; loss: 0.46; acc: 0.86
Batch: 340; loss: 0.03; acc: 1.0
Batch: 360; loss: 0.21; acc: 0.94
Batch: 380; loss: 0.22; acc: 0.91
Batch: 400; loss: 0.2; acc: 0.98
Batch: 420; loss: 0.12; acc: 0.98
Batch: 440; loss: 0.12; acc: 0.97
Batch: 460; loss: 0.17; acc: 0.95
Batch: 480; loss: 0.08; acc: 0.97
Batch: 500; loss: 0.15; acc: 0.95
Batch: 520; loss: 0.06; acc: 0.97
Batch: 540; loss: 0.25; acc: 0.94
Batch: 560; loss: 0.1; acc: 0.98
Batch: 580; loss: 0.11; acc: 0.94
Batch: 600; loss: 0.06; acc: 0.98
Batch: 620; loss: 0.23; acc: 0.94
Batch: 640; loss: 0.09; acc: 0.97
Batch: 660; loss: 0.1; acc: 0.97
Batch: 680; loss: 0.05; acc: 0.98
Batch: 700; loss: 0.18; acc: 0.94
Batch: 720; loss: 0.09; acc: 0.97
Batch: 740; loss: 0.08; acc: 0.98
Batch: 760; loss: 0.23; acc: 0.94
Batch: 780; loss: 0.14; acc: 0.95
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

2.720712473092135e-05
8.772734872763976e-06
Batch: 0; loss: 0.05; acc: 0.97
Batch: 20; loss: 0.14; acc: 0.94
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.1; acc: 0.95
Batch: 120; loss: 0.16; acc: 0.92
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.13286370916920862; val_accuracy: 0.9617834394904459 

The current subspace-distance is: 8.772734872763976e-06 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.05; acc: 1.0
Batch: 20; loss: 0.06; acc: 0.98
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.1; acc: 0.95
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.09; acc: 0.97
Batch: 140; loss: 0.15; acc: 0.95
Batch: 160; loss: 0.05; acc: 0.98
Batch: 180; loss: 0.15; acc: 0.95
Batch: 200; loss: 0.1; acc: 0.98
Batch: 220; loss: 0.08; acc: 0.97
Batch: 240; loss: 0.07; acc: 0.95
Batch: 260; loss: 0.14; acc: 0.94
Batch: 280; loss: 0.03; acc: 1.0
Batch: 300; loss: 0.07; acc: 0.97
Batch: 320; loss: 0.22; acc: 0.94
Batch: 340; loss: 0.19; acc: 0.98
Batch: 360; loss: 0.28; acc: 0.91
Batch: 380; loss: 0.12; acc: 0.98
Batch: 400; loss: 0.06; acc: 0.95
Batch: 420; loss: 0.12; acc: 0.97
Batch: 440; loss: 0.13; acc: 0.97
Batch: 460; loss: 0.09; acc: 0.95
Batch: 480; loss: 0.02; acc: 1.0
Batch: 500; loss: 0.02; acc: 1.0
Batch: 520; loss: 0.13; acc: 0.95
Batch: 540; loss: 0.17; acc: 0.92
Batch: 560; loss: 0.04; acc: 1.0
Batch: 580; loss: 0.08; acc: 0.97
Batch: 600; loss: 0.07; acc: 0.97
Batch: 620; loss: 0.12; acc: 0.95
Batch: 640; loss: 0.06; acc: 0.98
Batch: 660; loss: 0.13; acc: 0.95
Batch: 680; loss: 0.19; acc: 0.92
Batch: 700; loss: 0.16; acc: 0.95
Batch: 720; loss: 0.15; acc: 0.95
Batch: 740; loss: 0.09; acc: 0.98
Batch: 760; loss: 0.25; acc: 0.91
Batch: 780; loss: 0.19; acc: 0.98
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

2.6884195904131047e-05
8.75074965733802e-06
Batch: 0; loss: 0.04; acc: 0.97
Batch: 20; loss: 0.13; acc: 0.97
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.09; acc: 0.95
Batch: 120; loss: 0.17; acc: 0.95
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.13060450328478387; val_accuracy: 0.9637738853503185 

The current subspace-distance is: 8.75074965733802e-06 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.18; acc: 0.97
Batch: 20; loss: 0.08; acc: 0.97
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.05; acc: 1.0
Batch: 80; loss: 0.13; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.97
Batch: 120; loss: 0.15; acc: 0.95
Batch: 140; loss: 0.13; acc: 0.97
Batch: 160; loss: 0.09; acc: 0.97
Batch: 180; loss: 0.05; acc: 0.98
Batch: 200; loss: 0.13; acc: 0.98
Batch: 220; loss: 0.08; acc: 0.97
Batch: 240; loss: 0.12; acc: 0.97
Batch: 260; loss: 0.23; acc: 0.92
Batch: 280; loss: 0.22; acc: 0.94
Batch: 300; loss: 0.09; acc: 0.97
Batch: 320; loss: 0.07; acc: 0.98
Batch: 340; loss: 0.03; acc: 1.0
Batch: 360; loss: 0.08; acc: 0.98
Batch: 380; loss: 0.25; acc: 0.92
Batch: 400; loss: 0.1; acc: 0.94
Batch: 420; loss: 0.17; acc: 0.95
Batch: 440; loss: 0.09; acc: 0.97
Batch: 460; loss: 0.05; acc: 0.98
Batch: 480; loss: 0.15; acc: 0.97
Batch: 500; loss: 0.23; acc: 0.94
Batch: 520; loss: 0.05; acc: 0.97
Batch: 540; loss: 0.41; acc: 0.95
Batch: 560; loss: 0.17; acc: 0.95
Batch: 580; loss: 0.04; acc: 0.97
Batch: 600; loss: 0.15; acc: 0.95
Batch: 620; loss: 0.16; acc: 0.97
Batch: 640; loss: 0.05; acc: 0.97
Batch: 660; loss: 0.05; acc: 0.98
Batch: 680; loss: 0.18; acc: 0.97
Batch: 700; loss: 0.15; acc: 0.95
Batch: 720; loss: 0.1; acc: 0.97
Batch: 740; loss: 0.07; acc: 0.97
Batch: 760; loss: 0.12; acc: 0.94
Batch: 780; loss: 0.09; acc: 0.98
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

2.6736002837424167e-05
8.764251106185839e-06
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.14; acc: 0.97
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.24; acc: 0.95
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.09; acc: 0.95
Batch: 120; loss: 0.17; acc: 0.92
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.13019691865630212; val_accuracy: 0.9636743630573248 

The current subspace-distance is: 8.764251106185839e-06 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.19; acc: 0.92
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.02; acc: 1.0
Batch: 120; loss: 0.15; acc: 0.97
Batch: 140; loss: 0.08; acc: 0.98
Batch: 160; loss: 0.24; acc: 0.89
Batch: 180; loss: 0.12; acc: 0.95
Batch: 200; loss: 0.17; acc: 0.95
Batch: 220; loss: 0.11; acc: 0.95
Batch: 240; loss: 0.05; acc: 0.98
Batch: 260; loss: 0.1; acc: 0.94
Batch: 280; loss: 0.18; acc: 0.94
Batch: 300; loss: 0.09; acc: 0.95
Batch: 320; loss: 0.03; acc: 1.0
Batch: 340; loss: 0.18; acc: 0.92
Batch: 360; loss: 0.13; acc: 0.94
Batch: 380; loss: 0.06; acc: 0.98
Batch: 400; loss: 0.09; acc: 0.97
Batch: 420; loss: 0.14; acc: 0.97
Batch: 440; loss: 0.15; acc: 0.95
Batch: 460; loss: 0.07; acc: 0.95
Batch: 480; loss: 0.1; acc: 0.97
Batch: 500; loss: 0.06; acc: 0.98
Batch: 520; loss: 0.26; acc: 0.91
Batch: 540; loss: 0.11; acc: 0.97
Batch: 560; loss: 0.07; acc: 0.97
Batch: 580; loss: 0.03; acc: 1.0
Batch: 600; loss: 0.19; acc: 0.95
Batch: 620; loss: 0.02; acc: 1.0
Batch: 640; loss: 0.28; acc: 0.92
Batch: 660; loss: 0.03; acc: 1.0
Batch: 680; loss: 0.09; acc: 0.95
Batch: 700; loss: 0.08; acc: 0.98
Batch: 720; loss: 0.1; acc: 0.97
Batch: 740; loss: 0.08; acc: 0.97
Batch: 760; loss: 0.18; acc: 0.95
Batch: 780; loss: 0.22; acc: 0.91
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

2.721544478845317e-05
8.539724149159156e-06
Batch: 0; loss: 0.04; acc: 0.97
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.24; acc: 0.95
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.09; acc: 0.95
Batch: 120; loss: 0.17; acc: 0.94
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.13064590730010325; val_accuracy: 0.9634753184713376 

The current subspace-distance is: 8.539724149159156e-06 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.12; acc: 0.98
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.22; acc: 0.98
Batch: 100; loss: 0.13; acc: 0.98
Batch: 120; loss: 0.12; acc: 0.97
Batch: 140; loss: 0.08; acc: 0.98
Batch: 160; loss: 0.11; acc: 0.95
Batch: 180; loss: 0.09; acc: 0.97
Batch: 200; loss: 0.2; acc: 0.95
Batch: 220; loss: 0.08; acc: 1.0
Batch: 240; loss: 0.15; acc: 0.95
Batch: 260; loss: 0.13; acc: 0.95
Batch: 280; loss: 0.1; acc: 0.95
Batch: 300; loss: 0.08; acc: 0.97
Batch: 320; loss: 0.06; acc: 0.98
Batch: 340; loss: 0.13; acc: 0.97
Batch: 360; loss: 0.12; acc: 0.95
Batch: 380; loss: 0.12; acc: 0.95
Batch: 400; loss: 0.19; acc: 0.94
Batch: 420; loss: 0.18; acc: 0.95
Batch: 440; loss: 0.11; acc: 0.97
Batch: 460; loss: 0.15; acc: 0.97
Batch: 480; loss: 0.29; acc: 0.94
Batch: 500; loss: 0.17; acc: 0.95
Batch: 520; loss: 0.18; acc: 0.95
Batch: 540; loss: 0.28; acc: 0.94
Batch: 560; loss: 0.23; acc: 0.95
Batch: 580; loss: 0.25; acc: 0.95
Batch: 600; loss: 0.28; acc: 0.94
Batch: 620; loss: 0.13; acc: 0.97
Batch: 640; loss: 0.13; acc: 0.95
Batch: 660; loss: 0.04; acc: 1.0
Batch: 680; loss: 0.08; acc: 0.97
Batch: 700; loss: 0.17; acc: 0.97
Batch: 720; loss: 0.04; acc: 0.98
Batch: 740; loss: 0.15; acc: 0.97
Batch: 760; loss: 0.06; acc: 0.98
Batch: 780; loss: 0.11; acc: 0.95
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

2.715191658353433e-05
8.480364158458542e-06
Batch: 0; loss: 0.04; acc: 0.97
Batch: 20; loss: 0.13; acc: 0.97
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.1; acc: 0.95
Batch: 120; loss: 0.15; acc: 0.95
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1304305718298171; val_accuracy: 0.9636743630573248 

The current subspace-distance is: 8.480364158458542e-06 

plots/subspace_training/reg_lenet_3/2020-01-22 20:51:04/d_dim_300_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
nonzero elements in E: 74708
elements in E: 15746500
fraction nonzero: 0.004744419394786143
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.31; acc: 0.08
Batch: 20; loss: 2.29; acc: 0.05
Batch: 40; loss: 2.3; acc: 0.09
Batch: 60; loss: 2.3; acc: 0.02
Batch: 80; loss: 2.3; acc: 0.08
Batch: 100; loss: 2.29; acc: 0.12
Batch: 120; loss: 2.3; acc: 0.11
Batch: 140; loss: 2.31; acc: 0.08
Batch: 160; loss: 2.3; acc: 0.08
Batch: 180; loss: 2.29; acc: 0.11
Batch: 200; loss: 2.28; acc: 0.14
Batch: 220; loss: 2.29; acc: 0.06
Batch: 240; loss: 2.28; acc: 0.05
Batch: 260; loss: 2.27; acc: 0.12
Batch: 280; loss: 2.25; acc: 0.19
Batch: 300; loss: 2.23; acc: 0.16
Batch: 320; loss: 2.21; acc: 0.17
Batch: 340; loss: 2.16; acc: 0.25
Batch: 360; loss: 2.1; acc: 0.34
Batch: 380; loss: 1.9; acc: 0.5
Batch: 400; loss: 1.68; acc: 0.48
Batch: 420; loss: 1.27; acc: 0.64
Batch: 440; loss: 1.53; acc: 0.45
Batch: 460; loss: 0.99; acc: 0.75
Batch: 480; loss: 1.38; acc: 0.56
Batch: 500; loss: 1.0; acc: 0.69
Batch: 520; loss: 0.86; acc: 0.58
Batch: 540; loss: 0.57; acc: 0.8
Batch: 560; loss: 0.53; acc: 0.84
Batch: 580; loss: 0.72; acc: 0.72
Batch: 600; loss: 0.6; acc: 0.8
Batch: 620; loss: 0.98; acc: 0.72
Batch: 640; loss: 0.87; acc: 0.75
Batch: 660; loss: 0.62; acc: 0.8
Batch: 680; loss: 0.59; acc: 0.81
Batch: 700; loss: 0.78; acc: 0.75
Batch: 720; loss: 0.48; acc: 0.84
Batch: 740; loss: 0.54; acc: 0.83
Batch: 760; loss: 0.63; acc: 0.83
Batch: 780; loss: 0.64; acc: 0.77
Train Epoch over. train_loss: 1.54; train_accuracy: 0.44 

1.2138846614107024e-05
4.485839326662244e-06
Batch: 0; loss: 0.65; acc: 0.8
Batch: 20; loss: 1.04; acc: 0.64
Batch: 40; loss: 0.3; acc: 0.88
Batch: 60; loss: 0.74; acc: 0.78
Batch: 80; loss: 0.43; acc: 0.83
Batch: 100; loss: 0.47; acc: 0.86
Batch: 120; loss: 1.01; acc: 0.64
Batch: 140; loss: 0.46; acc: 0.75
Val Epoch over. val_loss: 0.5782215155803474; val_accuracy: 0.8067277070063694 

The current subspace-distance is: 4.485839326662244e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 0.65; acc: 0.8
Batch: 20; loss: 0.46; acc: 0.81
Batch: 40; loss: 0.51; acc: 0.84
Batch: 60; loss: 0.41; acc: 0.89
Batch: 80; loss: 0.58; acc: 0.86
Batch: 100; loss: 0.4; acc: 0.83
Batch: 120; loss: 0.56; acc: 0.86
Batch: 140; loss: 0.45; acc: 0.84
Batch: 160; loss: 0.48; acc: 0.86
Batch: 180; loss: 0.34; acc: 0.86
Batch: 200; loss: 0.39; acc: 0.84
Batch: 220; loss: 0.68; acc: 0.83
Batch: 240; loss: 0.51; acc: 0.84
Batch: 260; loss: 0.35; acc: 0.89
Batch: 280; loss: 0.39; acc: 0.86
Batch: 300; loss: 0.35; acc: 0.89
Batch: 320; loss: 0.35; acc: 0.94
Batch: 340; loss: 0.61; acc: 0.83
Batch: 360; loss: 0.53; acc: 0.84
Batch: 380; loss: 0.32; acc: 0.91
Batch: 400; loss: 0.26; acc: 0.94
Batch: 420; loss: 0.34; acc: 0.88
Batch: 440; loss: 0.85; acc: 0.81
Batch: 460; loss: 0.39; acc: 0.88
Batch: 480; loss: 0.24; acc: 0.91
Batch: 500; loss: 0.29; acc: 0.91
Batch: 520; loss: 0.28; acc: 0.89
Batch: 540; loss: 0.17; acc: 0.95
Batch: 560; loss: 0.35; acc: 0.89
Batch: 580; loss: 0.16; acc: 0.97
Batch: 600; loss: 0.46; acc: 0.83
Batch: 620; loss: 0.2; acc: 0.95
Batch: 640; loss: 0.57; acc: 0.86
Batch: 660; loss: 0.5; acc: 0.84
Batch: 680; loss: 0.43; acc: 0.83
Batch: 700; loss: 0.28; acc: 0.88
Batch: 720; loss: 0.32; acc: 0.88
Batch: 740; loss: 0.38; acc: 0.94
Batch: 760; loss: 0.5; acc: 0.8
Batch: 780; loss: 0.48; acc: 0.86
Train Epoch over. train_loss: 0.41; train_accuracy: 0.87 

1.909896673168987e-05
6.081225819798419e-06
Batch: 0; loss: 0.22; acc: 0.91
Batch: 20; loss: 0.42; acc: 0.84
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.48; acc: 0.88
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.45; acc: 0.8
Batch: 140; loss: 0.09; acc: 0.98
Val Epoch over. val_loss: 0.2775760691399407; val_accuracy: 0.9140127388535032 

The current subspace-distance is: 6.081225819798419e-06 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.36; acc: 0.88
Batch: 20; loss: 0.24; acc: 0.95
Batch: 40; loss: 0.16; acc: 0.97
Batch: 60; loss: 0.31; acc: 0.86
Batch: 80; loss: 0.34; acc: 0.88
Batch: 100; loss: 0.42; acc: 0.89
Batch: 120; loss: 0.35; acc: 0.86
Batch: 140; loss: 0.36; acc: 0.89
Batch: 160; loss: 0.19; acc: 0.95
Batch: 180; loss: 0.15; acc: 0.94
Batch: 200; loss: 0.26; acc: 0.92
Batch: 220; loss: 0.37; acc: 0.92
Batch: 240; loss: 0.52; acc: 0.84
Batch: 260; loss: 0.29; acc: 0.91
Batch: 280; loss: 0.23; acc: 0.92
Batch: 300; loss: 0.27; acc: 0.95
Batch: 320; loss: 0.34; acc: 0.92
Batch: 340; loss: 0.21; acc: 0.95
Batch: 360; loss: 0.2; acc: 0.94
Batch: 380; loss: 0.32; acc: 0.94
Batch: 400; loss: 0.45; acc: 0.89
Batch: 420; loss: 0.36; acc: 0.84
Batch: 440; loss: 0.2; acc: 0.95
Batch: 460; loss: 0.33; acc: 0.91
Batch: 480; loss: 0.34; acc: 0.91
Batch: 500; loss: 0.39; acc: 0.88
Batch: 520; loss: 0.1; acc: 1.0
Batch: 540; loss: 0.21; acc: 0.95
Batch: 560; loss: 0.31; acc: 0.92
Batch: 580; loss: 0.2; acc: 0.94
Batch: 600; loss: 0.28; acc: 0.92
Batch: 620; loss: 0.43; acc: 0.81
Batch: 640; loss: 0.19; acc: 0.92
Batch: 660; loss: 0.24; acc: 0.91
Batch: 680; loss: 0.3; acc: 0.91
Batch: 700; loss: 0.45; acc: 0.8
Batch: 720; loss: 0.1; acc: 0.98
Batch: 740; loss: 0.27; acc: 0.95
Batch: 760; loss: 0.23; acc: 0.92
Batch: 780; loss: 0.23; acc: 0.92
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

2.203149961133022e-05
7.217315669549862e-06
Batch: 0; loss: 0.15; acc: 0.98
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.09; acc: 0.95
Batch: 60; loss: 0.33; acc: 0.89
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.35; acc: 0.86
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.2007884746002164; val_accuracy: 0.9406847133757962 

The current subspace-distance is: 7.217315669549862e-06 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.18; acc: 0.92
Batch: 40; loss: 0.24; acc: 0.89
Batch: 60; loss: 0.2; acc: 0.91
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.08; acc: 0.97
Batch: 120; loss: 0.14; acc: 0.97
Batch: 140; loss: 0.14; acc: 0.97
Batch: 160; loss: 0.21; acc: 0.95
Batch: 180; loss: 0.16; acc: 0.95
Batch: 200; loss: 0.23; acc: 0.95
Batch: 220; loss: 0.47; acc: 0.91
Batch: 240; loss: 0.26; acc: 0.91
Batch: 260; loss: 0.06; acc: 1.0
Batch: 280; loss: 0.22; acc: 0.94
Batch: 300; loss: 0.26; acc: 0.92
Batch: 320; loss: 0.36; acc: 0.91
Batch: 340; loss: 0.16; acc: 0.95
Batch: 360; loss: 0.17; acc: 0.94
Batch: 380; loss: 0.11; acc: 0.97
Batch: 400; loss: 0.26; acc: 0.89
Batch: 420; loss: 0.26; acc: 0.89
Batch: 440; loss: 0.12; acc: 0.95
Batch: 460; loss: 0.17; acc: 0.97
Batch: 480; loss: 0.25; acc: 0.91
Batch: 500; loss: 0.16; acc: 0.97
Batch: 520; loss: 0.21; acc: 0.91
Batch: 540; loss: 0.13; acc: 0.97
Batch: 560; loss: 0.28; acc: 0.88
Batch: 580; loss: 0.23; acc: 0.91
Batch: 600; loss: 0.24; acc: 0.92
Batch: 620; loss: 0.29; acc: 0.94
Batch: 640; loss: 0.26; acc: 0.94
Batch: 660; loss: 0.33; acc: 0.89
Batch: 680; loss: 0.3; acc: 0.94
Batch: 700; loss: 0.14; acc: 0.97
Batch: 720; loss: 0.32; acc: 0.89
Batch: 740; loss: 0.22; acc: 0.97
Batch: 760; loss: 0.12; acc: 0.95
Batch: 780; loss: 0.06; acc: 0.98
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.3751113985781558e-05
7.722685040789656e-06
Batch: 0; loss: 0.21; acc: 0.97
Batch: 20; loss: 0.24; acc: 0.91
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.15; acc: 0.94
Batch: 100; loss: 0.32; acc: 0.86
Batch: 120; loss: 0.38; acc: 0.88
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.290852021070043; val_accuracy: 0.9079418789808917 

The current subspace-distance is: 7.722685040789656e-06 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.34; acc: 0.89
Batch: 60; loss: 0.19; acc: 0.92
Batch: 80; loss: 0.39; acc: 0.91
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.15; acc: 0.97
Batch: 140; loss: 0.14; acc: 0.97
Batch: 160; loss: 0.13; acc: 0.98
Batch: 180; loss: 0.14; acc: 0.95
Batch: 200; loss: 0.08; acc: 0.97
Batch: 220; loss: 0.11; acc: 0.97
Batch: 240; loss: 0.21; acc: 0.92
Batch: 260; loss: 0.14; acc: 0.94
Batch: 280; loss: 0.16; acc: 0.97
Batch: 300; loss: 0.12; acc: 0.97
Batch: 320; loss: 0.07; acc: 0.98
Batch: 340; loss: 0.12; acc: 0.95
Batch: 360; loss: 0.25; acc: 0.92
Batch: 380; loss: 0.08; acc: 0.98
Batch: 400; loss: 0.22; acc: 0.95
Batch: 420; loss: 0.11; acc: 0.98
Batch: 440; loss: 0.14; acc: 0.97
Batch: 460; loss: 0.11; acc: 0.95
Batch: 480; loss: 0.18; acc: 0.94
Batch: 500; loss: 0.13; acc: 0.98
Batch: 520; loss: 0.19; acc: 0.92
Batch: 540; loss: 0.1; acc: 0.97
Batch: 560; loss: 0.25; acc: 0.89
Batch: 580; loss: 0.29; acc: 0.94
Batch: 600; loss: 0.08; acc: 0.98
Batch: 620; loss: 0.17; acc: 0.97
Batch: 640; loss: 0.11; acc: 0.97
Batch: 660; loss: 0.38; acc: 0.92
Batch: 680; loss: 0.24; acc: 0.92
Batch: 700; loss: 0.18; acc: 0.92
Batch: 720; loss: 0.1; acc: 0.98
Batch: 740; loss: 0.13; acc: 0.95
Batch: 760; loss: 0.19; acc: 0.92
Batch: 780; loss: 0.2; acc: 0.92
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

2.5233552150893956e-05
7.904847734607756e-06
Batch: 0; loss: 0.16; acc: 0.94
Batch: 20; loss: 0.33; acc: 0.86
Batch: 40; loss: 0.04; acc: 1.0
Batch: 60; loss: 0.31; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.16; acc: 0.97
Batch: 120; loss: 0.36; acc: 0.89
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.23311238807098122; val_accuracy: 0.9282444267515924 

The current subspace-distance is: 7.904847734607756e-06 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.24; acc: 0.89
Batch: 20; loss: 0.11; acc: 0.98
Batch: 40; loss: 0.3; acc: 0.88
Batch: 60; loss: 0.15; acc: 0.95
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.28; acc: 0.88
Batch: 120; loss: 0.12; acc: 0.97
Batch: 140; loss: 0.24; acc: 0.89
Batch: 160; loss: 0.11; acc: 0.97
Batch: 180; loss: 0.12; acc: 0.97
Batch: 200; loss: 0.19; acc: 0.92
Batch: 220; loss: 0.07; acc: 0.98
Batch: 240; loss: 0.33; acc: 0.92
Batch: 260; loss: 0.27; acc: 0.92
Batch: 280; loss: 0.07; acc: 0.98
Batch: 300; loss: 0.25; acc: 0.94
Batch: 320; loss: 0.18; acc: 0.94
Batch: 340; loss: 0.22; acc: 0.94
Batch: 360; loss: 0.28; acc: 0.91
Batch: 380; loss: 0.25; acc: 0.91
Batch: 400; loss: 0.06; acc: 0.97
Batch: 420; loss: 0.05; acc: 0.98
Batch: 440; loss: 0.16; acc: 0.92
Batch: 460; loss: 0.16; acc: 0.95
Batch: 480; loss: 0.13; acc: 0.94
Batch: 500; loss: 0.07; acc: 0.98
Batch: 520; loss: 0.11; acc: 0.97
Batch: 540; loss: 0.11; acc: 0.97
Batch: 560; loss: 0.22; acc: 0.95
Batch: 580; loss: 0.14; acc: 0.94
Batch: 600; loss: 0.13; acc: 0.95
Batch: 620; loss: 0.06; acc: 0.98
Batch: 640; loss: 0.22; acc: 0.94
Batch: 660; loss: 0.41; acc: 0.89
Batch: 680; loss: 0.08; acc: 0.98
Batch: 700; loss: 0.08; acc: 0.98
Batch: 720; loss: 0.41; acc: 0.88
Batch: 740; loss: 0.09; acc: 0.95
Batch: 760; loss: 0.2; acc: 0.92
Batch: 780; loss: 0.12; acc: 0.95
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

2.64387927018106e-05
9.083389159059152e-06
Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.05; acc: 0.98
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.27; acc: 0.89
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.25; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.17358780441105745; val_accuracy: 0.9467555732484076 

The current subspace-distance is: 9.083389159059152e-06 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.39; acc: 0.88
Batch: 20; loss: 0.05; acc: 0.98
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.14; acc: 0.92
Batch: 100; loss: 0.17; acc: 0.97
Batch: 120; loss: 0.1; acc: 0.95
Batch: 140; loss: 0.13; acc: 0.97
Batch: 160; loss: 0.33; acc: 0.89
Batch: 180; loss: 0.12; acc: 0.95
Batch: 200; loss: 0.29; acc: 0.94
Batch: 220; loss: 0.17; acc: 0.91
Batch: 240; loss: 0.23; acc: 0.94
Batch: 260; loss: 0.27; acc: 0.92
Batch: 280; loss: 0.17; acc: 0.91
Batch: 300; loss: 0.12; acc: 0.97
Batch: 320; loss: 0.08; acc: 1.0
Batch: 340; loss: 0.14; acc: 0.94
Batch: 360; loss: 0.23; acc: 0.94
Batch: 380; loss: 0.2; acc: 0.95
Batch: 400; loss: 0.18; acc: 0.92
Batch: 420; loss: 0.26; acc: 0.92
Batch: 440; loss: 0.26; acc: 0.94
Batch: 460; loss: 0.03; acc: 0.98
Batch: 480; loss: 0.08; acc: 0.98
Batch: 500; loss: 0.12; acc: 0.92
Batch: 520; loss: 0.08; acc: 0.95
Batch: 540; loss: 0.07; acc: 0.98
Batch: 560; loss: 0.13; acc: 0.95
Batch: 580; loss: 0.13; acc: 0.95
Batch: 600; loss: 0.05; acc: 1.0
Batch: 620; loss: 0.11; acc: 0.95
Batch: 640; loss: 0.3; acc: 0.94
Batch: 660; loss: 0.08; acc: 0.97
Batch: 680; loss: 0.09; acc: 0.98
Batch: 700; loss: 0.15; acc: 0.95
Batch: 720; loss: 0.08; acc: 0.97
Batch: 740; loss: 0.04; acc: 1.0
Batch: 760; loss: 0.16; acc: 0.97
Batch: 780; loss: 0.08; acc: 0.98
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

2.7167587177245878e-05
8.388176865992136e-06
Batch: 0; loss: 0.2; acc: 0.91
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.29; acc: 0.88
Batch: 80; loss: 0.17; acc: 0.97
Batch: 100; loss: 0.27; acc: 0.91
Batch: 120; loss: 0.41; acc: 0.81
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.22610068276144896; val_accuracy: 0.9242635350318471 

The current subspace-distance is: 8.388176865992136e-06 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.33; acc: 0.94
Batch: 20; loss: 0.04; acc: 0.98
Batch: 40; loss: 0.09; acc: 0.95
Batch: 60; loss: 0.18; acc: 0.92
Batch: 80; loss: 0.17; acc: 0.92
Batch: 100; loss: 0.05; acc: 1.0
Batch: 120; loss: 0.13; acc: 0.97
Batch: 140; loss: 0.14; acc: 0.92
Batch: 160; loss: 0.08; acc: 0.98
Batch: 180; loss: 0.1; acc: 0.97
Batch: 200; loss: 0.05; acc: 0.97
Batch: 220; loss: 0.13; acc: 0.95
Batch: 240; loss: 0.12; acc: 0.94
Batch: 260; loss: 0.06; acc: 0.98
Batch: 280; loss: 0.28; acc: 0.94
Batch: 300; loss: 0.25; acc: 0.89
Batch: 320; loss: 0.27; acc: 0.92
Batch: 340; loss: 0.29; acc: 0.95
Batch: 360; loss: 0.06; acc: 0.98
Batch: 380; loss: 0.03; acc: 1.0
Batch: 400; loss: 0.23; acc: 0.92
Batch: 420; loss: 0.03; acc: 1.0
Batch: 440; loss: 0.09; acc: 0.98
Batch: 460; loss: 0.11; acc: 0.95
Batch: 480; loss: 0.12; acc: 0.97
Batch: 500; loss: 0.12; acc: 0.97
Batch: 520; loss: 0.23; acc: 0.91
Batch: 540; loss: 0.1; acc: 0.95
Batch: 560; loss: 0.07; acc: 0.97
Batch: 580; loss: 0.19; acc: 0.95
Batch: 600; loss: 0.15; acc: 0.97
Batch: 620; loss: 0.17; acc: 0.95
Batch: 640; loss: 0.04; acc: 0.98
Batch: 660; loss: 0.11; acc: 0.97
Batch: 680; loss: 0.06; acc: 0.97
Batch: 700; loss: 0.06; acc: 0.97
Batch: 720; loss: 0.06; acc: 0.98
Batch: 740; loss: 0.07; acc: 0.98
Batch: 760; loss: 0.07; acc: 0.97
Batch: 780; loss: 0.11; acc: 0.98
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

2.8175900297355838e-05
9.178915206575766e-06
Batch: 0; loss: 0.16; acc: 0.94
Batch: 20; loss: 0.08; acc: 0.98
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.21; acc: 0.94
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.09; acc: 0.98
Batch: 120; loss: 0.32; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.13500470539946466; val_accuracy: 0.9590963375796179 

The current subspace-distance is: 9.178915206575766e-06 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.04; acc: 1.0
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.17; acc: 0.94
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.03; acc: 1.0
Batch: 120; loss: 0.07; acc: 0.97
Batch: 140; loss: 0.17; acc: 0.95
Batch: 160; loss: 0.17; acc: 0.97
Batch: 180; loss: 0.14; acc: 0.95
Batch: 200; loss: 0.1; acc: 0.97
Batch: 220; loss: 0.11; acc: 0.95
Batch: 240; loss: 0.09; acc: 0.97
Batch: 260; loss: 0.06; acc: 0.98
Batch: 280; loss: 0.27; acc: 0.94
Batch: 300; loss: 0.08; acc: 0.97
Batch: 320; loss: 0.13; acc: 0.95
Batch: 340; loss: 0.29; acc: 0.92
Batch: 360; loss: 0.2; acc: 0.94
Batch: 380; loss: 0.02; acc: 1.0
Batch: 400; loss: 0.07; acc: 0.98
Batch: 420; loss: 0.11; acc: 0.97
Batch: 440; loss: 0.14; acc: 0.97
Batch: 460; loss: 0.09; acc: 0.95
Batch: 480; loss: 0.39; acc: 0.91
Batch: 500; loss: 0.22; acc: 0.92
Batch: 520; loss: 0.19; acc: 0.95
Batch: 540; loss: 0.22; acc: 0.89
Batch: 560; loss: 0.12; acc: 0.95
Batch: 580; loss: 0.17; acc: 0.94
Batch: 600; loss: 0.11; acc: 0.95
Batch: 620; loss: 0.03; acc: 0.98
Batch: 640; loss: 0.2; acc: 0.91
Batch: 660; loss: 0.17; acc: 0.95
Batch: 680; loss: 0.17; acc: 0.94
Batch: 700; loss: 0.16; acc: 0.95
Batch: 720; loss: 0.05; acc: 1.0
Batch: 740; loss: 0.13; acc: 0.97
Batch: 760; loss: 0.12; acc: 0.98
Batch: 780; loss: 0.12; acc: 0.97
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

2.882516673707869e-05
9.301517820858862e-06
Batch: 0; loss: 0.06; acc: 0.97
Batch: 20; loss: 0.04; acc: 0.98
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.07; acc: 0.98
Batch: 120; loss: 0.23; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.11207883451489886; val_accuracy: 0.9674562101910829 

The current subspace-distance is: 9.301517820858862e-06 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.21; acc: 0.92
Batch: 60; loss: 0.09; acc: 0.95
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.12; acc: 0.95
Batch: 140; loss: 0.16; acc: 0.95
Batch: 160; loss: 0.03; acc: 0.98
Batch: 180; loss: 0.16; acc: 0.95
Batch: 200; loss: 0.07; acc: 0.98
Batch: 220; loss: 0.33; acc: 0.89
Batch: 240; loss: 0.09; acc: 0.95
Batch: 260; loss: 0.09; acc: 0.95
Batch: 280; loss: 0.04; acc: 0.98
Batch: 300; loss: 0.01; acc: 1.0
Batch: 320; loss: 0.24; acc: 0.91
Batch: 340; loss: 0.04; acc: 1.0
Batch: 360; loss: 0.05; acc: 0.98
Batch: 380; loss: 0.06; acc: 0.97
Batch: 400; loss: 0.2; acc: 0.95
Batch: 420; loss: 0.08; acc: 0.97
Batch: 440; loss: 0.2; acc: 0.95
Batch: 460; loss: 0.13; acc: 0.95
Batch: 480; loss: 0.06; acc: 0.98
Batch: 500; loss: 0.07; acc: 0.97
Batch: 520; loss: 0.14; acc: 0.95
Batch: 540; loss: 0.08; acc: 0.98
Batch: 560; loss: 0.11; acc: 0.98
Batch: 580; loss: 0.13; acc: 0.95
Batch: 600; loss: 0.02; acc: 1.0
Batch: 620; loss: 0.16; acc: 0.94
Batch: 640; loss: 0.12; acc: 0.97
Batch: 660; loss: 0.05; acc: 0.98
Batch: 680; loss: 0.05; acc: 0.98
Batch: 700; loss: 0.16; acc: 0.95
Batch: 720; loss: 0.24; acc: 0.89
Batch: 740; loss: 0.13; acc: 0.97
Batch: 760; loss: 0.11; acc: 0.95
Batch: 780; loss: 0.13; acc: 0.95
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

2.849033808161039e-05
9.08295714907581e-06
Batch: 0; loss: 0.3; acc: 0.92
Batch: 20; loss: 0.06; acc: 0.98
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.47; acc: 0.89
Batch: 80; loss: 0.06; acc: 0.97
Batch: 100; loss: 0.15; acc: 0.94
Batch: 120; loss: 0.4; acc: 0.86
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.2423333905305073; val_accuracy: 0.9217754777070064 

The current subspace-distance is: 9.08295714907581e-06 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.35; acc: 0.89
Batch: 20; loss: 0.12; acc: 0.94
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.13; acc: 0.97
Batch: 80; loss: 0.03; acc: 1.0
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.04; acc: 1.0
Batch: 140; loss: 0.14; acc: 0.97
Batch: 160; loss: 0.03; acc: 1.0
Batch: 180; loss: 0.12; acc: 0.94
Batch: 200; loss: 0.33; acc: 0.94
Batch: 220; loss: 0.1; acc: 0.95
Batch: 240; loss: 0.07; acc: 0.97
Batch: 260; loss: 0.08; acc: 0.97
Batch: 280; loss: 0.06; acc: 0.97
Batch: 300; loss: 0.03; acc: 1.0
Batch: 320; loss: 0.09; acc: 0.95
Batch: 340; loss: 0.1; acc: 0.94
Batch: 360; loss: 0.17; acc: 0.94
Batch: 380; loss: 0.19; acc: 0.95
Batch: 400; loss: 0.18; acc: 0.94
Batch: 420; loss: 0.05; acc: 1.0
Batch: 440; loss: 0.07; acc: 0.97
Batch: 460; loss: 0.04; acc: 1.0
Batch: 480; loss: 0.06; acc: 0.98
Batch: 500; loss: 0.13; acc: 0.94
Batch: 520; loss: 0.21; acc: 0.89
Batch: 540; loss: 0.12; acc: 0.94
Batch: 560; loss: 0.13; acc: 0.98
Batch: 580; loss: 0.09; acc: 0.97
Batch: 600; loss: 0.02; acc: 1.0
Batch: 620; loss: 0.12; acc: 0.98
Batch: 640; loss: 0.19; acc: 0.94
Batch: 660; loss: 0.18; acc: 0.97
Batch: 680; loss: 0.18; acc: 0.92
Batch: 700; loss: 0.08; acc: 0.97
Batch: 720; loss: 0.14; acc: 0.98
Batch: 740; loss: 0.06; acc: 0.98
Batch: 760; loss: 0.14; acc: 0.94
Batch: 780; loss: 0.04; acc: 0.98
Train Epoch over. train_loss: 0.11; train_accuracy: 0.97 

2.867474904633127e-05
8.564031304558739e-06
Batch: 0; loss: 0.06; acc: 0.95
Batch: 20; loss: 0.04; acc: 0.98
Batch: 40; loss: 0.04; acc: 0.97
Batch: 60; loss: 0.13; acc: 0.95
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.04; acc: 0.98
Batch: 120; loss: 0.2; acc: 0.94
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.10416083692745039; val_accuracy: 0.9689490445859873 

The current subspace-distance is: 8.564031304558739e-06 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.04; acc: 0.98
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.13; acc: 0.94
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.04; acc: 0.98
Batch: 140; loss: 0.25; acc: 0.97
Batch: 160; loss: 0.09; acc: 0.97
Batch: 180; loss: 0.02; acc: 1.0
Batch: 200; loss: 0.23; acc: 0.94
Batch: 220; loss: 0.12; acc: 0.97
Batch: 240; loss: 0.04; acc: 0.98
Batch: 260; loss: 0.05; acc: 0.98
Batch: 280; loss: 0.04; acc: 0.98
Batch: 300; loss: 0.03; acc: 0.98
Batch: 320; loss: 0.11; acc: 0.95
Batch: 340; loss: 0.13; acc: 0.94
Batch: 360; loss: 0.31; acc: 0.91
Batch: 380; loss: 0.18; acc: 0.97
Batch: 400; loss: 0.02; acc: 0.98
Batch: 420; loss: 0.07; acc: 0.95
Batch: 440; loss: 0.18; acc: 0.94
Batch: 460; loss: 0.24; acc: 0.91
Batch: 480; loss: 0.12; acc: 0.95
Batch: 500; loss: 0.15; acc: 0.97
Batch: 520; loss: 0.25; acc: 0.94
Batch: 540; loss: 0.1; acc: 0.97
Batch: 560; loss: 0.18; acc: 0.94
Batch: 580; loss: 0.06; acc: 0.95
Batch: 600; loss: 0.19; acc: 0.94
Batch: 620; loss: 0.23; acc: 0.95
Batch: 640; loss: 0.16; acc: 0.95
Batch: 660; loss: 0.09; acc: 0.95
Batch: 680; loss: 0.03; acc: 1.0
Batch: 700; loss: 0.04; acc: 0.98
Batch: 720; loss: 0.1; acc: 0.95
Batch: 740; loss: 0.13; acc: 0.95
Batch: 760; loss: 0.21; acc: 0.92
Batch: 780; loss: 0.08; acc: 0.98
Train Epoch over. train_loss: 0.1; train_accuracy: 0.97 

2.9506343707907945e-05
9.165730261884164e-06
Batch: 0; loss: 0.08; acc: 0.97
Batch: 20; loss: 0.06; acc: 0.98
Batch: 40; loss: 0.05; acc: 0.97
Batch: 60; loss: 0.17; acc: 0.95
Batch: 80; loss: 0.03; acc: 0.98
Batch: 100; loss: 0.06; acc: 0.95
Batch: 120; loss: 0.18; acc: 0.94
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.11493104505263696; val_accuracy: 0.9650676751592356 

The current subspace-distance is: 9.165730261884164e-06 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.06; acc: 0.98
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.04; acc: 0.98
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.08; acc: 0.98
Batch: 120; loss: 0.23; acc: 0.95
Batch: 140; loss: 0.02; acc: 1.0
Batch: 160; loss: 0.02; acc: 0.98
Batch: 180; loss: 0.09; acc: 0.97
Batch: 200; loss: 0.1; acc: 0.97
Batch: 220; loss: 0.04; acc: 0.98
Batch: 240; loss: 0.05; acc: 0.98
Batch: 260; loss: 0.05; acc: 0.98
Batch: 280; loss: 0.16; acc: 0.95
Batch: 300; loss: 0.16; acc: 0.95
Batch: 320; loss: 0.25; acc: 0.95
Batch: 340; loss: 0.03; acc: 0.98
Batch: 360; loss: 0.13; acc: 0.97
Batch: 380; loss: 0.1; acc: 0.94
Batch: 400; loss: 0.07; acc: 0.98
Batch: 420; loss: 0.01; acc: 1.0
Batch: 440; loss: 0.07; acc: 0.95
Batch: 460; loss: 0.08; acc: 0.97
Batch: 480; loss: 0.19; acc: 0.97
Batch: 500; loss: 0.04; acc: 0.98
Batch: 520; loss: 0.04; acc: 0.98
Batch: 540; loss: 0.17; acc: 0.94
Batch: 560; loss: 0.01; acc: 1.0
Batch: 580; loss: 0.07; acc: 0.98
Batch: 600; loss: 0.09; acc: 0.97
Batch: 620; loss: 0.23; acc: 0.97
Batch: 640; loss: 0.04; acc: 0.98
Batch: 660; loss: 0.19; acc: 0.97
Batch: 680; loss: 0.1; acc: 0.97
Batch: 700; loss: 0.13; acc: 0.97
Batch: 720; loss: 0.06; acc: 0.98
Batch: 740; loss: 0.06; acc: 0.97
Batch: 760; loss: 0.29; acc: 0.92
Batch: 780; loss: 0.16; acc: 0.97
Train Epoch over. train_loss: 0.1; train_accuracy: 0.97 

2.988897540490143e-05
9.782720553630497e-06
Batch: 0; loss: 0.07; acc: 0.95
Batch: 20; loss: 0.05; acc: 0.98
Batch: 40; loss: 0.04; acc: 0.97
Batch: 60; loss: 0.13; acc: 0.95
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.19; acc: 0.95
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.10970028913372261; val_accuracy: 0.9672571656050956 

The current subspace-distance is: 9.782720553630497e-06 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.07; acc: 0.98
Batch: 40; loss: 0.06; acc: 1.0
Batch: 60; loss: 0.04; acc: 1.0
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.12; acc: 0.98
Batch: 120; loss: 0.07; acc: 0.98
Batch: 140; loss: 0.11; acc: 0.97
Batch: 160; loss: 0.14; acc: 0.94
Batch: 180; loss: 0.02; acc: 1.0
Batch: 200; loss: 0.06; acc: 0.97
Batch: 220; loss: 0.26; acc: 0.94
Batch: 240; loss: 0.08; acc: 0.97
Batch: 260; loss: 0.12; acc: 0.95
Batch: 280; loss: 0.05; acc: 0.97
Batch: 300; loss: 0.09; acc: 0.97
Batch: 320; loss: 0.07; acc: 0.98
Batch: 340; loss: 0.18; acc: 0.94
Batch: 360; loss: 0.11; acc: 0.97
Batch: 380; loss: 0.08; acc: 0.97
Batch: 400; loss: 0.09; acc: 0.97
Batch: 420; loss: 0.04; acc: 0.98
Batch: 440; loss: 0.08; acc: 0.98
Batch: 460; loss: 0.18; acc: 0.95
Batch: 480; loss: 0.04; acc: 0.98
Batch: 500; loss: 0.06; acc: 0.95
Batch: 520; loss: 0.06; acc: 0.98
Batch: 540; loss: 0.03; acc: 1.0
Batch: 560; loss: 0.36; acc: 0.92
Batch: 580; loss: 0.17; acc: 0.97
Batch: 600; loss: 0.08; acc: 0.95
Batch: 620; loss: 0.24; acc: 0.94
Batch: 640; loss: 0.04; acc: 0.98
Batch: 660; loss: 0.08; acc: 0.97
Batch: 680; loss: 0.15; acc: 0.95
Batch: 700; loss: 0.26; acc: 0.95
Batch: 720; loss: 0.06; acc: 0.98
Batch: 740; loss: 0.05; acc: 0.98
Batch: 760; loss: 0.12; acc: 0.95
Batch: 780; loss: 0.2; acc: 0.95
Train Epoch over. train_loss: 0.1; train_accuracy: 0.97 

2.9714206903008744e-05
1.003613397188019e-05
Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.03; acc: 0.98
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.15; acc: 0.94
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.06; acc: 0.97
Batch: 120; loss: 0.18; acc: 0.92
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.10000084172103815; val_accuracy: 0.9694466560509554 

The current subspace-distance is: 1.003613397188019e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.15; acc: 0.94
Batch: 20; loss: 0.02; acc: 0.98
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.04; acc: 0.98
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.08; acc: 0.98
Batch: 120; loss: 0.07; acc: 0.97
Batch: 140; loss: 0.04; acc: 0.98
Batch: 160; loss: 0.08; acc: 0.95
Batch: 180; loss: 0.08; acc: 0.97
Batch: 200; loss: 0.22; acc: 0.97
Batch: 220; loss: 0.07; acc: 0.97
Batch: 240; loss: 0.16; acc: 0.95
Batch: 260; loss: 0.06; acc: 0.98
Batch: 280; loss: 0.06; acc: 0.97
Batch: 300; loss: 0.1; acc: 0.95
Batch: 320; loss: 0.29; acc: 0.91
Batch: 340; loss: 0.05; acc: 1.0
Batch: 360; loss: 0.06; acc: 0.98
Batch: 380; loss: 0.06; acc: 0.98
Batch: 400; loss: 0.19; acc: 0.95
Batch: 420; loss: 0.15; acc: 0.94
Batch: 440; loss: 0.09; acc: 0.98
Batch: 460; loss: 0.21; acc: 0.91
Batch: 480; loss: 0.03; acc: 1.0
Batch: 500; loss: 0.09; acc: 0.97
Batch: 520; loss: 0.07; acc: 0.95
Batch: 540; loss: 0.02; acc: 1.0
Batch: 560; loss: 0.11; acc: 0.95
Batch: 580; loss: 0.03; acc: 1.0
Batch: 600; loss: 0.12; acc: 0.94
Batch: 620; loss: 0.05; acc: 0.98
Batch: 640; loss: 0.1; acc: 0.97
Batch: 660; loss: 0.12; acc: 0.97
Batch: 680; loss: 0.08; acc: 0.97
Batch: 700; loss: 0.04; acc: 0.98
Batch: 720; loss: 0.14; acc: 0.95
Batch: 740; loss: 0.05; acc: 0.97
Batch: 760; loss: 0.12; acc: 0.95
Batch: 780; loss: 0.02; acc: 1.0
Train Epoch over. train_loss: 0.1; train_accuracy: 0.97 

3.051245766982902e-05
1.0270199709339067e-05
Batch: 0; loss: 0.09; acc: 0.95
Batch: 20; loss: 0.06; acc: 0.97
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.13; acc: 0.97
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.2; acc: 0.94
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.10588895228163452; val_accuracy: 0.9677547770700637 

The current subspace-distance is: 1.0270199709339067e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.08; acc: 0.95
Batch: 20; loss: 0.15; acc: 0.97
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.04; acc: 1.0
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.09; acc: 0.98
Batch: 140; loss: 0.02; acc: 1.0
Batch: 160; loss: 0.14; acc: 0.94
Batch: 180; loss: 0.2; acc: 0.95
Batch: 200; loss: 0.22; acc: 0.91
Batch: 220; loss: 0.06; acc: 0.98
Batch: 240; loss: 0.06; acc: 0.97
Batch: 260; loss: 0.06; acc: 0.98
Batch: 280; loss: 0.15; acc: 0.97
Batch: 300; loss: 0.08; acc: 0.98
Batch: 320; loss: 0.16; acc: 0.94
Batch: 340; loss: 0.17; acc: 0.95
Batch: 360; loss: 0.1; acc: 0.97
Batch: 380; loss: 0.15; acc: 0.94
Batch: 400; loss: 0.22; acc: 0.95
Batch: 420; loss: 0.21; acc: 0.95
Batch: 440; loss: 0.2; acc: 0.92
Batch: 460; loss: 0.04; acc: 0.98
Batch: 480; loss: 0.12; acc: 0.95
Batch: 500; loss: 0.2; acc: 0.94
Batch: 520; loss: 0.03; acc: 0.98
Batch: 540; loss: 0.09; acc: 0.98
Batch: 560; loss: 0.02; acc: 1.0
Batch: 580; loss: 0.06; acc: 0.97
Batch: 600; loss: 0.04; acc: 1.0
Batch: 620; loss: 0.04; acc: 0.98
Batch: 640; loss: 0.09; acc: 0.97
Batch: 660; loss: 0.05; acc: 0.97
Batch: 680; loss: 0.04; acc: 0.97
Batch: 700; loss: 0.15; acc: 0.92
Batch: 720; loss: 0.12; acc: 0.97
Batch: 740; loss: 0.06; acc: 0.97
Batch: 760; loss: 0.08; acc: 0.97
Batch: 780; loss: 0.1; acc: 0.95
Train Epoch over. train_loss: 0.1; train_accuracy: 0.97 

2.953888542833738e-05
9.415329259354621e-06
Batch: 0; loss: 0.08; acc: 0.95
Batch: 20; loss: 0.07; acc: 0.98
Batch: 40; loss: 0.04; acc: 0.97
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.11; acc: 0.94
Batch: 120; loss: 0.17; acc: 0.94
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.10477526633033327; val_accuracy: 0.9684514331210191 

The current subspace-distance is: 9.415329259354621e-06 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.07; acc: 0.95
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.07; acc: 0.98
Batch: 140; loss: 0.04; acc: 0.98
Batch: 160; loss: 0.29; acc: 0.92
Batch: 180; loss: 0.04; acc: 1.0
Batch: 200; loss: 0.13; acc: 0.97
Batch: 220; loss: 0.08; acc: 0.98
Batch: 240; loss: 0.17; acc: 0.94
Batch: 260; loss: 0.11; acc: 0.97
Batch: 280; loss: 0.06; acc: 0.97
Batch: 300; loss: 0.06; acc: 0.98
Batch: 320; loss: 0.06; acc: 0.98
Batch: 340; loss: 0.04; acc: 0.98
Batch: 360; loss: 0.12; acc: 0.95
Batch: 380; loss: 0.15; acc: 0.95
Batch: 400; loss: 0.22; acc: 0.92
Batch: 420; loss: 0.3; acc: 0.91
Batch: 440; loss: 0.17; acc: 0.95
Batch: 460; loss: 0.03; acc: 0.98
Batch: 480; loss: 0.02; acc: 1.0
Batch: 500; loss: 0.12; acc: 0.94
Batch: 520; loss: 0.11; acc: 0.94
Batch: 540; loss: 0.12; acc: 0.95
Batch: 560; loss: 0.22; acc: 0.94
Batch: 580; loss: 0.06; acc: 0.98
Batch: 600; loss: 0.06; acc: 0.98
Batch: 620; loss: 0.06; acc: 0.98
Batch: 640; loss: 0.08; acc: 0.98
Batch: 660; loss: 0.18; acc: 0.94
Batch: 680; loss: 0.04; acc: 0.97
Batch: 700; loss: 0.01; acc: 1.0
Batch: 720; loss: 0.04; acc: 0.98
Batch: 740; loss: 0.1; acc: 0.95
Batch: 760; loss: 0.11; acc: 0.95
Batch: 780; loss: 0.13; acc: 0.95
Train Epoch over. train_loss: 0.1; train_accuracy: 0.97 

3.082353214267641e-05
9.721228707348928e-06
Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.04; acc: 0.98
Batch: 40; loss: 0.03; acc: 0.97
Batch: 60; loss: 0.11; acc: 0.95
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.19; acc: 0.92
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.09350675617338745; val_accuracy: 0.9710390127388535 

The current subspace-distance is: 9.721228707348928e-06 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.04; acc: 0.98
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.13; acc: 0.97
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.16; acc: 0.91
Batch: 120; loss: 0.07; acc: 0.98
Batch: 140; loss: 0.05; acc: 1.0
Batch: 160; loss: 0.14; acc: 0.94
Batch: 180; loss: 0.09; acc: 0.95
Batch: 200; loss: 0.13; acc: 0.97
Batch: 220; loss: 0.05; acc: 0.97
Batch: 240; loss: 0.07; acc: 0.98
Batch: 260; loss: 0.2; acc: 0.94
Batch: 280; loss: 0.1; acc: 0.97
Batch: 300; loss: 0.14; acc: 0.95
Batch: 320; loss: 0.08; acc: 0.98
Batch: 340; loss: 0.09; acc: 0.97
Batch: 360; loss: 0.07; acc: 0.97
Batch: 380; loss: 0.02; acc: 1.0
Batch: 400; loss: 0.07; acc: 0.98
Batch: 420; loss: 0.12; acc: 0.97
Batch: 440; loss: 0.12; acc: 0.98
Batch: 460; loss: 0.08; acc: 0.97
Batch: 480; loss: 0.12; acc: 0.97
Batch: 500; loss: 0.17; acc: 0.95
Batch: 520; loss: 0.04; acc: 1.0
Batch: 540; loss: 0.05; acc: 0.98
Batch: 560; loss: 0.05; acc: 0.98
Batch: 580; loss: 0.17; acc: 0.95
Batch: 600; loss: 0.08; acc: 0.95
Batch: 620; loss: 0.02; acc: 1.0
Batch: 640; loss: 0.1; acc: 0.97
Batch: 660; loss: 0.11; acc: 0.98
Batch: 680; loss: 0.03; acc: 1.0
Batch: 700; loss: 0.11; acc: 0.97
Batch: 720; loss: 0.14; acc: 0.97
Batch: 740; loss: 0.12; acc: 0.97
Batch: 760; loss: 0.02; acc: 1.0
Batch: 780; loss: 0.1; acc: 0.95
Train Epoch over. train_loss: 0.1; train_accuracy: 0.97 

3.021171323780436e-05
9.725532436277717e-06
Batch: 0; loss: 0.08; acc: 0.97
Batch: 20; loss: 0.05; acc: 0.98
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.13; acc: 0.95
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.07; acc: 0.98
Batch: 120; loss: 0.16; acc: 0.94
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.09805815641999624; val_accuracy: 0.9705414012738853 

The current subspace-distance is: 9.725532436277717e-06 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.11; acc: 0.95
Batch: 20; loss: 0.03; acc: 1.0
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.08; acc: 0.97
Batch: 80; loss: 0.17; acc: 0.92
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.01; acc: 1.0
Batch: 140; loss: 0.13; acc: 0.94
Batch: 160; loss: 0.04; acc: 0.98
Batch: 180; loss: 0.19; acc: 0.95
Batch: 200; loss: 0.34; acc: 0.92
Batch: 220; loss: 0.29; acc: 0.94
Batch: 240; loss: 0.06; acc: 0.97
Batch: 260; loss: 0.09; acc: 0.95
Batch: 280; loss: 0.12; acc: 0.94
Batch: 300; loss: 0.06; acc: 0.98
Batch: 320; loss: 0.11; acc: 0.95
Batch: 340; loss: 0.06; acc: 0.98
Batch: 360; loss: 0.08; acc: 0.97
Batch: 380; loss: 0.01; acc: 1.0
Batch: 400; loss: 0.05; acc: 0.98
Batch: 420; loss: 0.07; acc: 0.98
Batch: 440; loss: 0.08; acc: 0.97
Batch: 460; loss: 0.02; acc: 1.0
Batch: 480; loss: 0.12; acc: 0.94
Batch: 500; loss: 0.19; acc: 0.95
Batch: 520; loss: 0.07; acc: 0.97
Batch: 540; loss: 0.05; acc: 0.98
Batch: 560; loss: 0.02; acc: 1.0
Batch: 580; loss: 0.16; acc: 0.94
Batch: 600; loss: 0.04; acc: 0.98
Batch: 620; loss: 0.09; acc: 0.98
Batch: 640; loss: 0.09; acc: 0.97
Batch: 660; loss: 0.03; acc: 1.0
Batch: 680; loss: 0.04; acc: 1.0
Batch: 700; loss: 0.02; acc: 1.0
Batch: 720; loss: 0.23; acc: 0.95
Batch: 740; loss: 0.03; acc: 1.0
Batch: 760; loss: 0.03; acc: 0.98
Batch: 780; loss: 0.22; acc: 0.97
Train Epoch over. train_loss: 0.1; train_accuracy: 0.97 

2.978520205942914e-05
9.350379514216911e-06
Batch: 0; loss: 0.07; acc: 0.97
Batch: 20; loss: 0.04; acc: 0.98
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.13; acc: 0.94
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.04; acc: 0.98
Batch: 120; loss: 0.19; acc: 0.92
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.09266330128547492; val_accuracy: 0.9717356687898089 

The current subspace-distance is: 9.350379514216911e-06 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.05; acc: 0.97
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.01; acc: 1.0
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.02; acc: 1.0
Batch: 120; loss: 0.13; acc: 0.97
Batch: 140; loss: 0.18; acc: 0.95
Batch: 160; loss: 0.16; acc: 0.97
Batch: 180; loss: 0.07; acc: 0.97
Batch: 200; loss: 0.13; acc: 0.98
Batch: 220; loss: 0.07; acc: 0.97
Batch: 240; loss: 0.06; acc: 0.98
Batch: 260; loss: 0.07; acc: 0.97
Batch: 280; loss: 0.09; acc: 0.98
Batch: 300; loss: 0.15; acc: 0.95
Batch: 320; loss: 0.06; acc: 0.98
Batch: 340; loss: 0.02; acc: 0.98
Batch: 360; loss: 0.12; acc: 0.95
Batch: 380; loss: 0.06; acc: 0.98
Batch: 400; loss: 0.12; acc: 0.95
Batch: 420; loss: 0.16; acc: 0.95
Batch: 440; loss: 0.21; acc: 0.92
Batch: 460; loss: 0.07; acc: 0.97
Batch: 480; loss: 0.01; acc: 1.0
Batch: 500; loss: 0.07; acc: 0.98
Batch: 520; loss: 0.06; acc: 0.97
Batch: 540; loss: 0.02; acc: 1.0
Batch: 560; loss: 0.15; acc: 0.97
Batch: 580; loss: 0.06; acc: 0.97
Batch: 600; loss: 0.19; acc: 0.94
Batch: 620; loss: 0.13; acc: 0.97
Batch: 640; loss: 0.09; acc: 0.95
Batch: 660; loss: 0.05; acc: 0.97
Batch: 680; loss: 0.09; acc: 0.97
Batch: 700; loss: 0.17; acc: 0.95
Batch: 720; loss: 0.06; acc: 0.98
Batch: 740; loss: 0.09; acc: 0.97
Batch: 760; loss: 0.11; acc: 0.97
Batch: 780; loss: 0.08; acc: 0.97
Train Epoch over. train_loss: 0.1; train_accuracy: 0.97 

2.9420049031614326e-05
9.354165740660392e-06
Batch: 0; loss: 0.05; acc: 0.97
Batch: 20; loss: 0.04; acc: 0.98
Batch: 40; loss: 0.04; acc: 0.97
Batch: 60; loss: 0.09; acc: 0.97
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.15; acc: 0.97
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.09751092807455047; val_accuracy: 0.9703423566878981 

The current subspace-distance is: 9.354165740660392e-06 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.0; acc: 1.0
Batch: 40; loss: 0.14; acc: 0.94
Batch: 60; loss: 0.07; acc: 0.97
Batch: 80; loss: 0.16; acc: 0.98
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.04; acc: 0.98
Batch: 140; loss: 0.1; acc: 0.97
Batch: 160; loss: 0.09; acc: 0.97
Batch: 180; loss: 0.06; acc: 0.97
Batch: 200; loss: 0.07; acc: 0.98
Batch: 220; loss: 0.12; acc: 0.97
Batch: 240; loss: 0.02; acc: 1.0
Batch: 260; loss: 0.17; acc: 0.95
Batch: 280; loss: 0.11; acc: 0.97
Batch: 300; loss: 0.05; acc: 0.98
Batch: 320; loss: 0.04; acc: 0.97
Batch: 340; loss: 0.1; acc: 0.95
Batch: 360; loss: 0.01; acc: 1.0
Batch: 380; loss: 0.18; acc: 0.97
Batch: 400; loss: 0.03; acc: 0.98
Batch: 420; loss: 0.03; acc: 1.0
Batch: 440; loss: 0.06; acc: 0.97
Batch: 460; loss: 0.08; acc: 0.98
Batch: 480; loss: 0.08; acc: 0.97
Batch: 500; loss: 0.1; acc: 0.98
Batch: 520; loss: 0.04; acc: 0.98
Batch: 540; loss: 0.09; acc: 0.95
Batch: 560; loss: 0.13; acc: 0.95
Batch: 580; loss: 0.04; acc: 0.98
Batch: 600; loss: 0.12; acc: 0.98
Batch: 620; loss: 0.09; acc: 0.97
Batch: 640; loss: 0.05; acc: 0.97
Batch: 660; loss: 0.03; acc: 1.0
Batch: 680; loss: 0.13; acc: 0.97
Batch: 700; loss: 0.02; acc: 1.0
Batch: 720; loss: 0.16; acc: 0.95
Batch: 740; loss: 0.03; acc: 1.0
Batch: 760; loss: 0.11; acc: 0.95
Batch: 780; loss: 0.05; acc: 0.97
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

3.0120363589958288e-05
9.799341569305398e-06
Batch: 0; loss: 0.07; acc: 0.95
Batch: 20; loss: 0.05; acc: 0.97
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.16; acc: 0.94
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.09473059752327241; val_accuracy: 0.9715366242038217 

The current subspace-distance is: 9.799341569305398e-06 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.05; acc: 0.98
Batch: 40; loss: 0.01; acc: 1.0
Batch: 60; loss: 0.04; acc: 0.98
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.04; acc: 0.97
Batch: 120; loss: 0.23; acc: 0.94
Batch: 140; loss: 0.01; acc: 1.0
Batch: 160; loss: 0.06; acc: 0.97
Batch: 180; loss: 0.02; acc: 1.0
Batch: 200; loss: 0.06; acc: 0.98
Batch: 220; loss: 0.02; acc: 0.98
Batch: 240; loss: 0.02; acc: 1.0
Batch: 260; loss: 0.05; acc: 0.97
Batch: 280; loss: 0.01; acc: 1.0
Batch: 300; loss: 0.12; acc: 0.97
Batch: 320; loss: 0.08; acc: 0.97
Batch: 340; loss: 0.01; acc: 1.0
Batch: 360; loss: 0.06; acc: 0.97
Batch: 380; loss: 0.04; acc: 1.0
Batch: 400; loss: 0.03; acc: 1.0
Batch: 420; loss: 0.04; acc: 0.98
Batch: 440; loss: 0.13; acc: 0.95
Batch: 460; loss: 0.17; acc: 0.94
Batch: 480; loss: 0.03; acc: 1.0
Batch: 500; loss: 0.05; acc: 0.98
Batch: 520; loss: 0.2; acc: 0.94
Batch: 540; loss: 0.16; acc: 0.94
Batch: 560; loss: 0.1; acc: 0.95
Batch: 580; loss: 0.06; acc: 0.98
Batch: 600; loss: 0.08; acc: 0.97
Batch: 620; loss: 0.08; acc: 0.98
Batch: 640; loss: 0.11; acc: 0.97
Batch: 660; loss: 0.19; acc: 0.95
Batch: 680; loss: 0.03; acc: 0.98
Batch: 700; loss: 0.01; acc: 1.0
Batch: 720; loss: 0.05; acc: 0.98
Batch: 740; loss: 0.03; acc: 0.98
Batch: 760; loss: 0.08; acc: 0.97
Batch: 780; loss: 0.07; acc: 0.97
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

3.012533125001937e-05
9.099659109779168e-06
Batch: 0; loss: 0.05; acc: 0.98
Batch: 20; loss: 0.04; acc: 0.98
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.17; acc: 0.95
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.09146043534871119; val_accuracy: 0.9729299363057324 

The current subspace-distance is: 9.099659109779168e-06 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.07; acc: 0.97
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.05; acc: 0.97
Batch: 80; loss: 0.08; acc: 0.95
Batch: 100; loss: 0.08; acc: 0.97
Batch: 120; loss: 0.31; acc: 0.91
Batch: 140; loss: 0.07; acc: 0.95
Batch: 160; loss: 0.15; acc: 0.94
Batch: 180; loss: 0.1; acc: 0.98
Batch: 200; loss: 0.11; acc: 0.94
Batch: 220; loss: 0.02; acc: 1.0
Batch: 240; loss: 0.06; acc: 0.97
Batch: 260; loss: 0.06; acc: 0.98
Batch: 280; loss: 0.09; acc: 0.94
Batch: 300; loss: 0.05; acc: 0.97
Batch: 320; loss: 0.16; acc: 0.97
Batch: 340; loss: 0.04; acc: 0.98
Batch: 360; loss: 0.03; acc: 1.0
Batch: 380; loss: 0.07; acc: 0.97
Batch: 400; loss: 0.11; acc: 0.97
Batch: 420; loss: 0.05; acc: 0.98
Batch: 440; loss: 0.28; acc: 0.92
Batch: 460; loss: 0.04; acc: 0.98
Batch: 480; loss: 0.03; acc: 1.0
Batch: 500; loss: 0.15; acc: 0.95
Batch: 520; loss: 0.12; acc: 0.95
Batch: 540; loss: 0.03; acc: 0.98
Batch: 560; loss: 0.14; acc: 0.94
Batch: 580; loss: 0.12; acc: 0.97
Batch: 600; loss: 0.07; acc: 0.98
Batch: 620; loss: 0.05; acc: 0.97
Batch: 640; loss: 0.05; acc: 0.98
Batch: 660; loss: 0.1; acc: 0.95
Batch: 680; loss: 0.02; acc: 1.0
Batch: 700; loss: 0.05; acc: 0.98
Batch: 720; loss: 0.18; acc: 0.94
Batch: 740; loss: 0.05; acc: 0.97
Batch: 760; loss: 0.01; acc: 1.0
Batch: 780; loss: 0.17; acc: 0.95
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

3.0071463697822765e-05
9.48108845477691e-06
Batch: 0; loss: 0.05; acc: 0.98
Batch: 20; loss: 0.04; acc: 1.0
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.17; acc: 0.94
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.09455112831750113; val_accuracy: 0.9720342356687898 

The current subspace-distance is: 9.48108845477691e-06 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.11; acc: 0.98
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.27; acc: 0.94
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.02; acc: 0.98
Batch: 120; loss: 0.14; acc: 0.95
Batch: 140; loss: 0.04; acc: 1.0
Batch: 160; loss: 0.14; acc: 0.97
Batch: 180; loss: 0.13; acc: 0.95
Batch: 200; loss: 0.02; acc: 1.0
Batch: 220; loss: 0.13; acc: 0.94
Batch: 240; loss: 0.09; acc: 0.98
Batch: 260; loss: 0.19; acc: 0.95
Batch: 280; loss: 0.06; acc: 0.97
Batch: 300; loss: 0.06; acc: 0.97
Batch: 320; loss: 0.02; acc: 1.0
Batch: 340; loss: 0.1; acc: 0.95
Batch: 360; loss: 0.04; acc: 1.0
Batch: 380; loss: 0.06; acc: 0.98
Batch: 400; loss: 0.05; acc: 0.98
Batch: 420; loss: 0.12; acc: 0.97
Batch: 440; loss: 0.06; acc: 0.98
Batch: 460; loss: 0.07; acc: 0.97
Batch: 480; loss: 0.21; acc: 0.92
Batch: 500; loss: 0.05; acc: 0.97
Batch: 520; loss: 0.02; acc: 0.98
Batch: 540; loss: 0.07; acc: 0.98
Batch: 560; loss: 0.09; acc: 0.98
Batch: 580; loss: 0.05; acc: 0.98
Batch: 600; loss: 0.03; acc: 0.98
Batch: 620; loss: 0.02; acc: 1.0
Batch: 640; loss: 0.32; acc: 0.92
Batch: 660; loss: 0.06; acc: 0.97
Batch: 680; loss: 0.1; acc: 0.97
Batch: 700; loss: 0.03; acc: 1.0
Batch: 720; loss: 0.07; acc: 0.97
Batch: 740; loss: 0.06; acc: 0.98
Batch: 760; loss: 0.07; acc: 0.98
Batch: 780; loss: 0.31; acc: 0.94
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

3.0444898584391922e-05
1.0309811841580085e-05
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.04; acc: 0.98
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.16; acc: 0.95
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.09319810184893335; val_accuracy: 0.9723328025477707 

The current subspace-distance is: 1.0309811841580085e-05 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.14; acc: 0.98
Batch: 20; loss: 0.25; acc: 0.95
Batch: 40; loss: 0.12; acc: 0.94
Batch: 60; loss: 0.03; acc: 1.0
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.11; acc: 0.95
Batch: 140; loss: 0.05; acc: 0.98
Batch: 160; loss: 0.04; acc: 1.0
Batch: 180; loss: 0.05; acc: 0.98
Batch: 200; loss: 0.05; acc: 0.97
Batch: 220; loss: 0.03; acc: 1.0
Batch: 240; loss: 0.13; acc: 0.97
Batch: 260; loss: 0.08; acc: 0.97
Batch: 280; loss: 0.04; acc: 0.98
Batch: 300; loss: 0.04; acc: 0.98
Batch: 320; loss: 0.16; acc: 0.97
Batch: 340; loss: 0.08; acc: 0.95
Batch: 360; loss: 0.02; acc: 1.0
Batch: 380; loss: 0.28; acc: 0.95
Batch: 400; loss: 0.12; acc: 0.97
Batch: 420; loss: 0.09; acc: 0.95
Batch: 440; loss: 0.06; acc: 0.98
Batch: 460; loss: 0.17; acc: 0.94
Batch: 480; loss: 0.16; acc: 0.97
Batch: 500; loss: 0.3; acc: 0.98
Batch: 520; loss: 0.11; acc: 0.95
Batch: 540; loss: 0.09; acc: 0.98
Batch: 560; loss: 0.02; acc: 1.0
Batch: 580; loss: 0.12; acc: 0.97
Batch: 600; loss: 0.1; acc: 0.97
Batch: 620; loss: 0.03; acc: 0.98
Batch: 640; loss: 0.07; acc: 0.97
Batch: 660; loss: 0.25; acc: 0.95
Batch: 680; loss: 0.12; acc: 0.97
Batch: 700; loss: 0.11; acc: 0.97
Batch: 720; loss: 0.08; acc: 0.97
Batch: 740; loss: 0.01; acc: 1.0
Batch: 760; loss: 0.09; acc: 0.95
Batch: 780; loss: 0.06; acc: 1.0
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

3.0154520572978072e-05
1.0266306162520777e-05
Batch: 0; loss: 0.06; acc: 0.98
Batch: 20; loss: 0.04; acc: 0.98
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.04; acc: 0.98
Batch: 120; loss: 0.16; acc: 0.95
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.09063881279746439; val_accuracy: 0.9719347133757962 

The current subspace-distance is: 1.0266306162520777e-05 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.07; acc: 0.95
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.06; acc: 0.97
Batch: 80; loss: 0.39; acc: 0.92
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.01; acc: 1.0
Batch: 140; loss: 0.1; acc: 0.95
Batch: 160; loss: 0.04; acc: 0.98
Batch: 180; loss: 0.1; acc: 0.98
Batch: 200; loss: 0.13; acc: 0.94
Batch: 220; loss: 0.28; acc: 0.94
Batch: 240; loss: 0.08; acc: 0.95
Batch: 260; loss: 0.02; acc: 1.0
Batch: 280; loss: 0.15; acc: 0.97
Batch: 300; loss: 0.17; acc: 0.95
Batch: 320; loss: 0.07; acc: 0.97
Batch: 340; loss: 0.06; acc: 0.97
Batch: 360; loss: 0.08; acc: 0.98
Batch: 380; loss: 0.06; acc: 0.98
Batch: 400; loss: 0.03; acc: 1.0
Batch: 420; loss: 0.09; acc: 0.95
Batch: 440; loss: 0.03; acc: 1.0
Batch: 460; loss: 0.21; acc: 0.94
Batch: 480; loss: 0.12; acc: 0.98
Batch: 500; loss: 0.06; acc: 0.97
Batch: 520; loss: 0.05; acc: 0.97
Batch: 540; loss: 0.05; acc: 1.0
Batch: 560; loss: 0.08; acc: 0.97
Batch: 580; loss: 0.12; acc: 0.95
Batch: 600; loss: 0.08; acc: 0.98
Batch: 620; loss: 0.04; acc: 1.0
Batch: 640; loss: 0.23; acc: 0.95
Batch: 660; loss: 0.1; acc: 0.97
Batch: 680; loss: 0.01; acc: 1.0
Batch: 700; loss: 0.09; acc: 0.97
Batch: 720; loss: 0.08; acc: 0.97
Batch: 740; loss: 0.09; acc: 0.98
Batch: 760; loss: 0.13; acc: 0.95
Batch: 780; loss: 0.02; acc: 1.0
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

2.9636719773407094e-05
9.465425137022976e-06
Batch: 0; loss: 0.05; acc: 0.98
Batch: 20; loss: 0.04; acc: 0.98
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.12; acc: 0.97
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.06; acc: 0.97
Batch: 120; loss: 0.16; acc: 0.95
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.09143515720156728; val_accuracy: 0.9709394904458599 

The current subspace-distance is: 9.465425137022976e-06 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.07; acc: 0.97
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.26; acc: 0.91
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.04; acc: 0.98
Batch: 140; loss: 0.05; acc: 0.98
Batch: 160; loss: 0.17; acc: 0.95
Batch: 180; loss: 0.03; acc: 0.98
Batch: 200; loss: 0.03; acc: 1.0
Batch: 220; loss: 0.15; acc: 0.97
Batch: 240; loss: 0.04; acc: 0.98
Batch: 260; loss: 0.06; acc: 0.97
Batch: 280; loss: 0.21; acc: 0.94
Batch: 300; loss: 0.06; acc: 0.97
Batch: 320; loss: 0.12; acc: 0.95
Batch: 340; loss: 0.06; acc: 0.98
Batch: 360; loss: 0.09; acc: 0.97
Batch: 380; loss: 0.17; acc: 0.97
Batch: 400; loss: 0.04; acc: 0.98
Batch: 420; loss: 0.23; acc: 0.97
Batch: 440; loss: 0.01; acc: 1.0
Batch: 460; loss: 0.16; acc: 0.97
Batch: 480; loss: 0.05; acc: 0.97
Batch: 500; loss: 0.07; acc: 0.97
Batch: 520; loss: 0.16; acc: 0.95
Batch: 540; loss: 0.12; acc: 0.98
Batch: 560; loss: 0.04; acc: 0.98
Batch: 580; loss: 0.14; acc: 0.95
Batch: 600; loss: 0.07; acc: 0.97
Batch: 620; loss: 0.33; acc: 0.94
Batch: 640; loss: 0.04; acc: 0.98
Batch: 660; loss: 0.21; acc: 0.97
Batch: 680; loss: 0.17; acc: 0.95
Batch: 700; loss: 0.12; acc: 0.97
Batch: 720; loss: 0.07; acc: 0.98
Batch: 740; loss: 0.05; acc: 0.98
Batch: 760; loss: 0.08; acc: 0.97
Batch: 780; loss: 0.04; acc: 1.0
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

3.0348504878929816e-05
1.09694728962495e-05
Batch: 0; loss: 0.05; acc: 0.98
Batch: 20; loss: 0.05; acc: 0.98
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.08; acc: 0.97
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.04; acc: 0.98
Batch: 120; loss: 0.16; acc: 0.95
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.09108565448765542; val_accuracy: 0.9718351910828026 

The current subspace-distance is: 1.09694728962495e-05 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.06; acc: 0.97
Batch: 20; loss: 0.08; acc: 0.97
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.08; acc: 0.98
Batch: 80; loss: 0.06; acc: 0.97
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.04; acc: 0.98
Batch: 140; loss: 0.18; acc: 0.97
Batch: 160; loss: 0.05; acc: 0.97
Batch: 180; loss: 0.09; acc: 0.98
Batch: 200; loss: 0.04; acc: 0.98
Batch: 220; loss: 0.14; acc: 0.97
Batch: 240; loss: 0.14; acc: 0.95
Batch: 260; loss: 0.12; acc: 0.95
Batch: 280; loss: 0.09; acc: 0.98
Batch: 300; loss: 0.11; acc: 0.94
Batch: 320; loss: 0.02; acc: 1.0
Batch: 340; loss: 0.11; acc: 0.98
Batch: 360; loss: 0.14; acc: 0.95
Batch: 380; loss: 0.09; acc: 0.95
Batch: 400; loss: 0.09; acc: 0.98
Batch: 420; loss: 0.08; acc: 0.95
Batch: 440; loss: 0.21; acc: 0.94
Batch: 460; loss: 0.15; acc: 0.94
Batch: 480; loss: 0.05; acc: 0.98
Batch: 500; loss: 0.17; acc: 0.98
Batch: 520; loss: 0.08; acc: 0.97
Batch: 540; loss: 0.17; acc: 0.95
Batch: 560; loss: 0.06; acc: 0.98
Batch: 580; loss: 0.13; acc: 0.97
Batch: 600; loss: 0.08; acc: 0.97
Batch: 620; loss: 0.05; acc: 0.98
Batch: 640; loss: 0.0; acc: 1.0
Batch: 660; loss: 0.31; acc: 0.92
Batch: 680; loss: 0.04; acc: 0.98
Batch: 700; loss: 0.09; acc: 0.95
Batch: 720; loss: 0.05; acc: 0.98
Batch: 740; loss: 0.15; acc: 0.97
Batch: 760; loss: 0.29; acc: 0.89
Batch: 780; loss: 0.24; acc: 0.94
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

2.9756036383332685e-05
1.0020039553637616e-05
Batch: 0; loss: 0.05; acc: 0.98
Batch: 20; loss: 0.04; acc: 0.98
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.09; acc: 0.97
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.15; acc: 0.94
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.09086543759390427; val_accuracy: 0.972531847133758 

The current subspace-distance is: 1.0020039553637616e-05 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.05; acc: 0.98
Batch: 20; loss: 0.11; acc: 0.95
Batch: 40; loss: 0.02; acc: 0.98
Batch: 60; loss: 0.1; acc: 0.98
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.06; acc: 0.98
Batch: 140; loss: 0.11; acc: 0.98
Batch: 160; loss: 0.08; acc: 0.95
Batch: 180; loss: 0.08; acc: 0.97
Batch: 200; loss: 0.04; acc: 1.0
Batch: 220; loss: 0.09; acc: 0.98
Batch: 240; loss: 0.01; acc: 1.0
Batch: 260; loss: 0.27; acc: 0.91
Batch: 280; loss: 0.14; acc: 0.97
Batch: 300; loss: 0.02; acc: 1.0
Batch: 320; loss: 0.04; acc: 0.98
Batch: 340; loss: 0.06; acc: 0.97
Batch: 360; loss: 0.1; acc: 0.97
Batch: 380; loss: 0.25; acc: 0.94
Batch: 400; loss: 0.07; acc: 0.95
Batch: 420; loss: 0.1; acc: 0.94
Batch: 440; loss: 0.2; acc: 0.97
Batch: 460; loss: 0.05; acc: 0.98
Batch: 480; loss: 0.02; acc: 1.0
Batch: 500; loss: 0.03; acc: 0.98
Batch: 520; loss: 0.04; acc: 0.97
Batch: 540; loss: 0.03; acc: 1.0
Batch: 560; loss: 0.02; acc: 1.0
Batch: 580; loss: 0.03; acc: 1.0
Batch: 600; loss: 0.12; acc: 0.95
Batch: 620; loss: 0.02; acc: 1.0
Batch: 640; loss: 0.1; acc: 0.95
Batch: 660; loss: 0.01; acc: 1.0
Batch: 680; loss: 0.21; acc: 0.95
Batch: 700; loss: 0.05; acc: 0.97
Batch: 720; loss: 0.04; acc: 0.98
Batch: 740; loss: 0.04; acc: 0.98
Batch: 760; loss: 0.02; acc: 0.98
Batch: 780; loss: 0.01; acc: 1.0
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

3.0664115911349654e-05
9.335137292509899e-06
Batch: 0; loss: 0.04; acc: 1.0
Batch: 20; loss: 0.05; acc: 0.98
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.18; acc: 0.94
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.09383022479096036; val_accuracy: 0.9719347133757962 

The current subspace-distance is: 9.335137292509899e-06 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.07; acc: 0.98
Batch: 40; loss: 0.05; acc: 0.97
Batch: 60; loss: 0.13; acc: 0.97
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.04; acc: 0.98
Batch: 120; loss: 0.03; acc: 0.98
Batch: 140; loss: 0.05; acc: 0.98
Batch: 160; loss: 0.05; acc: 0.98
Batch: 180; loss: 0.08; acc: 0.97
Batch: 200; loss: 0.04; acc: 0.97
Batch: 220; loss: 0.13; acc: 0.94
Batch: 240; loss: 0.1; acc: 0.98
Batch: 260; loss: 0.02; acc: 1.0
Batch: 280; loss: 0.06; acc: 0.98
Batch: 300; loss: 0.14; acc: 0.95
Batch: 320; loss: 0.24; acc: 0.95
Batch: 340; loss: 0.01; acc: 1.0
Batch: 360; loss: 0.06; acc: 0.97
Batch: 380; loss: 0.1; acc: 0.98
Batch: 400; loss: 0.06; acc: 0.97
Batch: 420; loss: 0.08; acc: 0.97
Batch: 440; loss: 0.17; acc: 0.95
Batch: 460; loss: 0.1; acc: 0.95
Batch: 480; loss: 0.05; acc: 0.97
Batch: 500; loss: 0.03; acc: 0.98
Batch: 520; loss: 0.06; acc: 0.97
Batch: 540; loss: 0.11; acc: 0.97
Batch: 560; loss: 0.02; acc: 1.0
Batch: 580; loss: 0.07; acc: 0.98
Batch: 600; loss: 0.08; acc: 0.98
Batch: 620; loss: 0.15; acc: 0.97
Batch: 640; loss: 0.18; acc: 0.95
Batch: 660; loss: 0.02; acc: 1.0
Batch: 680; loss: 0.07; acc: 0.98
Batch: 700; loss: 0.14; acc: 0.95
Batch: 720; loss: 0.03; acc: 1.0
Batch: 740; loss: 0.03; acc: 1.0
Batch: 760; loss: 0.1; acc: 0.97
Batch: 780; loss: 0.16; acc: 0.98
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

3.0203516871551983e-05
9.344922546006273e-06
Batch: 0; loss: 0.04; acc: 0.97
Batch: 20; loss: 0.04; acc: 0.98
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.06; acc: 0.97
Batch: 120; loss: 0.15; acc: 0.95
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.09142101531148336; val_accuracy: 0.9720342356687898 

The current subspace-distance is: 9.344922546006273e-06 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.03; acc: 1.0
Batch: 40; loss: 0.04; acc: 1.0
Batch: 60; loss: 0.08; acc: 0.98
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.11; acc: 0.95
Batch: 140; loss: 0.32; acc: 0.92
Batch: 160; loss: 0.05; acc: 0.98
Batch: 180; loss: 0.03; acc: 0.98
Batch: 200; loss: 0.1; acc: 0.98
Batch: 220; loss: 0.12; acc: 0.97
Batch: 240; loss: 0.07; acc: 0.95
Batch: 260; loss: 0.04; acc: 0.98
Batch: 280; loss: 0.11; acc: 0.97
Batch: 300; loss: 0.08; acc: 0.98
Batch: 320; loss: 0.08; acc: 0.95
Batch: 340; loss: 0.08; acc: 0.97
Batch: 360; loss: 0.06; acc: 0.98
Batch: 380; loss: 0.02; acc: 1.0
Batch: 400; loss: 0.04; acc: 0.98
Batch: 420; loss: 0.05; acc: 0.97
Batch: 440; loss: 0.12; acc: 0.97
Batch: 460; loss: 0.15; acc: 0.95
Batch: 480; loss: 0.05; acc: 0.98
Batch: 500; loss: 0.03; acc: 1.0
Batch: 520; loss: 0.09; acc: 0.95
Batch: 540; loss: 0.05; acc: 0.98
Batch: 560; loss: 0.04; acc: 0.98
Batch: 580; loss: 0.11; acc: 0.98
Batch: 600; loss: 0.05; acc: 0.98
Batch: 620; loss: 0.03; acc: 0.98
Batch: 640; loss: 0.13; acc: 0.97
Batch: 660; loss: 0.07; acc: 0.98
Batch: 680; loss: 0.02; acc: 1.0
Batch: 700; loss: 0.05; acc: 0.98
Batch: 720; loss: 0.12; acc: 0.97
Batch: 740; loss: 0.05; acc: 0.97
Batch: 760; loss: 0.18; acc: 0.95
Batch: 780; loss: 0.06; acc: 0.98
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

3.0143699405016378e-05
9.657348527980503e-06
Batch: 0; loss: 0.05; acc: 0.98
Batch: 20; loss: 0.04; acc: 0.98
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.15; acc: 0.95
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.08910331644924582; val_accuracy: 0.9728304140127388 

The current subspace-distance is: 9.657348527980503e-06 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.06; acc: 0.98
Batch: 40; loss: 0.09; acc: 0.95
Batch: 60; loss: 0.04; acc: 1.0
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.06; acc: 0.97
Batch: 120; loss: 0.09; acc: 0.97
Batch: 140; loss: 0.22; acc: 0.94
Batch: 160; loss: 0.03; acc: 0.98
Batch: 180; loss: 0.03; acc: 0.98
Batch: 200; loss: 0.06; acc: 0.98
Batch: 220; loss: 0.03; acc: 1.0
Batch: 240; loss: 0.06; acc: 0.98
Batch: 260; loss: 0.06; acc: 0.97
Batch: 280; loss: 0.15; acc: 0.97
Batch: 300; loss: 0.28; acc: 0.94
Batch: 320; loss: 0.02; acc: 1.0
Batch: 340; loss: 0.13; acc: 0.95
Batch: 360; loss: 0.07; acc: 0.98
Batch: 380; loss: 0.04; acc: 0.98
Batch: 400; loss: 0.06; acc: 0.97
Batch: 420; loss: 0.11; acc: 0.97
Batch: 440; loss: 0.07; acc: 0.98
Batch: 460; loss: 0.11; acc: 0.95
Batch: 480; loss: 0.02; acc: 0.98
Batch: 500; loss: 0.09; acc: 0.95
Batch: 520; loss: 0.07; acc: 0.95
Batch: 540; loss: 0.06; acc: 0.97
Batch: 560; loss: 0.15; acc: 0.94
Batch: 580; loss: 0.04; acc: 0.98
Batch: 600; loss: 0.05; acc: 0.98
Batch: 620; loss: 0.15; acc: 0.94
Batch: 640; loss: 0.01; acc: 1.0
Batch: 660; loss: 0.04; acc: 0.97
Batch: 680; loss: 0.09; acc: 0.95
Batch: 700; loss: 0.01; acc: 1.0
Batch: 720; loss: 0.03; acc: 0.98
Batch: 740; loss: 0.05; acc: 0.98
Batch: 760; loss: 0.03; acc: 0.98
Batch: 780; loss: 0.04; acc: 0.98
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

3.0343999242177233e-05
8.785552381596062e-06
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.04; acc: 0.98
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.16; acc: 0.95
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.08763499938805772; val_accuracy: 0.9726313694267515 

The current subspace-distance is: 8.785552381596062e-06 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.11; acc: 0.95
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.01; acc: 1.0
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.12; acc: 0.97
Batch: 140; loss: 0.21; acc: 0.98
Batch: 160; loss: 0.04; acc: 0.98
Batch: 180; loss: 0.08; acc: 0.98
Batch: 200; loss: 0.02; acc: 1.0
Batch: 220; loss: 0.06; acc: 0.98
Batch: 240; loss: 0.17; acc: 0.92
Batch: 260; loss: 0.09; acc: 0.95
Batch: 280; loss: 0.04; acc: 0.97
Batch: 300; loss: 0.11; acc: 0.97
Batch: 320; loss: 0.06; acc: 0.97
Batch: 340; loss: 0.02; acc: 1.0
Batch: 360; loss: 0.04; acc: 0.98
Batch: 380; loss: 0.08; acc: 0.97
Batch: 400; loss: 0.13; acc: 0.95
Batch: 420; loss: 0.06; acc: 0.98
Batch: 440; loss: 0.18; acc: 0.95
Batch: 460; loss: 0.04; acc: 0.98
Batch: 480; loss: 0.03; acc: 0.98
Batch: 500; loss: 0.05; acc: 0.98
Batch: 520; loss: 0.03; acc: 1.0
Batch: 540; loss: 0.05; acc: 0.97
Batch: 560; loss: 0.03; acc: 0.98
Batch: 580; loss: 0.05; acc: 0.97
Batch: 600; loss: 0.02; acc: 1.0
Batch: 620; loss: 0.02; acc: 1.0
Batch: 640; loss: 0.1; acc: 0.97
Batch: 660; loss: 0.02; acc: 1.0
Batch: 680; loss: 0.26; acc: 0.94
Batch: 700; loss: 0.03; acc: 1.0
Batch: 720; loss: 0.06; acc: 0.97
Batch: 740; loss: 0.07; acc: 0.98
Batch: 760; loss: 0.08; acc: 0.95
Batch: 780; loss: 0.1; acc: 0.97
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

3.0266301109804772e-05
9.563411367707886e-06
Batch: 0; loss: 0.05; acc: 0.98
Batch: 20; loss: 0.04; acc: 0.98
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.16; acc: 0.95
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.08828810422094005; val_accuracy: 0.9728304140127388 

The current subspace-distance is: 9.563411367707886e-06 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.07; acc: 0.98
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.1; acc: 0.95
Batch: 80; loss: 0.05; acc: 0.97
Batch: 100; loss: 0.14; acc: 0.97
Batch: 120; loss: 0.08; acc: 0.95
Batch: 140; loss: 0.05; acc: 0.98
Batch: 160; loss: 0.04; acc: 0.97
Batch: 180; loss: 0.03; acc: 0.98
Batch: 200; loss: 0.09; acc: 0.94
Batch: 220; loss: 0.07; acc: 0.98
Batch: 240; loss: 0.03; acc: 0.98
Batch: 260; loss: 0.04; acc: 1.0
Batch: 280; loss: 0.03; acc: 0.98
Batch: 300; loss: 0.03; acc: 1.0
Batch: 320; loss: 0.17; acc: 0.94
Batch: 340; loss: 0.16; acc: 0.95
Batch: 360; loss: 0.03; acc: 1.0
Batch: 380; loss: 0.03; acc: 0.98
Batch: 400; loss: 0.18; acc: 0.95
Batch: 420; loss: 0.05; acc: 0.98
Batch: 440; loss: 0.06; acc: 0.97
Batch: 460; loss: 0.06; acc: 0.98
Batch: 480; loss: 0.04; acc: 0.98
Batch: 500; loss: 0.14; acc: 0.94
Batch: 520; loss: 0.04; acc: 0.97
Batch: 540; loss: 0.11; acc: 0.97
Batch: 560; loss: 0.06; acc: 0.98
Batch: 580; loss: 0.01; acc: 1.0
Batch: 600; loss: 0.08; acc: 0.98
Batch: 620; loss: 0.06; acc: 0.97
Batch: 640; loss: 0.04; acc: 0.98
Batch: 660; loss: 0.22; acc: 0.92
Batch: 680; loss: 0.08; acc: 0.98
Batch: 700; loss: 0.04; acc: 0.98
Batch: 720; loss: 0.02; acc: 0.98
Batch: 740; loss: 0.1; acc: 0.95
Batch: 760; loss: 0.04; acc: 0.98
Batch: 780; loss: 0.08; acc: 0.98
Train Epoch over. train_loss: 0.08; train_accuracy: 0.97 

3.097005173913203e-05
1.0460841622261796e-05
Batch: 0; loss: 0.05; acc: 0.98
Batch: 20; loss: 0.03; acc: 0.98
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.0; acc: 1.0
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.15; acc: 0.95
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.08776754903707915; val_accuracy: 0.9728304140127388 

The current subspace-distance is: 1.0460841622261796e-05 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.24; acc: 0.95
Batch: 20; loss: 0.1; acc: 0.95
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.02; acc: 1.0
Batch: 80; loss: 0.04; acc: 1.0
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.14; acc: 0.94
Batch: 140; loss: 0.03; acc: 0.98
Batch: 160; loss: 0.08; acc: 0.97
Batch: 180; loss: 0.07; acc: 0.98
Batch: 200; loss: 0.08; acc: 0.97
Batch: 220; loss: 0.1; acc: 0.94
Batch: 240; loss: 0.06; acc: 0.98
Batch: 260; loss: 0.1; acc: 0.95
Batch: 280; loss: 0.17; acc: 0.97
Batch: 300; loss: 0.08; acc: 0.95
Batch: 320; loss: 0.12; acc: 0.97
Batch: 340; loss: 0.06; acc: 0.98
Batch: 360; loss: 0.15; acc: 0.95
Batch: 380; loss: 0.03; acc: 0.98
Batch: 400; loss: 0.1; acc: 0.97
Batch: 420; loss: 0.12; acc: 0.95
Batch: 440; loss: 0.24; acc: 0.94
Batch: 460; loss: 0.04; acc: 0.98
Batch: 480; loss: 0.04; acc: 0.98
Batch: 500; loss: 0.03; acc: 0.98
Batch: 520; loss: 0.05; acc: 0.97
Batch: 540; loss: 0.13; acc: 0.97
Batch: 560; loss: 0.02; acc: 1.0
Batch: 580; loss: 0.07; acc: 0.98
Batch: 600; loss: 0.02; acc: 1.0
Batch: 620; loss: 0.09; acc: 0.97
Batch: 640; loss: 0.18; acc: 0.95
Batch: 660; loss: 0.03; acc: 0.98
Batch: 680; loss: 0.02; acc: 1.0
Batch: 700; loss: 0.01; acc: 1.0
Batch: 720; loss: 0.13; acc: 0.97
Batch: 740; loss: 0.09; acc: 0.97
Batch: 760; loss: 0.12; acc: 0.95
Batch: 780; loss: 0.2; acc: 0.95
Train Epoch over. train_loss: 0.08; train_accuracy: 0.97 

3.071549872402102e-05
1.0218534043815453e-05
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.03; acc: 1.0
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.1; acc: 0.95
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.16; acc: 0.94
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.08802251242528296; val_accuracy: 0.9722332802547771 

The current subspace-distance is: 1.0218534043815453e-05 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.05; acc: 0.98
Batch: 20; loss: 0.08; acc: 0.95
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.31; acc: 0.95
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.03; acc: 0.98
Batch: 120; loss: 0.03; acc: 0.98
Batch: 140; loss: 0.05; acc: 0.97
Batch: 160; loss: 0.06; acc: 0.98
Batch: 180; loss: 0.17; acc: 0.94
Batch: 200; loss: 0.05; acc: 0.98
Batch: 220; loss: 0.02; acc: 1.0
Batch: 240; loss: 0.1; acc: 0.97
Batch: 260; loss: 0.16; acc: 0.94
Batch: 280; loss: 0.17; acc: 0.94
Batch: 300; loss: 0.05; acc: 0.98
Batch: 320; loss: 0.08; acc: 0.97
Batch: 340; loss: 0.11; acc: 0.98
Batch: 360; loss: 0.17; acc: 0.95
Batch: 380; loss: 0.04; acc: 1.0
Batch: 400; loss: 0.0; acc: 1.0
Batch: 420; loss: 0.08; acc: 0.95
Batch: 440; loss: 0.07; acc: 0.97
Batch: 460; loss: 0.05; acc: 0.98
Batch: 480; loss: 0.1; acc: 0.94
Batch: 500; loss: 0.06; acc: 0.97
Batch: 520; loss: 0.03; acc: 1.0
Batch: 540; loss: 0.14; acc: 0.94
Batch: 560; loss: 0.1; acc: 0.97
Batch: 580; loss: 0.18; acc: 0.92
Batch: 600; loss: 0.11; acc: 0.95
Batch: 620; loss: 0.12; acc: 0.95
Batch: 640; loss: 0.08; acc: 0.97
Batch: 660; loss: 0.17; acc: 0.95
Batch: 680; loss: 0.01; acc: 1.0
Batch: 700; loss: 0.05; acc: 0.98
Batch: 720; loss: 0.06; acc: 0.97
Batch: 740; loss: 0.1; acc: 0.95
Batch: 760; loss: 0.18; acc: 0.94
Batch: 780; loss: 0.12; acc: 0.95
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

3.06334623019211e-05
1.09485436041723e-05
Batch: 0; loss: 0.05; acc: 1.0
Batch: 20; loss: 0.03; acc: 1.0
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.16; acc: 0.97
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.08999628721955855; val_accuracy: 0.9717356687898089 

The current subspace-distance is: 1.09485436041723e-05 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.15; acc: 0.98
Batch: 80; loss: 0.06; acc: 0.97
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.16; acc: 0.94
Batch: 140; loss: 0.03; acc: 1.0
Batch: 160; loss: 0.13; acc: 0.92
Batch: 180; loss: 0.12; acc: 0.98
Batch: 200; loss: 0.04; acc: 1.0
Batch: 220; loss: 0.07; acc: 0.98
Batch: 240; loss: 0.13; acc: 0.94
Batch: 260; loss: 0.07; acc: 0.98
Batch: 280; loss: 0.13; acc: 0.97
Batch: 300; loss: 0.18; acc: 0.94
Batch: 320; loss: 0.03; acc: 1.0
Batch: 340; loss: 0.09; acc: 0.95
Batch: 360; loss: 0.04; acc: 0.98
Batch: 380; loss: 0.03; acc: 0.98
Batch: 400; loss: 0.08; acc: 0.97
Batch: 420; loss: 0.02; acc: 1.0
Batch: 440; loss: 0.06; acc: 0.98
Batch: 460; loss: 0.11; acc: 0.98
Batch: 480; loss: 0.1; acc: 0.95
Batch: 500; loss: 0.04; acc: 0.98
Batch: 520; loss: 0.09; acc: 0.97
Batch: 540; loss: 0.12; acc: 0.95
Batch: 560; loss: 0.02; acc: 1.0
Batch: 580; loss: 0.25; acc: 0.95
Batch: 600; loss: 0.1; acc: 0.95
Batch: 620; loss: 0.05; acc: 0.98
Batch: 640; loss: 0.23; acc: 0.94
Batch: 660; loss: 0.09; acc: 0.97
Batch: 680; loss: 0.06; acc: 0.97
Batch: 700; loss: 0.14; acc: 0.98
Batch: 720; loss: 0.03; acc: 0.98
Batch: 740; loss: 0.03; acc: 1.0
Batch: 760; loss: 0.12; acc: 0.97
Batch: 780; loss: 0.13; acc: 0.94
Train Epoch over. train_loss: 0.08; train_accuracy: 0.97 

3.076214125030674e-05
9.399172085977625e-06
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.04; acc: 0.98
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.09; acc: 0.97
Batch: 80; loss: 0.0; acc: 1.0
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.16; acc: 0.95
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.0874315122272938; val_accuracy: 0.9727308917197452 

The current subspace-distance is: 9.399172085977625e-06 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.08; acc: 0.97
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.09; acc: 0.98
Batch: 140; loss: 0.08; acc: 0.98
Batch: 160; loss: 0.09; acc: 0.97
Batch: 180; loss: 0.01; acc: 1.0
Batch: 200; loss: 0.06; acc: 0.97
Batch: 220; loss: 0.07; acc: 0.97
Batch: 240; loss: 0.11; acc: 0.98
Batch: 260; loss: 0.04; acc: 0.97
Batch: 280; loss: 0.1; acc: 0.97
Batch: 300; loss: 0.05; acc: 0.98
Batch: 320; loss: 0.03; acc: 0.98
Batch: 340; loss: 0.05; acc: 0.98
Batch: 360; loss: 0.09; acc: 0.95
Batch: 380; loss: 0.06; acc: 0.98
Batch: 400; loss: 0.03; acc: 0.98
Batch: 420; loss: 0.1; acc: 0.97
Batch: 440; loss: 0.15; acc: 0.97
Batch: 460; loss: 0.1; acc: 0.97
Batch: 480; loss: 0.04; acc: 0.98
Batch: 500; loss: 0.06; acc: 0.98
Batch: 520; loss: 0.14; acc: 0.94
Batch: 540; loss: 0.05; acc: 0.97
Batch: 560; loss: 0.02; acc: 1.0
Batch: 580; loss: 0.03; acc: 1.0
Batch: 600; loss: 0.14; acc: 0.95
Batch: 620; loss: 0.04; acc: 0.98
Batch: 640; loss: 0.03; acc: 1.0
Batch: 660; loss: 0.05; acc: 0.98
Batch: 680; loss: 0.06; acc: 0.97
Batch: 700; loss: 0.12; acc: 0.97
Batch: 720; loss: 0.04; acc: 0.98
Batch: 740; loss: 0.09; acc: 0.97
Batch: 760; loss: 0.03; acc: 0.98
Batch: 780; loss: 0.08; acc: 0.97
Train Epoch over. train_loss: 0.08; train_accuracy: 0.97 

3.0995113775134087e-05
9.537701771478169e-06
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.04; acc: 0.98
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.09; acc: 0.97
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.04; acc: 0.98
Batch: 120; loss: 0.16; acc: 0.95
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.08810156487687758; val_accuracy: 0.9732285031847133 

The current subspace-distance is: 9.537701771478169e-06 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.11; acc: 0.95
Batch: 20; loss: 0.23; acc: 0.94
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.02; acc: 1.0
Batch: 80; loss: 0.16; acc: 0.92
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.13; acc: 0.95
Batch: 140; loss: 0.09; acc: 0.97
Batch: 160; loss: 0.05; acc: 0.98
Batch: 180; loss: 0.08; acc: 0.98
Batch: 200; loss: 0.11; acc: 0.97
Batch: 220; loss: 0.11; acc: 0.95
Batch: 240; loss: 0.11; acc: 0.97
Batch: 260; loss: 0.07; acc: 0.97
Batch: 280; loss: 0.01; acc: 1.0
Batch: 300; loss: 0.24; acc: 0.97
Batch: 320; loss: 0.14; acc: 0.97
Batch: 340; loss: 0.06; acc: 0.98
Batch: 360; loss: 0.01; acc: 1.0
Batch: 380; loss: 0.01; acc: 1.0
Batch: 400; loss: 0.12; acc: 0.98
Batch: 420; loss: 0.15; acc: 0.95
Batch: 440; loss: 0.04; acc: 0.98
Batch: 460; loss: 0.04; acc: 1.0
Batch: 480; loss: 0.04; acc: 0.98
Batch: 500; loss: 0.2; acc: 0.97
Batch: 520; loss: 0.18; acc: 0.95
Batch: 540; loss: 0.03; acc: 1.0
Batch: 560; loss: 0.09; acc: 0.95
Batch: 580; loss: 0.1; acc: 0.97
Batch: 600; loss: 0.06; acc: 0.98
Batch: 620; loss: 0.08; acc: 0.98
Batch: 640; loss: 0.02; acc: 1.0
Batch: 660; loss: 0.01; acc: 1.0
Batch: 680; loss: 0.01; acc: 1.0
Batch: 700; loss: 0.08; acc: 0.97
Batch: 720; loss: 0.06; acc: 0.97
Batch: 740; loss: 0.17; acc: 0.95
Batch: 760; loss: 0.16; acc: 0.97
Batch: 780; loss: 0.01; acc: 1.0
Train Epoch over. train_loss: 0.08; train_accuracy: 0.97 

3.046422170882579e-05
1.0365009984525386e-05
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.04; acc: 0.98
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.09; acc: 0.97
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.15; acc: 0.95
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.08810684509622822; val_accuracy: 0.9728304140127388 

The current subspace-distance is: 1.0365009984525386e-05 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.09; acc: 0.95
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.03; acc: 1.0
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.03; acc: 0.98
Batch: 120; loss: 0.04; acc: 1.0
Batch: 140; loss: 0.02; acc: 1.0
Batch: 160; loss: 0.12; acc: 0.95
Batch: 180; loss: 0.04; acc: 0.98
Batch: 200; loss: 0.04; acc: 0.98
Batch: 220; loss: 0.05; acc: 0.97
Batch: 240; loss: 0.06; acc: 0.97
Batch: 260; loss: 0.07; acc: 0.97
Batch: 280; loss: 0.14; acc: 0.95
Batch: 300; loss: 0.05; acc: 0.98
Batch: 320; loss: 0.04; acc: 0.98
Batch: 340; loss: 0.07; acc: 0.97
Batch: 360; loss: 0.16; acc: 0.95
Batch: 380; loss: 0.1; acc: 0.97
Batch: 400; loss: 0.01; acc: 1.0
Batch: 420; loss: 0.02; acc: 0.98
Batch: 440; loss: 0.06; acc: 0.95
Batch: 460; loss: 0.08; acc: 0.95
Batch: 480; loss: 0.09; acc: 0.95
Batch: 500; loss: 0.1; acc: 0.94
Batch: 520; loss: 0.02; acc: 1.0
Batch: 540; loss: 0.08; acc: 0.95
Batch: 560; loss: 0.0; acc: 1.0
Batch: 580; loss: 0.03; acc: 0.98
Batch: 600; loss: 0.05; acc: 0.97
Batch: 620; loss: 0.04; acc: 0.98
Batch: 640; loss: 0.05; acc: 0.98
Batch: 660; loss: 0.06; acc: 0.97
Batch: 680; loss: 0.18; acc: 0.94
Batch: 700; loss: 0.09; acc: 0.95
Batch: 720; loss: 0.06; acc: 0.97
Batch: 740; loss: 0.12; acc: 0.97
Batch: 760; loss: 0.02; acc: 1.0
Batch: 780; loss: 0.07; acc: 0.98
Train Epoch over. train_loss: 0.08; train_accuracy: 0.97 

3.040752199012786e-05
1.0927713447017595e-05
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.03; acc: 1.0
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.09; acc: 0.98
Batch: 80; loss: 0.0; acc: 1.0
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.17; acc: 0.95
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.08715830197569671; val_accuracy: 0.9738256369426752 

The current subspace-distance is: 1.0927713447017595e-05 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.05; acc: 0.98
Batch: 20; loss: 0.2; acc: 0.97
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.05; acc: 0.98
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.17; acc: 0.95
Batch: 140; loss: 0.06; acc: 0.97
Batch: 160; loss: 0.08; acc: 0.97
Batch: 180; loss: 0.03; acc: 0.97
Batch: 200; loss: 0.03; acc: 1.0
Batch: 220; loss: 0.17; acc: 0.97
Batch: 240; loss: 0.09; acc: 0.98
Batch: 260; loss: 0.02; acc: 1.0
Batch: 280; loss: 0.1; acc: 0.95
Batch: 300; loss: 0.03; acc: 0.98
Batch: 320; loss: 0.08; acc: 0.95
Batch: 340; loss: 0.02; acc: 1.0
Batch: 360; loss: 0.18; acc: 0.97
Batch: 380; loss: 0.16; acc: 0.95
Batch: 400; loss: 0.13; acc: 0.92
Batch: 420; loss: 0.08; acc: 0.97
Batch: 440; loss: 0.15; acc: 0.92
Batch: 460; loss: 0.11; acc: 0.95
Batch: 480; loss: 0.04; acc: 1.0
Batch: 500; loss: 0.02; acc: 0.98
Batch: 520; loss: 0.06; acc: 0.97
Batch: 540; loss: 0.07; acc: 0.98
Batch: 560; loss: 0.07; acc: 0.97
Batch: 580; loss: 0.1; acc: 0.97
Batch: 600; loss: 0.06; acc: 0.97
Batch: 620; loss: 0.03; acc: 0.98
Batch: 640; loss: 0.06; acc: 0.97
Batch: 660; loss: 0.11; acc: 0.97
Batch: 680; loss: 0.02; acc: 1.0
Batch: 700; loss: 0.11; acc: 0.98
Batch: 720; loss: 0.11; acc: 0.97
Batch: 740; loss: 0.03; acc: 0.98
Batch: 760; loss: 0.01; acc: 1.0
Batch: 780; loss: 0.03; acc: 1.0
Train Epoch over. train_loss: 0.08; train_accuracy: 0.97 

3.112910781055689e-05
1.0447457498230506e-05
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.03; acc: 0.98
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.15; acc: 0.95
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.08696880356473907; val_accuracy: 0.9726313694267515 

The current subspace-distance is: 1.0447457498230506e-05 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.11; acc: 0.98
Batch: 20; loss: 0.05; acc: 0.98
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.05; acc: 0.98
Batch: 80; loss: 0.2; acc: 0.91
Batch: 100; loss: 0.04; acc: 0.98
Batch: 120; loss: 0.07; acc: 0.97
Batch: 140; loss: 0.11; acc: 0.95
Batch: 160; loss: 0.24; acc: 0.92
Batch: 180; loss: 0.09; acc: 0.95
Batch: 200; loss: 0.08; acc: 0.97
Batch: 220; loss: 0.02; acc: 0.98
Batch: 240; loss: 0.08; acc: 0.97
Batch: 260; loss: 0.1; acc: 0.98
Batch: 280; loss: 0.07; acc: 0.97
Batch: 300; loss: 0.01; acc: 1.0
Batch: 320; loss: 0.11; acc: 0.97
Batch: 340; loss: 0.06; acc: 0.98
Batch: 360; loss: 0.1; acc: 0.98
Batch: 380; loss: 0.02; acc: 1.0
Batch: 400; loss: 0.05; acc: 0.97
Batch: 420; loss: 0.09; acc: 0.95
Batch: 440; loss: 0.02; acc: 1.0
Batch: 460; loss: 0.05; acc: 0.98
Batch: 480; loss: 0.08; acc: 0.98
Batch: 500; loss: 0.14; acc: 0.95
Batch: 520; loss: 0.09; acc: 0.98
Batch: 540; loss: 0.18; acc: 0.91
Batch: 560; loss: 0.04; acc: 0.98
Batch: 580; loss: 0.18; acc: 0.94
Batch: 600; loss: 0.11; acc: 0.95
Batch: 620; loss: 0.04; acc: 1.0
Batch: 640; loss: 0.01; acc: 1.0
Batch: 660; loss: 0.07; acc: 0.97
Batch: 680; loss: 0.05; acc: 0.98
Batch: 700; loss: 0.07; acc: 0.98
Batch: 720; loss: 0.04; acc: 0.98
Batch: 740; loss: 0.03; acc: 0.98
Batch: 760; loss: 0.04; acc: 0.98
Batch: 780; loss: 0.07; acc: 0.98
Train Epoch over. train_loss: 0.08; train_accuracy: 0.97 

3.076836947002448e-05
9.973286978492979e-06
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.04; acc: 0.98
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.09; acc: 0.97
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.15; acc: 0.95
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.08744949964913214; val_accuracy: 0.9738256369426752 

The current subspace-distance is: 9.973286978492979e-06 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.21; acc: 0.95
Batch: 20; loss: 0.2; acc: 0.95
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.06; acc: 0.98
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.03; acc: 0.97
Batch: 120; loss: 0.04; acc: 0.98
Batch: 140; loss: 0.06; acc: 0.98
Batch: 160; loss: 0.01; acc: 1.0
Batch: 180; loss: 0.11; acc: 0.97
Batch: 200; loss: 0.05; acc: 0.97
Batch: 220; loss: 0.06; acc: 0.95
Batch: 240; loss: 0.08; acc: 0.95
Batch: 260; loss: 0.17; acc: 0.95
Batch: 280; loss: 0.07; acc: 0.98
Batch: 300; loss: 0.08; acc: 0.97
Batch: 320; loss: 0.06; acc: 0.98
Batch: 340; loss: 0.03; acc: 0.98
Batch: 360; loss: 0.06; acc: 0.97
Batch: 380; loss: 0.11; acc: 0.95
Batch: 400; loss: 0.05; acc: 0.97
Batch: 420; loss: 0.04; acc: 0.98
Batch: 440; loss: 0.05; acc: 0.97
Batch: 460; loss: 0.04; acc: 0.98
Batch: 480; loss: 0.11; acc: 0.95
Batch: 500; loss: 0.02; acc: 1.0
Batch: 520; loss: 0.12; acc: 0.97
Batch: 540; loss: 0.21; acc: 0.94
Batch: 560; loss: 0.05; acc: 0.98
Batch: 580; loss: 0.18; acc: 0.89
Batch: 600; loss: 0.07; acc: 0.98
Batch: 620; loss: 0.05; acc: 0.97
Batch: 640; loss: 0.05; acc: 0.95
Batch: 660; loss: 0.09; acc: 0.98
Batch: 680; loss: 0.07; acc: 0.97
Batch: 700; loss: 0.02; acc: 1.0
Batch: 720; loss: 0.16; acc: 0.94
Batch: 740; loss: 0.05; acc: 0.98
Batch: 760; loss: 0.01; acc: 1.0
Batch: 780; loss: 0.03; acc: 1.0
Train Epoch over. train_loss: 0.08; train_accuracy: 0.97 

3.008413659699727e-05
9.698738722363487e-06
Batch: 0; loss: 0.04; acc: 1.0
Batch: 20; loss: 0.04; acc: 0.98
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.09; acc: 0.97
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.15; acc: 0.95
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.08763585976402091; val_accuracy: 0.9737261146496815 

The current subspace-distance is: 9.698738722363487e-06 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.12; acc: 0.94
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.11; acc: 0.95
Batch: 120; loss: 0.09; acc: 0.98
Batch: 140; loss: 0.14; acc: 0.95
Batch: 160; loss: 0.06; acc: 0.97
Batch: 180; loss: 0.1; acc: 0.95
Batch: 200; loss: 0.05; acc: 0.97
Batch: 220; loss: 0.11; acc: 0.95
Batch: 240; loss: 0.08; acc: 0.95
Batch: 260; loss: 0.08; acc: 0.97
Batch: 280; loss: 0.14; acc: 0.95
Batch: 300; loss: 0.15; acc: 0.95
Batch: 320; loss: 0.3; acc: 0.95
Batch: 340; loss: 0.1; acc: 0.97
Batch: 360; loss: 0.02; acc: 1.0
Batch: 380; loss: 0.12; acc: 0.97
Batch: 400; loss: 0.15; acc: 0.97
Batch: 420; loss: 0.12; acc: 0.91
Batch: 440; loss: 0.07; acc: 0.97
Batch: 460; loss: 0.04; acc: 1.0
Batch: 480; loss: 0.14; acc: 0.95
Batch: 500; loss: 0.09; acc: 0.95
Batch: 520; loss: 0.12; acc: 0.97
Batch: 540; loss: 0.02; acc: 1.0
Batch: 560; loss: 0.11; acc: 0.98
Batch: 580; loss: 0.18; acc: 0.97
Batch: 600; loss: 0.18; acc: 0.95
Batch: 620; loss: 0.03; acc: 0.98
Batch: 640; loss: 0.08; acc: 0.98
Batch: 660; loss: 0.11; acc: 0.94
Batch: 680; loss: 0.04; acc: 0.98
Batch: 700; loss: 0.05; acc: 0.98
Batch: 720; loss: 0.04; acc: 0.98
Batch: 740; loss: 0.23; acc: 0.95
Batch: 760; loss: 0.05; acc: 0.98
Batch: 780; loss: 0.04; acc: 0.98
Train Epoch over. train_loss: 0.08; train_accuracy: 0.97 

3.052085594390519e-05
9.712707651488017e-06
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.04; acc: 0.98
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.09; acc: 0.97
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.16; acc: 0.94
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.0880782356853508; val_accuracy: 0.9729299363057324 

The current subspace-distance is: 9.712707651488017e-06 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.1; acc: 0.97
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.19; acc: 0.97
Batch: 80; loss: 0.03; acc: 0.98
Batch: 100; loss: 0.02; acc: 1.0
Batch: 120; loss: 0.16; acc: 0.95
Batch: 140; loss: 0.01; acc: 1.0
Batch: 160; loss: 0.03; acc: 0.98
Batch: 180; loss: 0.01; acc: 1.0
Batch: 200; loss: 0.16; acc: 0.97
Batch: 220; loss: 0.03; acc: 0.98
Batch: 240; loss: 0.22; acc: 0.95
Batch: 260; loss: 0.15; acc: 0.98
Batch: 280; loss: 0.21; acc: 0.94
Batch: 300; loss: 0.09; acc: 0.98
Batch: 320; loss: 0.07; acc: 0.98
Batch: 340; loss: 0.02; acc: 1.0
Batch: 360; loss: 0.11; acc: 0.95
Batch: 380; loss: 0.02; acc: 1.0
Batch: 400; loss: 0.03; acc: 0.98
Batch: 420; loss: 0.1; acc: 0.97
Batch: 440; loss: 0.13; acc: 0.92
Batch: 460; loss: 0.1; acc: 0.97
Batch: 480; loss: 0.05; acc: 0.98
Batch: 500; loss: 0.03; acc: 0.98
Batch: 520; loss: 0.03; acc: 1.0
Batch: 540; loss: 0.06; acc: 0.98
Batch: 560; loss: 0.01; acc: 1.0
Batch: 580; loss: 0.03; acc: 0.98
Batch: 600; loss: 0.18; acc: 0.97
Batch: 620; loss: 0.03; acc: 1.0
Batch: 640; loss: 0.05; acc: 0.97
Batch: 660; loss: 0.08; acc: 0.95
Batch: 680; loss: 0.1; acc: 0.97
Batch: 700; loss: 0.12; acc: 0.95
Batch: 720; loss: 0.19; acc: 0.92
Batch: 740; loss: 0.11; acc: 0.97
Batch: 760; loss: 0.06; acc: 0.98
Batch: 780; loss: 0.08; acc: 0.97
Train Epoch over. train_loss: 0.08; train_accuracy: 0.97 

3.081380054936744e-05
1.0029627446783707e-05
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.03; acc: 0.98
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.16; acc: 0.95
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.08689964099959203; val_accuracy: 0.9729299363057324 

The current subspace-distance is: 1.0029627446783707e-05 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.08; acc: 0.97
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.06; acc: 0.98
Batch: 80; loss: 0.03; acc: 1.0
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.11; acc: 0.97
Batch: 140; loss: 0.13; acc: 0.98
Batch: 160; loss: 0.06; acc: 0.98
Batch: 180; loss: 0.03; acc: 1.0
Batch: 200; loss: 0.11; acc: 0.95
Batch: 220; loss: 0.08; acc: 0.98
Batch: 240; loss: 0.06; acc: 0.97
Batch: 260; loss: 0.02; acc: 1.0
Batch: 280; loss: 0.08; acc: 0.97
Batch: 300; loss: 0.15; acc: 0.97
Batch: 320; loss: 0.27; acc: 0.95
Batch: 340; loss: 0.05; acc: 0.98
Batch: 360; loss: 0.22; acc: 0.94
Batch: 380; loss: 0.07; acc: 0.98
Batch: 400; loss: 0.02; acc: 1.0
Batch: 420; loss: 0.13; acc: 0.97
Batch: 440; loss: 0.02; acc: 1.0
Batch: 460; loss: 0.23; acc: 0.95
Batch: 480; loss: 0.05; acc: 0.97
Batch: 500; loss: 0.1; acc: 0.98
Batch: 520; loss: 0.03; acc: 1.0
Batch: 540; loss: 0.13; acc: 0.97
Batch: 560; loss: 0.1; acc: 0.95
Batch: 580; loss: 0.08; acc: 0.97
Batch: 600; loss: 0.06; acc: 0.98
Batch: 620; loss: 0.13; acc: 0.95
Batch: 640; loss: 0.03; acc: 1.0
Batch: 660; loss: 0.09; acc: 0.97
Batch: 680; loss: 0.03; acc: 0.98
Batch: 700; loss: 0.08; acc: 0.97
Batch: 720; loss: 0.04; acc: 1.0
Batch: 740; loss: 0.06; acc: 0.98
Batch: 760; loss: 0.14; acc: 0.97
Batch: 780; loss: 0.09; acc: 0.97
Train Epoch over. train_loss: 0.08; train_accuracy: 0.97 

3.0553586839232594e-05
1.0724997082434129e-05
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.04; acc: 0.98
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.09; acc: 0.97
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.04; acc: 0.98
Batch: 120; loss: 0.15; acc: 0.95
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.08807694884669628; val_accuracy: 0.9735270700636943 

The current subspace-distance is: 1.0724997082434129e-05 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.08; acc: 0.95
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.03; acc: 0.98
Batch: 80; loss: 0.08; acc: 0.95
Batch: 100; loss: 0.09; acc: 0.98
Batch: 120; loss: 0.1; acc: 0.97
Batch: 140; loss: 0.04; acc: 0.98
Batch: 160; loss: 0.03; acc: 1.0
Batch: 180; loss: 0.04; acc: 1.0
Batch: 200; loss: 0.04; acc: 1.0
Batch: 220; loss: 0.11; acc: 0.95
Batch: 240; loss: 0.01; acc: 1.0
Batch: 260; loss: 0.18; acc: 0.95
Batch: 280; loss: 0.07; acc: 0.97
Batch: 300; loss: 0.01; acc: 1.0
Batch: 320; loss: 0.04; acc: 0.97
Batch: 340; loss: 0.14; acc: 0.98
Batch: 360; loss: 0.13; acc: 0.97
Batch: 380; loss: 0.05; acc: 0.98
Batch: 400; loss: 0.04; acc: 0.98
Batch: 420; loss: 0.08; acc: 0.97
Batch: 440; loss: 0.02; acc: 1.0
Batch: 460; loss: 0.11; acc: 0.95
Batch: 480; loss: 0.01; acc: 1.0
Batch: 500; loss: 0.04; acc: 0.97
Batch: 520; loss: 0.07; acc: 0.97
Batch: 540; loss: 0.14; acc: 0.97
Batch: 560; loss: 0.03; acc: 0.98
Batch: 580; loss: 0.06; acc: 0.95
Batch: 600; loss: 0.05; acc: 0.98
Batch: 620; loss: 0.13; acc: 0.97
Batch: 640; loss: 0.06; acc: 0.97
Batch: 660; loss: 0.04; acc: 1.0
Batch: 680; loss: 0.1; acc: 0.97
Batch: 700; loss: 0.22; acc: 0.95
Batch: 720; loss: 0.09; acc: 0.94
Batch: 740; loss: 0.18; acc: 0.97
Batch: 760; loss: 0.04; acc: 0.98
Batch: 780; loss: 0.08; acc: 0.98
Train Epoch over. train_loss: 0.08; train_accuracy: 0.97 

3.2013347663450986e-05
1.0523373020987492e-05
Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.04; acc: 0.98
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.09; acc: 0.97
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.15; acc: 0.95
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.0881505029477701; val_accuracy: 0.9736265923566879 

The current subspace-distance is: 1.0523373020987492e-05 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.14; acc: 0.98
Batch: 20; loss: 0.07; acc: 0.97
Batch: 40; loss: 0.01; acc: 1.0
Batch: 60; loss: 0.04; acc: 1.0
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.1; acc: 0.98
Batch: 120; loss: 0.03; acc: 0.98
Batch: 140; loss: 0.11; acc: 0.94
Batch: 160; loss: 0.05; acc: 0.98
Batch: 180; loss: 0.04; acc: 0.98
Batch: 200; loss: 0.11; acc: 0.95
Batch: 220; loss: 0.01; acc: 1.0
Batch: 240; loss: 0.07; acc: 0.97
Batch: 260; loss: 0.09; acc: 0.97
Batch: 280; loss: 0.16; acc: 0.94
Batch: 300; loss: 0.05; acc: 0.98
Batch: 320; loss: 0.16; acc: 0.97
Batch: 340; loss: 0.02; acc: 1.0
Batch: 360; loss: 0.09; acc: 0.97
Batch: 380; loss: 0.17; acc: 0.94
Batch: 400; loss: 0.07; acc: 0.98
Batch: 420; loss: 0.04; acc: 0.98
Batch: 440; loss: 0.02; acc: 1.0
Batch: 460; loss: 0.02; acc: 1.0
Batch: 480; loss: 0.1; acc: 0.98
Batch: 500; loss: 0.15; acc: 0.97
Batch: 520; loss: 0.1; acc: 0.97
Batch: 540; loss: 0.35; acc: 0.92
Batch: 560; loss: 0.18; acc: 0.92
Batch: 580; loss: 0.03; acc: 1.0
Batch: 600; loss: 0.14; acc: 0.97
Batch: 620; loss: 0.15; acc: 0.95
Batch: 640; loss: 0.08; acc: 0.97
Batch: 660; loss: 0.02; acc: 1.0
Batch: 680; loss: 0.05; acc: 0.98
Batch: 700; loss: 0.03; acc: 1.0
Batch: 720; loss: 0.07; acc: 0.97
Batch: 740; loss: 0.01; acc: 1.0
Batch: 760; loss: 0.04; acc: 0.98
Batch: 780; loss: 0.05; acc: 0.98
Train Epoch over. train_loss: 0.08; train_accuracy: 0.97 

3.131162156932987e-05
9.698503163235728e-06
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.04; acc: 0.98
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.09; acc: 0.97
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.16; acc: 0.95
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.08790446807197325; val_accuracy: 0.9729299363057324 

The current subspace-distance is: 9.698503163235728e-06 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.2; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.15; acc: 0.95
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.02; acc: 1.0
Batch: 120; loss: 0.05; acc: 0.98
Batch: 140; loss: 0.02; acc: 0.98
Batch: 160; loss: 0.11; acc: 0.97
Batch: 180; loss: 0.03; acc: 1.0
Batch: 200; loss: 0.08; acc: 0.98
Batch: 220; loss: 0.02; acc: 1.0
Batch: 240; loss: 0.04; acc: 1.0
Batch: 260; loss: 0.04; acc: 0.98
Batch: 280; loss: 0.28; acc: 0.97
Batch: 300; loss: 0.03; acc: 0.98
Batch: 320; loss: 0.01; acc: 1.0
Batch: 340; loss: 0.21; acc: 0.92
Batch: 360; loss: 0.08; acc: 0.98
Batch: 380; loss: 0.02; acc: 1.0
Batch: 400; loss: 0.14; acc: 0.97
Batch: 420; loss: 0.13; acc: 0.97
Batch: 440; loss: 0.02; acc: 1.0
Batch: 460; loss: 0.01; acc: 1.0
Batch: 480; loss: 0.05; acc: 0.97
Batch: 500; loss: 0.08; acc: 0.95
Batch: 520; loss: 0.18; acc: 0.97
Batch: 540; loss: 0.09; acc: 0.97
Batch: 560; loss: 0.04; acc: 1.0
Batch: 580; loss: 0.07; acc: 0.98
Batch: 600; loss: 0.12; acc: 0.98
Batch: 620; loss: 0.01; acc: 1.0
Batch: 640; loss: 0.2; acc: 0.95
Batch: 660; loss: 0.01; acc: 1.0
Batch: 680; loss: 0.06; acc: 0.98
Batch: 700; loss: 0.02; acc: 1.0
Batch: 720; loss: 0.04; acc: 1.0
Batch: 740; loss: 0.06; acc: 0.95
Batch: 760; loss: 0.06; acc: 0.95
Batch: 780; loss: 0.14; acc: 0.95
Train Epoch over. train_loss: 0.08; train_accuracy: 0.97 

3.098078741459176e-05
9.310577297583222e-06
Batch: 0; loss: 0.04; acc: 1.0
Batch: 20; loss: 0.04; acc: 0.98
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.09; acc: 0.97
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.15; acc: 0.95
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.08781768841918107; val_accuracy: 0.9731289808917197 

The current subspace-distance is: 9.310577297583222e-06 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.11; acc: 0.95
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.08; acc: 0.98
Batch: 80; loss: 0.23; acc: 0.97
Batch: 100; loss: 0.03; acc: 0.98
Batch: 120; loss: 0.14; acc: 0.95
Batch: 140; loss: 0.12; acc: 0.97
Batch: 160; loss: 0.05; acc: 0.98
Batch: 180; loss: 0.05; acc: 0.98
Batch: 200; loss: 0.09; acc: 0.95
Batch: 220; loss: 0.09; acc: 0.97
Batch: 240; loss: 0.11; acc: 0.98
Batch: 260; loss: 0.12; acc: 0.97
Batch: 280; loss: 0.07; acc: 0.97
Batch: 300; loss: 0.04; acc: 0.98
Batch: 320; loss: 0.08; acc: 0.95
Batch: 340; loss: 0.02; acc: 1.0
Batch: 360; loss: 0.12; acc: 0.95
Batch: 380; loss: 0.07; acc: 0.98
Batch: 400; loss: 0.11; acc: 0.94
Batch: 420; loss: 0.04; acc: 0.98
Batch: 440; loss: 0.04; acc: 0.97
Batch: 460; loss: 0.09; acc: 0.98
Batch: 480; loss: 0.04; acc: 0.98
Batch: 500; loss: 0.03; acc: 0.98
Batch: 520; loss: 0.03; acc: 1.0
Batch: 540; loss: 0.07; acc: 0.97
Batch: 560; loss: 0.08; acc: 0.97
Batch: 580; loss: 0.12; acc: 0.97
Batch: 600; loss: 0.08; acc: 0.98
Batch: 620; loss: 0.04; acc: 0.98
Batch: 640; loss: 0.05; acc: 0.98
Batch: 660; loss: 0.03; acc: 1.0
Batch: 680; loss: 0.09; acc: 0.97
Batch: 700; loss: 0.14; acc: 0.95
Batch: 720; loss: 0.02; acc: 0.98
Batch: 740; loss: 0.08; acc: 0.97
Batch: 760; loss: 0.07; acc: 0.97
Batch: 780; loss: 0.1; acc: 0.95
Train Epoch over. train_loss: 0.08; train_accuracy: 0.97 

2.932330062321853e-05
9.092827895074151e-06
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.04; acc: 0.98
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.09; acc: 0.97
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.15; acc: 0.95
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.08787501824035007; val_accuracy: 0.9727308917197452 

The current subspace-distance is: 9.092827895074151e-06 

plots/subspace_training/reg_lenet_3/2020-01-22 20:51:04/d_dim_350_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
nonzero elements in E: 84962
elements in E: 17996000
fraction nonzero: 0.004721160257835075
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.31; acc: 0.08
Batch: 20; loss: 2.29; acc: 0.05
Batch: 40; loss: 2.3; acc: 0.09
Batch: 60; loss: 2.3; acc: 0.02
Batch: 80; loss: 2.29; acc: 0.08
Batch: 100; loss: 2.29; acc: 0.17
Batch: 120; loss: 2.3; acc: 0.11
Batch: 140; loss: 2.3; acc: 0.06
Batch: 160; loss: 2.29; acc: 0.19
Batch: 180; loss: 2.28; acc: 0.16
Batch: 200; loss: 2.27; acc: 0.16
Batch: 220; loss: 2.27; acc: 0.22
Batch: 240; loss: 2.27; acc: 0.16
Batch: 260; loss: 2.25; acc: 0.28
Batch: 280; loss: 2.2; acc: 0.44
Batch: 300; loss: 2.11; acc: 0.34
Batch: 320; loss: 1.98; acc: 0.45
Batch: 340; loss: 1.64; acc: 0.47
Batch: 360; loss: 1.58; acc: 0.47
Batch: 380; loss: 1.38; acc: 0.48
Batch: 400; loss: 1.69; acc: 0.36
Batch: 420; loss: 1.21; acc: 0.59
Batch: 440; loss: 1.03; acc: 0.66
Batch: 460; loss: 0.83; acc: 0.67
Batch: 480; loss: 0.99; acc: 0.62
Batch: 500; loss: 1.16; acc: 0.61
Batch: 520; loss: 0.83; acc: 0.67
Batch: 540; loss: 0.82; acc: 0.72
Batch: 560; loss: 0.68; acc: 0.77
Batch: 580; loss: 0.77; acc: 0.75
Batch: 600; loss: 0.52; acc: 0.83
Batch: 620; loss: 0.63; acc: 0.75
Batch: 640; loss: 0.69; acc: 0.8
Batch: 660; loss: 0.56; acc: 0.86
Batch: 680; loss: 0.58; acc: 0.8
Batch: 700; loss: 0.54; acc: 0.83
Batch: 720; loss: 0.55; acc: 0.83
Batch: 740; loss: 0.44; acc: 0.88
Batch: 760; loss: 0.5; acc: 0.88
Batch: 780; loss: 0.52; acc: 0.88
Train Epoch over. train_loss: 1.47; train_accuracy: 0.48 

1.4769785593671259e-05
8.78506398294121e-06
Batch: 0; loss: 0.38; acc: 0.89
Batch: 20; loss: 0.59; acc: 0.8
Batch: 40; loss: 0.22; acc: 0.91
Batch: 60; loss: 0.63; acc: 0.81
Batch: 80; loss: 0.32; acc: 0.91
Batch: 100; loss: 0.41; acc: 0.92
Batch: 120; loss: 0.58; acc: 0.81
Batch: 140; loss: 0.25; acc: 0.91
Val Epoch over. val_loss: 0.44263551118457395; val_accuracy: 0.868531050955414 

The current subspace-distance is: 8.78506398294121e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 0.5; acc: 0.84
Batch: 20; loss: 0.49; acc: 0.83
Batch: 40; loss: 0.26; acc: 0.91
Batch: 60; loss: 0.47; acc: 0.88
Batch: 80; loss: 0.49; acc: 0.84
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.44; acc: 0.91
Batch: 140; loss: 0.39; acc: 0.88
Batch: 160; loss: 0.41; acc: 0.89
Batch: 180; loss: 0.34; acc: 0.92
Batch: 200; loss: 0.25; acc: 0.91
Batch: 220; loss: 0.63; acc: 0.84
Batch: 240; loss: 0.4; acc: 0.89
Batch: 260; loss: 0.34; acc: 0.92
Batch: 280; loss: 0.36; acc: 0.88
Batch: 300; loss: 0.21; acc: 0.95
Batch: 320; loss: 0.36; acc: 0.91
Batch: 340; loss: 0.55; acc: 0.8
Batch: 360; loss: 0.16; acc: 0.94
Batch: 380; loss: 0.22; acc: 0.92
Batch: 400; loss: 0.3; acc: 0.91
Batch: 420; loss: 0.39; acc: 0.81
Batch: 440; loss: 0.42; acc: 0.91
Batch: 460; loss: 0.27; acc: 0.92
Batch: 480; loss: 0.08; acc: 0.98
Batch: 500; loss: 0.16; acc: 0.95
Batch: 520; loss: 0.19; acc: 0.92
Batch: 540; loss: 0.22; acc: 0.95
Batch: 560; loss: 0.16; acc: 0.92
Batch: 580; loss: 0.14; acc: 0.95
Batch: 600; loss: 0.22; acc: 0.92
Batch: 620; loss: 0.22; acc: 0.94
Batch: 640; loss: 0.26; acc: 0.92
Batch: 660; loss: 0.39; acc: 0.88
Batch: 680; loss: 0.23; acc: 0.92
Batch: 700; loss: 0.28; acc: 0.91
Batch: 720; loss: 0.32; acc: 0.91
Batch: 740; loss: 0.48; acc: 0.91
Batch: 760; loss: 0.29; acc: 0.92
Batch: 780; loss: 0.21; acc: 0.94
Train Epoch over. train_loss: 0.31; train_accuracy: 0.9 

2.2677742890664376e-05
1.1122112482553348e-05
Batch: 0; loss: 0.16; acc: 0.91
Batch: 20; loss: 0.18; acc: 0.92
Batch: 40; loss: 0.18; acc: 0.97
Batch: 60; loss: 0.46; acc: 0.84
Batch: 80; loss: 0.3; acc: 0.92
Batch: 100; loss: 0.34; acc: 0.94
Batch: 120; loss: 0.48; acc: 0.83
Batch: 140; loss: 0.08; acc: 1.0
Val Epoch over. val_loss: 0.2805296720545383; val_accuracy: 0.9130175159235668 

The current subspace-distance is: 1.1122112482553348e-05 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.37; acc: 0.89
Batch: 20; loss: 0.28; acc: 0.94
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.31; acc: 0.89
Batch: 100; loss: 0.28; acc: 0.89
Batch: 120; loss: 0.48; acc: 0.86
Batch: 140; loss: 0.23; acc: 0.92
Batch: 160; loss: 0.24; acc: 0.95
Batch: 180; loss: 0.22; acc: 0.88
Batch: 200; loss: 0.17; acc: 0.94
Batch: 220; loss: 0.24; acc: 0.94
Batch: 240; loss: 0.39; acc: 0.91
Batch: 260; loss: 0.35; acc: 0.88
Batch: 280; loss: 0.07; acc: 0.97
Batch: 300; loss: 0.19; acc: 0.97
Batch: 320; loss: 0.19; acc: 0.92
Batch: 340; loss: 0.12; acc: 0.95
Batch: 360; loss: 0.11; acc: 0.94
Batch: 380; loss: 0.37; acc: 0.92
Batch: 400; loss: 0.32; acc: 0.94
Batch: 420; loss: 0.38; acc: 0.89
Batch: 440; loss: 0.2; acc: 0.95
Batch: 460; loss: 0.36; acc: 0.94
Batch: 480; loss: 0.13; acc: 0.94
Batch: 500; loss: 0.41; acc: 0.86
Batch: 520; loss: 0.1; acc: 0.97
Batch: 540; loss: 0.12; acc: 0.98
Batch: 560; loss: 0.15; acc: 0.92
Batch: 580; loss: 0.09; acc: 0.97
Batch: 600; loss: 0.22; acc: 0.94
Batch: 620; loss: 0.6; acc: 0.86
Batch: 640; loss: 0.11; acc: 0.95
Batch: 660; loss: 0.27; acc: 0.92
Batch: 680; loss: 0.18; acc: 0.94
Batch: 700; loss: 0.25; acc: 0.92
Batch: 720; loss: 0.04; acc: 1.0
Batch: 740; loss: 0.11; acc: 0.97
Batch: 760; loss: 0.14; acc: 0.95
Batch: 780; loss: 0.17; acc: 0.94
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.45803330471972e-05
1.1126254321425222e-05
Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.2; acc: 0.95
Batch: 40; loss: 0.14; acc: 0.94
Batch: 60; loss: 0.27; acc: 0.91
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.29; acc: 0.88
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.1913187650928072; val_accuracy: 0.9442675159235668 

The current subspace-distance is: 1.1126254321425222e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.1; acc: 0.95
Batch: 40; loss: 0.18; acc: 0.92
Batch: 60; loss: 0.11; acc: 0.95
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.04; acc: 1.0
Batch: 120; loss: 0.07; acc: 0.98
Batch: 140; loss: 0.14; acc: 0.97
Batch: 160; loss: 0.12; acc: 0.95
Batch: 180; loss: 0.19; acc: 0.94
Batch: 200; loss: 0.12; acc: 0.97
Batch: 220; loss: 0.47; acc: 0.92
Batch: 240; loss: 0.36; acc: 0.92
Batch: 260; loss: 0.07; acc: 1.0
Batch: 280; loss: 0.33; acc: 0.97
Batch: 300; loss: 0.13; acc: 0.94
Batch: 320; loss: 0.13; acc: 0.97
Batch: 340; loss: 0.14; acc: 0.97
Batch: 360; loss: 0.1; acc: 0.97
Batch: 380; loss: 0.13; acc: 0.91
Batch: 400; loss: 0.11; acc: 0.97
Batch: 420; loss: 0.36; acc: 0.91
Batch: 440; loss: 0.04; acc: 0.98
Batch: 460; loss: 0.07; acc: 0.98
Batch: 480; loss: 0.23; acc: 0.92
Batch: 500; loss: 0.17; acc: 0.94
Batch: 520; loss: 0.16; acc: 0.91
Batch: 540; loss: 0.19; acc: 0.95
Batch: 560; loss: 0.42; acc: 0.89
Batch: 580; loss: 0.21; acc: 0.94
Batch: 600; loss: 0.11; acc: 0.95
Batch: 620; loss: 0.47; acc: 0.89
Batch: 640; loss: 0.33; acc: 0.92
Batch: 660; loss: 0.35; acc: 0.88
Batch: 680; loss: 0.2; acc: 0.95
Batch: 700; loss: 0.12; acc: 0.95
Batch: 720; loss: 0.27; acc: 0.94
Batch: 740; loss: 0.18; acc: 0.95
Batch: 760; loss: 0.13; acc: 0.94
Batch: 780; loss: 0.05; acc: 0.97
Train Epoch over. train_loss: 0.18; train_accuracy: 0.94 

2.6052992325276136e-05
1.2253130080353003e-05
Batch: 0; loss: 0.06; acc: 0.98
Batch: 20; loss: 0.17; acc: 0.92
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.14; acc: 0.94
Batch: 80; loss: 0.08; acc: 0.95
Batch: 100; loss: 0.17; acc: 0.97
Batch: 120; loss: 0.18; acc: 0.94
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.15067862451171418; val_accuracy: 0.95421974522293 

The current subspace-distance is: 1.2253130080353003e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.1; acc: 0.94
Batch: 20; loss: 0.26; acc: 0.92
Batch: 40; loss: 0.2; acc: 0.92
Batch: 60; loss: 0.26; acc: 0.91
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.07; acc: 0.98
Batch: 120; loss: 0.15; acc: 0.92
Batch: 140; loss: 0.2; acc: 0.94
Batch: 160; loss: 0.1; acc: 0.94
Batch: 180; loss: 0.05; acc: 0.98
Batch: 200; loss: 0.18; acc: 0.92
Batch: 220; loss: 0.13; acc: 0.92
Batch: 240; loss: 0.16; acc: 0.95
Batch: 260; loss: 0.16; acc: 0.92
Batch: 280; loss: 0.19; acc: 0.94
Batch: 300; loss: 0.18; acc: 0.95
Batch: 320; loss: 0.07; acc: 0.98
Batch: 340; loss: 0.09; acc: 0.97
Batch: 360; loss: 0.06; acc: 1.0
Batch: 380; loss: 0.05; acc: 1.0
Batch: 400; loss: 0.12; acc: 0.97
Batch: 420; loss: 0.18; acc: 0.92
Batch: 440; loss: 0.08; acc: 0.98
Batch: 460; loss: 0.15; acc: 0.95
Batch: 480; loss: 0.08; acc: 0.98
Batch: 500; loss: 0.18; acc: 0.97
Batch: 520; loss: 0.03; acc: 1.0
Batch: 540; loss: 0.11; acc: 0.98
Batch: 560; loss: 0.15; acc: 0.94
Batch: 580; loss: 0.2; acc: 0.95
Batch: 600; loss: 0.11; acc: 0.97
Batch: 620; loss: 0.09; acc: 0.97
Batch: 640; loss: 0.2; acc: 0.92
Batch: 660; loss: 0.4; acc: 0.91
Batch: 680; loss: 0.18; acc: 0.95
Batch: 700; loss: 0.14; acc: 0.94
Batch: 720; loss: 0.15; acc: 0.92
Batch: 740; loss: 0.09; acc: 0.97
Batch: 760; loss: 0.21; acc: 0.95
Batch: 780; loss: 0.06; acc: 0.98
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

2.683689490368124e-05
1.275537670153426e-05
Batch: 0; loss: 0.21; acc: 0.97
Batch: 20; loss: 0.14; acc: 0.94
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.16; acc: 0.92
Batch: 80; loss: 0.23; acc: 0.91
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.26; acc: 0.92
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.208518253912212; val_accuracy: 0.9366042993630573 

The current subspace-distance is: 1.275537670153426e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.24; acc: 0.91
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.11; acc: 0.94
Batch: 140; loss: 0.12; acc: 0.94
Batch: 160; loss: 0.16; acc: 0.95
Batch: 180; loss: 0.06; acc: 1.0
Batch: 200; loss: 0.17; acc: 0.95
Batch: 220; loss: 0.09; acc: 0.98
Batch: 240; loss: 0.09; acc: 0.97
Batch: 260; loss: 0.27; acc: 0.95
Batch: 280; loss: 0.02; acc: 1.0
Batch: 300; loss: 0.22; acc: 0.95
Batch: 320; loss: 0.09; acc: 0.98
Batch: 340; loss: 0.09; acc: 0.98
Batch: 360; loss: 0.18; acc: 0.92
Batch: 380; loss: 0.31; acc: 0.91
Batch: 400; loss: 0.05; acc: 1.0
Batch: 420; loss: 0.24; acc: 0.91
Batch: 440; loss: 0.27; acc: 0.94
Batch: 460; loss: 0.08; acc: 0.98
Batch: 480; loss: 0.14; acc: 0.97
Batch: 500; loss: 0.17; acc: 0.92
Batch: 520; loss: 0.16; acc: 0.94
Batch: 540; loss: 0.11; acc: 0.98
Batch: 560; loss: 0.21; acc: 0.94
Batch: 580; loss: 0.04; acc: 0.98
Batch: 600; loss: 0.14; acc: 0.95
Batch: 620; loss: 0.04; acc: 1.0
Batch: 640; loss: 0.16; acc: 0.94
Batch: 660; loss: 0.39; acc: 0.91
Batch: 680; loss: 0.1; acc: 0.97
Batch: 700; loss: 0.14; acc: 0.97
Batch: 720; loss: 0.3; acc: 0.92
Batch: 740; loss: 0.1; acc: 0.98
Batch: 760; loss: 0.12; acc: 0.97
Batch: 780; loss: 0.09; acc: 0.98
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.77003382507246e-05
1.365141633868916e-05
Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.14; acc: 0.97
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.14; acc: 0.94
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.16; acc: 0.95
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.12934032405257984; val_accuracy: 0.9626791401273885 

The current subspace-distance is: 1.365141633868916e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.03; acc: 1.0
Batch: 40; loss: 0.1; acc: 0.95
Batch: 60; loss: 0.09; acc: 0.97
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.97
Batch: 120; loss: 0.13; acc: 0.95
Batch: 140; loss: 0.17; acc: 0.97
Batch: 160; loss: 0.25; acc: 0.94
Batch: 180; loss: 0.13; acc: 0.94
Batch: 200; loss: 0.19; acc: 0.95
Batch: 220; loss: 0.13; acc: 0.95
Batch: 240; loss: 0.16; acc: 0.94
Batch: 260; loss: 0.16; acc: 0.95
Batch: 280; loss: 0.16; acc: 0.95
Batch: 300; loss: 0.06; acc: 0.98
Batch: 320; loss: 0.17; acc: 0.95
Batch: 340; loss: 0.32; acc: 0.89
Batch: 360; loss: 0.19; acc: 0.94
Batch: 380; loss: 0.21; acc: 0.94
Batch: 400; loss: 0.14; acc: 0.95
Batch: 420; loss: 0.2; acc: 0.88
Batch: 440; loss: 0.21; acc: 0.92
Batch: 460; loss: 0.04; acc: 0.98
Batch: 480; loss: 0.09; acc: 0.98
Batch: 500; loss: 0.03; acc: 0.98
Batch: 520; loss: 0.08; acc: 0.97
Batch: 540; loss: 0.13; acc: 0.95
Batch: 560; loss: 0.04; acc: 1.0
Batch: 580; loss: 0.06; acc: 0.97
Batch: 600; loss: 0.04; acc: 1.0
Batch: 620; loss: 0.17; acc: 0.97
Batch: 640; loss: 0.27; acc: 0.89
Batch: 660; loss: 0.16; acc: 0.94
Batch: 680; loss: 0.06; acc: 0.98
Batch: 700; loss: 0.15; acc: 0.95
Batch: 720; loss: 0.09; acc: 0.95
Batch: 740; loss: 0.01; acc: 1.0
Batch: 760; loss: 0.1; acc: 0.95
Batch: 780; loss: 0.1; acc: 0.95
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

2.9612901926157065e-05
1.420700027665589e-05
Batch: 0; loss: 0.09; acc: 0.95
Batch: 20; loss: 0.12; acc: 0.95
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.19; acc: 0.92
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.29; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14159750096072818; val_accuracy: 0.9580015923566879 

The current subspace-distance is: 1.420700027665589e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.02; acc: 1.0
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.15; acc: 0.98
Batch: 80; loss: 0.38; acc: 0.89
Batch: 100; loss: 0.04; acc: 0.98
Batch: 120; loss: 0.15; acc: 0.95
Batch: 140; loss: 0.12; acc: 0.97
Batch: 160; loss: 0.17; acc: 0.94
Batch: 180; loss: 0.12; acc: 0.95
Batch: 200; loss: 0.08; acc: 0.97
Batch: 220; loss: 0.14; acc: 0.95
Batch: 240; loss: 0.11; acc: 0.97
Batch: 260; loss: 0.11; acc: 0.97
Batch: 280; loss: 0.25; acc: 0.95
Batch: 300; loss: 0.11; acc: 0.92
Batch: 320; loss: 0.26; acc: 0.92
Batch: 340; loss: 0.13; acc: 0.95
Batch: 360; loss: 0.12; acc: 0.97
Batch: 380; loss: 0.03; acc: 0.98
Batch: 400; loss: 0.14; acc: 0.95
Batch: 420; loss: 0.07; acc: 0.97
Batch: 440; loss: 0.11; acc: 0.97
Batch: 460; loss: 0.09; acc: 0.94
Batch: 480; loss: 0.1; acc: 0.97
Batch: 500; loss: 0.1; acc: 0.97
Batch: 520; loss: 0.14; acc: 0.95
Batch: 540; loss: 0.18; acc: 0.95
Batch: 560; loss: 0.05; acc: 0.98
Batch: 580; loss: 0.1; acc: 0.98
Batch: 600; loss: 0.15; acc: 0.95
Batch: 620; loss: 0.12; acc: 0.97
Batch: 640; loss: 0.02; acc: 1.0
Batch: 660; loss: 0.14; acc: 0.98
Batch: 680; loss: 0.09; acc: 0.97
Batch: 700; loss: 0.17; acc: 0.94
Batch: 720; loss: 0.05; acc: 1.0
Batch: 740; loss: 0.24; acc: 0.94
Batch: 760; loss: 0.02; acc: 1.0
Batch: 780; loss: 0.1; acc: 0.97
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

2.9199796699685976e-05
1.3779908840660937e-05
Batch: 0; loss: 0.06; acc: 1.0
Batch: 20; loss: 0.12; acc: 0.95
Batch: 40; loss: 0.05; acc: 0.97
Batch: 60; loss: 0.16; acc: 0.94
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.27; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.13285215664061772; val_accuracy: 0.9617834394904459 

The current subspace-distance is: 1.3779908840660937e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.05; acc: 0.97
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.34; acc: 0.92
Batch: 80; loss: 0.24; acc: 0.97
Batch: 100; loss: 0.03; acc: 1.0
Batch: 120; loss: 0.2; acc: 0.94
Batch: 140; loss: 0.28; acc: 0.92
Batch: 160; loss: 0.13; acc: 0.94
Batch: 180; loss: 0.22; acc: 0.91
Batch: 200; loss: 0.03; acc: 0.98
Batch: 220; loss: 0.1; acc: 0.98
Batch: 240; loss: 0.06; acc: 0.98
Batch: 260; loss: 0.06; acc: 0.98
Batch: 280; loss: 0.31; acc: 0.91
Batch: 300; loss: 0.05; acc: 1.0
Batch: 320; loss: 0.42; acc: 0.95
Batch: 340; loss: 0.13; acc: 0.95
Batch: 360; loss: 0.12; acc: 0.98
Batch: 380; loss: 0.06; acc: 0.98
Batch: 400; loss: 0.09; acc: 0.98
Batch: 420; loss: 0.05; acc: 0.97
Batch: 440; loss: 0.12; acc: 0.97
Batch: 460; loss: 0.05; acc: 0.97
Batch: 480; loss: 0.21; acc: 0.92
Batch: 500; loss: 0.18; acc: 0.94
Batch: 520; loss: 0.16; acc: 0.92
Batch: 540; loss: 0.22; acc: 0.95
Batch: 560; loss: 0.16; acc: 0.95
Batch: 580; loss: 0.15; acc: 0.95
Batch: 600; loss: 0.14; acc: 0.95
Batch: 620; loss: 0.14; acc: 0.94
Batch: 640; loss: 0.15; acc: 0.92
Batch: 660; loss: 0.06; acc: 0.97
Batch: 680; loss: 0.27; acc: 0.92
Batch: 700; loss: 0.27; acc: 0.94
Batch: 720; loss: 0.09; acc: 0.97
Batch: 740; loss: 0.05; acc: 0.98
Batch: 760; loss: 0.08; acc: 0.97
Batch: 780; loss: 0.14; acc: 0.98
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

2.9702832762268372e-05
1.3943710655439645e-05
Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.36; acc: 0.89
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.12; acc: 0.94
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.24; acc: 0.89
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.16476632199089997; val_accuracy: 0.953125 

The current subspace-distance is: 1.3943710655439645e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.29; acc: 0.89
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.31; acc: 0.91
Batch: 60; loss: 0.04; acc: 0.98
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.22; acc: 0.95
Batch: 140; loss: 0.1; acc: 0.95
Batch: 160; loss: 0.05; acc: 0.98
Batch: 180; loss: 0.06; acc: 0.98
Batch: 200; loss: 0.05; acc: 1.0
Batch: 220; loss: 0.26; acc: 0.91
Batch: 240; loss: 0.15; acc: 0.94
Batch: 260; loss: 0.08; acc: 0.97
Batch: 280; loss: 0.06; acc: 0.98
Batch: 300; loss: 0.04; acc: 0.98
Batch: 320; loss: 0.22; acc: 0.94
Batch: 340; loss: 0.11; acc: 0.94
Batch: 360; loss: 0.15; acc: 0.94
Batch: 380; loss: 0.04; acc: 0.97
Batch: 400; loss: 0.11; acc: 0.97
Batch: 420; loss: 0.06; acc: 0.97
Batch: 440; loss: 0.07; acc: 0.97
Batch: 460; loss: 0.11; acc: 0.97
Batch: 480; loss: 0.12; acc: 0.97
Batch: 500; loss: 0.1; acc: 0.97
Batch: 520; loss: 0.28; acc: 0.94
Batch: 540; loss: 0.06; acc: 0.98
Batch: 560; loss: 0.17; acc: 0.97
Batch: 580; loss: 0.16; acc: 0.95
Batch: 600; loss: 0.03; acc: 0.98
Batch: 620; loss: 0.22; acc: 0.91
Batch: 640; loss: 0.14; acc: 0.97
Batch: 660; loss: 0.05; acc: 1.0
Batch: 680; loss: 0.05; acc: 0.98
Batch: 700; loss: 0.23; acc: 0.92
Batch: 720; loss: 0.16; acc: 0.91
Batch: 740; loss: 0.15; acc: 0.97
Batch: 760; loss: 0.12; acc: 0.95
Batch: 780; loss: 0.12; acc: 0.97
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

2.9895256375311874e-05
1.4380300854099914e-05
Batch: 0; loss: 0.07; acc: 0.97
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.15; acc: 0.95
Batch: 80; loss: 0.06; acc: 0.97
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.25; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.11286816347366685; val_accuracy: 0.9681528662420382 

The current subspace-distance is: 1.4380300854099914e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.1; acc: 0.94
Batch: 20; loss: 0.06; acc: 0.97
Batch: 40; loss: 0.24; acc: 0.97
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.08; acc: 0.97
Batch: 120; loss: 0.04; acc: 0.98
Batch: 140; loss: 0.07; acc: 0.98
Batch: 160; loss: 0.07; acc: 0.97
Batch: 180; loss: 0.06; acc: 0.98
Batch: 200; loss: 0.31; acc: 0.95
Batch: 220; loss: 0.06; acc: 1.0
Batch: 240; loss: 0.1; acc: 0.97
Batch: 260; loss: 0.05; acc: 0.98
Batch: 280; loss: 0.02; acc: 1.0
Batch: 300; loss: 0.13; acc: 0.97
Batch: 320; loss: 0.2; acc: 0.92
Batch: 340; loss: 0.07; acc: 0.97
Batch: 360; loss: 0.19; acc: 0.95
Batch: 380; loss: 0.3; acc: 0.92
Batch: 400; loss: 0.21; acc: 0.94
Batch: 420; loss: 0.09; acc: 0.97
Batch: 440; loss: 0.07; acc: 0.97
Batch: 460; loss: 0.02; acc: 1.0
Batch: 480; loss: 0.08; acc: 0.97
Batch: 500; loss: 0.11; acc: 0.97
Batch: 520; loss: 0.07; acc: 0.97
Batch: 540; loss: 0.1; acc: 0.97
Batch: 560; loss: 0.07; acc: 0.98
Batch: 580; loss: 0.11; acc: 0.95
Batch: 600; loss: 0.06; acc: 0.97
Batch: 620; loss: 0.05; acc: 0.98
Batch: 640; loss: 0.13; acc: 0.97
Batch: 660; loss: 0.3; acc: 0.95
Batch: 680; loss: 0.23; acc: 0.92
Batch: 700; loss: 0.08; acc: 0.97
Batch: 720; loss: 0.11; acc: 0.95
Batch: 740; loss: 0.14; acc: 0.94
Batch: 760; loss: 0.1; acc: 0.97
Batch: 780; loss: 0.1; acc: 0.97
Train Epoch over. train_loss: 0.11; train_accuracy: 0.97 

3.029945037269499e-05
1.4414204997592606e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.17; acc: 0.94
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.05; acc: 0.97
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.16; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.09821328881439889; val_accuracy: 0.9705414012738853 

The current subspace-distance is: 1.4414204997592606e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.1; acc: 0.98
Batch: 20; loss: 0.19; acc: 0.95
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.2; acc: 0.94
Batch: 80; loss: 0.08; acc: 0.95
Batch: 100; loss: 0.02; acc: 1.0
Batch: 120; loss: 0.03; acc: 1.0
Batch: 140; loss: 0.18; acc: 0.97
Batch: 160; loss: 0.06; acc: 0.98
Batch: 180; loss: 0.05; acc: 0.98
Batch: 200; loss: 0.15; acc: 0.97
Batch: 220; loss: 0.05; acc: 0.98
Batch: 240; loss: 0.12; acc: 0.95
Batch: 260; loss: 0.03; acc: 1.0
Batch: 280; loss: 0.07; acc: 0.97
Batch: 300; loss: 0.02; acc: 1.0
Batch: 320; loss: 0.09; acc: 0.97
Batch: 340; loss: 0.1; acc: 0.95
Batch: 360; loss: 0.12; acc: 0.95
Batch: 380; loss: 0.15; acc: 0.97
Batch: 400; loss: 0.04; acc: 0.98
Batch: 420; loss: 0.08; acc: 0.97
Batch: 440; loss: 0.18; acc: 0.94
Batch: 460; loss: 0.17; acc: 0.94
Batch: 480; loss: 0.17; acc: 0.98
Batch: 500; loss: 0.13; acc: 0.92
Batch: 520; loss: 0.16; acc: 0.92
Batch: 540; loss: 0.04; acc: 1.0
Batch: 560; loss: 0.15; acc: 0.97
Batch: 580; loss: 0.04; acc: 0.98
Batch: 600; loss: 0.09; acc: 0.98
Batch: 620; loss: 0.09; acc: 0.97
Batch: 640; loss: 0.1; acc: 0.97
Batch: 660; loss: 0.09; acc: 0.98
Batch: 680; loss: 0.04; acc: 0.98
Batch: 700; loss: 0.01; acc: 1.0
Batch: 720; loss: 0.09; acc: 0.97
Batch: 740; loss: 0.28; acc: 0.95
Batch: 760; loss: 0.13; acc: 0.94
Batch: 780; loss: 0.05; acc: 0.97
Train Epoch over. train_loss: 0.11; train_accuracy: 0.97 

3.046837809961289e-05
1.5066082596604247e-05
Batch: 0; loss: 0.11; acc: 0.95
Batch: 20; loss: 0.22; acc: 0.91
Batch: 40; loss: 0.08; acc: 0.95
Batch: 60; loss: 0.18; acc: 0.95
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.25; acc: 0.92
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.14518208061433902; val_accuracy: 0.9545183121019108 

The current subspace-distance is: 1.5066082596604247e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.14; acc: 0.97
Batch: 20; loss: 0.05; acc: 0.98
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.03; acc: 1.0
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.1; acc: 0.95
Batch: 120; loss: 0.16; acc: 0.95
Batch: 140; loss: 0.07; acc: 0.97
Batch: 160; loss: 0.03; acc: 1.0
Batch: 180; loss: 0.07; acc: 0.97
Batch: 200; loss: 0.08; acc: 0.98
Batch: 220; loss: 0.03; acc: 1.0
Batch: 240; loss: 0.1; acc: 0.95
Batch: 260; loss: 0.05; acc: 0.98
Batch: 280; loss: 0.13; acc: 0.97
Batch: 300; loss: 0.11; acc: 0.95
Batch: 320; loss: 0.15; acc: 0.94
Batch: 340; loss: 0.08; acc: 0.97
Batch: 360; loss: 0.13; acc: 0.97
Batch: 380; loss: 0.07; acc: 0.97
Batch: 400; loss: 0.06; acc: 0.98
Batch: 420; loss: 0.05; acc: 0.98
Batch: 440; loss: 0.06; acc: 0.98
Batch: 460; loss: 0.05; acc: 0.98
Batch: 480; loss: 0.08; acc: 0.98
Batch: 500; loss: 0.03; acc: 1.0
Batch: 520; loss: 0.07; acc: 0.98
Batch: 540; loss: 0.21; acc: 0.94
Batch: 560; loss: 0.02; acc: 1.0
Batch: 580; loss: 0.15; acc: 0.94
Batch: 600; loss: 0.07; acc: 0.97
Batch: 620; loss: 0.26; acc: 0.95
Batch: 640; loss: 0.07; acc: 0.98
Batch: 660; loss: 0.12; acc: 0.97
Batch: 680; loss: 0.06; acc: 0.97
Batch: 700; loss: 0.25; acc: 0.94
Batch: 720; loss: 0.03; acc: 0.98
Batch: 740; loss: 0.03; acc: 0.98
Batch: 760; loss: 0.13; acc: 0.95
Batch: 780; loss: 0.27; acc: 0.94
Train Epoch over. train_loss: 0.11; train_accuracy: 0.97 

2.972101719933562e-05
1.3922131074650679e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.13; acc: 0.97
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.12; acc: 0.97
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.16; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.09309386072834586; val_accuracy: 0.9726313694267515 

The current subspace-distance is: 1.3922131074650679e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.06; acc: 0.98
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.03; acc: 1.0
Batch: 80; loss: 0.03; acc: 0.98
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.13; acc: 0.97
Batch: 140; loss: 0.05; acc: 0.98
Batch: 160; loss: 0.12; acc: 0.95
Batch: 180; loss: 0.01; acc: 1.0
Batch: 200; loss: 0.04; acc: 1.0
Batch: 220; loss: 0.15; acc: 0.97
Batch: 240; loss: 0.08; acc: 0.95
Batch: 260; loss: 0.05; acc: 0.98
Batch: 280; loss: 0.03; acc: 1.0
Batch: 300; loss: 0.23; acc: 0.91
Batch: 320; loss: 0.06; acc: 0.98
Batch: 340; loss: 0.17; acc: 0.95
Batch: 360; loss: 0.17; acc: 0.94
Batch: 380; loss: 0.11; acc: 0.97
Batch: 400; loss: 0.18; acc: 0.92
Batch: 420; loss: 0.06; acc: 0.97
Batch: 440; loss: 0.05; acc: 1.0
Batch: 460; loss: 0.12; acc: 0.97
Batch: 480; loss: 0.16; acc: 0.95
Batch: 500; loss: 0.21; acc: 0.92
Batch: 520; loss: 0.08; acc: 0.95
Batch: 540; loss: 0.09; acc: 0.95
Batch: 560; loss: 0.26; acc: 0.91
Batch: 580; loss: 0.08; acc: 0.98
Batch: 600; loss: 0.15; acc: 0.94
Batch: 620; loss: 0.12; acc: 0.97
Batch: 640; loss: 0.05; acc: 0.98
Batch: 660; loss: 0.05; acc: 0.97
Batch: 680; loss: 0.22; acc: 0.92
Batch: 700; loss: 0.24; acc: 0.95
Batch: 720; loss: 0.08; acc: 0.97
Batch: 740; loss: 0.02; acc: 1.0
Batch: 760; loss: 0.04; acc: 0.98
Batch: 780; loss: 0.12; acc: 0.92
Train Epoch over. train_loss: 0.1; train_accuracy: 0.97 

3.072157414862886e-05
1.452101696486352e-05
Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.17; acc: 0.95
Batch: 40; loss: 0.02; acc: 0.98
Batch: 60; loss: 0.14; acc: 0.95
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.11; acc: 0.97
Batch: 120; loss: 0.18; acc: 0.92
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.09814006389136527; val_accuracy: 0.9710390127388535 

The current subspace-distance is: 1.452101696486352e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.06; acc: 0.98
Batch: 20; loss: 0.02; acc: 1.0
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.1; acc: 0.95
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.09; acc: 0.97
Batch: 140; loss: 0.03; acc: 0.98
Batch: 160; loss: 0.05; acc: 0.98
Batch: 180; loss: 0.08; acc: 0.94
Batch: 200; loss: 0.2; acc: 0.95
Batch: 220; loss: 0.07; acc: 0.98
Batch: 240; loss: 0.11; acc: 0.95
Batch: 260; loss: 0.06; acc: 0.98
Batch: 280; loss: 0.02; acc: 1.0
Batch: 300; loss: 0.06; acc: 0.97
Batch: 320; loss: 0.46; acc: 0.94
Batch: 340; loss: 0.03; acc: 1.0
Batch: 360; loss: 0.11; acc: 0.97
Batch: 380; loss: 0.09; acc: 0.95
Batch: 400; loss: 0.14; acc: 0.95
Batch: 420; loss: 0.08; acc: 0.97
Batch: 440; loss: 0.09; acc: 0.98
Batch: 460; loss: 0.09; acc: 0.98
Batch: 480; loss: 0.03; acc: 1.0
Batch: 500; loss: 0.04; acc: 1.0
Batch: 520; loss: 0.08; acc: 0.98
Batch: 540; loss: 0.02; acc: 1.0
Batch: 560; loss: 0.06; acc: 0.97
Batch: 580; loss: 0.03; acc: 1.0
Batch: 600; loss: 0.07; acc: 0.97
Batch: 620; loss: 0.05; acc: 0.95
Batch: 640; loss: 0.12; acc: 0.97
Batch: 660; loss: 0.1; acc: 0.95
Batch: 680; loss: 0.09; acc: 0.97
Batch: 700; loss: 0.08; acc: 0.95
Batch: 720; loss: 0.11; acc: 0.95
Batch: 740; loss: 0.08; acc: 0.97
Batch: 760; loss: 0.18; acc: 0.92
Batch: 780; loss: 0.03; acc: 0.98
Train Epoch over. train_loss: 0.1; train_accuracy: 0.97 

3.0737606721231714e-05
1.4756437849428039e-05
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.11; acc: 0.97
Batch: 120; loss: 0.17; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.10535774496235666; val_accuracy: 0.9694466560509554 

The current subspace-distance is: 1.4756437849428039e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.14; acc: 0.94
Batch: 20; loss: 0.07; acc: 0.98
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.03; acc: 0.98
Batch: 80; loss: 0.12; acc: 0.94
Batch: 100; loss: 0.08; acc: 0.98
Batch: 120; loss: 0.16; acc: 0.92
Batch: 140; loss: 0.02; acc: 1.0
Batch: 160; loss: 0.23; acc: 0.92
Batch: 180; loss: 0.22; acc: 0.94
Batch: 200; loss: 0.06; acc: 0.98
Batch: 220; loss: 0.11; acc: 0.95
Batch: 240; loss: 0.08; acc: 0.98
Batch: 260; loss: 0.11; acc: 0.97
Batch: 280; loss: 0.31; acc: 0.94
Batch: 300; loss: 0.04; acc: 0.98
Batch: 320; loss: 0.18; acc: 0.92
Batch: 340; loss: 0.18; acc: 0.94
Batch: 360; loss: 0.05; acc: 0.98
Batch: 380; loss: 0.21; acc: 0.97
Batch: 400; loss: 0.2; acc: 0.97
Batch: 420; loss: 0.12; acc: 0.98
Batch: 440; loss: 0.1; acc: 0.95
Batch: 460; loss: 0.07; acc: 0.97
Batch: 480; loss: 0.1; acc: 0.97
Batch: 500; loss: 0.12; acc: 0.95
Batch: 520; loss: 0.03; acc: 1.0
Batch: 540; loss: 0.07; acc: 0.95
Batch: 560; loss: 0.03; acc: 0.98
Batch: 580; loss: 0.04; acc: 1.0
Batch: 600; loss: 0.13; acc: 0.95
Batch: 620; loss: 0.07; acc: 0.97
Batch: 640; loss: 0.1; acc: 0.97
Batch: 660; loss: 0.01; acc: 1.0
Batch: 680; loss: 0.04; acc: 0.97
Batch: 700; loss: 0.21; acc: 0.94
Batch: 720; loss: 0.03; acc: 0.98
Batch: 740; loss: 0.09; acc: 0.95
Batch: 760; loss: 0.2; acc: 0.92
Batch: 780; loss: 0.19; acc: 0.91
Train Epoch over. train_loss: 0.1; train_accuracy: 0.97 

3.0717303161509335e-05
1.4498727978207171e-05
Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.16; acc: 0.97
Batch: 120; loss: 0.12; acc: 0.92
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.0984375812825124; val_accuracy: 0.971437101910828 

The current subspace-distance is: 1.4498727978207171e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.11; acc: 0.94
Batch: 40; loss: 0.12; acc: 0.98
Batch: 60; loss: 0.08; acc: 0.95
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.12; acc: 0.95
Batch: 140; loss: 0.01; acc: 1.0
Batch: 160; loss: 0.4; acc: 0.92
Batch: 180; loss: 0.16; acc: 0.95
Batch: 200; loss: 0.09; acc: 0.97
Batch: 220; loss: 0.04; acc: 0.98
Batch: 240; loss: 0.11; acc: 0.95
Batch: 260; loss: 0.08; acc: 0.97
Batch: 280; loss: 0.13; acc: 0.95
Batch: 300; loss: 0.12; acc: 0.97
Batch: 320; loss: 0.07; acc: 0.98
Batch: 340; loss: 0.01; acc: 1.0
Batch: 360; loss: 0.13; acc: 0.97
Batch: 380; loss: 0.2; acc: 0.91
Batch: 400; loss: 0.18; acc: 0.94
Batch: 420; loss: 0.16; acc: 0.92
Batch: 440; loss: 0.1; acc: 0.95
Batch: 460; loss: 0.06; acc: 0.98
Batch: 480; loss: 0.1; acc: 0.95
Batch: 500; loss: 0.06; acc: 0.97
Batch: 520; loss: 0.11; acc: 0.97
Batch: 540; loss: 0.12; acc: 0.95
Batch: 560; loss: 0.28; acc: 0.95
Batch: 580; loss: 0.08; acc: 0.97
Batch: 600; loss: 0.05; acc: 0.97
Batch: 620; loss: 0.13; acc: 0.98
Batch: 640; loss: 0.09; acc: 0.97
Batch: 660; loss: 0.07; acc: 0.97
Batch: 680; loss: 0.05; acc: 0.98
Batch: 700; loss: 0.02; acc: 1.0
Batch: 720; loss: 0.17; acc: 0.97
Batch: 740; loss: 0.06; acc: 0.98
Batch: 760; loss: 0.05; acc: 0.98
Batch: 780; loss: 0.19; acc: 0.94
Train Epoch over. train_loss: 0.1; train_accuracy: 0.97 

3.030822153959889e-05
1.4300346265372355e-05
Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.14; acc: 0.97
Batch: 120; loss: 0.16; acc: 0.95
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.09624776476697558; val_accuracy: 0.9709394904458599 

The current subspace-distance is: 1.4300346265372355e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.06; acc: 0.98
Batch: 20; loss: 0.02; acc: 1.0
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.05; acc: 0.98
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.1; acc: 0.95
Batch: 120; loss: 0.02; acc: 1.0
Batch: 140; loss: 0.05; acc: 0.98
Batch: 160; loss: 0.06; acc: 0.98
Batch: 180; loss: 0.09; acc: 0.97
Batch: 200; loss: 0.18; acc: 0.95
Batch: 220; loss: 0.02; acc: 1.0
Batch: 240; loss: 0.14; acc: 0.95
Batch: 260; loss: 0.29; acc: 0.92
Batch: 280; loss: 0.22; acc: 0.95
Batch: 300; loss: 0.13; acc: 0.94
Batch: 320; loss: 0.04; acc: 0.98
Batch: 340; loss: 0.06; acc: 0.97
Batch: 360; loss: 0.06; acc: 0.97
Batch: 380; loss: 0.03; acc: 0.98
Batch: 400; loss: 0.17; acc: 0.97
Batch: 420; loss: 0.09; acc: 0.98
Batch: 440; loss: 0.18; acc: 0.95
Batch: 460; loss: 0.06; acc: 0.97
Batch: 480; loss: 0.09; acc: 0.97
Batch: 500; loss: 0.06; acc: 0.97
Batch: 520; loss: 0.1; acc: 0.95
Batch: 540; loss: 0.04; acc: 1.0
Batch: 560; loss: 0.06; acc: 0.98
Batch: 580; loss: 0.12; acc: 0.97
Batch: 600; loss: 0.15; acc: 0.94
Batch: 620; loss: 0.06; acc: 0.98
Batch: 640; loss: 0.13; acc: 0.94
Batch: 660; loss: 0.04; acc: 0.98
Batch: 680; loss: 0.04; acc: 0.98
Batch: 700; loss: 0.14; acc: 0.95
Batch: 720; loss: 0.26; acc: 0.97
Batch: 740; loss: 0.12; acc: 0.95
Batch: 760; loss: 0.04; acc: 0.98
Batch: 780; loss: 0.13; acc: 0.94
Train Epoch over. train_loss: 0.1; train_accuracy: 0.97 

3.091777762165293e-05
1.4804442798777018e-05
Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.24; acc: 0.94
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.09; acc: 0.97
Batch: 80; loss: 0.03; acc: 0.98
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.17; acc: 0.92
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1077456452237193; val_accuracy: 0.9671576433121019 

The current subspace-distance is: 1.4804442798777018e-05 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.07; acc: 0.97
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.21; acc: 0.97
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.14; acc: 0.94
Batch: 120; loss: 0.03; acc: 1.0
Batch: 140; loss: 0.26; acc: 0.89
Batch: 160; loss: 0.09; acc: 0.97
Batch: 180; loss: 0.13; acc: 0.97
Batch: 200; loss: 0.29; acc: 0.92
Batch: 220; loss: 0.1; acc: 0.97
Batch: 240; loss: 0.09; acc: 0.98
Batch: 260; loss: 0.17; acc: 0.92
Batch: 280; loss: 0.14; acc: 0.94
Batch: 300; loss: 0.05; acc: 0.98
Batch: 320; loss: 0.1; acc: 0.97
Batch: 340; loss: 0.11; acc: 0.95
Batch: 360; loss: 0.17; acc: 0.95
Batch: 380; loss: 0.05; acc: 0.98
Batch: 400; loss: 0.03; acc: 1.0
Batch: 420; loss: 0.15; acc: 0.95
Batch: 440; loss: 0.03; acc: 0.98
Batch: 460; loss: 0.04; acc: 0.98
Batch: 480; loss: 0.19; acc: 0.92
Batch: 500; loss: 0.18; acc: 0.94
Batch: 520; loss: 0.16; acc: 0.92
Batch: 540; loss: 0.03; acc: 1.0
Batch: 560; loss: 0.02; acc: 1.0
Batch: 580; loss: 0.14; acc: 0.97
Batch: 600; loss: 0.04; acc: 0.98
Batch: 620; loss: 0.05; acc: 0.98
Batch: 640; loss: 0.07; acc: 0.98
Batch: 660; loss: 0.01; acc: 1.0
Batch: 680; loss: 0.12; acc: 0.95
Batch: 700; loss: 0.04; acc: 0.98
Batch: 720; loss: 0.22; acc: 0.95
Batch: 740; loss: 0.01; acc: 1.0
Batch: 760; loss: 0.08; acc: 0.98
Batch: 780; loss: 0.17; acc: 0.97
Train Epoch over. train_loss: 0.1; train_accuracy: 0.97 

3.100388858001679e-05
1.4818963791185524e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.1; acc: 0.98
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.16; acc: 0.97
Batch: 120; loss: 0.18; acc: 0.92
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.09464127885972619; val_accuracy: 0.9712380573248408 

The current subspace-distance is: 1.4818963791185524e-05 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.03; acc: 1.0
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.01; acc: 1.0
Batch: 80; loss: 0.05; acc: 1.0
Batch: 100; loss: 0.03; acc: 0.98
Batch: 120; loss: 0.03; acc: 1.0
Batch: 140; loss: 0.09; acc: 0.97
Batch: 160; loss: 0.11; acc: 0.97
Batch: 180; loss: 0.14; acc: 0.98
Batch: 200; loss: 0.07; acc: 0.98
Batch: 220; loss: 0.05; acc: 0.98
Batch: 240; loss: 0.05; acc: 0.98
Batch: 260; loss: 0.07; acc: 0.98
Batch: 280; loss: 0.04; acc: 0.97
Batch: 300; loss: 0.13; acc: 0.94
Batch: 320; loss: 0.22; acc: 0.94
Batch: 340; loss: 0.04; acc: 0.98
Batch: 360; loss: 0.11; acc: 0.95
Batch: 380; loss: 0.1; acc: 0.95
Batch: 400; loss: 0.17; acc: 0.97
Batch: 420; loss: 0.07; acc: 0.97
Batch: 440; loss: 0.1; acc: 0.95
Batch: 460; loss: 0.15; acc: 0.95
Batch: 480; loss: 0.07; acc: 0.97
Batch: 500; loss: 0.07; acc: 0.98
Batch: 520; loss: 0.15; acc: 0.95
Batch: 540; loss: 0.07; acc: 0.98
Batch: 560; loss: 0.44; acc: 0.92
Batch: 580; loss: 0.08; acc: 0.95
Batch: 600; loss: 0.09; acc: 0.98
Batch: 620; loss: 0.2; acc: 0.95
Batch: 640; loss: 0.14; acc: 0.97
Batch: 660; loss: 0.1; acc: 0.97
Batch: 680; loss: 0.12; acc: 0.95
Batch: 700; loss: 0.19; acc: 0.97
Batch: 720; loss: 0.04; acc: 1.0
Batch: 740; loss: 0.02; acc: 1.0
Batch: 760; loss: 0.07; acc: 0.97
Batch: 780; loss: 0.05; acc: 0.98
Train Epoch over. train_loss: 0.1; train_accuracy: 0.97 

3.088347511948086e-05
1.4446346540353261e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.09; acc: 0.97
Batch: 80; loss: 0.03; acc: 0.98
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.1; acc: 0.97
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.08865355776183924; val_accuracy: 0.9734275477707006 

The current subspace-distance is: 1.4446346540353261e-05 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.14; acc: 0.94
Batch: 20; loss: 0.06; acc: 0.98
Batch: 40; loss: 0.15; acc: 0.92
Batch: 60; loss: 0.06; acc: 0.98
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.06; acc: 0.98
Batch: 140; loss: 0.07; acc: 0.98
Batch: 160; loss: 0.08; acc: 0.97
Batch: 180; loss: 0.12; acc: 0.95
Batch: 200; loss: 0.05; acc: 0.98
Batch: 220; loss: 0.12; acc: 0.95
Batch: 240; loss: 0.04; acc: 0.97
Batch: 260; loss: 0.17; acc: 0.97
Batch: 280; loss: 0.08; acc: 0.97
Batch: 300; loss: 0.05; acc: 0.97
Batch: 320; loss: 0.14; acc: 0.97
Batch: 340; loss: 0.11; acc: 0.95
Batch: 360; loss: 0.01; acc: 1.0
Batch: 380; loss: 0.05; acc: 0.97
Batch: 400; loss: 0.07; acc: 0.98
Batch: 420; loss: 0.06; acc: 0.98
Batch: 440; loss: 0.07; acc: 0.97
Batch: 460; loss: 0.02; acc: 1.0
Batch: 480; loss: 0.11; acc: 0.95
Batch: 500; loss: 0.15; acc: 0.92
Batch: 520; loss: 0.02; acc: 1.0
Batch: 540; loss: 0.02; acc: 1.0
Batch: 560; loss: 0.16; acc: 0.94
Batch: 580; loss: 0.06; acc: 0.98
Batch: 600; loss: 0.08; acc: 0.98
Batch: 620; loss: 0.15; acc: 0.95
Batch: 640; loss: 0.04; acc: 0.98
Batch: 660; loss: 0.04; acc: 0.98
Batch: 680; loss: 0.22; acc: 0.94
Batch: 700; loss: 0.02; acc: 1.0
Batch: 720; loss: 0.16; acc: 0.97
Batch: 740; loss: 0.02; acc: 1.0
Batch: 760; loss: 0.14; acc: 0.95
Batch: 780; loss: 0.11; acc: 0.97
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

3.063391341129318e-05
1.4329957593872678e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.12; acc: 0.97
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.14; acc: 0.95
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.09633435686207881; val_accuracy: 0.9720342356687898 

The current subspace-distance is: 1.4329957593872678e-05 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.06; acc: 0.98
Batch: 20; loss: 0.02; acc: 1.0
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.05; acc: 0.98
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.18; acc: 0.97
Batch: 140; loss: 0.03; acc: 0.98
Batch: 160; loss: 0.04; acc: 0.98
Batch: 180; loss: 0.02; acc: 1.0
Batch: 200; loss: 0.13; acc: 0.95
Batch: 220; loss: 0.01; acc: 1.0
Batch: 240; loss: 0.01; acc: 1.0
Batch: 260; loss: 0.04; acc: 1.0
Batch: 280; loss: 0.04; acc: 0.98
Batch: 300; loss: 0.15; acc: 0.94
Batch: 320; loss: 0.28; acc: 0.94
Batch: 340; loss: 0.02; acc: 1.0
Batch: 360; loss: 0.04; acc: 0.98
Batch: 380; loss: 0.03; acc: 1.0
Batch: 400; loss: 0.09; acc: 0.97
Batch: 420; loss: 0.04; acc: 0.97
Batch: 440; loss: 0.1; acc: 0.97
Batch: 460; loss: 0.17; acc: 0.95
Batch: 480; loss: 0.03; acc: 1.0
Batch: 500; loss: 0.11; acc: 0.95
Batch: 520; loss: 0.17; acc: 0.95
Batch: 540; loss: 0.09; acc: 0.92
Batch: 560; loss: 0.04; acc: 0.98
Batch: 580; loss: 0.08; acc: 0.97
Batch: 600; loss: 0.1; acc: 0.97
Batch: 620; loss: 0.1; acc: 0.95
Batch: 640; loss: 0.15; acc: 0.92
Batch: 660; loss: 0.17; acc: 0.95
Batch: 680; loss: 0.07; acc: 0.98
Batch: 700; loss: 0.02; acc: 1.0
Batch: 720; loss: 0.02; acc: 1.0
Batch: 740; loss: 0.04; acc: 1.0
Batch: 760; loss: 0.13; acc: 0.95
Batch: 780; loss: 0.07; acc: 0.97
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

3.0915260140318424e-05
1.4742125131306238e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.16; acc: 0.94
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.16; acc: 0.97
Batch: 120; loss: 0.14; acc: 0.95
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.09381537834645078; val_accuracy: 0.972531847133758 

The current subspace-distance is: 1.4742125131306238e-05 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.22; acc: 0.97
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.14; acc: 0.95
Batch: 80; loss: 0.17; acc: 0.97
Batch: 100; loss: 0.05; acc: 0.97
Batch: 120; loss: 0.47; acc: 0.92
Batch: 140; loss: 0.04; acc: 0.98
Batch: 160; loss: 0.1; acc: 0.97
Batch: 180; loss: 0.1; acc: 0.95
Batch: 200; loss: 0.08; acc: 0.97
Batch: 220; loss: 0.14; acc: 0.98
Batch: 240; loss: 0.16; acc: 0.97
Batch: 260; loss: 0.17; acc: 0.97
Batch: 280; loss: 0.06; acc: 0.97
Batch: 300; loss: 0.05; acc: 0.98
Batch: 320; loss: 0.2; acc: 0.95
Batch: 340; loss: 0.06; acc: 0.98
Batch: 360; loss: 0.11; acc: 0.97
Batch: 380; loss: 0.11; acc: 0.97
Batch: 400; loss: 0.08; acc: 0.98
Batch: 420; loss: 0.04; acc: 1.0
Batch: 440; loss: 0.34; acc: 0.91
Batch: 460; loss: 0.19; acc: 0.94
Batch: 480; loss: 0.05; acc: 0.98
Batch: 500; loss: 0.09; acc: 0.97
Batch: 520; loss: 0.09; acc: 0.98
Batch: 540; loss: 0.13; acc: 0.97
Batch: 560; loss: 0.17; acc: 0.94
Batch: 580; loss: 0.14; acc: 0.97
Batch: 600; loss: 0.06; acc: 0.97
Batch: 620; loss: 0.02; acc: 1.0
Batch: 640; loss: 0.06; acc: 0.97
Batch: 660; loss: 0.04; acc: 1.0
Batch: 680; loss: 0.03; acc: 0.98
Batch: 700; loss: 0.06; acc: 0.98
Batch: 720; loss: 0.1; acc: 0.95
Batch: 740; loss: 0.03; acc: 0.98
Batch: 760; loss: 0.02; acc: 1.0
Batch: 780; loss: 0.18; acc: 0.95
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

3.0860595870763063e-05
1.4545508747687563e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.01; acc: 1.0
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.13; acc: 0.97
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.08911918986375165; val_accuracy: 0.9739251592356688 

The current subspace-distance is: 1.4545508747687563e-05 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.05; acc: 1.0
Batch: 20; loss: 0.05; acc: 0.97
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.23; acc: 0.95
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.03; acc: 0.98
Batch: 120; loss: 0.07; acc: 0.98
Batch: 140; loss: 0.05; acc: 0.98
Batch: 160; loss: 0.12; acc: 0.98
Batch: 180; loss: 0.08; acc: 0.98
Batch: 200; loss: 0.01; acc: 1.0
Batch: 220; loss: 0.27; acc: 0.92
Batch: 240; loss: 0.08; acc: 0.97
Batch: 260; loss: 0.09; acc: 0.97
Batch: 280; loss: 0.08; acc: 0.97
Batch: 300; loss: 0.06; acc: 0.97
Batch: 320; loss: 0.01; acc: 1.0
Batch: 340; loss: 0.14; acc: 0.97
Batch: 360; loss: 0.11; acc: 0.95
Batch: 380; loss: 0.13; acc: 0.94
Batch: 400; loss: 0.05; acc: 0.97
Batch: 420; loss: 0.2; acc: 0.94
Batch: 440; loss: 0.07; acc: 0.98
Batch: 460; loss: 0.08; acc: 0.97
Batch: 480; loss: 0.17; acc: 0.94
Batch: 500; loss: 0.11; acc: 0.95
Batch: 520; loss: 0.05; acc: 0.98
Batch: 540; loss: 0.15; acc: 0.98
Batch: 560; loss: 0.03; acc: 1.0
Batch: 580; loss: 0.05; acc: 1.0
Batch: 600; loss: 0.06; acc: 0.98
Batch: 620; loss: 0.06; acc: 0.97
Batch: 640; loss: 0.15; acc: 0.91
Batch: 660; loss: 0.16; acc: 0.97
Batch: 680; loss: 0.19; acc: 0.94
Batch: 700; loss: 0.04; acc: 0.98
Batch: 720; loss: 0.05; acc: 0.98
Batch: 740; loss: 0.09; acc: 0.95
Batch: 760; loss: 0.02; acc: 1.0
Batch: 780; loss: 0.16; acc: 0.92
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

3.099611058132723e-05
1.451720527256839e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.01; acc: 1.0
Batch: 60; loss: 0.08; acc: 0.97
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.14; acc: 0.97
Batch: 120; loss: 0.13; acc: 0.95
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.0865991739140954; val_accuracy: 0.9751194267515924 

The current subspace-distance is: 1.451720527256839e-05 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.04; acc: 0.97
Batch: 20; loss: 0.17; acc: 0.95
Batch: 40; loss: 0.05; acc: 0.97
Batch: 60; loss: 0.03; acc: 1.0
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.22; acc: 0.95
Batch: 120; loss: 0.07; acc: 0.98
Batch: 140; loss: 0.04; acc: 0.98
Batch: 160; loss: 0.04; acc: 0.98
Batch: 180; loss: 0.05; acc: 0.98
Batch: 200; loss: 0.03; acc: 1.0
Batch: 220; loss: 0.11; acc: 0.97
Batch: 240; loss: 0.09; acc: 0.98
Batch: 260; loss: 0.02; acc: 1.0
Batch: 280; loss: 0.09; acc: 0.97
Batch: 300; loss: 0.02; acc: 1.0
Batch: 320; loss: 0.14; acc: 0.95
Batch: 340; loss: 0.02; acc: 1.0
Batch: 360; loss: 0.05; acc: 0.97
Batch: 380; loss: 0.27; acc: 0.95
Batch: 400; loss: 0.1; acc: 0.97
Batch: 420; loss: 0.12; acc: 0.97
Batch: 440; loss: 0.03; acc: 1.0
Batch: 460; loss: 0.2; acc: 0.91
Batch: 480; loss: 0.06; acc: 0.98
Batch: 500; loss: 0.26; acc: 0.95
Batch: 520; loss: 0.09; acc: 0.97
Batch: 540; loss: 0.24; acc: 0.95
Batch: 560; loss: 0.02; acc: 1.0
Batch: 580; loss: 0.04; acc: 0.98
Batch: 600; loss: 0.07; acc: 0.97
Batch: 620; loss: 0.04; acc: 0.97
Batch: 640; loss: 0.1; acc: 0.97
Batch: 660; loss: 0.2; acc: 0.97
Batch: 680; loss: 0.11; acc: 0.95
Batch: 700; loss: 0.08; acc: 0.98
Batch: 720; loss: 0.03; acc: 0.98
Batch: 740; loss: 0.12; acc: 0.95
Batch: 760; loss: 0.13; acc: 0.97
Batch: 780; loss: 0.13; acc: 0.97
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

3.1369272619485855e-05
1.5016131328593474e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.18; acc: 0.95
Batch: 40; loss: 0.02; acc: 0.98
Batch: 60; loss: 0.09; acc: 0.97
Batch: 80; loss: 0.03; acc: 0.98
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.14; acc: 0.94
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.08842203030540685; val_accuracy: 0.9731289808917197 

The current subspace-distance is: 1.5016131328593474e-05 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.08; acc: 0.98
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.15; acc: 0.97
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.11; acc: 0.95
Batch: 120; loss: 0.03; acc: 0.98
Batch: 140; loss: 0.09; acc: 0.95
Batch: 160; loss: 0.06; acc: 0.97
Batch: 180; loss: 0.12; acc: 0.98
Batch: 200; loss: 0.06; acc: 0.97
Batch: 220; loss: 0.21; acc: 0.97
Batch: 240; loss: 0.03; acc: 1.0
Batch: 260; loss: 0.02; acc: 1.0
Batch: 280; loss: 0.04; acc: 0.98
Batch: 300; loss: 0.06; acc: 0.98
Batch: 320; loss: 0.04; acc: 0.97
Batch: 340; loss: 0.05; acc: 0.98
Batch: 360; loss: 0.08; acc: 0.98
Batch: 380; loss: 0.02; acc: 1.0
Batch: 400; loss: 0.08; acc: 0.95
Batch: 420; loss: 0.08; acc: 0.98
Batch: 440; loss: 0.02; acc: 1.0
Batch: 460; loss: 0.2; acc: 0.95
Batch: 480; loss: 0.07; acc: 0.98
Batch: 500; loss: 0.08; acc: 0.97
Batch: 520; loss: 0.05; acc: 0.97
Batch: 540; loss: 0.13; acc: 0.98
Batch: 560; loss: 0.09; acc: 0.97
Batch: 580; loss: 0.07; acc: 0.97
Batch: 600; loss: 0.11; acc: 0.98
Batch: 620; loss: 0.07; acc: 0.98
Batch: 640; loss: 0.25; acc: 0.92
Batch: 660; loss: 0.05; acc: 0.98
Batch: 680; loss: 0.04; acc: 0.98
Batch: 700; loss: 0.13; acc: 0.95
Batch: 720; loss: 0.07; acc: 0.97
Batch: 740; loss: 0.1; acc: 0.98
Batch: 760; loss: 0.09; acc: 0.97
Batch: 780; loss: 0.02; acc: 1.0
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

3.1373176170745865e-05
1.4573684893548489e-05
Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.17; acc: 0.95
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.14; acc: 0.95
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.08872284597841798; val_accuracy: 0.9738256369426752 

The current subspace-distance is: 1.4573684893548489e-05 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.07; acc: 0.97
Batch: 20; loss: 0.1; acc: 0.95
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.13; acc: 0.94
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.05; acc: 0.97
Batch: 140; loss: 0.19; acc: 0.94
Batch: 160; loss: 0.16; acc: 0.94
Batch: 180; loss: 0.02; acc: 1.0
Batch: 200; loss: 0.02; acc: 1.0
Batch: 220; loss: 0.1; acc: 0.95
Batch: 240; loss: 0.02; acc: 1.0
Batch: 260; loss: 0.08; acc: 0.97
Batch: 280; loss: 0.1; acc: 0.97
Batch: 300; loss: 0.04; acc: 0.98
Batch: 320; loss: 0.06; acc: 0.98
Batch: 340; loss: 0.08; acc: 0.98
Batch: 360; loss: 0.06; acc: 0.98
Batch: 380; loss: 0.1; acc: 0.97
Batch: 400; loss: 0.01; acc: 1.0
Batch: 420; loss: 0.2; acc: 0.95
Batch: 440; loss: 0.03; acc: 1.0
Batch: 460; loss: 0.12; acc: 0.94
Batch: 480; loss: 0.01; acc: 1.0
Batch: 500; loss: 0.13; acc: 0.97
Batch: 520; loss: 0.06; acc: 0.97
Batch: 540; loss: 0.18; acc: 0.94
Batch: 560; loss: 0.08; acc: 0.97
Batch: 580; loss: 0.16; acc: 0.94
Batch: 600; loss: 0.1; acc: 0.97
Batch: 620; loss: 0.26; acc: 0.95
Batch: 640; loss: 0.09; acc: 0.98
Batch: 660; loss: 0.1; acc: 0.97
Batch: 680; loss: 0.18; acc: 0.97
Batch: 700; loss: 0.2; acc: 0.94
Batch: 720; loss: 0.07; acc: 0.97
Batch: 740; loss: 0.12; acc: 0.95
Batch: 760; loss: 0.09; acc: 0.97
Batch: 780; loss: 0.09; acc: 0.98
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

3.105346695519984e-05
1.5384688595077023e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.18; acc: 0.95
Batch: 40; loss: 0.01; acc: 1.0
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.02; acc: 0.98
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.11; acc: 0.95
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.08574609951988148; val_accuracy: 0.9738256369426752 

The current subspace-distance is: 1.5384688595077023e-05 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.17; acc: 0.98
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.12; acc: 0.95
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.04; acc: 0.98
Batch: 120; loss: 0.06; acc: 0.97
Batch: 140; loss: 0.25; acc: 0.97
Batch: 160; loss: 0.02; acc: 1.0
Batch: 180; loss: 0.04; acc: 1.0
Batch: 200; loss: 0.06; acc: 0.97
Batch: 220; loss: 0.08; acc: 0.97
Batch: 240; loss: 0.06; acc: 0.97
Batch: 260; loss: 0.05; acc: 0.98
Batch: 280; loss: 0.1; acc: 0.97
Batch: 300; loss: 0.16; acc: 0.95
Batch: 320; loss: 0.01; acc: 1.0
Batch: 340; loss: 0.06; acc: 0.98
Batch: 360; loss: 0.11; acc: 0.95
Batch: 380; loss: 0.05; acc: 0.98
Batch: 400; loss: 0.09; acc: 0.95
Batch: 420; loss: 0.22; acc: 0.95
Batch: 440; loss: 0.17; acc: 0.97
Batch: 460; loss: 0.12; acc: 0.94
Batch: 480; loss: 0.07; acc: 0.97
Batch: 500; loss: 0.11; acc: 0.98
Batch: 520; loss: 0.08; acc: 0.94
Batch: 540; loss: 0.14; acc: 0.92
Batch: 560; loss: 0.06; acc: 0.97
Batch: 580; loss: 0.1; acc: 0.95
Batch: 600; loss: 0.01; acc: 1.0
Batch: 620; loss: 0.03; acc: 0.98
Batch: 640; loss: 0.02; acc: 1.0
Batch: 660; loss: 0.31; acc: 0.91
Batch: 680; loss: 0.02; acc: 1.0
Batch: 700; loss: 0.22; acc: 0.95
Batch: 720; loss: 0.06; acc: 0.98
Batch: 740; loss: 0.18; acc: 0.97
Batch: 760; loss: 0.14; acc: 0.95
Batch: 780; loss: 0.22; acc: 0.98
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

3.1271814805222675e-05
1.4907984223100357e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.17; acc: 0.95
Batch: 40; loss: 0.01; acc: 1.0
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.02; acc: 0.98
Batch: 100; loss: 0.17; acc: 0.97
Batch: 120; loss: 0.11; acc: 0.95
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.08650363765799315; val_accuracy: 0.974422770700637 

The current subspace-distance is: 1.4907984223100357e-05 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.06; acc: 0.97
Batch: 20; loss: 0.07; acc: 0.97
Batch: 40; loss: 0.1; acc: 0.98
Batch: 60; loss: 0.07; acc: 0.97
Batch: 80; loss: 0.08; acc: 0.95
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.05; acc: 0.98
Batch: 140; loss: 0.11; acc: 0.97
Batch: 160; loss: 0.08; acc: 0.97
Batch: 180; loss: 0.01; acc: 1.0
Batch: 200; loss: 0.06; acc: 0.98
Batch: 220; loss: 0.07; acc: 0.95
Batch: 240; loss: 0.01; acc: 1.0
Batch: 260; loss: 0.26; acc: 0.91
Batch: 280; loss: 0.17; acc: 0.97
Batch: 300; loss: 0.04; acc: 0.97
Batch: 320; loss: 0.08; acc: 0.94
Batch: 340; loss: 0.04; acc: 0.98
Batch: 360; loss: 0.1; acc: 0.95
Batch: 380; loss: 0.26; acc: 0.97
Batch: 400; loss: 0.04; acc: 0.98
Batch: 420; loss: 0.1; acc: 0.95
Batch: 440; loss: 0.15; acc: 0.97
Batch: 460; loss: 0.14; acc: 0.94
Batch: 480; loss: 0.02; acc: 1.0
Batch: 500; loss: 0.03; acc: 1.0
Batch: 520; loss: 0.04; acc: 0.98
Batch: 540; loss: 0.04; acc: 0.98
Batch: 560; loss: 0.04; acc: 0.98
Batch: 580; loss: 0.1; acc: 0.95
Batch: 600; loss: 0.19; acc: 0.94
Batch: 620; loss: 0.05; acc: 0.98
Batch: 640; loss: 0.16; acc: 0.97
Batch: 660; loss: 0.02; acc: 1.0
Batch: 680; loss: 0.11; acc: 0.97
Batch: 700; loss: 0.07; acc: 0.98
Batch: 720; loss: 0.03; acc: 0.98
Batch: 740; loss: 0.03; acc: 0.98
Batch: 760; loss: 0.03; acc: 0.98
Batch: 780; loss: 0.04; acc: 0.98
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

3.180499334121123e-05
1.4919158275006339e-05
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.17; acc: 0.94
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.1; acc: 0.98
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.19; acc: 0.94
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.09374571506195008; val_accuracy: 0.9709394904458599 

The current subspace-distance is: 1.4919158275006339e-05 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.07; acc: 0.98
Batch: 40; loss: 0.09; acc: 0.95
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.03; acc: 0.98
Batch: 120; loss: 0.08; acc: 0.97
Batch: 140; loss: 0.02; acc: 1.0
Batch: 160; loss: 0.04; acc: 0.98
Batch: 180; loss: 0.05; acc: 0.98
Batch: 200; loss: 0.03; acc: 0.98
Batch: 220; loss: 0.07; acc: 0.98
Batch: 240; loss: 0.04; acc: 0.98
Batch: 260; loss: 0.07; acc: 0.98
Batch: 280; loss: 0.01; acc: 1.0
Batch: 300; loss: 0.05; acc: 0.98
Batch: 320; loss: 0.05; acc: 0.97
Batch: 340; loss: 0.05; acc: 0.97
Batch: 360; loss: 0.08; acc: 0.97
Batch: 380; loss: 0.08; acc: 0.97
Batch: 400; loss: 0.05; acc: 0.98
Batch: 420; loss: 0.06; acc: 0.95
Batch: 440; loss: 0.14; acc: 0.95
Batch: 460; loss: 0.08; acc: 0.95
Batch: 480; loss: 0.02; acc: 1.0
Batch: 500; loss: 0.03; acc: 0.98
Batch: 520; loss: 0.04; acc: 0.98
Batch: 540; loss: 0.1; acc: 0.98
Batch: 560; loss: 0.05; acc: 0.98
Batch: 580; loss: 0.1; acc: 0.95
Batch: 600; loss: 0.05; acc: 0.98
Batch: 620; loss: 0.08; acc: 0.97
Batch: 640; loss: 0.15; acc: 0.95
Batch: 660; loss: 0.01; acc: 1.0
Batch: 680; loss: 0.08; acc: 0.97
Batch: 700; loss: 0.12; acc: 0.95
Batch: 720; loss: 0.02; acc: 1.0
Batch: 740; loss: 0.09; acc: 0.97
Batch: 760; loss: 0.06; acc: 0.98
Batch: 780; loss: 0.16; acc: 0.97
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

3.1007224606582895e-05
1.476478973927442e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.13; acc: 0.97
Batch: 40; loss: 0.01; acc: 1.0
Batch: 60; loss: 0.12; acc: 0.97
Batch: 80; loss: 0.03; acc: 0.98
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.11; acc: 0.95
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.082505958522581; val_accuracy: 0.9754179936305732 

The current subspace-distance is: 1.476478973927442e-05 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.05; acc: 0.98
Batch: 20; loss: 0.04; acc: 1.0
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.11; acc: 0.95
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.04; acc: 0.98
Batch: 120; loss: 0.09; acc: 0.98
Batch: 140; loss: 0.32; acc: 0.94
Batch: 160; loss: 0.06; acc: 0.97
Batch: 180; loss: 0.07; acc: 0.97
Batch: 200; loss: 0.21; acc: 0.94
Batch: 220; loss: 0.06; acc: 0.97
Batch: 240; loss: 0.08; acc: 0.97
Batch: 260; loss: 0.11; acc: 0.97
Batch: 280; loss: 0.06; acc: 0.97
Batch: 300; loss: 0.19; acc: 0.95
Batch: 320; loss: 0.03; acc: 1.0
Batch: 340; loss: 0.03; acc: 1.0
Batch: 360; loss: 0.04; acc: 1.0
Batch: 380; loss: 0.03; acc: 0.98
Batch: 400; loss: 0.07; acc: 0.97
Batch: 420; loss: 0.11; acc: 0.97
Batch: 440; loss: 0.1; acc: 0.95
Batch: 460; loss: 0.11; acc: 0.95
Batch: 480; loss: 0.11; acc: 0.97
Batch: 500; loss: 0.01; acc: 1.0
Batch: 520; loss: 0.1; acc: 0.97
Batch: 540; loss: 0.04; acc: 0.98
Batch: 560; loss: 0.05; acc: 0.97
Batch: 580; loss: 0.04; acc: 0.98
Batch: 600; loss: 0.12; acc: 0.95
Batch: 620; loss: 0.03; acc: 0.98
Batch: 640; loss: 0.2; acc: 0.94
Batch: 660; loss: 0.07; acc: 0.97
Batch: 680; loss: 0.04; acc: 0.98
Batch: 700; loss: 0.22; acc: 0.94
Batch: 720; loss: 0.12; acc: 0.97
Batch: 740; loss: 0.09; acc: 0.98
Batch: 760; loss: 0.16; acc: 0.92
Batch: 780; loss: 0.09; acc: 0.98
Train Epoch over. train_loss: 0.08; train_accuracy: 0.97 

3.120718611171469e-05
1.5306421119021252e-05
Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.01; acc: 1.0
Batch: 60; loss: 0.12; acc: 0.97
Batch: 80; loss: 0.03; acc: 0.98
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.11; acc: 0.97
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.08145588486912145; val_accuracy: 0.9755175159235668 

The current subspace-distance is: 1.5306421119021252e-05 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.07; acc: 0.97
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.02; acc: 1.0
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.13; acc: 0.97
Batch: 140; loss: 0.18; acc: 0.97
Batch: 160; loss: 0.02; acc: 1.0
Batch: 180; loss: 0.02; acc: 1.0
Batch: 200; loss: 0.09; acc: 0.98
Batch: 220; loss: 0.07; acc: 0.97
Batch: 240; loss: 0.01; acc: 1.0
Batch: 260; loss: 0.02; acc: 1.0
Batch: 280; loss: 0.11; acc: 0.95
Batch: 300; loss: 0.35; acc: 0.92
Batch: 320; loss: 0.04; acc: 0.98
Batch: 340; loss: 0.16; acc: 0.94
Batch: 360; loss: 0.08; acc: 0.98
Batch: 380; loss: 0.11; acc: 0.98
Batch: 400; loss: 0.07; acc: 0.98
Batch: 420; loss: 0.07; acc: 0.98
Batch: 440; loss: 0.05; acc: 0.97
Batch: 460; loss: 0.03; acc: 1.0
Batch: 480; loss: 0.02; acc: 1.0
Batch: 500; loss: 0.14; acc: 0.95
Batch: 520; loss: 0.08; acc: 0.98
Batch: 540; loss: 0.02; acc: 1.0
Batch: 560; loss: 0.04; acc: 1.0
Batch: 580; loss: 0.02; acc: 1.0
Batch: 600; loss: 0.04; acc: 0.98
Batch: 620; loss: 0.21; acc: 0.92
Batch: 640; loss: 0.06; acc: 0.98
Batch: 660; loss: 0.03; acc: 1.0
Batch: 680; loss: 0.1; acc: 0.97
Batch: 700; loss: 0.08; acc: 0.97
Batch: 720; loss: 0.03; acc: 0.98
Batch: 740; loss: 0.03; acc: 0.98
Batch: 760; loss: 0.02; acc: 1.0
Batch: 780; loss: 0.17; acc: 0.95
Train Epoch over. train_loss: 0.08; train_accuracy: 0.97 

3.1246458092937246e-05
1.4954045582271647e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.01; acc: 1.0
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.03; acc: 0.98
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.13; acc: 0.95
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.08465628615420336; val_accuracy: 0.9745222929936306 

The current subspace-distance is: 1.4954045582271647e-05 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.1; acc: 0.94
Batch: 20; loss: 0.07; acc: 0.97
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.03; acc: 0.98
Batch: 80; loss: 0.11; acc: 0.95
Batch: 100; loss: 0.03; acc: 0.98
Batch: 120; loss: 0.05; acc: 0.98
Batch: 140; loss: 0.15; acc: 0.95
Batch: 160; loss: 0.04; acc: 1.0
Batch: 180; loss: 0.06; acc: 0.97
Batch: 200; loss: 0.03; acc: 1.0
Batch: 220; loss: 0.03; acc: 1.0
Batch: 240; loss: 0.16; acc: 0.97
Batch: 260; loss: 0.14; acc: 0.95
Batch: 280; loss: 0.06; acc: 0.95
Batch: 300; loss: 0.05; acc: 0.97
Batch: 320; loss: 0.07; acc: 0.98
Batch: 340; loss: 0.07; acc: 0.97
Batch: 360; loss: 0.01; acc: 1.0
Batch: 380; loss: 0.08; acc: 0.95
Batch: 400; loss: 0.03; acc: 0.98
Batch: 420; loss: 0.05; acc: 0.98
Batch: 440; loss: 0.22; acc: 0.94
Batch: 460; loss: 0.02; acc: 1.0
Batch: 480; loss: 0.03; acc: 1.0
Batch: 500; loss: 0.03; acc: 0.98
Batch: 520; loss: 0.06; acc: 0.98
Batch: 540; loss: 0.02; acc: 1.0
Batch: 560; loss: 0.03; acc: 0.98
Batch: 580; loss: 0.1; acc: 0.97
Batch: 600; loss: 0.05; acc: 0.98
Batch: 620; loss: 0.09; acc: 0.98
Batch: 640; loss: 0.03; acc: 1.0
Batch: 660; loss: 0.04; acc: 0.98
Batch: 680; loss: 0.21; acc: 0.91
Batch: 700; loss: 0.01; acc: 1.0
Batch: 720; loss: 0.13; acc: 0.97
Batch: 740; loss: 0.09; acc: 0.97
Batch: 760; loss: 0.04; acc: 0.98
Batch: 780; loss: 0.08; acc: 0.95
Train Epoch over. train_loss: 0.08; train_accuracy: 0.97 

3.143435969832353e-05
1.4736822777194902e-05
Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.01; acc: 1.0
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.02; acc: 0.98
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.11; acc: 0.97
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.08175721581859194; val_accuracy: 0.9758160828025477 

The current subspace-distance is: 1.4736822777194902e-05 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.07; acc: 0.94
Batch: 20; loss: 0.17; acc: 0.95
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.08; acc: 0.95
Batch: 100; loss: 0.12; acc: 0.98
Batch: 120; loss: 0.06; acc: 0.98
Batch: 140; loss: 0.08; acc: 0.97
Batch: 160; loss: 0.05; acc: 0.98
Batch: 180; loss: 0.07; acc: 0.98
Batch: 200; loss: 0.06; acc: 0.98
Batch: 220; loss: 0.11; acc: 0.95
Batch: 240; loss: 0.1; acc: 0.97
Batch: 260; loss: 0.05; acc: 0.97
Batch: 280; loss: 0.07; acc: 0.98
Batch: 300; loss: 0.01; acc: 1.0
Batch: 320; loss: 0.2; acc: 0.94
Batch: 340; loss: 0.13; acc: 0.94
Batch: 360; loss: 0.05; acc: 0.97
Batch: 380; loss: 0.03; acc: 1.0
Batch: 400; loss: 0.09; acc: 0.97
Batch: 420; loss: 0.07; acc: 0.97
Batch: 440; loss: 0.06; acc: 0.97
Batch: 460; loss: 0.04; acc: 0.98
Batch: 480; loss: 0.01; acc: 1.0
Batch: 500; loss: 0.07; acc: 0.97
Batch: 520; loss: 0.05; acc: 0.98
Batch: 540; loss: 0.11; acc: 0.97
Batch: 560; loss: 0.03; acc: 1.0
Batch: 580; loss: 0.05; acc: 0.97
Batch: 600; loss: 0.05; acc: 0.98
Batch: 620; loss: 0.03; acc: 0.98
Batch: 640; loss: 0.04; acc: 0.97
Batch: 660; loss: 0.31; acc: 0.92
Batch: 680; loss: 0.06; acc: 0.95
Batch: 700; loss: 0.13; acc: 0.97
Batch: 720; loss: 0.02; acc: 1.0
Batch: 740; loss: 0.08; acc: 0.97
Batch: 760; loss: 0.05; acc: 0.97
Batch: 780; loss: 0.08; acc: 0.97
Train Epoch over. train_loss: 0.08; train_accuracy: 0.97 

3.056626519537531e-05
1.4189680769050028e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.01; acc: 1.0
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.02; acc: 0.98
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.1; acc: 0.97
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.08327966790859866; val_accuracy: 0.9750199044585988 

The current subspace-distance is: 1.4189680769050028e-05 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.19; acc: 0.98
Batch: 20; loss: 0.03; acc: 1.0
Batch: 40; loss: 0.12; acc: 0.98
Batch: 60; loss: 0.04; acc: 0.98
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.11; acc: 0.97
Batch: 120; loss: 0.03; acc: 1.0
Batch: 140; loss: 0.02; acc: 1.0
Batch: 160; loss: 0.18; acc: 0.94
Batch: 180; loss: 0.05; acc: 0.98
Batch: 200; loss: 0.05; acc: 0.98
Batch: 220; loss: 0.05; acc: 0.98
Batch: 240; loss: 0.09; acc: 0.97
Batch: 260; loss: 0.05; acc: 0.98
Batch: 280; loss: 0.18; acc: 0.95
Batch: 300; loss: 0.17; acc: 0.97
Batch: 320; loss: 0.16; acc: 0.97
Batch: 340; loss: 0.02; acc: 1.0
Batch: 360; loss: 0.13; acc: 0.95
Batch: 380; loss: 0.12; acc: 0.97
Batch: 400; loss: 0.09; acc: 0.97
Batch: 420; loss: 0.03; acc: 0.98
Batch: 440; loss: 0.24; acc: 0.94
Batch: 460; loss: 0.1; acc: 0.98
Batch: 480; loss: 0.02; acc: 1.0
Batch: 500; loss: 0.04; acc: 0.98
Batch: 520; loss: 0.1; acc: 0.92
Batch: 540; loss: 0.11; acc: 0.95
Batch: 560; loss: 0.03; acc: 1.0
Batch: 580; loss: 0.15; acc: 0.97
Batch: 600; loss: 0.04; acc: 0.98
Batch: 620; loss: 0.05; acc: 0.97
Batch: 640; loss: 0.21; acc: 0.94
Batch: 660; loss: 0.1; acc: 0.97
Batch: 680; loss: 0.02; acc: 1.0
Batch: 700; loss: 0.05; acc: 0.98
Batch: 720; loss: 0.09; acc: 0.97
Batch: 740; loss: 0.15; acc: 0.94
Batch: 760; loss: 0.18; acc: 0.97
Batch: 780; loss: 0.03; acc: 0.98
Train Epoch over. train_loss: 0.08; train_accuracy: 0.97 

3.130376717308536e-05
1.4509358152281493e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.01; acc: 1.0
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.02; acc: 0.98
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.12; acc: 0.97
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.08180714991821605; val_accuracy: 0.9755175159235668 

The current subspace-distance is: 1.4509358152281493e-05 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.1; acc: 0.97
Batch: 40; loss: 0.26; acc: 0.91
Batch: 60; loss: 0.19; acc: 0.98
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.01; acc: 1.0
Batch: 140; loss: 0.08; acc: 0.95
Batch: 160; loss: 0.07; acc: 0.97
Batch: 180; loss: 0.09; acc: 0.95
Batch: 200; loss: 0.06; acc: 0.98
Batch: 220; loss: 0.01; acc: 1.0
Batch: 240; loss: 0.01; acc: 1.0
Batch: 260; loss: 0.05; acc: 0.98
Batch: 280; loss: 0.1; acc: 0.98
Batch: 300; loss: 0.07; acc: 0.95
Batch: 320; loss: 0.09; acc: 0.97
Batch: 340; loss: 0.07; acc: 0.98
Batch: 360; loss: 0.08; acc: 0.98
Batch: 380; loss: 0.05; acc: 0.98
Batch: 400; loss: 0.02; acc: 1.0
Batch: 420; loss: 0.07; acc: 0.95
Batch: 440; loss: 0.01; acc: 1.0
Batch: 460; loss: 0.13; acc: 0.95
Batch: 480; loss: 0.08; acc: 0.98
Batch: 500; loss: 0.1; acc: 0.97
Batch: 520; loss: 0.02; acc: 1.0
Batch: 540; loss: 0.13; acc: 0.94
Batch: 560; loss: 0.07; acc: 0.97
Batch: 580; loss: 0.09; acc: 0.98
Batch: 600; loss: 0.23; acc: 0.97
Batch: 620; loss: 0.06; acc: 0.97
Batch: 640; loss: 0.14; acc: 0.97
Batch: 660; loss: 0.18; acc: 0.97
Batch: 680; loss: 0.06; acc: 0.97
Batch: 700; loss: 0.07; acc: 0.95
Batch: 720; loss: 0.07; acc: 0.98
Batch: 740; loss: 0.19; acc: 0.92
Batch: 760; loss: 0.1; acc: 0.98
Batch: 780; loss: 0.11; acc: 0.98
Train Epoch over. train_loss: 0.08; train_accuracy: 0.97 

3.139509499305859e-05
1.5403156794491224e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.01; acc: 1.0
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.02; acc: 0.98
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.12; acc: 0.97
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.08276173059537911; val_accuracy: 0.9748208598726115 

The current subspace-distance is: 1.5403156794491224e-05 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.15; acc: 0.97
Batch: 40; loss: 0.1; acc: 0.95
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.03; acc: 0.98
Batch: 120; loss: 0.09; acc: 0.97
Batch: 140; loss: 0.02; acc: 1.0
Batch: 160; loss: 0.14; acc: 0.94
Batch: 180; loss: 0.15; acc: 0.98
Batch: 200; loss: 0.06; acc: 0.97
Batch: 220; loss: 0.12; acc: 0.94
Batch: 240; loss: 0.04; acc: 0.97
Batch: 260; loss: 0.03; acc: 0.98
Batch: 280; loss: 0.05; acc: 0.98
Batch: 300; loss: 0.11; acc: 0.95
Batch: 320; loss: 0.03; acc: 1.0
Batch: 340; loss: 0.18; acc: 0.95
Batch: 360; loss: 0.03; acc: 0.98
Batch: 380; loss: 0.04; acc: 0.98
Batch: 400; loss: 0.07; acc: 0.98
Batch: 420; loss: 0.03; acc: 0.98
Batch: 440; loss: 0.02; acc: 1.0
Batch: 460; loss: 0.14; acc: 0.95
Batch: 480; loss: 0.07; acc: 0.97
Batch: 500; loss: 0.04; acc: 0.98
Batch: 520; loss: 0.04; acc: 0.98
Batch: 540; loss: 0.17; acc: 0.94
Batch: 560; loss: 0.11; acc: 0.94
Batch: 580; loss: 0.15; acc: 0.95
Batch: 600; loss: 0.14; acc: 0.97
Batch: 620; loss: 0.06; acc: 0.98
Batch: 640; loss: 0.14; acc: 0.97
Batch: 660; loss: 0.02; acc: 1.0
Batch: 680; loss: 0.07; acc: 0.95
Batch: 700; loss: 0.19; acc: 0.92
Batch: 720; loss: 0.07; acc: 0.98
Batch: 740; loss: 0.04; acc: 0.98
Batch: 760; loss: 0.05; acc: 0.98
Batch: 780; loss: 0.12; acc: 0.97
Train Epoch over. train_loss: 0.08; train_accuracy: 0.97 

3.122397538390942e-05
1.4355205166793894e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.01; acc: 1.0
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.02; acc: 0.98
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.12; acc: 0.95
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.0836385506068825; val_accuracy: 0.9750199044585988 

The current subspace-distance is: 1.4355205166793894e-05 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.05; acc: 0.98
Batch: 20; loss: 0.06; acc: 0.97
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.01; acc: 1.0
Batch: 120; loss: 0.04; acc: 0.97
Batch: 140; loss: 0.06; acc: 1.0
Batch: 160; loss: 0.05; acc: 0.98
Batch: 180; loss: 0.07; acc: 0.98
Batch: 200; loss: 0.1; acc: 0.95
Batch: 220; loss: 0.06; acc: 0.97
Batch: 240; loss: 0.24; acc: 0.92
Batch: 260; loss: 0.02; acc: 1.0
Batch: 280; loss: 0.1; acc: 0.95
Batch: 300; loss: 0.06; acc: 0.97
Batch: 320; loss: 0.03; acc: 1.0
Batch: 340; loss: 0.04; acc: 1.0
Batch: 360; loss: 0.11; acc: 0.97
Batch: 380; loss: 0.02; acc: 1.0
Batch: 400; loss: 0.07; acc: 0.98
Batch: 420; loss: 0.11; acc: 0.97
Batch: 440; loss: 0.16; acc: 0.92
Batch: 460; loss: 0.04; acc: 0.98
Batch: 480; loss: 0.12; acc: 0.97
Batch: 500; loss: 0.1; acc: 0.97
Batch: 520; loss: 0.13; acc: 0.97
Batch: 540; loss: 0.01; acc: 1.0
Batch: 560; loss: 0.02; acc: 1.0
Batch: 580; loss: 0.03; acc: 1.0
Batch: 600; loss: 0.06; acc: 0.95
Batch: 620; loss: 0.07; acc: 0.98
Batch: 640; loss: 0.02; acc: 0.98
Batch: 660; loss: 0.01; acc: 1.0
Batch: 680; loss: 0.1; acc: 0.98
Batch: 700; loss: 0.23; acc: 0.97
Batch: 720; loss: 0.03; acc: 1.0
Batch: 740; loss: 0.07; acc: 0.98
Batch: 760; loss: 0.04; acc: 0.98
Batch: 780; loss: 0.19; acc: 0.95
Train Epoch over. train_loss: 0.08; train_accuracy: 0.97 

3.0781109671806917e-05
1.3496597603079863e-05
Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.01; acc: 1.0
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.02; acc: 0.98
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.11; acc: 0.95
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.08332541691744404; val_accuracy: 0.9748208598726115 

The current subspace-distance is: 1.3496597603079863e-05 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.1; acc: 0.98
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.01; acc: 1.0
Batch: 80; loss: 0.22; acc: 0.95
Batch: 100; loss: 0.09; acc: 0.95
Batch: 120; loss: 0.16; acc: 0.95
Batch: 140; loss: 0.06; acc: 0.97
Batch: 160; loss: 0.1; acc: 0.97
Batch: 180; loss: 0.05; acc: 0.98
Batch: 200; loss: 0.13; acc: 0.92
Batch: 220; loss: 0.09; acc: 0.97
Batch: 240; loss: 0.06; acc: 0.97
Batch: 260; loss: 0.02; acc: 1.0
Batch: 280; loss: 0.04; acc: 0.98
Batch: 300; loss: 0.2; acc: 0.95
Batch: 320; loss: 0.16; acc: 0.95
Batch: 340; loss: 0.01; acc: 1.0
Batch: 360; loss: 0.02; acc: 1.0
Batch: 380; loss: 0.02; acc: 0.98
Batch: 400; loss: 0.04; acc: 0.98
Batch: 420; loss: 0.12; acc: 0.94
Batch: 440; loss: 0.01; acc: 1.0
Batch: 460; loss: 0.01; acc: 1.0
Batch: 480; loss: 0.03; acc: 0.98
Batch: 500; loss: 0.08; acc: 0.98
Batch: 520; loss: 0.04; acc: 1.0
Batch: 540; loss: 0.07; acc: 0.98
Batch: 560; loss: 0.07; acc: 0.98
Batch: 580; loss: 0.05; acc: 0.98
Batch: 600; loss: 0.04; acc: 0.98
Batch: 620; loss: 0.05; acc: 0.98
Batch: 640; loss: 0.01; acc: 1.0
Batch: 660; loss: 0.04; acc: 1.0
Batch: 680; loss: 0.01; acc: 1.0
Batch: 700; loss: 0.07; acc: 0.97
Batch: 720; loss: 0.1; acc: 0.98
Batch: 740; loss: 0.23; acc: 0.91
Batch: 760; loss: 0.08; acc: 0.97
Batch: 780; loss: 0.05; acc: 0.98
Train Epoch over. train_loss: 0.08; train_accuracy: 0.97 

3.096989530604333e-05
1.3983908502268605e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.18; acc: 0.95
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.12; acc: 0.95
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.08347664215857056; val_accuracy: 0.9762141719745223 

The current subspace-distance is: 1.3983908502268605e-05 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.06; acc: 0.98
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.02; acc: 1.0
Batch: 120; loss: 0.02; acc: 1.0
Batch: 140; loss: 0.08; acc: 0.97
Batch: 160; loss: 0.13; acc: 0.94
Batch: 180; loss: 0.09; acc: 0.97
Batch: 200; loss: 0.03; acc: 0.98
Batch: 220; loss: 0.06; acc: 0.98
Batch: 240; loss: 0.07; acc: 0.98
Batch: 260; loss: 0.12; acc: 0.97
Batch: 280; loss: 0.08; acc: 0.98
Batch: 300; loss: 0.08; acc: 0.95
Batch: 320; loss: 0.02; acc: 1.0
Batch: 340; loss: 0.08; acc: 0.97
Batch: 360; loss: 0.06; acc: 0.98
Batch: 380; loss: 0.14; acc: 0.97
Batch: 400; loss: 0.05; acc: 0.97
Batch: 420; loss: 0.04; acc: 0.98
Batch: 440; loss: 0.11; acc: 0.97
Batch: 460; loss: 0.05; acc: 0.98
Batch: 480; loss: 0.07; acc: 0.98
Batch: 500; loss: 0.06; acc: 0.98
Batch: 520; loss: 0.07; acc: 0.98
Batch: 540; loss: 0.07; acc: 0.98
Batch: 560; loss: 0.02; acc: 0.98
Batch: 580; loss: 0.09; acc: 0.95
Batch: 600; loss: 0.02; acc: 1.0
Batch: 620; loss: 0.04; acc: 0.98
Batch: 640; loss: 0.05; acc: 0.98
Batch: 660; loss: 0.05; acc: 0.98
Batch: 680; loss: 0.24; acc: 0.92
Batch: 700; loss: 0.04; acc: 0.98
Batch: 720; loss: 0.08; acc: 0.97
Batch: 740; loss: 0.17; acc: 0.94
Batch: 760; loss: 0.09; acc: 0.95
Batch: 780; loss: 0.06; acc: 0.98
Train Epoch over. train_loss: 0.08; train_accuracy: 0.97 

3.1272727937903255e-05
1.3985962141305208e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.01; acc: 1.0
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.03; acc: 0.98
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.12; acc: 0.95
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.08280041941981407; val_accuracy: 0.9750199044585988 

The current subspace-distance is: 1.3985962141305208e-05 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.06; acc: 0.98
Batch: 20; loss: 0.17; acc: 0.95
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.05; acc: 0.97
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.12; acc: 0.97
Batch: 120; loss: 0.05; acc: 0.98
Batch: 140; loss: 0.03; acc: 0.98
Batch: 160; loss: 0.15; acc: 0.95
Batch: 180; loss: 0.06; acc: 0.98
Batch: 200; loss: 0.03; acc: 1.0
Batch: 220; loss: 0.12; acc: 0.97
Batch: 240; loss: 0.02; acc: 1.0
Batch: 260; loss: 0.01; acc: 1.0
Batch: 280; loss: 0.13; acc: 0.95
Batch: 300; loss: 0.06; acc: 0.97
Batch: 320; loss: 0.06; acc: 0.97
Batch: 340; loss: 0.06; acc: 0.98
Batch: 360; loss: 0.23; acc: 0.97
Batch: 380; loss: 0.11; acc: 0.95
Batch: 400; loss: 0.07; acc: 0.97
Batch: 420; loss: 0.09; acc: 0.97
Batch: 440; loss: 0.05; acc: 0.98
Batch: 460; loss: 0.05; acc: 0.97
Batch: 480; loss: 0.05; acc: 0.98
Batch: 500; loss: 0.06; acc: 0.98
Batch: 520; loss: 0.08; acc: 0.97
Batch: 540; loss: 0.07; acc: 0.97
Batch: 560; loss: 0.1; acc: 0.97
Batch: 580; loss: 0.06; acc: 0.98
Batch: 600; loss: 0.06; acc: 0.98
Batch: 620; loss: 0.02; acc: 0.98
Batch: 640; loss: 0.1; acc: 0.98
Batch: 660; loss: 0.09; acc: 0.97
Batch: 680; loss: 0.03; acc: 0.98
Batch: 700; loss: 0.1; acc: 0.94
Batch: 720; loss: 0.16; acc: 0.95
Batch: 740; loss: 0.05; acc: 0.98
Batch: 760; loss: 0.02; acc: 1.0
Batch: 780; loss: 0.02; acc: 1.0
Train Epoch over. train_loss: 0.08; train_accuracy: 0.98 

3.059835944441147e-05
1.4498793461825699e-05
Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.01; acc: 1.0
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.02; acc: 0.98
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.12; acc: 0.95
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.0813523987723384; val_accuracy: 0.9757165605095541 

The current subspace-distance is: 1.4498793461825699e-05 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.19; acc: 0.97
Batch: 20; loss: 0.02; acc: 1.0
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.07; acc: 0.97
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.03; acc: 0.98
Batch: 120; loss: 0.16; acc: 0.91
Batch: 140; loss: 0.09; acc: 0.95
Batch: 160; loss: 0.15; acc: 0.97
Batch: 180; loss: 0.05; acc: 0.98
Batch: 200; loss: 0.04; acc: 1.0
Batch: 220; loss: 0.03; acc: 0.98
Batch: 240; loss: 0.08; acc: 0.97
Batch: 260; loss: 0.07; acc: 0.97
Batch: 280; loss: 0.04; acc: 1.0
Batch: 300; loss: 0.02; acc: 1.0
Batch: 320; loss: 0.09; acc: 0.94
Batch: 340; loss: 0.04; acc: 0.98
Batch: 360; loss: 0.08; acc: 0.98
Batch: 380; loss: 0.02; acc: 1.0
Batch: 400; loss: 0.08; acc: 0.97
Batch: 420; loss: 0.05; acc: 0.98
Batch: 440; loss: 0.04; acc: 0.98
Batch: 460; loss: 0.03; acc: 1.0
Batch: 480; loss: 0.03; acc: 1.0
Batch: 500; loss: 0.21; acc: 0.97
Batch: 520; loss: 0.14; acc: 0.97
Batch: 540; loss: 0.08; acc: 0.98
Batch: 560; loss: 0.04; acc: 0.97
Batch: 580; loss: 0.08; acc: 0.97
Batch: 600; loss: 0.11; acc: 0.95
Batch: 620; loss: 0.04; acc: 0.98
Batch: 640; loss: 0.08; acc: 0.97
Batch: 660; loss: 0.03; acc: 1.0
Batch: 680; loss: 0.01; acc: 1.0
Batch: 700; loss: 0.15; acc: 0.97
Batch: 720; loss: 0.05; acc: 0.97
Batch: 740; loss: 0.05; acc: 0.98
Batch: 760; loss: 0.03; acc: 0.98
Batch: 780; loss: 0.14; acc: 0.97
Train Epoch over. train_loss: 0.08; train_accuracy: 0.98 

3.077820656471886e-05
1.4011327039042953e-05
Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.01; acc: 1.0
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.02; acc: 0.98
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.11; acc: 0.95
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.0807259881477447; val_accuracy: 0.976015127388535 

The current subspace-distance is: 1.4011327039042953e-05 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.24; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.95
Batch: 60; loss: 0.06; acc: 0.95
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.03; acc: 0.98
Batch: 120; loss: 0.03; acc: 0.98
Batch: 140; loss: 0.07; acc: 0.97
Batch: 160; loss: 0.04; acc: 0.98
Batch: 180; loss: 0.06; acc: 0.98
Batch: 200; loss: 0.02; acc: 1.0
Batch: 220; loss: 0.02; acc: 1.0
Batch: 240; loss: 0.04; acc: 0.98
Batch: 260; loss: 0.15; acc: 0.92
Batch: 280; loss: 0.03; acc: 1.0
Batch: 300; loss: 0.09; acc: 0.97
Batch: 320; loss: 0.03; acc: 1.0
Batch: 340; loss: 0.01; acc: 1.0
Batch: 360; loss: 0.05; acc: 0.98
Batch: 380; loss: 0.08; acc: 0.97
Batch: 400; loss: 0.11; acc: 0.95
Batch: 420; loss: 0.04; acc: 0.98
Batch: 440; loss: 0.02; acc: 1.0
Batch: 460; loss: 0.05; acc: 0.98
Batch: 480; loss: 0.1; acc: 0.98
Batch: 500; loss: 0.08; acc: 0.98
Batch: 520; loss: 0.16; acc: 0.95
Batch: 540; loss: 0.09; acc: 0.97
Batch: 560; loss: 0.07; acc: 0.95
Batch: 580; loss: 0.09; acc: 0.97
Batch: 600; loss: 0.04; acc: 1.0
Batch: 620; loss: 0.04; acc: 1.0
Batch: 640; loss: 0.03; acc: 0.98
Batch: 660; loss: 0.03; acc: 0.98
Batch: 680; loss: 0.13; acc: 0.97
Batch: 700; loss: 0.04; acc: 0.98
Batch: 720; loss: 0.13; acc: 0.97
Batch: 740; loss: 0.07; acc: 0.98
Batch: 760; loss: 0.02; acc: 0.98
Batch: 780; loss: 0.06; acc: 0.97
Train Epoch over. train_loss: 0.08; train_accuracy: 0.98 

3.0323553801281378e-05
1.411527773598209e-05
Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.01; acc: 1.0
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.02; acc: 0.98
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.11; acc: 0.95
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.08096359442373749; val_accuracy: 0.9751194267515924 

The current subspace-distance is: 1.411527773598209e-05 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.12; acc: 0.98
Batch: 40; loss: 0.02; acc: 0.98
Batch: 60; loss: 0.24; acc: 0.97
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.17; acc: 0.98
Batch: 140; loss: 0.23; acc: 0.97
Batch: 160; loss: 0.19; acc: 0.94
Batch: 180; loss: 0.09; acc: 0.97
Batch: 200; loss: 0.03; acc: 0.98
Batch: 220; loss: 0.02; acc: 1.0
Batch: 240; loss: 0.07; acc: 0.97
Batch: 260; loss: 0.01; acc: 1.0
Batch: 280; loss: 0.1; acc: 0.97
Batch: 300; loss: 0.04; acc: 0.98
Batch: 320; loss: 0.2; acc: 0.95
Batch: 340; loss: 0.18; acc: 0.92
Batch: 360; loss: 0.08; acc: 0.98
Batch: 380; loss: 0.18; acc: 0.97
Batch: 400; loss: 0.22; acc: 0.92
Batch: 420; loss: 0.08; acc: 0.97
Batch: 440; loss: 0.09; acc: 0.97
Batch: 460; loss: 0.02; acc: 1.0
Batch: 480; loss: 0.16; acc: 0.91
Batch: 500; loss: 0.26; acc: 0.95
Batch: 520; loss: 0.13; acc: 0.95
Batch: 540; loss: 0.02; acc: 1.0
Batch: 560; loss: 0.15; acc: 0.98
Batch: 580; loss: 0.14; acc: 0.97
Batch: 600; loss: 0.18; acc: 0.95
Batch: 620; loss: 0.03; acc: 0.98
Batch: 640; loss: 0.05; acc: 0.98
Batch: 660; loss: 0.14; acc: 0.97
Batch: 680; loss: 0.12; acc: 0.98
Batch: 700; loss: 0.04; acc: 0.98
Batch: 720; loss: 0.11; acc: 0.97
Batch: 740; loss: 0.24; acc: 0.97
Batch: 760; loss: 0.12; acc: 0.92
Batch: 780; loss: 0.05; acc: 0.97
Train Epoch over. train_loss: 0.08; train_accuracy: 0.97 

3.0431096092797816e-05
1.447715658287052e-05
Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.01; acc: 1.0
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.02; acc: 0.98
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.11; acc: 0.95
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.08196850695237992; val_accuracy: 0.9748208598726115 

The current subspace-distance is: 1.447715658287052e-05 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.07; acc: 0.97
Batch: 20; loss: 0.02; acc: 1.0
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.1; acc: 0.98
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.03; acc: 0.98
Batch: 120; loss: 0.06; acc: 0.98
Batch: 140; loss: 0.01; acc: 1.0
Batch: 160; loss: 0.02; acc: 1.0
Batch: 180; loss: 0.03; acc: 0.98
Batch: 200; loss: 0.05; acc: 0.98
Batch: 220; loss: 0.02; acc: 1.0
Batch: 240; loss: 0.19; acc: 0.92
Batch: 260; loss: 0.15; acc: 0.98
Batch: 280; loss: 0.17; acc: 0.92
Batch: 300; loss: 0.02; acc: 1.0
Batch: 320; loss: 0.08; acc: 0.98
Batch: 340; loss: 0.02; acc: 0.98
Batch: 360; loss: 0.13; acc: 0.95
Batch: 380; loss: 0.03; acc: 1.0
Batch: 400; loss: 0.01; acc: 1.0
Batch: 420; loss: 0.14; acc: 0.95
Batch: 440; loss: 0.14; acc: 0.95
Batch: 460; loss: 0.01; acc: 1.0
Batch: 480; loss: 0.05; acc: 0.98
Batch: 500; loss: 0.01; acc: 1.0
Batch: 520; loss: 0.01; acc: 1.0
Batch: 540; loss: 0.03; acc: 0.98
Batch: 560; loss: 0.02; acc: 1.0
Batch: 580; loss: 0.04; acc: 0.98
Batch: 600; loss: 0.16; acc: 0.95
Batch: 620; loss: 0.02; acc: 1.0
Batch: 640; loss: 0.02; acc: 1.0
Batch: 660; loss: 0.04; acc: 0.98
Batch: 680; loss: 0.06; acc: 0.98
Batch: 700; loss: 0.07; acc: 0.97
Batch: 720; loss: 0.21; acc: 0.94
Batch: 740; loss: 0.13; acc: 0.97
Batch: 760; loss: 0.1; acc: 0.97
Batch: 780; loss: 0.03; acc: 1.0
Train Epoch over. train_loss: 0.08; train_accuracy: 0.98 

3.096864020335488e-05
1.4340642337629106e-05
Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.01; acc: 1.0
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.02; acc: 0.98
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.12; acc: 0.95
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.08080657132586856; val_accuracy: 0.9761146496815286 

The current subspace-distance is: 1.4340642337629106e-05 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.16; acc: 0.92
Batch: 40; loss: 0.04; acc: 0.97
Batch: 60; loss: 0.04; acc: 0.97
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.17; acc: 0.91
Batch: 140; loss: 0.09; acc: 0.97
Batch: 160; loss: 0.19; acc: 0.97
Batch: 180; loss: 0.04; acc: 0.97
Batch: 200; loss: 0.04; acc: 1.0
Batch: 220; loss: 0.12; acc: 0.97
Batch: 240; loss: 0.08; acc: 0.98
Batch: 260; loss: 0.03; acc: 1.0
Batch: 280; loss: 0.15; acc: 0.98
Batch: 300; loss: 0.11; acc: 0.97
Batch: 320; loss: 0.42; acc: 0.92
Batch: 340; loss: 0.03; acc: 0.98
Batch: 360; loss: 0.22; acc: 0.92
Batch: 380; loss: 0.05; acc: 0.97
Batch: 400; loss: 0.07; acc: 0.98
Batch: 420; loss: 0.12; acc: 0.97
Batch: 440; loss: 0.04; acc: 0.98
Batch: 460; loss: 0.16; acc: 0.94
Batch: 480; loss: 0.03; acc: 1.0
Batch: 500; loss: 0.11; acc: 0.95
Batch: 520; loss: 0.06; acc: 0.97
Batch: 540; loss: 0.14; acc: 0.97
Batch: 560; loss: 0.17; acc: 0.97
Batch: 580; loss: 0.04; acc: 0.98
Batch: 600; loss: 0.05; acc: 0.98
Batch: 620; loss: 0.16; acc: 0.94
Batch: 640; loss: 0.03; acc: 1.0
Batch: 660; loss: 0.07; acc: 0.97
Batch: 680; loss: 0.04; acc: 0.98
Batch: 700; loss: 0.08; acc: 0.98
Batch: 720; loss: 0.02; acc: 1.0
Batch: 740; loss: 0.01; acc: 1.0
Batch: 760; loss: 0.16; acc: 0.97
Batch: 780; loss: 0.02; acc: 1.0
Train Epoch over. train_loss: 0.08; train_accuracy: 0.98 

3.089886740781367e-05
1.4609118807129562e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.01; acc: 1.0
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.02; acc: 0.98
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.11; acc: 0.95
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.08184005908525674; val_accuracy: 0.9756170382165605 

The current subspace-distance is: 1.4609118807129562e-05 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.05; acc: 0.98
Batch: 20; loss: 0.03; acc: 0.98
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.05; acc: 0.98
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.11; acc: 0.95
Batch: 120; loss: 0.03; acc: 1.0
Batch: 140; loss: 0.25; acc: 0.92
Batch: 160; loss: 0.11; acc: 0.98
Batch: 180; loss: 0.05; acc: 0.97
Batch: 200; loss: 0.12; acc: 0.95
Batch: 220; loss: 0.06; acc: 0.98
Batch: 240; loss: 0.05; acc: 0.97
Batch: 260; loss: 0.13; acc: 0.97
Batch: 280; loss: 0.02; acc: 1.0
Batch: 300; loss: 0.01; acc: 1.0
Batch: 320; loss: 0.06; acc: 0.97
Batch: 340; loss: 0.16; acc: 0.97
Batch: 360; loss: 0.16; acc: 0.97
Batch: 380; loss: 0.04; acc: 0.98
Batch: 400; loss: 0.02; acc: 1.0
Batch: 420; loss: 0.07; acc: 0.98
Batch: 440; loss: 0.03; acc: 0.98
Batch: 460; loss: 0.03; acc: 0.98
Batch: 480; loss: 0.02; acc: 1.0
Batch: 500; loss: 0.04; acc: 0.98
Batch: 520; loss: 0.05; acc: 0.98
Batch: 540; loss: 0.08; acc: 0.95
Batch: 560; loss: 0.01; acc: 1.0
Batch: 580; loss: 0.01; acc: 1.0
Batch: 600; loss: 0.04; acc: 0.98
Batch: 620; loss: 0.12; acc: 0.97
Batch: 640; loss: 0.05; acc: 0.98
Batch: 660; loss: 0.02; acc: 1.0
Batch: 680; loss: 0.07; acc: 0.98
Batch: 700; loss: 0.07; acc: 0.97
Batch: 720; loss: 0.04; acc: 0.98
Batch: 740; loss: 0.07; acc: 0.98
Batch: 760; loss: 0.11; acc: 0.98
Batch: 780; loss: 0.2; acc: 0.98
Train Epoch over. train_loss: 0.08; train_accuracy: 0.98 

3.0720857466803864e-05
1.4356896826939192e-05
Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.01; acc: 1.0
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.02; acc: 0.98
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.11; acc: 0.95
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.08207100862340563; val_accuracy: 0.974422770700637 

The current subspace-distance is: 1.4356896826939192e-05 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.06; acc: 0.97
Batch: 20; loss: 0.03; acc: 1.0
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.03; acc: 1.0
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.06; acc: 0.97
Batch: 140; loss: 0.07; acc: 0.97
Batch: 160; loss: 0.03; acc: 1.0
Batch: 180; loss: 0.04; acc: 1.0
Batch: 200; loss: 0.06; acc: 0.98
Batch: 220; loss: 0.03; acc: 0.98
Batch: 240; loss: 0.02; acc: 1.0
Batch: 260; loss: 0.07; acc: 0.97
Batch: 280; loss: 0.13; acc: 0.97
Batch: 300; loss: 0.04; acc: 1.0
Batch: 320; loss: 0.05; acc: 0.98
Batch: 340; loss: 0.11; acc: 0.95
Batch: 360; loss: 0.08; acc: 0.98
Batch: 380; loss: 0.08; acc: 0.95
Batch: 400; loss: 0.07; acc: 0.98
Batch: 420; loss: 0.05; acc: 0.97
Batch: 440; loss: 0.03; acc: 0.98
Batch: 460; loss: 0.05; acc: 0.98
Batch: 480; loss: 0.19; acc: 0.97
Batch: 500; loss: 0.12; acc: 0.95
Batch: 520; loss: 0.01; acc: 1.0
Batch: 540; loss: 0.25; acc: 0.95
Batch: 560; loss: 0.12; acc: 0.94
Batch: 580; loss: 0.08; acc: 0.97
Batch: 600; loss: 0.09; acc: 0.97
Batch: 620; loss: 0.11; acc: 0.98
Batch: 640; loss: 0.1; acc: 0.98
Batch: 660; loss: 0.04; acc: 0.98
Batch: 680; loss: 0.03; acc: 1.0
Batch: 700; loss: 0.03; acc: 0.98
Batch: 720; loss: 0.13; acc: 0.97
Batch: 740; loss: 0.06; acc: 0.95
Batch: 760; loss: 0.1; acc: 0.97
Batch: 780; loss: 0.02; acc: 1.0
Train Epoch over. train_loss: 0.08; train_accuracy: 0.98 

3.0915609386283904e-05
1.4403523891814984e-05
Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.01; acc: 1.0
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.02; acc: 0.98
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.11; acc: 0.95
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.08234855556374143; val_accuracy: 0.9747213375796179 

The current subspace-distance is: 1.4403523891814984e-05 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.08; acc: 0.98
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.05; acc: 0.98
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.01; acc: 1.0
Batch: 120; loss: 0.09; acc: 0.98
Batch: 140; loss: 0.08; acc: 0.97
Batch: 160; loss: 0.02; acc: 1.0
Batch: 180; loss: 0.04; acc: 1.0
Batch: 200; loss: 0.12; acc: 0.97
Batch: 220; loss: 0.11; acc: 0.97
Batch: 240; loss: 0.01; acc: 1.0
Batch: 260; loss: 0.15; acc: 0.94
Batch: 280; loss: 0.19; acc: 0.94
Batch: 300; loss: 0.05; acc: 0.98
Batch: 320; loss: 0.02; acc: 0.98
Batch: 340; loss: 0.13; acc: 0.95
Batch: 360; loss: 0.1; acc: 0.97
Batch: 380; loss: 0.08; acc: 0.97
Batch: 400; loss: 0.09; acc: 0.95
Batch: 420; loss: 0.11; acc: 0.97
Batch: 440; loss: 0.07; acc: 0.95
Batch: 460; loss: 0.04; acc: 0.98
Batch: 480; loss: 0.03; acc: 1.0
Batch: 500; loss: 0.05; acc: 0.98
Batch: 520; loss: 0.22; acc: 0.95
Batch: 540; loss: 0.12; acc: 0.94
Batch: 560; loss: 0.1; acc: 0.97
Batch: 580; loss: 0.01; acc: 1.0
Batch: 600; loss: 0.02; acc: 1.0
Batch: 620; loss: 0.01; acc: 1.0
Batch: 640; loss: 0.32; acc: 0.92
Batch: 660; loss: 0.07; acc: 0.98
Batch: 680; loss: 0.03; acc: 1.0
Batch: 700; loss: 0.03; acc: 0.98
Batch: 720; loss: 0.08; acc: 0.98
Batch: 740; loss: 0.03; acc: 1.0
Batch: 760; loss: 0.2; acc: 0.95
Batch: 780; loss: 0.08; acc: 0.97
Train Epoch over. train_loss: 0.08; train_accuracy: 0.98 

3.1296382076106966e-05
1.5106993487279397e-05
Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.01; acc: 1.0
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.02; acc: 0.98
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.12; acc: 0.95
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.08201964674102273; val_accuracy: 0.975218949044586 

The current subspace-distance is: 1.5106993487279397e-05 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.17; acc: 0.95
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.06; acc: 0.97
Batch: 80; loss: 0.19; acc: 0.97
Batch: 100; loss: 0.03; acc: 1.0
Batch: 120; loss: 0.05; acc: 0.98
Batch: 140; loss: 0.12; acc: 0.98
Batch: 160; loss: 0.11; acc: 0.95
Batch: 180; loss: 0.03; acc: 0.98
Batch: 200; loss: 0.12; acc: 0.97
Batch: 220; loss: 0.09; acc: 0.95
Batch: 240; loss: 0.11; acc: 0.98
Batch: 260; loss: 0.08; acc: 0.97
Batch: 280; loss: 0.06; acc: 0.98
Batch: 300; loss: 0.04; acc: 0.98
Batch: 320; loss: 0.03; acc: 1.0
Batch: 340; loss: 0.02; acc: 1.0
Batch: 360; loss: 0.06; acc: 0.98
Batch: 380; loss: 0.1; acc: 0.95
Batch: 400; loss: 0.15; acc: 0.92
Batch: 420; loss: 0.07; acc: 0.97
Batch: 440; loss: 0.04; acc: 0.98
Batch: 460; loss: 0.06; acc: 0.98
Batch: 480; loss: 0.17; acc: 0.94
Batch: 500; loss: 0.04; acc: 1.0
Batch: 520; loss: 0.09; acc: 0.97
Batch: 540; loss: 0.07; acc: 0.98
Batch: 560; loss: 0.21; acc: 0.92
Batch: 580; loss: 0.14; acc: 0.97
Batch: 600; loss: 0.08; acc: 0.97
Batch: 620; loss: 0.1; acc: 0.97
Batch: 640; loss: 0.01; acc: 1.0
Batch: 660; loss: 0.01; acc: 1.0
Batch: 680; loss: 0.1; acc: 0.95
Batch: 700; loss: 0.22; acc: 0.97
Batch: 720; loss: 0.02; acc: 1.0
Batch: 740; loss: 0.06; acc: 0.98
Batch: 760; loss: 0.04; acc: 0.98
Batch: 780; loss: 0.14; acc: 0.98
Train Epoch over. train_loss: 0.08; train_accuracy: 0.98 

3.13140481011942e-05
1.5386551240226254e-05
Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.01; acc: 1.0
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.02; acc: 0.98
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.11; acc: 0.95
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.08188723836829707; val_accuracy: 0.9751194267515924 

The current subspace-distance is: 1.5386551240226254e-05 

plots/subspace_training/reg_lenet_3/2020-01-22 20:51:04/d_dim_400_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
nonzero elements in E: 94827
elements in E: 20245500
fraction nonzero: 0.004683855671630733
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.31; acc: 0.08
Batch: 20; loss: 2.3; acc: 0.05
Batch: 40; loss: 2.3; acc: 0.09
Batch: 60; loss: 2.3; acc: 0.02
Batch: 80; loss: 2.29; acc: 0.08
Batch: 100; loss: 2.29; acc: 0.12
Batch: 120; loss: 2.3; acc: 0.11
Batch: 140; loss: 2.3; acc: 0.09
Batch: 160; loss: 2.29; acc: 0.11
Batch: 180; loss: 2.28; acc: 0.11
Batch: 200; loss: 2.27; acc: 0.16
Batch: 220; loss: 2.27; acc: 0.19
Batch: 240; loss: 2.26; acc: 0.17
Batch: 260; loss: 2.26; acc: 0.23
Batch: 280; loss: 2.2; acc: 0.36
Batch: 300; loss: 2.15; acc: 0.27
Batch: 320; loss: 2.04; acc: 0.55
Batch: 340; loss: 1.8; acc: 0.55
Batch: 360; loss: 1.36; acc: 0.55
Batch: 380; loss: 1.37; acc: 0.58
Batch: 400; loss: 2.02; acc: 0.36
Batch: 420; loss: 1.2; acc: 0.61
Batch: 440; loss: 0.87; acc: 0.7
Batch: 460; loss: 0.71; acc: 0.83
Batch: 480; loss: 0.91; acc: 0.67
Batch: 500; loss: 0.78; acc: 0.7
Batch: 520; loss: 0.63; acc: 0.77
Batch: 540; loss: 0.5; acc: 0.84
Batch: 560; loss: 0.6; acc: 0.83
Batch: 580; loss: 0.52; acc: 0.84
Batch: 600; loss: 0.64; acc: 0.72
Batch: 620; loss: 0.54; acc: 0.78
Batch: 640; loss: 0.78; acc: 0.83
Batch: 660; loss: 0.41; acc: 0.84
Batch: 680; loss: 0.45; acc: 0.83
Batch: 700; loss: 0.58; acc: 0.81
Batch: 720; loss: 0.35; acc: 0.92
Batch: 740; loss: 0.43; acc: 0.86
Batch: 760; loss: 0.43; acc: 0.84
Batch: 780; loss: 0.67; acc: 0.75
Train Epoch over. train_loss: 1.42; train_accuracy: 0.5 

1.437787705071969e-05
7.626341357536148e-06
Batch: 0; loss: 0.38; acc: 0.89
Batch: 20; loss: 0.55; acc: 0.8
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.55; acc: 0.84
Batch: 80; loss: 0.18; acc: 0.97
Batch: 100; loss: 0.4; acc: 0.89
Batch: 120; loss: 0.55; acc: 0.86
Batch: 140; loss: 0.19; acc: 0.97
Val Epoch over. val_loss: 0.39363676831600775; val_accuracy: 0.8767914012738853 

The current subspace-distance is: 7.626341357536148e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 0.54; acc: 0.83
Batch: 20; loss: 0.52; acc: 0.83
Batch: 40; loss: 0.27; acc: 0.92
Batch: 60; loss: 0.3; acc: 0.91
Batch: 80; loss: 0.5; acc: 0.91
Batch: 100; loss: 0.3; acc: 0.88
Batch: 120; loss: 0.57; acc: 0.88
Batch: 140; loss: 0.32; acc: 0.89
Batch: 160; loss: 0.67; acc: 0.78
Batch: 180; loss: 0.33; acc: 0.89
Batch: 200; loss: 0.36; acc: 0.88
Batch: 220; loss: 0.44; acc: 0.8
Batch: 240; loss: 0.45; acc: 0.84
Batch: 260; loss: 0.3; acc: 0.92
Batch: 280; loss: 0.53; acc: 0.91
Batch: 300; loss: 0.2; acc: 0.94
Batch: 320; loss: 0.33; acc: 0.89
Batch: 340; loss: 0.5; acc: 0.84
Batch: 360; loss: 0.27; acc: 0.94
Batch: 380; loss: 0.22; acc: 0.94
Batch: 400; loss: 0.23; acc: 0.92
Batch: 420; loss: 0.27; acc: 0.95
Batch: 440; loss: 0.54; acc: 0.88
Batch: 460; loss: 0.28; acc: 0.89
Batch: 480; loss: 0.1; acc: 0.97
Batch: 500; loss: 0.24; acc: 0.92
Batch: 520; loss: 0.14; acc: 0.97
Batch: 540; loss: 0.2; acc: 0.97
Batch: 560; loss: 0.06; acc: 0.98
Batch: 580; loss: 0.25; acc: 0.91
Batch: 600; loss: 0.31; acc: 0.92
Batch: 620; loss: 0.23; acc: 0.92
Batch: 640; loss: 0.26; acc: 0.91
Batch: 660; loss: 0.81; acc: 0.73
Batch: 680; loss: 0.24; acc: 0.89
Batch: 700; loss: 0.23; acc: 0.92
Batch: 720; loss: 0.35; acc: 0.88
Batch: 740; loss: 0.26; acc: 0.92
Batch: 760; loss: 0.45; acc: 0.86
Batch: 780; loss: 0.31; acc: 0.92
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.2043721401132643e-05
1.0470555025676731e-05
Batch: 0; loss: 0.4; acc: 0.88
Batch: 20; loss: 0.37; acc: 0.89
Batch: 40; loss: 0.37; acc: 0.88
Batch: 60; loss: 0.71; acc: 0.83
Batch: 80; loss: 0.32; acc: 0.91
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.72; acc: 0.77
Batch: 140; loss: 0.2; acc: 0.94
Val Epoch over. val_loss: 0.3614588288269984; val_accuracy: 0.886046974522293 

The current subspace-distance is: 1.0470555025676731e-05 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.43; acc: 0.84
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.19; acc: 0.92
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.15; acc: 0.94
Batch: 100; loss: 0.46; acc: 0.86
Batch: 120; loss: 0.19; acc: 0.95
Batch: 140; loss: 0.24; acc: 0.92
Batch: 160; loss: 0.32; acc: 0.92
Batch: 180; loss: 0.24; acc: 0.92
Batch: 200; loss: 0.36; acc: 0.86
Batch: 220; loss: 0.44; acc: 0.91
Batch: 240; loss: 0.42; acc: 0.89
Batch: 260; loss: 0.19; acc: 0.94
Batch: 280; loss: 0.06; acc: 0.98
Batch: 300; loss: 0.19; acc: 0.97
Batch: 320; loss: 0.19; acc: 0.91
Batch: 340; loss: 0.16; acc: 0.95
Batch: 360; loss: 0.1; acc: 0.98
Batch: 380; loss: 0.3; acc: 0.94
Batch: 400; loss: 0.34; acc: 0.92
Batch: 420; loss: 0.28; acc: 0.91
Batch: 440; loss: 0.09; acc: 1.0
Batch: 460; loss: 0.2; acc: 0.95
Batch: 480; loss: 0.22; acc: 0.91
Batch: 500; loss: 0.13; acc: 0.95
Batch: 520; loss: 0.13; acc: 0.95
Batch: 540; loss: 0.21; acc: 0.94
Batch: 560; loss: 0.25; acc: 0.92
Batch: 580; loss: 0.15; acc: 0.94
Batch: 600; loss: 0.1; acc: 1.0
Batch: 620; loss: 0.32; acc: 0.84
Batch: 640; loss: 0.13; acc: 0.97
Batch: 660; loss: 0.21; acc: 0.92
Batch: 680; loss: 0.21; acc: 0.94
Batch: 700; loss: 0.17; acc: 0.94
Batch: 720; loss: 0.13; acc: 0.97
Batch: 740; loss: 0.19; acc: 0.91
Batch: 760; loss: 0.13; acc: 0.92
Batch: 780; loss: 0.12; acc: 0.94
Train Epoch over. train_loss: 0.21; train_accuracy: 0.94 

2.4524757463950664e-05
1.0859973372134846e-05
Batch: 0; loss: 0.06; acc: 1.0
Batch: 20; loss: 0.2; acc: 0.95
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.21; acc: 0.92
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.23; acc: 0.92
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.15359370287056942; val_accuracy: 0.9532245222929936 

The current subspace-distance is: 1.0859973372134846e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.12; acc: 0.97
Batch: 40; loss: 0.27; acc: 0.94
Batch: 60; loss: 0.15; acc: 0.95
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.13; acc: 0.95
Batch: 140; loss: 0.12; acc: 0.97
Batch: 160; loss: 0.06; acc: 0.98
Batch: 180; loss: 0.21; acc: 0.95
Batch: 200; loss: 0.08; acc: 0.97
Batch: 220; loss: 0.29; acc: 0.91
Batch: 240; loss: 0.43; acc: 0.89
Batch: 260; loss: 0.07; acc: 0.98
Batch: 280; loss: 0.22; acc: 0.97
Batch: 300; loss: 0.24; acc: 0.92
Batch: 320; loss: 0.24; acc: 0.95
Batch: 340; loss: 0.24; acc: 0.95
Batch: 360; loss: 0.07; acc: 1.0
Batch: 380; loss: 0.08; acc: 0.95
Batch: 400; loss: 0.1; acc: 0.97
Batch: 420; loss: 0.35; acc: 0.89
Batch: 440; loss: 0.03; acc: 1.0
Batch: 460; loss: 0.11; acc: 0.95
Batch: 480; loss: 0.28; acc: 0.92
Batch: 500; loss: 0.15; acc: 0.97
Batch: 520; loss: 0.15; acc: 0.95
Batch: 540; loss: 0.13; acc: 0.97
Batch: 560; loss: 0.43; acc: 0.84
Batch: 580; loss: 0.19; acc: 0.94
Batch: 600; loss: 0.29; acc: 0.91
Batch: 620; loss: 0.35; acc: 0.91
Batch: 640; loss: 0.13; acc: 0.95
Batch: 660; loss: 0.24; acc: 0.92
Batch: 680; loss: 0.21; acc: 0.92
Batch: 700; loss: 0.04; acc: 1.0
Batch: 720; loss: 0.28; acc: 0.91
Batch: 740; loss: 0.2; acc: 0.97
Batch: 760; loss: 0.14; acc: 0.94
Batch: 780; loss: 0.18; acc: 0.97
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

2.590717122075148e-05
1.1505013389978558e-05
Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.19; acc: 0.97
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.3; acc: 0.89
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.26918288085396125; val_accuracy: 0.9144108280254777 

The current subspace-distance is: 1.1505013389978558e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.2; acc: 0.95
Batch: 40; loss: 0.26; acc: 0.88
Batch: 60; loss: 0.14; acc: 0.91
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.03; acc: 1.0
Batch: 120; loss: 0.07; acc: 0.98
Batch: 140; loss: 0.31; acc: 0.89
Batch: 160; loss: 0.04; acc: 1.0
Batch: 180; loss: 0.05; acc: 0.98
Batch: 200; loss: 0.06; acc: 0.98
Batch: 220; loss: 0.17; acc: 0.95
Batch: 240; loss: 0.18; acc: 0.97
Batch: 260; loss: 0.17; acc: 0.92
Batch: 280; loss: 0.14; acc: 0.94
Batch: 300; loss: 0.06; acc: 0.98
Batch: 320; loss: 0.11; acc: 0.95
Batch: 340; loss: 0.06; acc: 0.97
Batch: 360; loss: 0.13; acc: 0.97
Batch: 380; loss: 0.04; acc: 1.0
Batch: 400; loss: 0.27; acc: 0.95
Batch: 420; loss: 0.17; acc: 0.94
Batch: 440; loss: 0.11; acc: 0.98
Batch: 460; loss: 0.19; acc: 0.95
Batch: 480; loss: 0.16; acc: 0.95
Batch: 500; loss: 0.16; acc: 0.94
Batch: 520; loss: 0.07; acc: 0.98
Batch: 540; loss: 0.1; acc: 0.98
Batch: 560; loss: 0.22; acc: 0.95
Batch: 580; loss: 0.16; acc: 0.94
Batch: 600; loss: 0.26; acc: 0.92
Batch: 620; loss: 0.15; acc: 0.95
Batch: 640; loss: 0.18; acc: 0.92
Batch: 660; loss: 0.51; acc: 0.89
Batch: 680; loss: 0.18; acc: 0.95
Batch: 700; loss: 0.15; acc: 0.92
Batch: 720; loss: 0.09; acc: 0.95
Batch: 740; loss: 0.14; acc: 0.97
Batch: 760; loss: 0.19; acc: 0.97
Batch: 780; loss: 0.14; acc: 0.97
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

2.707746170926839e-05
1.2460460311558563e-05
Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.25; acc: 0.92
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.1; acc: 0.98
Batch: 120; loss: 0.22; acc: 0.92
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.13367796119800798; val_accuracy: 0.9599920382165605 

The current subspace-distance is: 1.2460460311558563e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.17; acc: 0.92
Batch: 20; loss: 0.13; acc: 0.97
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.14; acc: 0.95
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.09; acc: 0.95
Batch: 140; loss: 0.22; acc: 0.92
Batch: 160; loss: 0.11; acc: 0.94
Batch: 180; loss: 0.04; acc: 1.0
Batch: 200; loss: 0.13; acc: 0.95
Batch: 220; loss: 0.07; acc: 0.97
Batch: 240; loss: 0.19; acc: 0.97
Batch: 260; loss: 0.22; acc: 0.94
Batch: 280; loss: 0.08; acc: 0.97
Batch: 300; loss: 0.2; acc: 0.91
Batch: 320; loss: 0.16; acc: 0.95
Batch: 340; loss: 0.05; acc: 0.98
Batch: 360; loss: 0.19; acc: 0.95
Batch: 380; loss: 0.25; acc: 0.91
Batch: 400; loss: 0.08; acc: 0.97
Batch: 420; loss: 0.11; acc: 0.97
Batch: 440; loss: 0.17; acc: 0.94
Batch: 460; loss: 0.11; acc: 0.94
Batch: 480; loss: 0.15; acc: 0.97
Batch: 500; loss: 0.08; acc: 0.98
Batch: 520; loss: 0.15; acc: 0.94
Batch: 540; loss: 0.08; acc: 0.97
Batch: 560; loss: 0.08; acc: 0.98
Batch: 580; loss: 0.13; acc: 0.97
Batch: 600; loss: 0.13; acc: 0.94
Batch: 620; loss: 0.05; acc: 1.0
Batch: 640; loss: 0.16; acc: 0.95
Batch: 660; loss: 0.18; acc: 0.94
Batch: 680; loss: 0.07; acc: 0.97
Batch: 700; loss: 0.16; acc: 0.92
Batch: 720; loss: 0.37; acc: 0.88
Batch: 740; loss: 0.15; acc: 0.94
Batch: 760; loss: 0.27; acc: 0.92
Batch: 780; loss: 0.16; acc: 0.97
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.7763782782130875e-05
1.2322138900344726e-05
Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.17; acc: 0.92
Batch: 40; loss: 0.18; acc: 0.97
Batch: 60; loss: 0.4; acc: 0.91
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.22; acc: 0.97
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.26479008466384973; val_accuracy: 0.9156050955414012 

The current subspace-distance is: 1.2322138900344726e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.5; acc: 0.84
Batch: 20; loss: 0.03; acc: 1.0
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.17; acc: 0.94
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.07; acc: 0.97
Batch: 140; loss: 0.2; acc: 0.95
Batch: 160; loss: 0.26; acc: 0.94
Batch: 180; loss: 0.17; acc: 0.97
Batch: 200; loss: 0.35; acc: 0.91
Batch: 220; loss: 0.04; acc: 1.0
Batch: 240; loss: 0.14; acc: 0.92
Batch: 260; loss: 0.08; acc: 0.97
Batch: 280; loss: 0.07; acc: 0.97
Batch: 300; loss: 0.13; acc: 0.95
Batch: 320; loss: 0.14; acc: 0.95
Batch: 340; loss: 0.06; acc: 0.98
Batch: 360; loss: 0.29; acc: 0.92
Batch: 380; loss: 0.11; acc: 0.98
Batch: 400; loss: 0.17; acc: 0.92
Batch: 420; loss: 0.19; acc: 0.92
Batch: 440; loss: 0.15; acc: 0.94
Batch: 460; loss: 0.05; acc: 0.98
Batch: 480; loss: 0.07; acc: 0.98
Batch: 500; loss: 0.1; acc: 0.95
Batch: 520; loss: 0.12; acc: 0.95
Batch: 540; loss: 0.08; acc: 0.97
Batch: 560; loss: 0.03; acc: 1.0
Batch: 580; loss: 0.12; acc: 0.98
Batch: 600; loss: 0.03; acc: 1.0
Batch: 620; loss: 0.1; acc: 0.95
Batch: 640; loss: 0.25; acc: 0.91
Batch: 660; loss: 0.24; acc: 0.94
Batch: 680; loss: 0.06; acc: 0.98
Batch: 700; loss: 0.12; acc: 0.95
Batch: 720; loss: 0.21; acc: 0.94
Batch: 740; loss: 0.04; acc: 0.98
Batch: 760; loss: 0.14; acc: 0.98
Batch: 780; loss: 0.03; acc: 1.0
Train Epoch over. train_loss: 0.15; train_accuracy: 0.96 

2.840598244802095e-05
1.2762243386532646e-05
Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.1; acc: 0.95
Batch: 60; loss: 0.27; acc: 0.94
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.09; acc: 0.98
Batch: 120; loss: 0.22; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.1714157576607481; val_accuracy: 0.9491441082802548 

The current subspace-distance is: 1.2762243386532646e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.31; acc: 0.91
Batch: 20; loss: 0.06; acc: 0.97
Batch: 40; loss: 0.04; acc: 1.0
Batch: 60; loss: 0.07; acc: 0.98
Batch: 80; loss: 0.23; acc: 0.88
Batch: 100; loss: 0.07; acc: 0.98
Batch: 120; loss: 0.34; acc: 0.91
Batch: 140; loss: 0.13; acc: 0.97
Batch: 160; loss: 0.16; acc: 0.97
Batch: 180; loss: 0.06; acc: 0.98
Batch: 200; loss: 0.06; acc: 0.98
Batch: 220; loss: 0.12; acc: 0.94
Batch: 240; loss: 0.1; acc: 0.97
Batch: 260; loss: 0.07; acc: 0.98
Batch: 280; loss: 0.23; acc: 0.95
Batch: 300; loss: 0.49; acc: 0.91
Batch: 320; loss: 0.22; acc: 0.92
Batch: 340; loss: 0.3; acc: 0.95
Batch: 360; loss: 0.05; acc: 0.97
Batch: 380; loss: 0.01; acc: 1.0
Batch: 400; loss: 0.12; acc: 0.94
Batch: 420; loss: 0.08; acc: 0.98
Batch: 440; loss: 0.13; acc: 0.97
Batch: 460; loss: 0.07; acc: 0.98
Batch: 480; loss: 0.04; acc: 0.98
Batch: 500; loss: 0.07; acc: 0.98
Batch: 520; loss: 0.26; acc: 0.92
Batch: 540; loss: 0.19; acc: 0.94
Batch: 560; loss: 0.05; acc: 0.97
Batch: 580; loss: 0.09; acc: 0.97
Batch: 600; loss: 0.16; acc: 0.97
Batch: 620; loss: 0.16; acc: 0.94
Batch: 640; loss: 0.06; acc: 0.97
Batch: 660; loss: 0.12; acc: 0.98
Batch: 680; loss: 0.05; acc: 1.0
Batch: 700; loss: 0.06; acc: 0.97
Batch: 720; loss: 0.11; acc: 0.95
Batch: 740; loss: 0.2; acc: 0.91
Batch: 760; loss: 0.1; acc: 0.94
Batch: 780; loss: 0.1; acc: 0.95
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

2.8329308406682685e-05
1.326656092714984e-05
Batch: 0; loss: 0.14; acc: 0.94
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.35; acc: 0.92
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.18; acc: 0.92
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.12810182994955285; val_accuracy: 0.9617834394904459 

The current subspace-distance is: 1.326656092714984e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.18; acc: 0.92
Batch: 20; loss: 0.05; acc: 0.97
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.21; acc: 0.94
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.22; acc: 0.92
Batch: 140; loss: 0.12; acc: 0.95
Batch: 160; loss: 0.11; acc: 0.97
Batch: 180; loss: 0.18; acc: 0.94
Batch: 200; loss: 0.06; acc: 0.98
Batch: 220; loss: 0.14; acc: 0.95
Batch: 240; loss: 0.09; acc: 0.97
Batch: 260; loss: 0.13; acc: 0.95
Batch: 280; loss: 0.22; acc: 0.95
Batch: 300; loss: 0.08; acc: 0.98
Batch: 320; loss: 0.21; acc: 0.95
Batch: 340; loss: 0.3; acc: 0.94
Batch: 360; loss: 0.09; acc: 0.97
Batch: 380; loss: 0.02; acc: 1.0
Batch: 400; loss: 0.12; acc: 0.95
Batch: 420; loss: 0.15; acc: 0.95
Batch: 440; loss: 0.1; acc: 0.97
Batch: 460; loss: 0.11; acc: 0.97
Batch: 480; loss: 0.33; acc: 0.91
Batch: 500; loss: 0.16; acc: 0.95
Batch: 520; loss: 0.28; acc: 0.92
Batch: 540; loss: 0.38; acc: 0.94
Batch: 560; loss: 0.09; acc: 0.97
Batch: 580; loss: 0.18; acc: 0.94
Batch: 600; loss: 0.14; acc: 0.94
Batch: 620; loss: 0.04; acc: 0.98
Batch: 640; loss: 0.09; acc: 0.95
Batch: 660; loss: 0.1; acc: 0.97
Batch: 680; loss: 0.25; acc: 0.92
Batch: 700; loss: 0.23; acc: 0.92
Batch: 720; loss: 0.1; acc: 0.97
Batch: 740; loss: 0.09; acc: 0.97
Batch: 760; loss: 0.09; acc: 0.97
Batch: 780; loss: 0.18; acc: 0.94
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

2.944307925645262e-05
1.3268398106447421e-05
Batch: 0; loss: 0.06; acc: 0.98
Batch: 20; loss: 0.12; acc: 0.97
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.3; acc: 0.92
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.1; acc: 0.98
Batch: 120; loss: 0.23; acc: 0.92
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.12117841132697027; val_accuracy: 0.9640724522292994 

The current subspace-distance is: 1.3268398106447421e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.08; acc: 0.97
Batch: 20; loss: 0.09; acc: 0.94
Batch: 40; loss: 0.18; acc: 0.91
Batch: 60; loss: 0.12; acc: 0.95
Batch: 80; loss: 0.14; acc: 0.94
Batch: 100; loss: 0.14; acc: 0.94
Batch: 120; loss: 0.13; acc: 0.97
Batch: 140; loss: 0.09; acc: 0.97
Batch: 160; loss: 0.19; acc: 0.95
Batch: 180; loss: 0.11; acc: 0.94
Batch: 200; loss: 0.11; acc: 0.97
Batch: 220; loss: 0.23; acc: 0.92
Batch: 240; loss: 0.15; acc: 0.94
Batch: 260; loss: 0.16; acc: 0.97
Batch: 280; loss: 0.12; acc: 0.97
Batch: 300; loss: 0.03; acc: 1.0
Batch: 320; loss: 0.29; acc: 0.92
Batch: 340; loss: 0.05; acc: 0.97
Batch: 360; loss: 0.16; acc: 0.95
Batch: 380; loss: 0.09; acc: 0.97
Batch: 400; loss: 0.18; acc: 0.91
Batch: 420; loss: 0.07; acc: 0.98
Batch: 440; loss: 0.16; acc: 0.95
Batch: 460; loss: 0.12; acc: 0.97
Batch: 480; loss: 0.19; acc: 0.92
Batch: 500; loss: 0.06; acc: 0.97
Batch: 520; loss: 0.29; acc: 0.92
Batch: 540; loss: 0.18; acc: 0.97
Batch: 560; loss: 0.2; acc: 0.97
Batch: 580; loss: 0.18; acc: 0.92
Batch: 600; loss: 0.02; acc: 1.0
Batch: 620; loss: 0.23; acc: 0.94
Batch: 640; loss: 0.11; acc: 0.97
Batch: 660; loss: 0.1; acc: 0.97
Batch: 680; loss: 0.02; acc: 1.0
Batch: 700; loss: 0.21; acc: 0.94
Batch: 720; loss: 0.16; acc: 0.94
Batch: 740; loss: 0.22; acc: 0.95
Batch: 760; loss: 0.1; acc: 0.98
Batch: 780; loss: 0.12; acc: 0.95
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

2.9248565624584444e-05
1.2388103641569614e-05
Batch: 0; loss: 0.08; acc: 0.97
Batch: 20; loss: 0.17; acc: 0.92
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.36; acc: 0.92
Batch: 80; loss: 0.05; acc: 0.97
Batch: 100; loss: 0.11; acc: 0.97
Batch: 120; loss: 0.18; acc: 0.92
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.12376369455247928; val_accuracy: 0.9612858280254777 

The current subspace-distance is: 1.2388103641569614e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.1; acc: 0.94
Batch: 20; loss: 0.17; acc: 0.94
Batch: 40; loss: 0.24; acc: 0.95
Batch: 60; loss: 0.09; acc: 0.95
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.03; acc: 1.0
Batch: 120; loss: 0.04; acc: 1.0
Batch: 140; loss: 0.13; acc: 0.97
Batch: 160; loss: 0.03; acc: 1.0
Batch: 180; loss: 0.1; acc: 0.95
Batch: 200; loss: 0.09; acc: 0.95
Batch: 220; loss: 0.07; acc: 0.97
Batch: 240; loss: 0.07; acc: 0.97
Batch: 260; loss: 0.08; acc: 0.98
Batch: 280; loss: 0.13; acc: 0.95
Batch: 300; loss: 0.08; acc: 0.98
Batch: 320; loss: 0.24; acc: 0.94
Batch: 340; loss: 0.15; acc: 0.97
Batch: 360; loss: 0.16; acc: 0.92
Batch: 380; loss: 0.25; acc: 0.94
Batch: 400; loss: 0.19; acc: 0.92
Batch: 420; loss: 0.06; acc: 0.97
Batch: 440; loss: 0.05; acc: 0.98
Batch: 460; loss: 0.09; acc: 0.97
Batch: 480; loss: 0.07; acc: 0.97
Batch: 500; loss: 0.07; acc: 0.98
Batch: 520; loss: 0.1; acc: 0.97
Batch: 540; loss: 0.09; acc: 0.95
Batch: 560; loss: 0.09; acc: 0.97
Batch: 580; loss: 0.07; acc: 0.98
Batch: 600; loss: 0.09; acc: 0.97
Batch: 620; loss: 0.07; acc: 0.97
Batch: 640; loss: 0.07; acc: 0.97
Batch: 660; loss: 0.16; acc: 0.95
Batch: 680; loss: 0.35; acc: 0.91
Batch: 700; loss: 0.04; acc: 0.98
Batch: 720; loss: 0.03; acc: 1.0
Batch: 740; loss: 0.07; acc: 0.97
Batch: 760; loss: 0.11; acc: 0.97
Batch: 780; loss: 0.15; acc: 0.95
Train Epoch over. train_loss: 0.11; train_accuracy: 0.97 

2.987078005389776e-05
1.323523792962078e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.1; acc: 0.97
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.08; acc: 0.97
Batch: 120; loss: 0.25; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.09976589310154983; val_accuracy: 0.9710390127388535 

The current subspace-distance is: 1.323523792962078e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.12; acc: 0.95
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.16; acc: 0.98
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.04; acc: 0.98
Batch: 120; loss: 0.03; acc: 1.0
Batch: 140; loss: 0.17; acc: 0.94
Batch: 160; loss: 0.18; acc: 0.97
Batch: 180; loss: 0.05; acc: 0.98
Batch: 200; loss: 0.13; acc: 0.95
Batch: 220; loss: 0.22; acc: 0.95
Batch: 240; loss: 0.09; acc: 0.97
Batch: 260; loss: 0.04; acc: 0.98
Batch: 280; loss: 0.01; acc: 1.0
Batch: 300; loss: 0.04; acc: 0.98
Batch: 320; loss: 0.02; acc: 1.0
Batch: 340; loss: 0.22; acc: 0.95
Batch: 360; loss: 0.11; acc: 0.97
Batch: 380; loss: 0.16; acc: 0.97
Batch: 400; loss: 0.1; acc: 0.95
Batch: 420; loss: 0.08; acc: 0.98
Batch: 440; loss: 0.15; acc: 0.92
Batch: 460; loss: 0.07; acc: 0.98
Batch: 480; loss: 0.14; acc: 0.98
Batch: 500; loss: 0.16; acc: 0.94
Batch: 520; loss: 0.14; acc: 0.97
Batch: 540; loss: 0.08; acc: 0.98
Batch: 560; loss: 0.08; acc: 0.97
Batch: 580; loss: 0.05; acc: 0.98
Batch: 600; loss: 0.04; acc: 0.98
Batch: 620; loss: 0.13; acc: 0.97
Batch: 640; loss: 0.07; acc: 0.95
Batch: 660; loss: 0.1; acc: 0.95
Batch: 680; loss: 0.04; acc: 0.98
Batch: 700; loss: 0.04; acc: 0.98
Batch: 720; loss: 0.13; acc: 0.95
Batch: 740; loss: 0.17; acc: 0.97
Batch: 760; loss: 0.08; acc: 0.97
Batch: 780; loss: 0.04; acc: 0.98
Train Epoch over. train_loss: 0.1; train_accuracy: 0.97 

2.909999057010282e-05
1.2674345271079801e-05
Batch: 0; loss: 0.06; acc: 0.98
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.09; acc: 0.95
Batch: 60; loss: 0.32; acc: 0.92
Batch: 80; loss: 0.11; acc: 0.98
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.31; acc: 0.91
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.13129320396644295; val_accuracy: 0.9599920382165605 

The current subspace-distance is: 1.2674345271079801e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.05; acc: 0.98
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.1; acc: 0.94
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.04; acc: 0.98
Batch: 120; loss: 0.23; acc: 0.95
Batch: 140; loss: 0.1; acc: 0.97
Batch: 160; loss: 0.12; acc: 0.98
Batch: 180; loss: 0.09; acc: 0.95
Batch: 200; loss: 0.1; acc: 0.97
Batch: 220; loss: 0.05; acc: 0.98
Batch: 240; loss: 0.14; acc: 0.95
Batch: 260; loss: 0.03; acc: 0.98
Batch: 280; loss: 0.08; acc: 0.97
Batch: 300; loss: 0.17; acc: 0.97
Batch: 320; loss: 0.07; acc: 0.97
Batch: 340; loss: 0.07; acc: 0.98
Batch: 360; loss: 0.17; acc: 0.95
Batch: 380; loss: 0.08; acc: 0.97
Batch: 400; loss: 0.06; acc: 1.0
Batch: 420; loss: 0.03; acc: 1.0
Batch: 440; loss: 0.17; acc: 0.97
Batch: 460; loss: 0.07; acc: 0.97
Batch: 480; loss: 0.07; acc: 0.98
Batch: 500; loss: 0.07; acc: 0.98
Batch: 520; loss: 0.1; acc: 0.97
Batch: 540; loss: 0.21; acc: 0.92
Batch: 560; loss: 0.03; acc: 0.98
Batch: 580; loss: 0.08; acc: 0.97
Batch: 600; loss: 0.12; acc: 0.97
Batch: 620; loss: 0.27; acc: 0.95
Batch: 640; loss: 0.03; acc: 1.0
Batch: 660; loss: 0.15; acc: 0.95
Batch: 680; loss: 0.07; acc: 0.97
Batch: 700; loss: 0.18; acc: 0.95
Batch: 720; loss: 0.06; acc: 0.97
Batch: 740; loss: 0.07; acc: 0.97
Batch: 760; loss: 0.2; acc: 0.94
Batch: 780; loss: 0.22; acc: 0.94
Train Epoch over. train_loss: 0.1; train_accuracy: 0.97 

3.0138866350171156e-05
1.3781817870039959e-05
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.09; acc: 0.95
Batch: 40; loss: 0.05; acc: 0.97
Batch: 60; loss: 0.22; acc: 0.95
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.08; acc: 0.98
Batch: 120; loss: 0.2; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.09722650784311021; val_accuracy: 0.9709394904458599 

The current subspace-distance is: 1.3781817870039959e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.05; acc: 0.98
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.03; acc: 1.0
Batch: 80; loss: 0.04; acc: 1.0
Batch: 100; loss: 0.11; acc: 0.95
Batch: 120; loss: 0.12; acc: 0.95
Batch: 140; loss: 0.1; acc: 0.95
Batch: 160; loss: 0.18; acc: 0.95
Batch: 180; loss: 0.07; acc: 0.98
Batch: 200; loss: 0.1; acc: 0.97
Batch: 220; loss: 0.1; acc: 0.95
Batch: 240; loss: 0.05; acc: 0.97
Batch: 260; loss: 0.13; acc: 0.95
Batch: 280; loss: 0.02; acc: 1.0
Batch: 300; loss: 0.15; acc: 0.97
Batch: 320; loss: 0.03; acc: 0.98
Batch: 340; loss: 0.16; acc: 0.97
Batch: 360; loss: 0.18; acc: 0.92
Batch: 380; loss: 0.04; acc: 0.97
Batch: 400; loss: 0.19; acc: 0.95
Batch: 420; loss: 0.11; acc: 0.95
Batch: 440; loss: 0.11; acc: 0.94
Batch: 460; loss: 0.08; acc: 0.95
Batch: 480; loss: 0.12; acc: 0.92
Batch: 500; loss: 0.09; acc: 0.95
Batch: 520; loss: 0.05; acc: 1.0
Batch: 540; loss: 0.07; acc: 0.97
Batch: 560; loss: 0.2; acc: 0.94
Batch: 580; loss: 0.06; acc: 0.98
Batch: 600; loss: 0.12; acc: 0.95
Batch: 620; loss: 0.14; acc: 0.95
Batch: 640; loss: 0.07; acc: 0.98
Batch: 660; loss: 0.17; acc: 0.95
Batch: 680; loss: 0.18; acc: 0.92
Batch: 700; loss: 0.04; acc: 0.98
Batch: 720; loss: 0.05; acc: 0.98
Batch: 740; loss: 0.04; acc: 0.97
Batch: 760; loss: 0.03; acc: 1.0
Batch: 780; loss: 0.07; acc: 0.98
Train Epoch over. train_loss: 0.1; train_accuracy: 0.97 

2.9579448892036453e-05
1.3119613868184388e-05
Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.16; acc: 0.94
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.09349966658409803; val_accuracy: 0.972531847133758 

The current subspace-distance is: 1.3119613868184388e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.05; acc: 0.97
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.06; acc: 0.98
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.05; acc: 0.98
Batch: 140; loss: 0.09; acc: 0.98
Batch: 160; loss: 0.1; acc: 0.98
Batch: 180; loss: 0.17; acc: 0.95
Batch: 200; loss: 0.12; acc: 0.94
Batch: 220; loss: 0.08; acc: 0.97
Batch: 240; loss: 0.11; acc: 0.97
Batch: 260; loss: 0.05; acc: 0.98
Batch: 280; loss: 0.03; acc: 0.98
Batch: 300; loss: 0.07; acc: 0.97
Batch: 320; loss: 0.18; acc: 0.95
Batch: 340; loss: 0.06; acc: 0.97
Batch: 360; loss: 0.13; acc: 0.97
Batch: 380; loss: 0.1; acc: 0.95
Batch: 400; loss: 0.12; acc: 0.95
Batch: 420; loss: 0.11; acc: 0.94
Batch: 440; loss: 0.06; acc: 0.98
Batch: 460; loss: 0.07; acc: 0.97
Batch: 480; loss: 0.02; acc: 1.0
Batch: 500; loss: 0.18; acc: 0.94
Batch: 520; loss: 0.1; acc: 0.97
Batch: 540; loss: 0.02; acc: 1.0
Batch: 560; loss: 0.12; acc: 0.92
Batch: 580; loss: 0.11; acc: 0.98
Batch: 600; loss: 0.07; acc: 0.98
Batch: 620; loss: 0.06; acc: 0.97
Batch: 640; loss: 0.19; acc: 0.95
Batch: 660; loss: 0.15; acc: 0.92
Batch: 680; loss: 0.02; acc: 1.0
Batch: 700; loss: 0.04; acc: 1.0
Batch: 720; loss: 0.13; acc: 0.94
Batch: 740; loss: 0.06; acc: 0.97
Batch: 760; loss: 0.23; acc: 0.91
Batch: 780; loss: 0.05; acc: 0.98
Train Epoch over. train_loss: 0.1; train_accuracy: 0.97 

3.0333749236888252e-05
1.3125477380526718e-05
Batch: 0; loss: 0.07; acc: 0.97
Batch: 20; loss: 0.1; acc: 0.97
Batch: 40; loss: 0.09; acc: 0.95
Batch: 60; loss: 0.31; acc: 0.94
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.15; acc: 0.94
Batch: 120; loss: 0.16; acc: 0.94
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.11120181767400472; val_accuracy: 0.9669585987261147 

The current subspace-distance is: 1.3125477380526718e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.23; acc: 0.91
Batch: 20; loss: 0.17; acc: 0.95
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.02; acc: 1.0
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.06; acc: 0.97
Batch: 120; loss: 0.13; acc: 0.97
Batch: 140; loss: 0.06; acc: 0.97
Batch: 160; loss: 0.12; acc: 0.94
Batch: 180; loss: 0.15; acc: 0.97
Batch: 200; loss: 0.05; acc: 0.95
Batch: 220; loss: 0.07; acc: 0.95
Batch: 240; loss: 0.05; acc: 0.97
Batch: 260; loss: 0.04; acc: 0.98
Batch: 280; loss: 0.31; acc: 0.92
Batch: 300; loss: 0.1; acc: 0.95
Batch: 320; loss: 0.25; acc: 0.94
Batch: 340; loss: 0.24; acc: 0.94
Batch: 360; loss: 0.06; acc: 0.98
Batch: 380; loss: 0.28; acc: 0.94
Batch: 400; loss: 0.08; acc: 0.95
Batch: 420; loss: 0.1; acc: 0.97
Batch: 440; loss: 0.09; acc: 0.95
Batch: 460; loss: 0.06; acc: 0.97
Batch: 480; loss: 0.1; acc: 0.95
Batch: 500; loss: 0.1; acc: 0.95
Batch: 520; loss: 0.02; acc: 1.0
Batch: 540; loss: 0.05; acc: 0.97
Batch: 560; loss: 0.07; acc: 0.97
Batch: 580; loss: 0.06; acc: 0.97
Batch: 600; loss: 0.21; acc: 0.94
Batch: 620; loss: 0.06; acc: 0.98
Batch: 640; loss: 0.07; acc: 0.97
Batch: 660; loss: 0.04; acc: 1.0
Batch: 680; loss: 0.03; acc: 0.98
Batch: 700; loss: 0.08; acc: 0.98
Batch: 720; loss: 0.04; acc: 1.0
Batch: 740; loss: 0.04; acc: 1.0
Batch: 760; loss: 0.15; acc: 0.92
Batch: 780; loss: 0.11; acc: 0.95
Train Epoch over. train_loss: 0.1; train_accuracy: 0.97 

2.9734446798102e-05
1.3388974366534967e-05
Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.11; acc: 0.95
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.25; acc: 0.97
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.21; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.11062110192883925; val_accuracy: 0.9680533439490446 

The current subspace-distance is: 1.3388974366534967e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.16; acc: 0.98
Batch: 60; loss: 0.06; acc: 0.98
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.11; acc: 0.94
Batch: 140; loss: 0.03; acc: 1.0
Batch: 160; loss: 0.45; acc: 0.89
Batch: 180; loss: 0.14; acc: 0.95
Batch: 200; loss: 0.07; acc: 0.95
Batch: 220; loss: 0.09; acc: 0.98
Batch: 240; loss: 0.1; acc: 0.95
Batch: 260; loss: 0.07; acc: 0.97
Batch: 280; loss: 0.03; acc: 0.98
Batch: 300; loss: 0.16; acc: 0.94
Batch: 320; loss: 0.05; acc: 0.98
Batch: 340; loss: 0.05; acc: 0.98
Batch: 360; loss: 0.04; acc: 0.98
Batch: 380; loss: 0.25; acc: 0.92
Batch: 400; loss: 0.12; acc: 0.94
Batch: 420; loss: 0.13; acc: 0.92
Batch: 440; loss: 0.12; acc: 0.98
Batch: 460; loss: 0.06; acc: 0.98
Batch: 480; loss: 0.06; acc: 0.98
Batch: 500; loss: 0.04; acc: 0.98
Batch: 520; loss: 0.06; acc: 0.97
Batch: 540; loss: 0.07; acc: 0.98
Batch: 560; loss: 0.07; acc: 0.97
Batch: 580; loss: 0.13; acc: 0.97
Batch: 600; loss: 0.04; acc: 1.0
Batch: 620; loss: 0.1; acc: 0.95
Batch: 640; loss: 0.07; acc: 0.98
Batch: 660; loss: 0.06; acc: 0.97
Batch: 680; loss: 0.05; acc: 0.98
Batch: 700; loss: 0.01; acc: 1.0
Batch: 720; loss: 0.03; acc: 1.0
Batch: 740; loss: 0.15; acc: 0.92
Batch: 760; loss: 0.08; acc: 0.97
Batch: 780; loss: 0.08; acc: 0.97
Train Epoch over. train_loss: 0.1; train_accuracy: 0.97 

2.979079363285564e-05
1.2755732313962653e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.08; acc: 0.97
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.22; acc: 0.92
Batch: 80; loss: 0.1; acc: 0.98
Batch: 100; loss: 0.08; acc: 0.98
Batch: 120; loss: 0.15; acc: 0.95
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.09286526267885402; val_accuracy: 0.9729299363057324 

The current subspace-distance is: 1.2755732313962653e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.17; acc: 0.98
Batch: 20; loss: 0.02; acc: 1.0
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.13; acc: 0.95
Batch: 80; loss: 0.0; acc: 1.0
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.03; acc: 1.0
Batch: 140; loss: 0.11; acc: 0.97
Batch: 160; loss: 0.18; acc: 0.97
Batch: 180; loss: 0.15; acc: 0.92
Batch: 200; loss: 0.16; acc: 0.97
Batch: 220; loss: 0.02; acc: 1.0
Batch: 240; loss: 0.04; acc: 1.0
Batch: 260; loss: 0.15; acc: 0.92
Batch: 280; loss: 0.11; acc: 0.95
Batch: 300; loss: 0.15; acc: 0.95
Batch: 320; loss: 0.19; acc: 0.94
Batch: 340; loss: 0.05; acc: 0.98
Batch: 360; loss: 0.02; acc: 1.0
Batch: 380; loss: 0.02; acc: 0.98
Batch: 400; loss: 0.1; acc: 0.97
Batch: 420; loss: 0.06; acc: 0.98
Batch: 440; loss: 0.1; acc: 0.97
Batch: 460; loss: 0.07; acc: 0.95
Batch: 480; loss: 0.03; acc: 1.0
Batch: 500; loss: 0.07; acc: 0.97
Batch: 520; loss: 0.11; acc: 0.95
Batch: 540; loss: 0.06; acc: 0.98
Batch: 560; loss: 0.1; acc: 0.98
Batch: 580; loss: 0.15; acc: 0.97
Batch: 600; loss: 0.11; acc: 0.97
Batch: 620; loss: 0.03; acc: 1.0
Batch: 640; loss: 0.02; acc: 1.0
Batch: 660; loss: 0.03; acc: 0.98
Batch: 680; loss: 0.03; acc: 1.0
Batch: 700; loss: 0.09; acc: 0.95
Batch: 720; loss: 0.1; acc: 0.94
Batch: 740; loss: 0.15; acc: 0.97
Batch: 760; loss: 0.02; acc: 1.0
Batch: 780; loss: 0.07; acc: 0.97
Train Epoch over. train_loss: 0.1; train_accuracy: 0.97 

3.0411272746277973e-05
1.3315225260157604e-05
Batch: 0; loss: 0.05; acc: 0.97
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.11; acc: 0.98
Batch: 120; loss: 0.11; acc: 0.95
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.09428670794175119; val_accuracy: 0.9729299363057324 

The current subspace-distance is: 1.3315225260157604e-05 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.09; acc: 0.98
Batch: 20; loss: 0.06; acc: 0.98
Batch: 40; loss: 0.05; acc: 0.97
Batch: 60; loss: 0.1; acc: 0.95
Batch: 80; loss: 0.23; acc: 0.95
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.06; acc: 0.98
Batch: 140; loss: 0.18; acc: 0.92
Batch: 160; loss: 0.04; acc: 0.98
Batch: 180; loss: 0.25; acc: 0.92
Batch: 200; loss: 0.18; acc: 0.92
Batch: 220; loss: 0.15; acc: 0.95
Batch: 240; loss: 0.12; acc: 0.97
Batch: 260; loss: 0.13; acc: 0.94
Batch: 280; loss: 0.11; acc: 0.98
Batch: 300; loss: 0.03; acc: 1.0
Batch: 320; loss: 0.12; acc: 0.97
Batch: 340; loss: 0.08; acc: 0.97
Batch: 360; loss: 0.16; acc: 0.97
Batch: 380; loss: 0.02; acc: 1.0
Batch: 400; loss: 0.08; acc: 0.95
Batch: 420; loss: 0.12; acc: 0.95
Batch: 440; loss: 0.05; acc: 0.97
Batch: 460; loss: 0.03; acc: 0.98
Batch: 480; loss: 0.2; acc: 0.94
Batch: 500; loss: 0.08; acc: 0.97
Batch: 520; loss: 0.2; acc: 0.92
Batch: 540; loss: 0.07; acc: 0.97
Batch: 560; loss: 0.01; acc: 1.0
Batch: 580; loss: 0.17; acc: 0.92
Batch: 600; loss: 0.05; acc: 0.97
Batch: 620; loss: 0.15; acc: 0.95
Batch: 640; loss: 0.06; acc: 0.98
Batch: 660; loss: 0.02; acc: 1.0
Batch: 680; loss: 0.11; acc: 0.95
Batch: 700; loss: 0.02; acc: 1.0
Batch: 720; loss: 0.16; acc: 0.97
Batch: 740; loss: 0.02; acc: 1.0
Batch: 760; loss: 0.03; acc: 1.0
Batch: 780; loss: 0.15; acc: 0.97
Train Epoch over. train_loss: 0.1; train_accuracy: 0.97 

3.0174658604664728e-05
1.3399023373494856e-05
Batch: 0; loss: 0.07; acc: 0.97
Batch: 20; loss: 0.15; acc: 0.97
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.24; acc: 0.97
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.1; acc: 0.98
Batch: 120; loss: 0.14; acc: 0.92
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.10092669642370218; val_accuracy: 0.9691480891719745 

The current subspace-distance is: 1.3399023373494856e-05 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.07; acc: 0.97
Batch: 20; loss: 0.06; acc: 0.98
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.02; acc: 1.0
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.05; acc: 0.97
Batch: 140; loss: 0.06; acc: 0.98
Batch: 160; loss: 0.13; acc: 0.95
Batch: 180; loss: 0.08; acc: 0.98
Batch: 200; loss: 0.1; acc: 0.98
Batch: 220; loss: 0.03; acc: 0.98
Batch: 240; loss: 0.03; acc: 0.98
Batch: 260; loss: 0.15; acc: 0.97
Batch: 280; loss: 0.07; acc: 0.95
Batch: 300; loss: 0.14; acc: 0.94
Batch: 320; loss: 0.13; acc: 0.94
Batch: 340; loss: 0.05; acc: 0.98
Batch: 360; loss: 0.18; acc: 0.97
Batch: 380; loss: 0.15; acc: 0.97
Batch: 400; loss: 0.09; acc: 0.98
Batch: 420; loss: 0.08; acc: 0.97
Batch: 440; loss: 0.1; acc: 0.97
Batch: 460; loss: 0.13; acc: 0.94
Batch: 480; loss: 0.03; acc: 0.98
Batch: 500; loss: 0.06; acc: 0.98
Batch: 520; loss: 0.06; acc: 0.98
Batch: 540; loss: 0.04; acc: 0.98
Batch: 560; loss: 0.28; acc: 0.92
Batch: 580; loss: 0.01; acc: 1.0
Batch: 600; loss: 0.07; acc: 0.97
Batch: 620; loss: 0.13; acc: 0.97
Batch: 640; loss: 0.09; acc: 0.97
Batch: 660; loss: 0.05; acc: 0.98
Batch: 680; loss: 0.08; acc: 0.97
Batch: 700; loss: 0.16; acc: 0.94
Batch: 720; loss: 0.04; acc: 0.98
Batch: 740; loss: 0.04; acc: 1.0
Batch: 760; loss: 0.23; acc: 0.92
Batch: 780; loss: 0.19; acc: 0.95
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

2.9696087949560024e-05
1.2680448890023399e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.24; acc: 0.92
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.16; acc: 0.94
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.09147095976836363; val_accuracy: 0.9709394904458599 

The current subspace-distance is: 1.2680448890023399e-05 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.02; acc: 1.0
Batch: 40; loss: 0.14; acc: 0.94
Batch: 60; loss: 0.23; acc: 0.95
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.02; acc: 1.0
Batch: 140; loss: 0.13; acc: 0.97
Batch: 160; loss: 0.1; acc: 0.98
Batch: 180; loss: 0.04; acc: 0.98
Batch: 200; loss: 0.02; acc: 1.0
Batch: 220; loss: 0.09; acc: 0.97
Batch: 240; loss: 0.05; acc: 0.98
Batch: 260; loss: 0.09; acc: 0.95
Batch: 280; loss: 0.08; acc: 0.97
Batch: 300; loss: 0.01; acc: 1.0
Batch: 320; loss: 0.11; acc: 0.97
Batch: 340; loss: 0.04; acc: 0.98
Batch: 360; loss: 0.02; acc: 0.98
Batch: 380; loss: 0.12; acc: 0.94
Batch: 400; loss: 0.05; acc: 0.98
Batch: 420; loss: 0.08; acc: 0.97
Batch: 440; loss: 0.04; acc: 0.98
Batch: 460; loss: 0.04; acc: 0.98
Batch: 480; loss: 0.15; acc: 0.95
Batch: 500; loss: 0.1; acc: 0.98
Batch: 520; loss: 0.02; acc: 1.0
Batch: 540; loss: 0.05; acc: 0.98
Batch: 560; loss: 0.08; acc: 0.97
Batch: 580; loss: 0.02; acc: 1.0
Batch: 600; loss: 0.15; acc: 0.95
Batch: 620; loss: 0.14; acc: 0.94
Batch: 640; loss: 0.06; acc: 0.98
Batch: 660; loss: 0.04; acc: 1.0
Batch: 680; loss: 0.09; acc: 0.98
Batch: 700; loss: 0.08; acc: 0.95
Batch: 720; loss: 0.16; acc: 0.95
Batch: 740; loss: 0.05; acc: 0.98
Batch: 760; loss: 0.14; acc: 0.97
Batch: 780; loss: 0.12; acc: 0.97
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

3.0186876756488346e-05
1.3187433069106191e-05
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.14; acc: 0.94
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.09; acc: 0.98
Batch: 120; loss: 0.15; acc: 0.94
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.09471611538605326; val_accuracy: 0.9710390127388535 

The current subspace-distance is: 1.3187433069106191e-05 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.08; acc: 0.97
Batch: 20; loss: 0.04; acc: 0.98
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.02; acc: 1.0
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.1; acc: 0.98
Batch: 120; loss: 0.13; acc: 0.95
Batch: 140; loss: 0.03; acc: 0.97
Batch: 160; loss: 0.05; acc: 0.98
Batch: 180; loss: 0.06; acc: 0.98
Batch: 200; loss: 0.17; acc: 0.94
Batch: 220; loss: 0.01; acc: 1.0
Batch: 240; loss: 0.03; acc: 0.98
Batch: 260; loss: 0.03; acc: 0.98
Batch: 280; loss: 0.05; acc: 0.97
Batch: 300; loss: 0.08; acc: 0.97
Batch: 320; loss: 0.19; acc: 0.95
Batch: 340; loss: 0.04; acc: 0.98
Batch: 360; loss: 0.04; acc: 0.98
Batch: 380; loss: 0.06; acc: 0.97
Batch: 400; loss: 0.1; acc: 0.97
Batch: 420; loss: 0.09; acc: 0.98
Batch: 440; loss: 0.04; acc: 1.0
Batch: 460; loss: 0.06; acc: 0.98
Batch: 480; loss: 0.06; acc: 0.98
Batch: 500; loss: 0.07; acc: 0.95
Batch: 520; loss: 0.15; acc: 0.95
Batch: 540; loss: 0.05; acc: 1.0
Batch: 560; loss: 0.02; acc: 0.98
Batch: 580; loss: 0.13; acc: 0.97
Batch: 600; loss: 0.16; acc: 0.97
Batch: 620; loss: 0.07; acc: 0.98
Batch: 640; loss: 0.12; acc: 0.95
Batch: 660; loss: 0.06; acc: 0.97
Batch: 680; loss: 0.02; acc: 1.0
Batch: 700; loss: 0.01; acc: 1.0
Batch: 720; loss: 0.08; acc: 0.95
Batch: 740; loss: 0.04; acc: 0.98
Batch: 760; loss: 0.07; acc: 0.97
Batch: 780; loss: 0.03; acc: 0.98
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

3.0219400287023745e-05
1.376231466565514e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.09; acc: 0.98
Batch: 120; loss: 0.16; acc: 0.92
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.0894378967891643; val_accuracy: 0.9737261146496815 

The current subspace-distance is: 1.376231466565514e-05 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.09; acc: 0.98
Batch: 20; loss: 0.17; acc: 0.94
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.06; acc: 0.97
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.11; acc: 0.97
Batch: 120; loss: 0.22; acc: 0.92
Batch: 140; loss: 0.04; acc: 0.98
Batch: 160; loss: 0.06; acc: 0.98
Batch: 180; loss: 0.14; acc: 0.94
Batch: 200; loss: 0.11; acc: 0.95
Batch: 220; loss: 0.02; acc: 1.0
Batch: 240; loss: 0.05; acc: 1.0
Batch: 260; loss: 0.08; acc: 0.97
Batch: 280; loss: 0.05; acc: 1.0
Batch: 300; loss: 0.15; acc: 0.95
Batch: 320; loss: 0.1; acc: 0.97
Batch: 340; loss: 0.06; acc: 0.98
Batch: 360; loss: 0.07; acc: 0.94
Batch: 380; loss: 0.08; acc: 0.98
Batch: 400; loss: 0.06; acc: 0.98
Batch: 420; loss: 0.07; acc: 0.97
Batch: 440; loss: 0.3; acc: 0.92
Batch: 460; loss: 0.05; acc: 0.98
Batch: 480; loss: 0.12; acc: 0.97
Batch: 500; loss: 0.19; acc: 0.92
Batch: 520; loss: 0.09; acc: 0.95
Batch: 540; loss: 0.01; acc: 1.0
Batch: 560; loss: 0.1; acc: 0.95
Batch: 580; loss: 0.1; acc: 0.98
Batch: 600; loss: 0.08; acc: 0.97
Batch: 620; loss: 0.06; acc: 0.97
Batch: 640; loss: 0.1; acc: 0.97
Batch: 660; loss: 0.03; acc: 1.0
Batch: 680; loss: 0.01; acc: 1.0
Batch: 700; loss: 0.06; acc: 0.95
Batch: 720; loss: 0.09; acc: 0.95
Batch: 740; loss: 0.02; acc: 1.0
Batch: 760; loss: 0.05; acc: 0.98
Batch: 780; loss: 0.08; acc: 0.95
Train Epoch over. train_loss: 0.08; train_accuracy: 0.97 

2.9766943043796346e-05
1.4378428204508964e-05
Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.1; acc: 0.98
Batch: 120; loss: 0.13; acc: 0.95
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.09159813351502084; val_accuracy: 0.9722332802547771 

The current subspace-distance is: 1.4378428204508964e-05 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.09; acc: 0.95
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.23; acc: 0.91
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.04; acc: 1.0
Batch: 120; loss: 0.08; acc: 0.97
Batch: 140; loss: 0.11; acc: 0.95
Batch: 160; loss: 0.05; acc: 0.98
Batch: 180; loss: 0.11; acc: 0.97
Batch: 200; loss: 0.02; acc: 1.0
Batch: 220; loss: 0.25; acc: 0.92
Batch: 240; loss: 0.1; acc: 0.95
Batch: 260; loss: 0.19; acc: 0.92
Batch: 280; loss: 0.05; acc: 0.98
Batch: 300; loss: 0.02; acc: 1.0
Batch: 320; loss: 0.04; acc: 0.98
Batch: 340; loss: 0.13; acc: 0.97
Batch: 360; loss: 0.04; acc: 1.0
Batch: 380; loss: 0.1; acc: 0.94
Batch: 400; loss: 0.08; acc: 0.98
Batch: 420; loss: 0.19; acc: 0.95
Batch: 440; loss: 0.05; acc: 0.98
Batch: 460; loss: 0.07; acc: 0.97
Batch: 480; loss: 0.14; acc: 0.94
Batch: 500; loss: 0.08; acc: 0.95
Batch: 520; loss: 0.05; acc: 0.98
Batch: 540; loss: 0.15; acc: 0.98
Batch: 560; loss: 0.04; acc: 0.98
Batch: 580; loss: 0.09; acc: 0.95
Batch: 600; loss: 0.07; acc: 0.97
Batch: 620; loss: 0.05; acc: 0.98
Batch: 640; loss: 0.16; acc: 0.94
Batch: 660; loss: 0.11; acc: 0.97
Batch: 680; loss: 0.1; acc: 0.98
Batch: 700; loss: 0.08; acc: 0.97
Batch: 720; loss: 0.11; acc: 0.95
Batch: 740; loss: 0.09; acc: 0.98
Batch: 760; loss: 0.02; acc: 1.0
Batch: 780; loss: 0.1; acc: 0.95
Train Epoch over. train_loss: 0.08; train_accuracy: 0.97 

3.025820478796959e-05
1.2838119801017456e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.12; acc: 0.97
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.15; acc: 0.95
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.08865867055667813; val_accuracy: 0.9734275477707006 

The current subspace-distance is: 1.2838119801017456e-05 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.07; acc: 0.97
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.01; acc: 1.0
Batch: 80; loss: 0.05; acc: 1.0
Batch: 100; loss: 0.11; acc: 0.97
Batch: 120; loss: 0.07; acc: 0.98
Batch: 140; loss: 0.05; acc: 0.98
Batch: 160; loss: 0.07; acc: 0.97
Batch: 180; loss: 0.04; acc: 0.98
Batch: 200; loss: 0.04; acc: 0.98
Batch: 220; loss: 0.1; acc: 0.97
Batch: 240; loss: 0.14; acc: 0.97
Batch: 260; loss: 0.02; acc: 0.98
Batch: 280; loss: 0.05; acc: 0.98
Batch: 300; loss: 0.07; acc: 0.98
Batch: 320; loss: 0.17; acc: 0.94
Batch: 340; loss: 0.04; acc: 1.0
Batch: 360; loss: 0.01; acc: 1.0
Batch: 380; loss: 0.13; acc: 0.97
Batch: 400; loss: 0.08; acc: 0.98
Batch: 420; loss: 0.09; acc: 0.97
Batch: 440; loss: 0.04; acc: 1.0
Batch: 460; loss: 0.14; acc: 0.95
Batch: 480; loss: 0.11; acc: 0.97
Batch: 500; loss: 0.07; acc: 0.97
Batch: 520; loss: 0.04; acc: 0.98
Batch: 540; loss: 0.24; acc: 0.95
Batch: 560; loss: 0.01; acc: 1.0
Batch: 580; loss: 0.05; acc: 0.98
Batch: 600; loss: 0.02; acc: 1.0
Batch: 620; loss: 0.04; acc: 0.98
Batch: 640; loss: 0.07; acc: 0.97
Batch: 660; loss: 0.13; acc: 0.95
Batch: 680; loss: 0.11; acc: 0.97
Batch: 700; loss: 0.06; acc: 0.98
Batch: 720; loss: 0.07; acc: 0.95
Batch: 740; loss: 0.14; acc: 0.97
Batch: 760; loss: 0.27; acc: 0.97
Batch: 780; loss: 0.11; acc: 0.97
Train Epoch over. train_loss: 0.08; train_accuracy: 0.97 

3.003864549100399e-05
1.344004886050243e-05
Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.11; acc: 0.98
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.21; acc: 0.94
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.1; acc: 0.98
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.08689934524832069; val_accuracy: 0.9754179936305732 

The current subspace-distance is: 1.344004886050243e-05 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.11; acc: 0.95
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.14; acc: 0.95
Batch: 80; loss: 0.25; acc: 0.95
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.05; acc: 0.98
Batch: 140; loss: 0.12; acc: 0.95
Batch: 160; loss: 0.13; acc: 0.98
Batch: 180; loss: 0.06; acc: 0.97
Batch: 200; loss: 0.05; acc: 0.98
Batch: 220; loss: 0.21; acc: 0.95
Batch: 240; loss: 0.11; acc: 0.95
Batch: 260; loss: 0.03; acc: 0.98
Batch: 280; loss: 0.15; acc: 0.97
Batch: 300; loss: 0.14; acc: 0.97
Batch: 320; loss: 0.02; acc: 1.0
Batch: 340; loss: 0.07; acc: 0.98
Batch: 360; loss: 0.04; acc: 0.98
Batch: 380; loss: 0.01; acc: 1.0
Batch: 400; loss: 0.08; acc: 0.97
Batch: 420; loss: 0.02; acc: 1.0
Batch: 440; loss: 0.01; acc: 1.0
Batch: 460; loss: 0.11; acc: 0.95
Batch: 480; loss: 0.16; acc: 0.95
Batch: 500; loss: 0.04; acc: 0.98
Batch: 520; loss: 0.09; acc: 0.98
Batch: 540; loss: 0.04; acc: 0.98
Batch: 560; loss: 0.04; acc: 0.97
Batch: 580; loss: 0.03; acc: 0.98
Batch: 600; loss: 0.01; acc: 1.0
Batch: 620; loss: 0.19; acc: 0.94
Batch: 640; loss: 0.2; acc: 0.94
Batch: 660; loss: 0.09; acc: 0.95
Batch: 680; loss: 0.04; acc: 1.0
Batch: 700; loss: 0.14; acc: 0.97
Batch: 720; loss: 0.06; acc: 0.98
Batch: 740; loss: 0.08; acc: 0.98
Batch: 760; loss: 0.15; acc: 0.97
Batch: 780; loss: 0.02; acc: 1.0
Train Epoch over. train_loss: 0.08; train_accuracy: 0.97 

2.98908071272308e-05
1.3261929780128412e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.13; acc: 0.97
Batch: 40; loss: 0.12; acc: 0.98
Batch: 60; loss: 0.25; acc: 0.92
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.11; acc: 0.95
Batch: 140; loss: 0.02; acc: 0.98
Val Epoch over. val_loss: 0.09682609446963687; val_accuracy: 0.9717356687898089 

The current subspace-distance is: 1.3261929780128412e-05 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.13; acc: 0.94
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.13; acc: 0.94
Batch: 80; loss: 0.11; acc: 0.94
Batch: 100; loss: 0.07; acc: 0.98
Batch: 120; loss: 0.06; acc: 0.97
Batch: 140; loss: 0.04; acc: 1.0
Batch: 160; loss: 0.11; acc: 0.95
Batch: 180; loss: 0.03; acc: 1.0
Batch: 200; loss: 0.05; acc: 0.97
Batch: 220; loss: 0.21; acc: 0.94
Batch: 240; loss: 0.14; acc: 0.94
Batch: 260; loss: 0.05; acc: 0.98
Batch: 280; loss: 0.09; acc: 0.98
Batch: 300; loss: 0.03; acc: 0.98
Batch: 320; loss: 0.08; acc: 0.98
Batch: 340; loss: 0.03; acc: 0.98
Batch: 360; loss: 0.05; acc: 0.97
Batch: 380; loss: 0.08; acc: 0.97
Batch: 400; loss: 0.05; acc: 0.98
Batch: 420; loss: 0.14; acc: 0.95
Batch: 440; loss: 0.01; acc: 1.0
Batch: 460; loss: 0.13; acc: 0.95
Batch: 480; loss: 0.09; acc: 0.97
Batch: 500; loss: 0.14; acc: 0.97
Batch: 520; loss: 0.06; acc: 0.97
Batch: 540; loss: 0.24; acc: 0.94
Batch: 560; loss: 0.12; acc: 0.95
Batch: 580; loss: 0.12; acc: 0.97
Batch: 600; loss: 0.11; acc: 0.95
Batch: 620; loss: 0.16; acc: 0.97
Batch: 640; loss: 0.06; acc: 0.98
Batch: 660; loss: 0.12; acc: 0.98
Batch: 680; loss: 0.06; acc: 0.97
Batch: 700; loss: 0.18; acc: 0.95
Batch: 720; loss: 0.05; acc: 0.98
Batch: 740; loss: 0.05; acc: 0.98
Batch: 760; loss: 0.06; acc: 0.97
Batch: 780; loss: 0.08; acc: 0.95
Train Epoch over. train_loss: 0.08; train_accuracy: 0.97 

3.0455787054961547e-05
1.3948097148386296e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.12; acc: 0.95
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.21; acc: 0.92
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.09; acc: 0.98
Batch: 120; loss: 0.14; acc: 0.94
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.08963033938958387; val_accuracy: 0.9736265923566879 

The current subspace-distance is: 1.3948097148386296e-05 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.11; acc: 0.98
Batch: 20; loss: 0.19; acc: 0.98
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.06; acc: 0.98
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.08; acc: 0.98
Batch: 120; loss: 0.08; acc: 0.98
Batch: 140; loss: 0.15; acc: 0.97
Batch: 160; loss: 0.1; acc: 0.97
Batch: 180; loss: 0.09; acc: 0.97
Batch: 200; loss: 0.03; acc: 0.98
Batch: 220; loss: 0.15; acc: 0.97
Batch: 240; loss: 0.07; acc: 0.97
Batch: 260; loss: 0.1; acc: 0.94
Batch: 280; loss: 0.04; acc: 0.98
Batch: 300; loss: 0.16; acc: 0.97
Batch: 320; loss: 0.02; acc: 1.0
Batch: 340; loss: 0.06; acc: 0.97
Batch: 360; loss: 0.16; acc: 0.95
Batch: 380; loss: 0.05; acc: 0.98
Batch: 400; loss: 0.01; acc: 1.0
Batch: 420; loss: 0.11; acc: 0.97
Batch: 440; loss: 0.19; acc: 0.97
Batch: 460; loss: 0.16; acc: 0.97
Batch: 480; loss: 0.2; acc: 0.95
Batch: 500; loss: 0.09; acc: 0.97
Batch: 520; loss: 0.26; acc: 0.95
Batch: 540; loss: 0.21; acc: 0.94
Batch: 560; loss: 0.18; acc: 0.95
Batch: 580; loss: 0.06; acc: 0.97
Batch: 600; loss: 0.03; acc: 0.98
Batch: 620; loss: 0.03; acc: 1.0
Batch: 640; loss: 0.01; acc: 1.0
Batch: 660; loss: 0.12; acc: 0.95
Batch: 680; loss: 0.02; acc: 1.0
Batch: 700; loss: 0.08; acc: 0.97
Batch: 720; loss: 0.09; acc: 0.95
Batch: 740; loss: 0.15; acc: 0.97
Batch: 760; loss: 0.13; acc: 0.95
Batch: 780; loss: 0.28; acc: 0.95
Train Epoch over. train_loss: 0.08; train_accuracy: 0.97 

3.0655020964331925e-05
1.3271479474497028e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.1; acc: 0.97
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.25; acc: 0.92
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.11; acc: 0.97
Batch: 120; loss: 0.13; acc: 0.92
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.08691672883500719; val_accuracy: 0.9738256369426752 

The current subspace-distance is: 1.3271479474497028e-05 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.05; acc: 0.98
Batch: 20; loss: 0.14; acc: 0.97
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.14; acc: 0.98
Batch: 120; loss: 0.13; acc: 0.97
Batch: 140; loss: 0.13; acc: 0.97
Batch: 160; loss: 0.04; acc: 1.0
Batch: 180; loss: 0.05; acc: 0.98
Batch: 200; loss: 0.11; acc: 0.97
Batch: 220; loss: 0.04; acc: 0.97
Batch: 240; loss: 0.05; acc: 0.98
Batch: 260; loss: 0.16; acc: 0.94
Batch: 280; loss: 0.22; acc: 0.95
Batch: 300; loss: 0.12; acc: 0.94
Batch: 320; loss: 0.03; acc: 0.98
Batch: 340; loss: 0.11; acc: 0.97
Batch: 360; loss: 0.03; acc: 1.0
Batch: 380; loss: 0.26; acc: 0.94
Batch: 400; loss: 0.03; acc: 1.0
Batch: 420; loss: 0.12; acc: 0.97
Batch: 440; loss: 0.13; acc: 0.95
Batch: 460; loss: 0.11; acc: 0.95
Batch: 480; loss: 0.06; acc: 0.97
Batch: 500; loss: 0.01; acc: 1.0
Batch: 520; loss: 0.04; acc: 1.0
Batch: 540; loss: 0.02; acc: 1.0
Batch: 560; loss: 0.04; acc: 0.98
Batch: 580; loss: 0.08; acc: 0.98
Batch: 600; loss: 0.09; acc: 0.97
Batch: 620; loss: 0.02; acc: 1.0
Batch: 640; loss: 0.08; acc: 0.97
Batch: 660; loss: 0.01; acc: 1.0
Batch: 680; loss: 0.11; acc: 0.95
Batch: 700; loss: 0.11; acc: 0.97
Batch: 720; loss: 0.04; acc: 0.98
Batch: 740; loss: 0.06; acc: 0.97
Batch: 760; loss: 0.01; acc: 1.0
Batch: 780; loss: 0.04; acc: 0.98
Train Epoch over. train_loss: 0.08; train_accuracy: 0.97 

2.992426925629843e-05
1.3531779586628545e-05
Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.17; acc: 0.95
Batch: 40; loss: 0.11; acc: 0.98
Batch: 60; loss: 0.32; acc: 0.94
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.11; acc: 0.98
Batch: 120; loss: 0.18; acc: 0.91
Batch: 140; loss: 0.02; acc: 0.98
Val Epoch over. val_loss: 0.10881933988113503; val_accuracy: 0.9671576433121019 

The current subspace-distance is: 1.3531779586628545e-05 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.13; acc: 0.94
Batch: 20; loss: 0.1; acc: 0.97
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.06; acc: 0.97
Batch: 80; loss: 0.03; acc: 0.98
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.08; acc: 0.97
Batch: 140; loss: 0.02; acc: 1.0
Batch: 160; loss: 0.03; acc: 0.98
Batch: 180; loss: 0.1; acc: 0.97
Batch: 200; loss: 0.02; acc: 1.0
Batch: 220; loss: 0.08; acc: 0.95
Batch: 240; loss: 0.03; acc: 0.98
Batch: 260; loss: 0.05; acc: 0.98
Batch: 280; loss: 0.06; acc: 0.97
Batch: 300; loss: 0.06; acc: 0.98
Batch: 320; loss: 0.09; acc: 0.98
Batch: 340; loss: 0.03; acc: 0.98
Batch: 360; loss: 0.1; acc: 0.97
Batch: 380; loss: 0.18; acc: 0.94
Batch: 400; loss: 0.06; acc: 0.98
Batch: 420; loss: 0.01; acc: 0.98
Batch: 440; loss: 0.16; acc: 0.95
Batch: 460; loss: 0.19; acc: 0.94
Batch: 480; loss: 0.03; acc: 1.0
Batch: 500; loss: 0.02; acc: 1.0
Batch: 520; loss: 0.04; acc: 0.97
Batch: 540; loss: 0.15; acc: 0.97
Batch: 560; loss: 0.01; acc: 1.0
Batch: 580; loss: 0.09; acc: 0.97
Batch: 600; loss: 0.02; acc: 0.98
Batch: 620; loss: 0.18; acc: 0.95
Batch: 640; loss: 0.13; acc: 0.94
Batch: 660; loss: 0.01; acc: 1.0
Batch: 680; loss: 0.17; acc: 0.92
Batch: 700; loss: 0.08; acc: 0.97
Batch: 720; loss: 0.12; acc: 0.95
Batch: 740; loss: 0.07; acc: 0.97
Batch: 760; loss: 0.06; acc: 0.98
Batch: 780; loss: 0.08; acc: 0.98
Train Epoch over. train_loss: 0.08; train_accuracy: 0.97 

3.060426388401538e-05
1.3650954315380659e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.1; acc: 0.97
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.09; acc: 0.98
Batch: 120; loss: 0.15; acc: 0.92
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.08678484345032911; val_accuracy: 0.9741242038216561 

The current subspace-distance is: 1.3650954315380659e-05 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.14; acc: 0.94
Batch: 20; loss: 0.05; acc: 0.98
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.01; acc: 1.0
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.09; acc: 0.98
Batch: 120; loss: 0.15; acc: 0.97
Batch: 140; loss: 0.23; acc: 0.94
Batch: 160; loss: 0.04; acc: 0.98
Batch: 180; loss: 0.02; acc: 0.98
Batch: 200; loss: 0.09; acc: 0.95
Batch: 220; loss: 0.06; acc: 0.97
Batch: 240; loss: 0.04; acc: 0.98
Batch: 260; loss: 0.09; acc: 0.98
Batch: 280; loss: 0.04; acc: 0.98
Batch: 300; loss: 0.15; acc: 0.94
Batch: 320; loss: 0.05; acc: 0.98
Batch: 340; loss: 0.03; acc: 1.0
Batch: 360; loss: 0.06; acc: 0.98
Batch: 380; loss: 0.02; acc: 0.98
Batch: 400; loss: 0.08; acc: 0.98
Batch: 420; loss: 0.09; acc: 0.98
Batch: 440; loss: 0.18; acc: 0.95
Batch: 460; loss: 0.08; acc: 0.98
Batch: 480; loss: 0.09; acc: 0.97
Batch: 500; loss: 0.01; acc: 1.0
Batch: 520; loss: 0.05; acc: 0.98
Batch: 540; loss: 0.02; acc: 1.0
Batch: 560; loss: 0.06; acc: 0.98
Batch: 580; loss: 0.1; acc: 0.98
Batch: 600; loss: 0.18; acc: 0.94
Batch: 620; loss: 0.02; acc: 0.98
Batch: 640; loss: 0.17; acc: 0.95
Batch: 660; loss: 0.02; acc: 1.0
Batch: 680; loss: 0.02; acc: 0.98
Batch: 700; loss: 0.12; acc: 0.95
Batch: 720; loss: 0.17; acc: 0.94
Batch: 740; loss: 0.05; acc: 0.98
Batch: 760; loss: 0.1; acc: 0.95
Batch: 780; loss: 0.15; acc: 0.95
Train Epoch over. train_loss: 0.08; train_accuracy: 0.98 

3.0208600946934894e-05
1.3478058463078924e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.1; acc: 0.97
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.24; acc: 0.92
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.12; acc: 0.95
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.08473289953129497; val_accuracy: 0.9748208598726115 

The current subspace-distance is: 1.3478058463078924e-05 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.05; acc: 0.97
Batch: 20; loss: 0.12; acc: 0.95
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.04; acc: 0.98
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.11; acc: 0.98
Batch: 140; loss: 0.2; acc: 0.95
Batch: 160; loss: 0.03; acc: 1.0
Batch: 180; loss: 0.02; acc: 1.0
Batch: 200; loss: 0.07; acc: 0.97
Batch: 220; loss: 0.1; acc: 0.97
Batch: 240; loss: 0.04; acc: 0.98
Batch: 260; loss: 0.05; acc: 0.97
Batch: 280; loss: 0.14; acc: 0.95
Batch: 300; loss: 0.29; acc: 0.94
Batch: 320; loss: 0.03; acc: 1.0
Batch: 340; loss: 0.1; acc: 0.97
Batch: 360; loss: 0.15; acc: 0.97
Batch: 380; loss: 0.02; acc: 1.0
Batch: 400; loss: 0.12; acc: 0.97
Batch: 420; loss: 0.13; acc: 0.94
Batch: 440; loss: 0.02; acc: 1.0
Batch: 460; loss: 0.04; acc: 0.98
Batch: 480; loss: 0.09; acc: 0.97
Batch: 500; loss: 0.07; acc: 0.98
Batch: 520; loss: 0.02; acc: 0.98
Batch: 540; loss: 0.07; acc: 0.97
Batch: 560; loss: 0.09; acc: 0.98
Batch: 580; loss: 0.07; acc: 0.98
Batch: 600; loss: 0.03; acc: 1.0
Batch: 620; loss: 0.17; acc: 0.94
Batch: 640; loss: 0.06; acc: 0.98
Batch: 660; loss: 0.02; acc: 1.0
Batch: 680; loss: 0.11; acc: 0.97
Batch: 700; loss: 0.02; acc: 1.0
Batch: 720; loss: 0.02; acc: 0.98
Batch: 740; loss: 0.02; acc: 1.0
Batch: 760; loss: 0.04; acc: 0.98
Batch: 780; loss: 0.07; acc: 0.97
Train Epoch over. train_loss: 0.08; train_accuracy: 0.98 

3.013171772181522e-05
1.2922707355755847e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.11; acc: 0.98
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.13; acc: 0.95
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.08614258092062868; val_accuracy: 0.9739251592356688 

The current subspace-distance is: 1.2922707355755847e-05 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.12; acc: 0.94
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.02; acc: 1.0
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.03; acc: 0.98
Batch: 120; loss: 0.05; acc: 0.97
Batch: 140; loss: 0.13; acc: 0.95
Batch: 160; loss: 0.05; acc: 0.97
Batch: 180; loss: 0.04; acc: 0.98
Batch: 200; loss: 0.04; acc: 0.98
Batch: 220; loss: 0.05; acc: 0.97
Batch: 240; loss: 0.21; acc: 0.94
Batch: 260; loss: 0.07; acc: 0.97
Batch: 280; loss: 0.04; acc: 0.98
Batch: 300; loss: 0.02; acc: 1.0
Batch: 320; loss: 0.09; acc: 0.98
Batch: 340; loss: 0.18; acc: 0.94
Batch: 360; loss: 0.03; acc: 0.98
Batch: 380; loss: 0.29; acc: 0.94
Batch: 400; loss: 0.13; acc: 0.97
Batch: 420; loss: 0.07; acc: 0.97
Batch: 440; loss: 0.17; acc: 0.95
Batch: 460; loss: 0.04; acc: 1.0
Batch: 480; loss: 0.03; acc: 0.98
Batch: 500; loss: 0.06; acc: 0.98
Batch: 520; loss: 0.01; acc: 1.0
Batch: 540; loss: 0.03; acc: 0.98
Batch: 560; loss: 0.02; acc: 1.0
Batch: 580; loss: 0.14; acc: 0.95
Batch: 600; loss: 0.12; acc: 0.97
Batch: 620; loss: 0.16; acc: 0.95
Batch: 640; loss: 0.05; acc: 0.98
Batch: 660; loss: 0.07; acc: 0.97
Batch: 680; loss: 0.16; acc: 0.92
Batch: 700; loss: 0.02; acc: 1.0
Batch: 720; loss: 0.14; acc: 0.98
Batch: 740; loss: 0.2; acc: 0.94
Batch: 760; loss: 0.02; acc: 1.0
Batch: 780; loss: 0.06; acc: 0.98
Train Epoch over. train_loss: 0.08; train_accuracy: 0.98 

2.9941073080408387e-05
1.2992674783163238e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.1; acc: 0.97
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.11; acc: 0.94
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.0839374522043831; val_accuracy: 0.9751194267515924 

The current subspace-distance is: 1.2992674783163238e-05 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.12; acc: 0.97
Batch: 40; loss: 0.01; acc: 1.0
Batch: 60; loss: 0.09; acc: 0.98
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.06; acc: 0.97
Batch: 120; loss: 0.12; acc: 0.95
Batch: 140; loss: 0.14; acc: 0.97
Batch: 160; loss: 0.09; acc: 0.97
Batch: 180; loss: 0.05; acc: 0.98
Batch: 200; loss: 0.05; acc: 0.98
Batch: 220; loss: 0.07; acc: 0.97
Batch: 240; loss: 0.06; acc: 0.98
Batch: 260; loss: 0.09; acc: 0.97
Batch: 280; loss: 0.04; acc: 0.98
Batch: 300; loss: 0.03; acc: 0.98
Batch: 320; loss: 0.34; acc: 0.94
Batch: 340; loss: 0.2; acc: 0.95
Batch: 360; loss: 0.03; acc: 0.98
Batch: 380; loss: 0.02; acc: 0.98
Batch: 400; loss: 0.07; acc: 0.97
Batch: 420; loss: 0.03; acc: 1.0
Batch: 440; loss: 0.06; acc: 0.98
Batch: 460; loss: 0.08; acc: 0.98
Batch: 480; loss: 0.01; acc: 1.0
Batch: 500; loss: 0.06; acc: 0.97
Batch: 520; loss: 0.01; acc: 1.0
Batch: 540; loss: 0.07; acc: 0.98
Batch: 560; loss: 0.04; acc: 0.98
Batch: 580; loss: 0.04; acc: 0.97
Batch: 600; loss: 0.05; acc: 0.98
Batch: 620; loss: 0.03; acc: 0.98
Batch: 640; loss: 0.05; acc: 0.98
Batch: 660; loss: 0.18; acc: 0.94
Batch: 680; loss: 0.07; acc: 0.97
Batch: 700; loss: 0.11; acc: 0.97
Batch: 720; loss: 0.02; acc: 1.0
Batch: 740; loss: 0.12; acc: 0.97
Batch: 760; loss: 0.04; acc: 1.0
Batch: 780; loss: 0.1; acc: 0.97
Train Epoch over. train_loss: 0.08; train_accuracy: 0.98 

2.978898919536732e-05
1.2966597751074005e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.1; acc: 0.97
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.1; acc: 0.98
Batch: 120; loss: 0.11; acc: 0.95
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.08460472414424275; val_accuracy: 0.9754179936305732 

The current subspace-distance is: 1.2966597751074005e-05 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.25; acc: 0.97
Batch: 20; loss: 0.08; acc: 0.98
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.03; acc: 1.0
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.06; acc: 0.98
Batch: 140; loss: 0.04; acc: 0.98
Batch: 160; loss: 0.14; acc: 0.98
Batch: 180; loss: 0.05; acc: 1.0
Batch: 200; loss: 0.04; acc: 0.98
Batch: 220; loss: 0.03; acc: 0.98
Batch: 240; loss: 0.03; acc: 1.0
Batch: 260; loss: 0.05; acc: 0.98
Batch: 280; loss: 0.18; acc: 0.94
Batch: 300; loss: 0.02; acc: 1.0
Batch: 320; loss: 0.13; acc: 0.95
Batch: 340; loss: 0.02; acc: 1.0
Batch: 360; loss: 0.05; acc: 0.98
Batch: 380; loss: 0.08; acc: 0.98
Batch: 400; loss: 0.13; acc: 0.98
Batch: 420; loss: 0.04; acc: 0.98
Batch: 440; loss: 0.16; acc: 0.95
Batch: 460; loss: 0.04; acc: 0.97
Batch: 480; loss: 0.04; acc: 0.97
Batch: 500; loss: 0.06; acc: 0.98
Batch: 520; loss: 0.01; acc: 1.0
Batch: 540; loss: 0.09; acc: 0.95
Batch: 560; loss: 0.01; acc: 1.0
Batch: 580; loss: 0.06; acc: 0.95
Batch: 600; loss: 0.1; acc: 0.97
Batch: 620; loss: 0.04; acc: 0.98
Batch: 640; loss: 0.16; acc: 0.95
Batch: 660; loss: 0.06; acc: 0.98
Batch: 680; loss: 0.03; acc: 0.98
Batch: 700; loss: 0.06; acc: 0.97
Batch: 720; loss: 0.09; acc: 0.95
Batch: 740; loss: 0.17; acc: 0.92
Batch: 760; loss: 0.17; acc: 0.98
Batch: 780; loss: 0.05; acc: 0.98
Train Epoch over. train_loss: 0.08; train_accuracy: 0.98 

3.045605080842506e-05
1.3983425560581964e-05
Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.1; acc: 0.98
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.11; acc: 0.95
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.08513360886365935; val_accuracy: 0.9747213375796179 

The current subspace-distance is: 1.3983425560581964e-05 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.07; acc: 0.97
Batch: 40; loss: 0.2; acc: 0.97
Batch: 60; loss: 0.04; acc: 0.98
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.01; acc: 1.0
Batch: 120; loss: 0.03; acc: 0.98
Batch: 140; loss: 0.04; acc: 1.0
Batch: 160; loss: 0.03; acc: 0.98
Batch: 180; loss: 0.14; acc: 0.97
Batch: 200; loss: 0.07; acc: 0.98
Batch: 220; loss: 0.06; acc: 0.98
Batch: 240; loss: 0.02; acc: 1.0
Batch: 260; loss: 0.07; acc: 0.98
Batch: 280; loss: 0.13; acc: 0.95
Batch: 300; loss: 0.13; acc: 0.97
Batch: 320; loss: 0.14; acc: 0.95
Batch: 340; loss: 0.15; acc: 0.97
Batch: 360; loss: 0.08; acc: 0.97
Batch: 380; loss: 0.04; acc: 0.98
Batch: 400; loss: 0.03; acc: 0.98
Batch: 420; loss: 0.08; acc: 0.97
Batch: 440; loss: 0.06; acc: 0.98
Batch: 460; loss: 0.1; acc: 0.95
Batch: 480; loss: 0.23; acc: 0.95
Batch: 500; loss: 0.06; acc: 0.97
Batch: 520; loss: 0.01; acc: 1.0
Batch: 540; loss: 0.08; acc: 0.98
Batch: 560; loss: 0.06; acc: 0.97
Batch: 580; loss: 0.12; acc: 0.97
Batch: 600; loss: 0.17; acc: 0.95
Batch: 620; loss: 0.06; acc: 0.95
Batch: 640; loss: 0.22; acc: 0.92
Batch: 660; loss: 0.19; acc: 0.94
Batch: 680; loss: 0.01; acc: 1.0
Batch: 700; loss: 0.05; acc: 0.97
Batch: 720; loss: 0.11; acc: 0.98
Batch: 740; loss: 0.05; acc: 0.97
Batch: 760; loss: 0.08; acc: 0.97
Batch: 780; loss: 0.08; acc: 0.97
Train Epoch over. train_loss: 0.08; train_accuracy: 0.98 

3.003499296028167e-05
1.3494501217792276e-05
Batch: 0; loss: 0.04; acc: 0.97
Batch: 20; loss: 0.13; acc: 0.97
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.11; acc: 0.95
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.09129153977438903; val_accuracy: 0.972531847133758 

The current subspace-distance is: 1.3494501217792276e-05 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.05; acc: 0.98
Batch: 20; loss: 0.03; acc: 1.0
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.12; acc: 0.97
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.03; acc: 0.98
Batch: 120; loss: 0.1; acc: 0.97
Batch: 140; loss: 0.01; acc: 1.0
Batch: 160; loss: 0.13; acc: 0.97
Batch: 180; loss: 0.08; acc: 0.98
Batch: 200; loss: 0.11; acc: 0.98
Batch: 220; loss: 0.06; acc: 0.98
Batch: 240; loss: 0.05; acc: 0.98
Batch: 260; loss: 0.06; acc: 0.98
Batch: 280; loss: 0.02; acc: 1.0
Batch: 300; loss: 0.15; acc: 0.95
Batch: 320; loss: 0.03; acc: 0.97
Batch: 340; loss: 0.22; acc: 0.94
Batch: 360; loss: 0.04; acc: 0.98
Batch: 380; loss: 0.02; acc: 0.98
Batch: 400; loss: 0.05; acc: 0.98
Batch: 420; loss: 0.06; acc: 0.97
Batch: 440; loss: 0.01; acc: 1.0
Batch: 460; loss: 0.04; acc: 0.98
Batch: 480; loss: 0.04; acc: 1.0
Batch: 500; loss: 0.02; acc: 1.0
Batch: 520; loss: 0.03; acc: 0.98
Batch: 540; loss: 0.16; acc: 0.95
Batch: 560; loss: 0.1; acc: 0.97
Batch: 580; loss: 0.19; acc: 0.92
Batch: 600; loss: 0.1; acc: 0.95
Batch: 620; loss: 0.04; acc: 0.98
Batch: 640; loss: 0.17; acc: 0.95
Batch: 660; loss: 0.02; acc: 0.98
Batch: 680; loss: 0.03; acc: 0.98
Batch: 700; loss: 0.16; acc: 0.95
Batch: 720; loss: 0.04; acc: 0.98
Batch: 740; loss: 0.0; acc: 1.0
Batch: 760; loss: 0.11; acc: 0.95
Batch: 780; loss: 0.07; acc: 0.97
Train Epoch over. train_loss: 0.08; train_accuracy: 0.98 

2.997654337377753e-05
1.3823316294292454e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.11; acc: 0.94
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.08464675470237519; val_accuracy: 0.9738256369426752 

The current subspace-distance is: 1.3823316294292454e-05 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.09; acc: 0.95
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.09; acc: 0.97
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.03; acc: 0.98
Batch: 120; loss: 0.13; acc: 0.95
Batch: 140; loss: 0.07; acc: 0.97
Batch: 160; loss: 0.04; acc: 1.0
Batch: 180; loss: 0.01; acc: 1.0
Batch: 200; loss: 0.06; acc: 0.98
Batch: 220; loss: 0.06; acc: 0.98
Batch: 240; loss: 0.12; acc: 0.95
Batch: 260; loss: 0.02; acc: 1.0
Batch: 280; loss: 0.08; acc: 0.98
Batch: 300; loss: 0.2; acc: 0.97
Batch: 320; loss: 0.03; acc: 0.98
Batch: 340; loss: 0.07; acc: 0.98
Batch: 360; loss: 0.08; acc: 0.95
Batch: 380; loss: 0.06; acc: 0.97
Batch: 400; loss: 0.03; acc: 0.98
Batch: 420; loss: 0.12; acc: 0.97
Batch: 440; loss: 0.11; acc: 0.98
Batch: 460; loss: 0.06; acc: 0.98
Batch: 480; loss: 0.11; acc: 0.97
Batch: 500; loss: 0.05; acc: 0.97
Batch: 520; loss: 0.19; acc: 0.95
Batch: 540; loss: 0.03; acc: 1.0
Batch: 560; loss: 0.15; acc: 0.97
Batch: 580; loss: 0.04; acc: 0.98
Batch: 600; loss: 0.05; acc: 0.98
Batch: 620; loss: 0.01; acc: 1.0
Batch: 640; loss: 0.02; acc: 1.0
Batch: 660; loss: 0.02; acc: 1.0
Batch: 680; loss: 0.08; acc: 0.98
Batch: 700; loss: 0.12; acc: 0.97
Batch: 720; loss: 0.07; acc: 0.95
Batch: 740; loss: 0.12; acc: 0.97
Batch: 760; loss: 0.06; acc: 0.97
Batch: 780; loss: 0.12; acc: 0.97
Train Epoch over. train_loss: 0.08; train_accuracy: 0.98 

2.9980375984450802e-05
1.2833383152610622e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.1; acc: 0.94
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.08438531703250424; val_accuracy: 0.9751194267515924 

The current subspace-distance is: 1.2833383152610622e-05 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.14; acc: 0.97
Batch: 20; loss: 0.08; acc: 0.97
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.05; acc: 0.98
Batch: 80; loss: 0.09; acc: 0.94
Batch: 100; loss: 0.12; acc: 0.97
Batch: 120; loss: 0.21; acc: 0.95
Batch: 140; loss: 0.02; acc: 1.0
Batch: 160; loss: 0.02; acc: 1.0
Batch: 180; loss: 0.04; acc: 0.98
Batch: 200; loss: 0.07; acc: 0.98
Batch: 220; loss: 0.06; acc: 0.97
Batch: 240; loss: 0.06; acc: 0.98
Batch: 260; loss: 0.03; acc: 0.98
Batch: 280; loss: 0.03; acc: 0.98
Batch: 300; loss: 0.13; acc: 0.97
Batch: 320; loss: 0.18; acc: 0.95
Batch: 340; loss: 0.02; acc: 1.0
Batch: 360; loss: 0.01; acc: 1.0
Batch: 380; loss: 0.01; acc: 1.0
Batch: 400; loss: 0.05; acc: 0.98
Batch: 420; loss: 0.06; acc: 0.97
Batch: 440; loss: 0.06; acc: 0.98
Batch: 460; loss: 0.03; acc: 0.98
Batch: 480; loss: 0.04; acc: 0.98
Batch: 500; loss: 0.06; acc: 0.98
Batch: 520; loss: 0.06; acc: 0.98
Batch: 540; loss: 0.02; acc: 1.0
Batch: 560; loss: 0.07; acc: 0.97
Batch: 580; loss: 0.24; acc: 0.95
Batch: 600; loss: 0.09; acc: 0.95
Batch: 620; loss: 0.04; acc: 0.98
Batch: 640; loss: 0.02; acc: 1.0
Batch: 660; loss: 0.02; acc: 1.0
Batch: 680; loss: 0.02; acc: 1.0
Batch: 700; loss: 0.05; acc: 1.0
Batch: 720; loss: 0.03; acc: 1.0
Batch: 740; loss: 0.1; acc: 0.95
Batch: 760; loss: 0.15; acc: 0.97
Batch: 780; loss: 0.07; acc: 0.97
Train Epoch over. train_loss: 0.08; train_accuracy: 0.98 

2.994860551552847e-05
1.2892848644696642e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.1; acc: 0.97
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.11; acc: 0.94
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.08433932503151476; val_accuracy: 0.975218949044586 

The current subspace-distance is: 1.2892848644696642e-05 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.13; acc: 0.92
Batch: 20; loss: 0.12; acc: 0.95
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.03; acc: 0.98
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.02; acc: 1.0
Batch: 120; loss: 0.02; acc: 1.0
Batch: 140; loss: 0.07; acc: 0.97
Batch: 160; loss: 0.15; acc: 0.94
Batch: 180; loss: 0.05; acc: 0.97
Batch: 200; loss: 0.03; acc: 1.0
Batch: 220; loss: 0.03; acc: 1.0
Batch: 240; loss: 0.05; acc: 0.98
Batch: 260; loss: 0.06; acc: 0.98
Batch: 280; loss: 0.12; acc: 0.97
Batch: 300; loss: 0.06; acc: 0.98
Batch: 320; loss: 0.03; acc: 0.98
Batch: 340; loss: 0.08; acc: 0.97
Batch: 360; loss: 0.04; acc: 0.98
Batch: 380; loss: 0.06; acc: 0.98
Batch: 400; loss: 0.02; acc: 0.98
Batch: 420; loss: 0.07; acc: 0.98
Batch: 440; loss: 0.04; acc: 1.0
Batch: 460; loss: 0.16; acc: 0.97
Batch: 480; loss: 0.02; acc: 1.0
Batch: 500; loss: 0.09; acc: 0.94
Batch: 520; loss: 0.02; acc: 0.98
Batch: 540; loss: 0.02; acc: 1.0
Batch: 560; loss: 0.01; acc: 1.0
Batch: 580; loss: 0.05; acc: 0.98
Batch: 600; loss: 0.01; acc: 1.0
Batch: 620; loss: 0.1; acc: 0.94
Batch: 640; loss: 0.02; acc: 1.0
Batch: 660; loss: 0.08; acc: 0.97
Batch: 680; loss: 0.15; acc: 0.92
Batch: 700; loss: 0.05; acc: 0.98
Batch: 720; loss: 0.06; acc: 0.98
Batch: 740; loss: 0.13; acc: 0.98
Batch: 760; loss: 0.04; acc: 0.98
Batch: 780; loss: 0.08; acc: 0.98
Train Epoch over. train_loss: 0.08; train_accuracy: 0.98 

2.95550544251455e-05
1.3206637049734127e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.09; acc: 0.98
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.12; acc: 0.94
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.08377578432203099; val_accuracy: 0.9750199044585988 

The current subspace-distance is: 1.3206637049734127e-05 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.02; acc: 0.98
Batch: 60; loss: 0.05; acc: 0.98
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.11; acc: 0.98
Batch: 140; loss: 0.04; acc: 1.0
Batch: 160; loss: 0.1; acc: 0.95
Batch: 180; loss: 0.04; acc: 0.98
Batch: 200; loss: 0.1; acc: 0.95
Batch: 220; loss: 0.1; acc: 0.94
Batch: 240; loss: 0.03; acc: 1.0
Batch: 260; loss: 0.05; acc: 0.98
Batch: 280; loss: 0.07; acc: 0.95
Batch: 300; loss: 0.02; acc: 1.0
Batch: 320; loss: 0.08; acc: 0.98
Batch: 340; loss: 0.02; acc: 1.0
Batch: 360; loss: 0.24; acc: 0.97
Batch: 380; loss: 0.09; acc: 0.95
Batch: 400; loss: 0.02; acc: 1.0
Batch: 420; loss: 0.09; acc: 0.97
Batch: 440; loss: 0.09; acc: 0.95
Batch: 460; loss: 0.11; acc: 0.97
Batch: 480; loss: 0.06; acc: 0.97
Batch: 500; loss: 0.02; acc: 0.98
Batch: 520; loss: 0.02; acc: 1.0
Batch: 540; loss: 0.03; acc: 1.0
Batch: 560; loss: 0.08; acc: 0.97
Batch: 580; loss: 0.07; acc: 0.95
Batch: 600; loss: 0.03; acc: 1.0
Batch: 620; loss: 0.03; acc: 0.98
Batch: 640; loss: 0.04; acc: 1.0
Batch: 660; loss: 0.13; acc: 0.97
Batch: 680; loss: 0.05; acc: 0.98
Batch: 700; loss: 0.08; acc: 0.98
Batch: 720; loss: 0.06; acc: 0.98
Batch: 740; loss: 0.02; acc: 1.0
Batch: 760; loss: 0.01; acc: 1.0
Batch: 780; loss: 0.0; acc: 1.0
Train Epoch over. train_loss: 0.08; train_accuracy: 0.98 

3.0078834242885932e-05
1.2844479897466954e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.1; acc: 0.97
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.12; acc: 0.94
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.08327282279445107; val_accuracy: 0.975218949044586 

The current subspace-distance is: 1.2844479897466954e-05 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.12; acc: 0.98
Batch: 20; loss: 0.04; acc: 0.97
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.02; acc: 1.0
Batch: 120; loss: 0.1; acc: 0.97
Batch: 140; loss: 0.05; acc: 1.0
Batch: 160; loss: 0.2; acc: 0.97
Batch: 180; loss: 0.1; acc: 0.97
Batch: 200; loss: 0.09; acc: 0.97
Batch: 220; loss: 0.02; acc: 1.0
Batch: 240; loss: 0.03; acc: 0.98
Batch: 260; loss: 0.02; acc: 1.0
Batch: 280; loss: 0.03; acc: 0.98
Batch: 300; loss: 0.03; acc: 0.98
Batch: 320; loss: 0.06; acc: 0.98
Batch: 340; loss: 0.0; acc: 1.0
Batch: 360; loss: 0.08; acc: 0.95
Batch: 380; loss: 0.01; acc: 1.0
Batch: 400; loss: 0.09; acc: 0.97
Batch: 420; loss: 0.04; acc: 0.98
Batch: 440; loss: 0.05; acc: 0.98
Batch: 460; loss: 0.01; acc: 1.0
Batch: 480; loss: 0.03; acc: 0.98
Batch: 500; loss: 0.08; acc: 0.98
Batch: 520; loss: 0.06; acc: 0.97
Batch: 540; loss: 0.13; acc: 0.97
Batch: 560; loss: 0.03; acc: 1.0
Batch: 580; loss: 0.06; acc: 0.98
Batch: 600; loss: 0.09; acc: 0.95
Batch: 620; loss: 0.05; acc: 0.97
Batch: 640; loss: 0.05; acc: 0.98
Batch: 660; loss: 0.09; acc: 0.97
Batch: 680; loss: 0.03; acc: 1.0
Batch: 700; loss: 0.16; acc: 0.95
Batch: 720; loss: 0.08; acc: 0.98
Batch: 740; loss: 0.03; acc: 0.98
Batch: 760; loss: 0.04; acc: 0.98
Batch: 780; loss: 0.06; acc: 0.98
Train Epoch over. train_loss: 0.08; train_accuracy: 0.98 

3.0005565349711105e-05
1.3447125638776924e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.09; acc: 0.98
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.11; acc: 0.95
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.08297798204811135; val_accuracy: 0.9757165605095541 

The current subspace-distance is: 1.3447125638776924e-05 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.3; acc: 0.94
Batch: 20; loss: 0.1; acc: 0.97
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.07; acc: 0.97
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.04; acc: 0.98
Batch: 120; loss: 0.04; acc: 0.98
Batch: 140; loss: 0.11; acc: 0.95
Batch: 160; loss: 0.03; acc: 1.0
Batch: 180; loss: 0.06; acc: 0.98
Batch: 200; loss: 0.14; acc: 0.97
Batch: 220; loss: 0.05; acc: 0.97
Batch: 240; loss: 0.09; acc: 0.97
Batch: 260; loss: 0.16; acc: 0.94
Batch: 280; loss: 0.01; acc: 1.0
Batch: 300; loss: 0.02; acc: 1.0
Batch: 320; loss: 0.05; acc: 0.98
Batch: 340; loss: 0.04; acc: 0.98
Batch: 360; loss: 0.04; acc: 0.98
Batch: 380; loss: 0.05; acc: 0.97
Batch: 400; loss: 0.05; acc: 0.97
Batch: 420; loss: 0.11; acc: 0.97
Batch: 440; loss: 0.02; acc: 1.0
Batch: 460; loss: 0.03; acc: 0.98
Batch: 480; loss: 0.05; acc: 0.98
Batch: 500; loss: 0.12; acc: 0.97
Batch: 520; loss: 0.09; acc: 0.97
Batch: 540; loss: 0.14; acc: 0.97
Batch: 560; loss: 0.18; acc: 0.94
Batch: 580; loss: 0.17; acc: 0.92
Batch: 600; loss: 0.02; acc: 1.0
Batch: 620; loss: 0.09; acc: 0.97
Batch: 640; loss: 0.05; acc: 0.98
Batch: 660; loss: 0.02; acc: 1.0
Batch: 680; loss: 0.03; acc: 1.0
Batch: 700; loss: 0.04; acc: 1.0
Batch: 720; loss: 0.2; acc: 0.97
Batch: 740; loss: 0.05; acc: 0.98
Batch: 760; loss: 0.02; acc: 1.0
Batch: 780; loss: 0.04; acc: 0.98
Train Epoch over. train_loss: 0.08; train_accuracy: 0.98 

3.024870966328308e-05
1.323094420513371e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.1; acc: 0.98
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.11; acc: 0.94
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.0837447661787841; val_accuracy: 0.975218949044586 

The current subspace-distance is: 1.323094420513371e-05 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.06; acc: 0.98
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.22; acc: 0.97
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.03; acc: 1.0
Batch: 140; loss: 0.22; acc: 0.94
Batch: 160; loss: 0.15; acc: 0.94
Batch: 180; loss: 0.17; acc: 0.94
Batch: 200; loss: 0.02; acc: 1.0
Batch: 220; loss: 0.04; acc: 0.98
Batch: 240; loss: 0.13; acc: 0.97
Batch: 260; loss: 0.06; acc: 0.98
Batch: 280; loss: 0.1; acc: 0.97
Batch: 300; loss: 0.02; acc: 1.0
Batch: 320; loss: 0.18; acc: 0.92
Batch: 340; loss: 0.09; acc: 0.98
Batch: 360; loss: 0.1; acc: 0.97
Batch: 380; loss: 0.1; acc: 0.95
Batch: 400; loss: 0.18; acc: 0.94
Batch: 420; loss: 0.05; acc: 0.97
Batch: 440; loss: 0.06; acc: 0.97
Batch: 460; loss: 0.01; acc: 1.0
Batch: 480; loss: 0.1; acc: 0.95
Batch: 500; loss: 0.3; acc: 0.94
Batch: 520; loss: 0.12; acc: 0.97
Batch: 540; loss: 0.05; acc: 0.97
Batch: 560; loss: 0.05; acc: 0.97
Batch: 580; loss: 0.11; acc: 0.95
Batch: 600; loss: 0.13; acc: 0.94
Batch: 620; loss: 0.03; acc: 1.0
Batch: 640; loss: 0.08; acc: 0.97
Batch: 660; loss: 0.11; acc: 0.97
Batch: 680; loss: 0.04; acc: 0.97
Batch: 700; loss: 0.12; acc: 0.97
Batch: 720; loss: 0.05; acc: 0.98
Batch: 740; loss: 0.29; acc: 0.94
Batch: 760; loss: 0.03; acc: 0.98
Batch: 780; loss: 0.01; acc: 1.0
Train Epoch over. train_loss: 0.08; train_accuracy: 0.98 

2.9938542866148055e-05
1.3411598047241569e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.1; acc: 0.97
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.12; acc: 0.94
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.084497566489135; val_accuracy: 0.9742237261146497 

The current subspace-distance is: 1.3411598047241569e-05 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.05; acc: 0.97
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.14; acc: 0.95
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.03; acc: 0.98
Batch: 120; loss: 0.11; acc: 0.97
Batch: 140; loss: 0.04; acc: 0.98
Batch: 160; loss: 0.01; acc: 1.0
Batch: 180; loss: 0.01; acc: 1.0
Batch: 200; loss: 0.22; acc: 0.94
Batch: 220; loss: 0.03; acc: 0.98
Batch: 240; loss: 0.16; acc: 0.97
Batch: 260; loss: 0.19; acc: 0.95
Batch: 280; loss: 0.06; acc: 0.98
Batch: 300; loss: 0.08; acc: 0.98
Batch: 320; loss: 0.06; acc: 0.98
Batch: 340; loss: 0.01; acc: 1.0
Batch: 360; loss: 0.02; acc: 1.0
Batch: 380; loss: 0.01; acc: 1.0
Batch: 400; loss: 0.03; acc: 0.98
Batch: 420; loss: 0.11; acc: 0.95
Batch: 440; loss: 0.04; acc: 1.0
Batch: 460; loss: 0.03; acc: 1.0
Batch: 480; loss: 0.09; acc: 0.97
Batch: 500; loss: 0.02; acc: 1.0
Batch: 520; loss: 0.02; acc: 1.0
Batch: 540; loss: 0.01; acc: 1.0
Batch: 560; loss: 0.02; acc: 0.98
Batch: 580; loss: 0.02; acc: 1.0
Batch: 600; loss: 0.15; acc: 0.97
Batch: 620; loss: 0.05; acc: 0.97
Batch: 640; loss: 0.06; acc: 0.98
Batch: 660; loss: 0.05; acc: 0.98
Batch: 680; loss: 0.06; acc: 0.98
Batch: 700; loss: 0.08; acc: 0.97
Batch: 720; loss: 0.17; acc: 0.95
Batch: 740; loss: 0.13; acc: 0.98
Batch: 760; loss: 0.07; acc: 0.97
Batch: 780; loss: 0.07; acc: 0.98
Train Epoch over. train_loss: 0.08; train_accuracy: 0.98 

2.998511445184704e-05
1.332080501015298e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.12; acc: 0.94
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.08411172270822297; val_accuracy: 0.9747213375796179 

The current subspace-distance is: 1.332080501015298e-05 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.11; acc: 0.95
Batch: 20; loss: 0.09; acc: 0.98
Batch: 40; loss: 0.04; acc: 1.0
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.15; acc: 0.98
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.18; acc: 0.91
Batch: 140; loss: 0.02; acc: 1.0
Batch: 160; loss: 0.02; acc: 1.0
Batch: 180; loss: 0.06; acc: 0.98
Batch: 200; loss: 0.07; acc: 0.97
Batch: 220; loss: 0.03; acc: 1.0
Batch: 240; loss: 0.11; acc: 0.98
Batch: 260; loss: 0.05; acc: 0.98
Batch: 280; loss: 0.05; acc: 0.97
Batch: 300; loss: 0.15; acc: 0.97
Batch: 320; loss: 0.31; acc: 0.95
Batch: 340; loss: 0.04; acc: 0.98
Batch: 360; loss: 0.12; acc: 0.94
Batch: 380; loss: 0.03; acc: 1.0
Batch: 400; loss: 0.07; acc: 0.98
Batch: 420; loss: 0.07; acc: 0.98
Batch: 440; loss: 0.03; acc: 1.0
Batch: 460; loss: 0.14; acc: 0.95
Batch: 480; loss: 0.08; acc: 0.97
Batch: 500; loss: 0.13; acc: 0.95
Batch: 520; loss: 0.09; acc: 0.97
Batch: 540; loss: 0.16; acc: 0.95
Batch: 560; loss: 0.16; acc: 0.94
Batch: 580; loss: 0.09; acc: 0.97
Batch: 600; loss: 0.04; acc: 1.0
Batch: 620; loss: 0.09; acc: 0.95
Batch: 640; loss: 0.03; acc: 0.98
Batch: 660; loss: 0.11; acc: 0.95
Batch: 680; loss: 0.01; acc: 1.0
Batch: 700; loss: 0.1; acc: 0.97
Batch: 720; loss: 0.04; acc: 0.98
Batch: 740; loss: 0.06; acc: 0.98
Batch: 760; loss: 0.28; acc: 0.97
Batch: 780; loss: 0.06; acc: 0.98
Train Epoch over. train_loss: 0.08; train_accuracy: 0.98 

2.9980988983879797e-05
1.31858987515443e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.1; acc: 0.97
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.11; acc: 0.95
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.08381097310572673; val_accuracy: 0.9747213375796179 

The current subspace-distance is: 1.31858987515443e-05 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.07; acc: 0.97
Batch: 20; loss: 0.02; acc: 1.0
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.04; acc: 0.98
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.08; acc: 0.97
Batch: 120; loss: 0.04; acc: 0.98
Batch: 140; loss: 0.07; acc: 0.97
Batch: 160; loss: 0.1; acc: 0.97
Batch: 180; loss: 0.1; acc: 0.97
Batch: 200; loss: 0.06; acc: 0.98
Batch: 220; loss: 0.15; acc: 0.97
Batch: 240; loss: 0.06; acc: 0.98
Batch: 260; loss: 0.11; acc: 0.98
Batch: 280; loss: 0.08; acc: 0.97
Batch: 300; loss: 0.03; acc: 1.0
Batch: 320; loss: 0.03; acc: 0.98
Batch: 340; loss: 0.11; acc: 0.98
Batch: 360; loss: 0.07; acc: 0.98
Batch: 380; loss: 0.04; acc: 0.98
Batch: 400; loss: 0.04; acc: 0.98
Batch: 420; loss: 0.08; acc: 0.98
Batch: 440; loss: 0.01; acc: 1.0
Batch: 460; loss: 0.01; acc: 1.0
Batch: 480; loss: 0.03; acc: 0.98
Batch: 500; loss: 0.01; acc: 1.0
Batch: 520; loss: 0.06; acc: 0.98
Batch: 540; loss: 0.05; acc: 1.0
Batch: 560; loss: 0.03; acc: 0.98
Batch: 580; loss: 0.04; acc: 1.0
Batch: 600; loss: 0.05; acc: 0.98
Batch: 620; loss: 0.09; acc: 0.98
Batch: 640; loss: 0.03; acc: 1.0
Batch: 660; loss: 0.03; acc: 1.0
Batch: 680; loss: 0.08; acc: 0.98
Batch: 700; loss: 0.15; acc: 0.95
Batch: 720; loss: 0.09; acc: 0.97
Batch: 740; loss: 0.09; acc: 0.98
Batch: 760; loss: 0.08; acc: 0.97
Batch: 780; loss: 0.13; acc: 0.98
Train Epoch over. train_loss: 0.08; train_accuracy: 0.98 

3.072423714911565e-05
1.3400549505604431e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.12; acc: 0.94
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.0841657648776557; val_accuracy: 0.9746218152866242 

The current subspace-distance is: 1.3400549505604431e-05 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.06; acc: 0.97
Batch: 20; loss: 0.03; acc: 1.0
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.08; acc: 0.98
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.11; acc: 0.97
Batch: 120; loss: 0.05; acc: 0.98
Batch: 140; loss: 0.15; acc: 0.95
Batch: 160; loss: 0.04; acc: 0.98
Batch: 180; loss: 0.02; acc: 1.0
Batch: 200; loss: 0.05; acc: 0.97
Batch: 220; loss: 0.03; acc: 0.98
Batch: 240; loss: 0.02; acc: 1.0
Batch: 260; loss: 0.08; acc: 0.97
Batch: 280; loss: 0.08; acc: 0.98
Batch: 300; loss: 0.1; acc: 0.95
Batch: 320; loss: 0.11; acc: 0.95
Batch: 340; loss: 0.06; acc: 0.98
Batch: 360; loss: 0.03; acc: 1.0
Batch: 380; loss: 0.08; acc: 0.97
Batch: 400; loss: 0.05; acc: 0.98
Batch: 420; loss: 0.13; acc: 0.94
Batch: 440; loss: 0.02; acc: 1.0
Batch: 460; loss: 0.04; acc: 0.98
Batch: 480; loss: 0.15; acc: 0.95
Batch: 500; loss: 0.07; acc: 0.98
Batch: 520; loss: 0.02; acc: 1.0
Batch: 540; loss: 0.16; acc: 0.95
Batch: 560; loss: 0.17; acc: 0.91
Batch: 580; loss: 0.07; acc: 0.97
Batch: 600; loss: 0.11; acc: 0.97
Batch: 620; loss: 0.09; acc: 0.98
Batch: 640; loss: 0.05; acc: 0.98
Batch: 660; loss: 0.07; acc: 0.94
Batch: 680; loss: 0.03; acc: 0.98
Batch: 700; loss: 0.04; acc: 0.98
Batch: 720; loss: 0.14; acc: 0.95
Batch: 740; loss: 0.05; acc: 0.98
Batch: 760; loss: 0.08; acc: 0.97
Batch: 780; loss: 0.01; acc: 1.0
Train Epoch over. train_loss: 0.08; train_accuracy: 0.98 

3.0357368814293295e-05
1.3553703865909483e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.12; acc: 0.92
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.0845555149339092; val_accuracy: 0.9743232484076433 

The current subspace-distance is: 1.3553703865909483e-05 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.04; acc: 1.0
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.03; acc: 1.0
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.01; acc: 1.0
Batch: 120; loss: 0.14; acc: 0.98
Batch: 140; loss: 0.06; acc: 0.98
Batch: 160; loss: 0.08; acc: 0.97
Batch: 180; loss: 0.03; acc: 0.98
Batch: 200; loss: 0.11; acc: 0.97
Batch: 220; loss: 0.06; acc: 0.98
Batch: 240; loss: 0.06; acc: 0.98
Batch: 260; loss: 0.1; acc: 0.97
Batch: 280; loss: 0.1; acc: 0.95
Batch: 300; loss: 0.12; acc: 0.97
Batch: 320; loss: 0.02; acc: 1.0
Batch: 340; loss: 0.13; acc: 0.97
Batch: 360; loss: 0.08; acc: 0.98
Batch: 380; loss: 0.03; acc: 0.98
Batch: 400; loss: 0.13; acc: 0.94
Batch: 420; loss: 0.04; acc: 0.97
Batch: 440; loss: 0.03; acc: 1.0
Batch: 460; loss: 0.03; acc: 1.0
Batch: 480; loss: 0.04; acc: 0.98
Batch: 500; loss: 0.12; acc: 0.97
Batch: 520; loss: 0.11; acc: 0.95
Batch: 540; loss: 0.03; acc: 0.98
Batch: 560; loss: 0.13; acc: 0.95
Batch: 580; loss: 0.03; acc: 0.98
Batch: 600; loss: 0.11; acc: 0.95
Batch: 620; loss: 0.01; acc: 1.0
Batch: 640; loss: 0.17; acc: 0.95
Batch: 660; loss: 0.09; acc: 0.95
Batch: 680; loss: 0.05; acc: 0.98
Batch: 700; loss: 0.02; acc: 0.98
Batch: 720; loss: 0.04; acc: 1.0
Batch: 740; loss: 0.12; acc: 0.95
Batch: 760; loss: 0.13; acc: 0.97
Batch: 780; loss: 0.19; acc: 0.94
Train Epoch over. train_loss: 0.08; train_accuracy: 0.98 

3.077237488469109e-05
1.4308365280157886e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.1; acc: 0.97
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.13; acc: 0.94
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.08445772757030028; val_accuracy: 0.9741242038216561 

The current subspace-distance is: 1.4308365280157886e-05 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.08; acc: 0.95
Batch: 20; loss: 0.08; acc: 0.98
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.09; acc: 0.97
Batch: 80; loss: 0.28; acc: 0.97
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.02; acc: 1.0
Batch: 140; loss: 0.08; acc: 0.98
Batch: 160; loss: 0.12; acc: 0.97
Batch: 180; loss: 0.02; acc: 1.0
Batch: 200; loss: 0.09; acc: 0.97
Batch: 220; loss: 0.09; acc: 0.97
Batch: 240; loss: 0.04; acc: 0.97
Batch: 260; loss: 0.26; acc: 0.95
Batch: 280; loss: 0.04; acc: 0.98
Batch: 300; loss: 0.01; acc: 1.0
Batch: 320; loss: 0.06; acc: 0.98
Batch: 340; loss: 0.02; acc: 1.0
Batch: 360; loss: 0.09; acc: 0.97
Batch: 380; loss: 0.07; acc: 0.98
Batch: 400; loss: 0.11; acc: 0.95
Batch: 420; loss: 0.12; acc: 0.97
Batch: 440; loss: 0.05; acc: 0.98
Batch: 460; loss: 0.08; acc: 0.98
Batch: 480; loss: 0.17; acc: 0.95
Batch: 500; loss: 0.03; acc: 0.98
Batch: 520; loss: 0.08; acc: 0.95
Batch: 540; loss: 0.04; acc: 0.98
Batch: 560; loss: 0.19; acc: 0.94
Batch: 580; loss: 0.15; acc: 0.97
Batch: 600; loss: 0.16; acc: 0.97
Batch: 620; loss: 0.05; acc: 0.98
Batch: 640; loss: 0.02; acc: 1.0
Batch: 660; loss: 0.04; acc: 1.0
Batch: 680; loss: 0.11; acc: 0.97
Batch: 700; loss: 0.04; acc: 0.98
Batch: 720; loss: 0.08; acc: 0.98
Batch: 740; loss: 0.13; acc: 0.98
Batch: 760; loss: 0.05; acc: 0.97
Batch: 780; loss: 0.22; acc: 0.97
Train Epoch over. train_loss: 0.08; train_accuracy: 0.98 

3.0079980206210166e-05
1.3443870557239279e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.1; acc: 0.97
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.12; acc: 0.94
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.0845779768861593; val_accuracy: 0.9745222929936306 

The current subspace-distance is: 1.3443870557239279e-05 

plots/subspace_training/reg_lenet_3/2020-01-22 20:51:04/d_dim_450_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
nonzero elements in E: 105557
elements in E: 22495000
fraction nonzero: 0.004692464992220494
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.31; acc: 0.08
Batch: 20; loss: 2.29; acc: 0.05
Batch: 40; loss: 2.3; acc: 0.09
Batch: 60; loss: 2.3; acc: 0.02
Batch: 80; loss: 2.29; acc: 0.08
Batch: 100; loss: 2.29; acc: 0.12
Batch: 120; loss: 2.29; acc: 0.11
Batch: 140; loss: 2.3; acc: 0.09
Batch: 160; loss: 2.29; acc: 0.11
Batch: 180; loss: 2.28; acc: 0.14
Batch: 200; loss: 2.27; acc: 0.19
Batch: 220; loss: 2.27; acc: 0.19
Batch: 240; loss: 2.26; acc: 0.23
Batch: 260; loss: 2.26; acc: 0.25
Batch: 280; loss: 2.2; acc: 0.23
Batch: 300; loss: 2.14; acc: 0.23
Batch: 320; loss: 2.05; acc: 0.44
Batch: 340; loss: 1.89; acc: 0.48
Batch: 360; loss: 1.67; acc: 0.52
Batch: 380; loss: 1.3; acc: 0.56
Batch: 400; loss: 1.9; acc: 0.38
Batch: 420; loss: 0.96; acc: 0.67
Batch: 440; loss: 1.01; acc: 0.67
Batch: 460; loss: 0.7; acc: 0.8
Batch: 480; loss: 0.69; acc: 0.81
Batch: 500; loss: 0.69; acc: 0.83
Batch: 520; loss: 0.61; acc: 0.77
Batch: 540; loss: 0.56; acc: 0.83
Batch: 560; loss: 0.63; acc: 0.81
Batch: 580; loss: 0.5; acc: 0.84
Batch: 600; loss: 0.34; acc: 0.88
Batch: 620; loss: 0.67; acc: 0.78
Batch: 640; loss: 0.6; acc: 0.78
Batch: 660; loss: 0.52; acc: 0.89
Batch: 680; loss: 0.49; acc: 0.84
Batch: 700; loss: 0.52; acc: 0.78
Batch: 720; loss: 0.33; acc: 0.89
Batch: 740; loss: 0.41; acc: 0.86
Batch: 760; loss: 0.46; acc: 0.86
Batch: 780; loss: 0.49; acc: 0.8
Train Epoch over. train_loss: 1.41; train_accuracy: 0.5 

1.491503917350201e-05
8.450836503470782e-06
Batch: 0; loss: 0.46; acc: 0.83
Batch: 20; loss: 0.64; acc: 0.77
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.63; acc: 0.81
Batch: 80; loss: 0.22; acc: 0.91
Batch: 100; loss: 0.48; acc: 0.91
Batch: 120; loss: 0.78; acc: 0.73
Batch: 140; loss: 0.31; acc: 0.89
Val Epoch over. val_loss: 0.43370666516244794; val_accuracy: 0.8675358280254777 

The current subspace-distance is: 8.450836503470782e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 0.44; acc: 0.86
Batch: 20; loss: 0.37; acc: 0.88
Batch: 40; loss: 0.28; acc: 0.91
Batch: 60; loss: 0.47; acc: 0.89
Batch: 80; loss: 0.41; acc: 0.89
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.4; acc: 0.94
Batch: 140; loss: 0.37; acc: 0.89
Batch: 160; loss: 0.49; acc: 0.88
Batch: 180; loss: 0.35; acc: 0.88
Batch: 200; loss: 0.37; acc: 0.92
Batch: 220; loss: 0.59; acc: 0.77
Batch: 240; loss: 0.33; acc: 0.89
Batch: 260; loss: 0.33; acc: 0.89
Batch: 280; loss: 0.37; acc: 0.89
Batch: 300; loss: 0.27; acc: 0.95
Batch: 320; loss: 0.3; acc: 0.92
Batch: 340; loss: 0.35; acc: 0.88
Batch: 360; loss: 0.2; acc: 0.88
Batch: 380; loss: 0.19; acc: 0.97
Batch: 400; loss: 0.24; acc: 0.94
Batch: 420; loss: 0.29; acc: 0.92
Batch: 440; loss: 0.54; acc: 0.91
Batch: 460; loss: 0.42; acc: 0.83
Batch: 480; loss: 0.17; acc: 0.94
Batch: 500; loss: 0.34; acc: 0.89
Batch: 520; loss: 0.13; acc: 0.94
Batch: 540; loss: 0.21; acc: 0.95
Batch: 560; loss: 0.23; acc: 0.92
Batch: 580; loss: 0.19; acc: 0.94
Batch: 600; loss: 0.4; acc: 0.88
Batch: 620; loss: 0.2; acc: 0.94
Batch: 640; loss: 0.32; acc: 0.88
Batch: 660; loss: 0.29; acc: 0.89
Batch: 680; loss: 0.33; acc: 0.89
Batch: 700; loss: 0.22; acc: 0.92
Batch: 720; loss: 0.29; acc: 0.94
Batch: 740; loss: 0.33; acc: 0.92
Batch: 760; loss: 0.41; acc: 0.91
Batch: 780; loss: 0.34; acc: 0.91
Train Epoch over. train_loss: 0.31; train_accuracy: 0.9 

2.1739610019722022e-05
1.0794329682539683e-05
Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.45; acc: 0.86
Batch: 80; loss: 0.19; acc: 0.92
Batch: 100; loss: 0.39; acc: 0.91
Batch: 120; loss: 0.57; acc: 0.81
Batch: 140; loss: 0.09; acc: 0.98
Val Epoch over. val_loss: 0.24888993737993725; val_accuracy: 0.923765923566879 

The current subspace-distance is: 1.0794329682539683e-05 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.31; acc: 0.91
Batch: 20; loss: 0.2; acc: 0.95
Batch: 40; loss: 0.26; acc: 0.92
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.39; acc: 0.86
Batch: 120; loss: 0.18; acc: 0.97
Batch: 140; loss: 0.32; acc: 0.86
Batch: 160; loss: 0.21; acc: 0.95
Batch: 180; loss: 0.13; acc: 0.95
Batch: 200; loss: 0.2; acc: 0.92
Batch: 220; loss: 0.16; acc: 0.97
Batch: 240; loss: 0.24; acc: 0.91
Batch: 260; loss: 0.28; acc: 0.89
Batch: 280; loss: 0.14; acc: 0.95
Batch: 300; loss: 0.17; acc: 0.95
Batch: 320; loss: 0.19; acc: 0.95
Batch: 340; loss: 0.16; acc: 0.95
Batch: 360; loss: 0.25; acc: 0.94
Batch: 380; loss: 0.41; acc: 0.95
Batch: 400; loss: 0.27; acc: 0.98
Batch: 420; loss: 0.25; acc: 0.91
Batch: 440; loss: 0.09; acc: 0.97
Batch: 460; loss: 0.23; acc: 0.92
Batch: 480; loss: 0.2; acc: 0.89
Batch: 500; loss: 0.22; acc: 0.89
Batch: 520; loss: 0.04; acc: 1.0
Batch: 540; loss: 0.14; acc: 0.95
Batch: 560; loss: 0.14; acc: 0.94
Batch: 580; loss: 0.25; acc: 0.94
Batch: 600; loss: 0.13; acc: 0.95
Batch: 620; loss: 0.31; acc: 0.89
Batch: 640; loss: 0.1; acc: 0.97
Batch: 660; loss: 0.23; acc: 0.92
Batch: 680; loss: 0.28; acc: 0.91
Batch: 700; loss: 0.13; acc: 0.98
Batch: 720; loss: 0.08; acc: 0.98
Batch: 740; loss: 0.13; acc: 0.94
Batch: 760; loss: 0.12; acc: 0.97
Batch: 780; loss: 0.2; acc: 0.95
Train Epoch over. train_loss: 0.21; train_accuracy: 0.94 

2.5092904252232984e-05
1.1783452464442234e-05
Batch: 0; loss: 0.14; acc: 0.97
Batch: 20; loss: 0.19; acc: 0.92
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.35; acc: 0.92
Batch: 80; loss: 0.11; acc: 0.94
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.48; acc: 0.86
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.1746632168010162; val_accuracy: 0.9498407643312102 

The current subspace-distance is: 1.1783452464442234e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.13; acc: 0.94
Batch: 20; loss: 0.12; acc: 0.95
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.06; acc: 1.0
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.04; acc: 0.98
Batch: 120; loss: 0.07; acc: 0.97
Batch: 140; loss: 0.13; acc: 0.97
Batch: 160; loss: 0.1; acc: 0.97
Batch: 180; loss: 0.16; acc: 0.95
Batch: 200; loss: 0.11; acc: 0.95
Batch: 220; loss: 0.46; acc: 0.92
Batch: 240; loss: 0.25; acc: 0.92
Batch: 260; loss: 0.07; acc: 0.98
Batch: 280; loss: 0.3; acc: 0.94
Batch: 300; loss: 0.21; acc: 0.97
Batch: 320; loss: 0.14; acc: 0.92
Batch: 340; loss: 0.14; acc: 0.97
Batch: 360; loss: 0.16; acc: 0.91
Batch: 380; loss: 0.19; acc: 0.92
Batch: 400; loss: 0.1; acc: 0.98
Batch: 420; loss: 0.22; acc: 0.92
Batch: 440; loss: 0.05; acc: 0.98
Batch: 460; loss: 0.13; acc: 0.95
Batch: 480; loss: 0.2; acc: 0.91
Batch: 500; loss: 0.08; acc: 0.97
Batch: 520; loss: 0.06; acc: 0.98
Batch: 540; loss: 0.09; acc: 0.97
Batch: 560; loss: 0.2; acc: 0.92
Batch: 580; loss: 0.15; acc: 0.95
Batch: 600; loss: 0.14; acc: 0.95
Batch: 620; loss: 0.24; acc: 0.92
Batch: 640; loss: 0.12; acc: 0.97
Batch: 660; loss: 0.25; acc: 0.91
Batch: 680; loss: 0.18; acc: 0.92
Batch: 700; loss: 0.11; acc: 0.97
Batch: 720; loss: 0.21; acc: 0.92
Batch: 740; loss: 0.21; acc: 0.95
Batch: 760; loss: 0.15; acc: 0.97
Batch: 780; loss: 0.09; acc: 0.97
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

2.616256824694574e-05
1.2298542969801929e-05
Batch: 0; loss: 0.07; acc: 0.97
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.21; acc: 0.91
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.42; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14513362495667614; val_accuracy: 0.9561106687898089 

The current subspace-distance is: 1.2298542969801929e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.08; acc: 0.97
Batch: 20; loss: 0.1; acc: 0.95
Batch: 40; loss: 0.29; acc: 0.94
Batch: 60; loss: 0.22; acc: 0.95
Batch: 80; loss: 0.19; acc: 0.92
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.07; acc: 0.98
Batch: 140; loss: 0.1; acc: 0.98
Batch: 160; loss: 0.06; acc: 0.98
Batch: 180; loss: 0.04; acc: 1.0
Batch: 200; loss: 0.04; acc: 0.98
Batch: 220; loss: 0.2; acc: 0.92
Batch: 240; loss: 0.16; acc: 0.97
Batch: 260; loss: 0.06; acc: 0.97
Batch: 280; loss: 0.09; acc: 0.97
Batch: 300; loss: 0.1; acc: 0.97
Batch: 320; loss: 0.1; acc: 0.97
Batch: 340; loss: 0.09; acc: 0.97
Batch: 360; loss: 0.08; acc: 0.98
Batch: 380; loss: 0.04; acc: 0.98
Batch: 400; loss: 0.31; acc: 0.91
Batch: 420; loss: 0.09; acc: 0.97
Batch: 440; loss: 0.06; acc: 0.98
Batch: 460; loss: 0.19; acc: 0.92
Batch: 480; loss: 0.2; acc: 0.94
Batch: 500; loss: 0.19; acc: 0.95
Batch: 520; loss: 0.05; acc: 0.98
Batch: 540; loss: 0.03; acc: 1.0
Batch: 560; loss: 0.27; acc: 0.92
Batch: 580; loss: 0.16; acc: 0.94
Batch: 600; loss: 0.04; acc: 1.0
Batch: 620; loss: 0.11; acc: 0.95
Batch: 640; loss: 0.1; acc: 0.97
Batch: 660; loss: 0.32; acc: 0.92
Batch: 680; loss: 0.06; acc: 0.98
Batch: 700; loss: 0.11; acc: 0.95
Batch: 720; loss: 0.12; acc: 0.98
Batch: 740; loss: 0.14; acc: 0.95
Batch: 760; loss: 0.11; acc: 0.95
Batch: 780; loss: 0.13; acc: 0.94
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

2.74854464805685e-05
1.3563390893978067e-05
Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.21; acc: 0.89
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.29; acc: 0.94
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.44; acc: 0.83
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.15486689526469086; val_accuracy: 0.9535230891719745 

The current subspace-distance is: 1.3563390893978067e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.27; acc: 0.89
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.17; acc: 0.92
Batch: 60; loss: 0.12; acc: 0.97
Batch: 80; loss: 0.03; acc: 1.0
Batch: 100; loss: 0.07; acc: 0.98
Batch: 120; loss: 0.12; acc: 0.95
Batch: 140; loss: 0.18; acc: 0.94
Batch: 160; loss: 0.1; acc: 0.97
Batch: 180; loss: 0.06; acc: 0.98
Batch: 200; loss: 0.11; acc: 0.95
Batch: 220; loss: 0.05; acc: 0.98
Batch: 240; loss: 0.11; acc: 0.95
Batch: 260; loss: 0.18; acc: 0.95
Batch: 280; loss: 0.05; acc: 0.98
Batch: 300; loss: 0.18; acc: 0.94
Batch: 320; loss: 0.11; acc: 0.94
Batch: 340; loss: 0.11; acc: 0.97
Batch: 360; loss: 0.24; acc: 0.92
Batch: 380; loss: 0.23; acc: 0.94
Batch: 400; loss: 0.17; acc: 0.92
Batch: 420; loss: 0.12; acc: 0.97
Batch: 440; loss: 0.19; acc: 0.97
Batch: 460; loss: 0.2; acc: 0.94
Batch: 480; loss: 0.11; acc: 0.95
Batch: 500; loss: 0.14; acc: 0.95
Batch: 520; loss: 0.17; acc: 0.95
Batch: 540; loss: 0.06; acc: 0.98
Batch: 560; loss: 0.17; acc: 0.97
Batch: 580; loss: 0.07; acc: 0.97
Batch: 600; loss: 0.06; acc: 0.97
Batch: 620; loss: 0.03; acc: 1.0
Batch: 640; loss: 0.11; acc: 0.97
Batch: 660; loss: 0.21; acc: 0.95
Batch: 680; loss: 0.08; acc: 0.98
Batch: 700; loss: 0.09; acc: 0.97
Batch: 720; loss: 0.27; acc: 0.92
Batch: 740; loss: 0.16; acc: 0.95
Batch: 760; loss: 0.11; acc: 0.97
Batch: 780; loss: 0.09; acc: 0.95
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

2.848139229172375e-05
1.3717249203182291e-05
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.22; acc: 0.92
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.1; acc: 0.95
Batch: 120; loss: 0.29; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.12330418732610478; val_accuracy: 0.9619824840764332 

The current subspace-distance is: 1.3717249203182291e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.26; acc: 0.92
Batch: 20; loss: 0.03; acc: 1.0
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.09; acc: 0.98
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.12; acc: 0.92
Batch: 120; loss: 0.04; acc: 1.0
Batch: 140; loss: 0.26; acc: 0.91
Batch: 160; loss: 0.13; acc: 0.95
Batch: 180; loss: 0.13; acc: 0.97
Batch: 200; loss: 0.28; acc: 0.91
Batch: 220; loss: 0.05; acc: 1.0
Batch: 240; loss: 0.15; acc: 0.95
Batch: 260; loss: 0.15; acc: 0.95
Batch: 280; loss: 0.12; acc: 0.95
Batch: 300; loss: 0.11; acc: 0.98
Batch: 320; loss: 0.05; acc: 0.97
Batch: 340; loss: 0.13; acc: 0.97
Batch: 360; loss: 0.13; acc: 0.98
Batch: 380; loss: 0.11; acc: 0.97
Batch: 400; loss: 0.11; acc: 0.97
Batch: 420; loss: 0.08; acc: 0.97
Batch: 440; loss: 0.15; acc: 0.95
Batch: 460; loss: 0.05; acc: 0.98
Batch: 480; loss: 0.07; acc: 0.98
Batch: 500; loss: 0.02; acc: 1.0
Batch: 520; loss: 0.06; acc: 0.98
Batch: 540; loss: 0.1; acc: 0.94
Batch: 560; loss: 0.05; acc: 0.97
Batch: 580; loss: 0.03; acc: 1.0
Batch: 600; loss: 0.04; acc: 1.0
Batch: 620; loss: 0.08; acc: 0.98
Batch: 640; loss: 0.22; acc: 0.92
Batch: 660; loss: 0.11; acc: 0.97
Batch: 680; loss: 0.13; acc: 0.94
Batch: 700; loss: 0.28; acc: 0.92
Batch: 720; loss: 0.05; acc: 0.98
Batch: 740; loss: 0.04; acc: 0.98
Batch: 760; loss: 0.1; acc: 0.97
Batch: 780; loss: 0.04; acc: 0.98
Train Epoch over. train_loss: 0.12; train_accuracy: 0.96 

2.8710603146464564e-05
1.3695181223738473e-05
Batch: 0; loss: 0.05; acc: 0.98
Batch: 20; loss: 0.14; acc: 0.97
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.17; acc: 0.94
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.07; acc: 0.95
Batch: 120; loss: 0.43; acc: 0.88
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.11943403090451174; val_accuracy: 0.9646695859872612 

The current subspace-distance is: 1.3695181223738473e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.16; acc: 0.97
Batch: 20; loss: 0.02; acc: 1.0
Batch: 40; loss: 0.11; acc: 0.98
Batch: 60; loss: 0.13; acc: 0.97
Batch: 80; loss: 0.19; acc: 0.92
Batch: 100; loss: 0.07; acc: 0.98
Batch: 120; loss: 0.15; acc: 0.94
Batch: 140; loss: 0.21; acc: 0.91
Batch: 160; loss: 0.06; acc: 0.98
Batch: 180; loss: 0.04; acc: 0.98
Batch: 200; loss: 0.06; acc: 0.98
Batch: 220; loss: 0.13; acc: 0.97
Batch: 240; loss: 0.11; acc: 0.95
Batch: 260; loss: 0.08; acc: 0.97
Batch: 280; loss: 0.33; acc: 0.92
Batch: 300; loss: 0.08; acc: 0.97
Batch: 320; loss: 0.19; acc: 0.92
Batch: 340; loss: 0.12; acc: 0.97
Batch: 360; loss: 0.07; acc: 0.98
Batch: 380; loss: 0.04; acc: 0.98
Batch: 400; loss: 0.05; acc: 0.98
Batch: 420; loss: 0.02; acc: 1.0
Batch: 440; loss: 0.2; acc: 0.94
Batch: 460; loss: 0.04; acc: 1.0
Batch: 480; loss: 0.12; acc: 0.97
Batch: 500; loss: 0.07; acc: 0.98
Batch: 520; loss: 0.14; acc: 0.95
Batch: 540; loss: 0.17; acc: 0.97
Batch: 560; loss: 0.1; acc: 0.97
Batch: 580; loss: 0.2; acc: 0.91
Batch: 600; loss: 0.18; acc: 0.94
Batch: 620; loss: 0.17; acc: 0.94
Batch: 640; loss: 0.01; acc: 1.0
Batch: 660; loss: 0.22; acc: 0.98
Batch: 680; loss: 0.08; acc: 0.97
Batch: 700; loss: 0.1; acc: 0.98
Batch: 720; loss: 0.08; acc: 0.98
Batch: 740; loss: 0.29; acc: 0.94
Batch: 760; loss: 0.1; acc: 0.95
Batch: 780; loss: 0.07; acc: 0.98
Train Epoch over. train_loss: 0.11; train_accuracy: 0.96 

2.9135528166079894e-05
1.3170219062885735e-05
Batch: 0; loss: 0.06; acc: 0.98
Batch: 20; loss: 0.15; acc: 0.94
Batch: 40; loss: 0.05; acc: 0.95
Batch: 60; loss: 0.28; acc: 0.92
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.43; acc: 0.86
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.11694063510816947; val_accuracy: 0.9644705414012739 

The current subspace-distance is: 1.3170219062885735e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.14; acc: 0.94
Batch: 20; loss: 0.05; acc: 0.97
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.12; acc: 0.97
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.08; acc: 0.95
Batch: 120; loss: 0.1; acc: 0.95
Batch: 140; loss: 0.12; acc: 0.94
Batch: 160; loss: 0.1; acc: 0.97
Batch: 180; loss: 0.14; acc: 0.95
Batch: 200; loss: 0.09; acc: 0.94
Batch: 220; loss: 0.04; acc: 1.0
Batch: 240; loss: 0.05; acc: 0.98
Batch: 260; loss: 0.05; acc: 0.97
Batch: 280; loss: 0.15; acc: 0.95
Batch: 300; loss: 0.04; acc: 0.98
Batch: 320; loss: 0.23; acc: 0.97
Batch: 340; loss: 0.18; acc: 0.94
Batch: 360; loss: 0.16; acc: 0.97
Batch: 380; loss: 0.1; acc: 0.97
Batch: 400; loss: 0.03; acc: 1.0
Batch: 420; loss: 0.05; acc: 0.97
Batch: 440; loss: 0.13; acc: 0.95
Batch: 460; loss: 0.02; acc: 1.0
Batch: 480; loss: 0.27; acc: 0.92
Batch: 500; loss: 0.21; acc: 0.95
Batch: 520; loss: 0.29; acc: 0.91
Batch: 540; loss: 0.27; acc: 0.91
Batch: 560; loss: 0.06; acc: 0.97
Batch: 580; loss: 0.13; acc: 0.94
Batch: 600; loss: 0.12; acc: 0.95
Batch: 620; loss: 0.08; acc: 0.95
Batch: 640; loss: 0.11; acc: 0.97
Batch: 660; loss: 0.16; acc: 0.95
Batch: 680; loss: 0.31; acc: 0.94
Batch: 700; loss: 0.11; acc: 0.97
Batch: 720; loss: 0.08; acc: 0.98
Batch: 740; loss: 0.05; acc: 0.98
Batch: 760; loss: 0.03; acc: 0.98
Batch: 780; loss: 0.22; acc: 0.91
Train Epoch over. train_loss: 0.11; train_accuracy: 0.97 

2.9630704375449568e-05
1.3410373867372982e-05
Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.08; acc: 0.97
Batch: 40; loss: 0.05; acc: 0.97
Batch: 60; loss: 0.18; acc: 0.95
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.31; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.10292262861588199; val_accuracy: 0.9685509554140127 

The current subspace-distance is: 1.3410373867372982e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.08; acc: 0.97
Batch: 20; loss: 0.05; acc: 0.98
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.08; acc: 0.95
Batch: 80; loss: 0.18; acc: 0.97
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.14; acc: 0.97
Batch: 140; loss: 0.09; acc: 0.97
Batch: 160; loss: 0.08; acc: 0.98
Batch: 180; loss: 0.04; acc: 0.97
Batch: 200; loss: 0.08; acc: 0.97
Batch: 220; loss: 0.29; acc: 0.95
Batch: 240; loss: 0.13; acc: 0.97
Batch: 260; loss: 0.1; acc: 0.97
Batch: 280; loss: 0.07; acc: 0.97
Batch: 300; loss: 0.01; acc: 1.0
Batch: 320; loss: 0.26; acc: 0.92
Batch: 340; loss: 0.12; acc: 0.97
Batch: 360; loss: 0.07; acc: 0.95
Batch: 380; loss: 0.03; acc: 0.98
Batch: 400; loss: 0.2; acc: 0.91
Batch: 420; loss: 0.11; acc: 0.97
Batch: 440; loss: 0.09; acc: 0.95
Batch: 460; loss: 0.21; acc: 0.95
Batch: 480; loss: 0.06; acc: 0.95
Batch: 500; loss: 0.06; acc: 0.97
Batch: 520; loss: 0.12; acc: 0.97
Batch: 540; loss: 0.06; acc: 0.97
Batch: 560; loss: 0.24; acc: 0.94
Batch: 580; loss: 0.21; acc: 0.97
Batch: 600; loss: 0.02; acc: 1.0
Batch: 620; loss: 0.18; acc: 0.94
Batch: 640; loss: 0.24; acc: 0.95
Batch: 660; loss: 0.08; acc: 0.95
Batch: 680; loss: 0.02; acc: 1.0
Batch: 700; loss: 0.26; acc: 0.91
Batch: 720; loss: 0.24; acc: 0.92
Batch: 740; loss: 0.15; acc: 0.95
Batch: 760; loss: 0.04; acc: 0.98
Batch: 780; loss: 0.15; acc: 0.95
Train Epoch over. train_loss: 0.11; train_accuracy: 0.97 

2.9934912163298577e-05
1.4255474525270984e-05
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.12; acc: 0.95
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.14; acc: 0.94
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.36; acc: 0.89
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.10791732029170747; val_accuracy: 0.9673566878980892 

The current subspace-distance is: 1.4255474525270984e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.1; acc: 0.97
Batch: 40; loss: 0.26; acc: 0.97
Batch: 60; loss: 0.03; acc: 1.0
Batch: 80; loss: 0.02; acc: 0.98
Batch: 100; loss: 0.02; acc: 1.0
Batch: 120; loss: 0.1; acc: 0.98
Batch: 140; loss: 0.09; acc: 0.98
Batch: 160; loss: 0.07; acc: 0.97
Batch: 180; loss: 0.13; acc: 0.95
Batch: 200; loss: 0.12; acc: 0.95
Batch: 220; loss: 0.09; acc: 0.98
Batch: 240; loss: 0.06; acc: 0.98
Batch: 260; loss: 0.03; acc: 1.0
Batch: 280; loss: 0.05; acc: 0.98
Batch: 300; loss: 0.03; acc: 1.0
Batch: 320; loss: 0.18; acc: 0.95
Batch: 340; loss: 0.07; acc: 0.97
Batch: 360; loss: 0.12; acc: 0.95
Batch: 380; loss: 0.26; acc: 0.95
Batch: 400; loss: 0.19; acc: 0.95
Batch: 420; loss: 0.03; acc: 1.0
Batch: 440; loss: 0.06; acc: 0.97
Batch: 460; loss: 0.02; acc: 1.0
Batch: 480; loss: 0.03; acc: 0.98
Batch: 500; loss: 0.09; acc: 0.94
Batch: 520; loss: 0.15; acc: 0.98
Batch: 540; loss: 0.05; acc: 1.0
Batch: 560; loss: 0.09; acc: 0.97
Batch: 580; loss: 0.1; acc: 0.97
Batch: 600; loss: 0.07; acc: 0.98
Batch: 620; loss: 0.02; acc: 1.0
Batch: 640; loss: 0.07; acc: 0.95
Batch: 660; loss: 0.27; acc: 0.94
Batch: 680; loss: 0.2; acc: 0.91
Batch: 700; loss: 0.04; acc: 0.98
Batch: 720; loss: 0.07; acc: 0.97
Batch: 740; loss: 0.12; acc: 0.98
Batch: 760; loss: 0.13; acc: 0.95
Batch: 780; loss: 0.09; acc: 0.98
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

3.012232446053531e-05
1.4114331861492246e-05
Batch: 0; loss: 0.02; acc: 0.98
Batch: 20; loss: 0.1; acc: 0.97
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.38; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.09830514529043702; val_accuracy: 0.9711385350318471 

The current subspace-distance is: 1.4114331861492246e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.04; acc: 0.98
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.08; acc: 0.98
Batch: 80; loss: 0.14; acc: 0.98
Batch: 100; loss: 0.04; acc: 0.98
Batch: 120; loss: 0.03; acc: 0.98
Batch: 140; loss: 0.18; acc: 0.95
Batch: 160; loss: 0.05; acc: 0.98
Batch: 180; loss: 0.02; acc: 1.0
Batch: 200; loss: 0.17; acc: 0.95
Batch: 220; loss: 0.02; acc: 1.0
Batch: 240; loss: 0.03; acc: 0.98
Batch: 260; loss: 0.06; acc: 0.98
Batch: 280; loss: 0.07; acc: 0.98
Batch: 300; loss: 0.05; acc: 0.97
Batch: 320; loss: 0.05; acc: 0.97
Batch: 340; loss: 0.16; acc: 0.95
Batch: 360; loss: 0.13; acc: 0.94
Batch: 380; loss: 0.07; acc: 0.97
Batch: 400; loss: 0.02; acc: 0.98
Batch: 420; loss: 0.06; acc: 0.98
Batch: 440; loss: 0.08; acc: 0.98
Batch: 460; loss: 0.29; acc: 0.89
Batch: 480; loss: 0.08; acc: 0.98
Batch: 500; loss: 0.19; acc: 0.94
Batch: 520; loss: 0.11; acc: 0.95
Batch: 540; loss: 0.12; acc: 0.97
Batch: 560; loss: 0.12; acc: 0.97
Batch: 580; loss: 0.03; acc: 0.98
Batch: 600; loss: 0.04; acc: 0.98
Batch: 620; loss: 0.18; acc: 0.94
Batch: 640; loss: 0.02; acc: 1.0
Batch: 660; loss: 0.06; acc: 0.98
Batch: 680; loss: 0.06; acc: 0.97
Batch: 700; loss: 0.02; acc: 1.0
Batch: 720; loss: 0.09; acc: 0.97
Batch: 740; loss: 0.22; acc: 0.92
Batch: 760; loss: 0.09; acc: 0.97
Batch: 780; loss: 0.05; acc: 0.98
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

3.0137038265820593e-05
1.4348769582284149e-05
Batch: 0; loss: 0.05; acc: 0.97
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.1; acc: 0.98
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.32; acc: 0.89
Batch: 140; loss: 0.02; acc: 0.98
Val Epoch over. val_loss: 0.12849258719261286; val_accuracy: 0.9619824840764332 

The current subspace-distance is: 1.4348769582284149e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.08; acc: 0.95
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.02; acc: 1.0
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.01; acc: 1.0
Batch: 120; loss: 0.11; acc: 0.97
Batch: 140; loss: 0.06; acc: 0.98
Batch: 160; loss: 0.03; acc: 1.0
Batch: 180; loss: 0.03; acc: 1.0
Batch: 200; loss: 0.11; acc: 0.95
Batch: 220; loss: 0.06; acc: 0.98
Batch: 240; loss: 0.04; acc: 0.98
Batch: 260; loss: 0.07; acc: 0.98
Batch: 280; loss: 0.09; acc: 0.95
Batch: 300; loss: 0.12; acc: 0.97
Batch: 320; loss: 0.04; acc: 0.98
Batch: 340; loss: 0.03; acc: 0.98
Batch: 360; loss: 0.06; acc: 0.97
Batch: 380; loss: 0.06; acc: 0.98
Batch: 400; loss: 0.08; acc: 0.98
Batch: 420; loss: 0.02; acc: 0.98
Batch: 440; loss: 0.07; acc: 0.97
Batch: 460; loss: 0.02; acc: 1.0
Batch: 480; loss: 0.04; acc: 0.98
Batch: 500; loss: 0.02; acc: 1.0
Batch: 520; loss: 0.03; acc: 0.98
Batch: 540; loss: 0.15; acc: 0.95
Batch: 560; loss: 0.01; acc: 1.0
Batch: 580; loss: 0.23; acc: 0.95
Batch: 600; loss: 0.1; acc: 0.97
Batch: 620; loss: 0.11; acc: 0.95
Batch: 640; loss: 0.04; acc: 1.0
Batch: 660; loss: 0.17; acc: 0.97
Batch: 680; loss: 0.1; acc: 0.97
Batch: 700; loss: 0.18; acc: 0.92
Batch: 720; loss: 0.05; acc: 0.97
Batch: 740; loss: 0.03; acc: 0.98
Batch: 760; loss: 0.08; acc: 0.98
Batch: 780; loss: 0.1; acc: 0.97
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

2.996296461788006e-05
1.3421235962596256e-05
Batch: 0; loss: 0.05; acc: 0.98
Batch: 20; loss: 0.12; acc: 0.97
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.18; acc: 0.95
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.11; acc: 0.95
Batch: 120; loss: 0.33; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.09700239015517721; val_accuracy: 0.9711385350318471 

The current subspace-distance is: 1.3421235962596256e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.08; acc: 0.95
Batch: 20; loss: 0.07; acc: 0.97
Batch: 40; loss: 0.07; acc: 0.95
Batch: 60; loss: 0.04; acc: 0.98
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.21; acc: 0.94
Batch: 140; loss: 0.1; acc: 0.98
Batch: 160; loss: 0.09; acc: 0.97
Batch: 180; loss: 0.05; acc: 0.98
Batch: 200; loss: 0.08; acc: 0.97
Batch: 220; loss: 0.16; acc: 0.97
Batch: 240; loss: 0.04; acc: 1.0
Batch: 260; loss: 0.08; acc: 0.98
Batch: 280; loss: 0.04; acc: 0.98
Batch: 300; loss: 0.12; acc: 0.97
Batch: 320; loss: 0.03; acc: 0.98
Batch: 340; loss: 0.07; acc: 0.98
Batch: 360; loss: 0.13; acc: 0.95
Batch: 380; loss: 0.04; acc: 0.98
Batch: 400; loss: 0.09; acc: 0.95
Batch: 420; loss: 0.07; acc: 0.98
Batch: 440; loss: 0.07; acc: 0.97
Batch: 460; loss: 0.04; acc: 0.98
Batch: 480; loss: 0.05; acc: 0.98
Batch: 500; loss: 0.24; acc: 0.95
Batch: 520; loss: 0.04; acc: 0.98
Batch: 540; loss: 0.01; acc: 1.0
Batch: 560; loss: 0.24; acc: 0.92
Batch: 580; loss: 0.13; acc: 0.94
Batch: 600; loss: 0.12; acc: 0.97
Batch: 620; loss: 0.17; acc: 0.95
Batch: 640; loss: 0.03; acc: 1.0
Batch: 660; loss: 0.06; acc: 0.97
Batch: 680; loss: 0.18; acc: 0.92
Batch: 700; loss: 0.19; acc: 0.97
Batch: 720; loss: 0.02; acc: 1.0
Batch: 740; loss: 0.03; acc: 1.0
Batch: 760; loss: 0.08; acc: 0.95
Batch: 780; loss: 0.15; acc: 0.94
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

3.043809556402266e-05
1.3629236491397023e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.08; acc: 0.97
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.13; acc: 0.95
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.27; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.09259430644143919; val_accuracy: 0.9724323248407644 

The current subspace-distance is: 1.3629236491397023e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.04; acc: 0.98
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.01; acc: 1.0
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.05; acc: 0.97
Batch: 120; loss: 0.09; acc: 0.95
Batch: 140; loss: 0.02; acc: 1.0
Batch: 160; loss: 0.08; acc: 0.98
Batch: 180; loss: 0.08; acc: 0.98
Batch: 200; loss: 0.04; acc: 0.98
Batch: 220; loss: 0.05; acc: 0.98
Batch: 240; loss: 0.16; acc: 0.94
Batch: 260; loss: 0.06; acc: 0.97
Batch: 280; loss: 0.06; acc: 0.97
Batch: 300; loss: 0.08; acc: 0.97
Batch: 320; loss: 0.22; acc: 0.97
Batch: 340; loss: 0.06; acc: 0.97
Batch: 360; loss: 0.21; acc: 0.94
Batch: 380; loss: 0.03; acc: 1.0
Batch: 400; loss: 0.24; acc: 0.94
Batch: 420; loss: 0.12; acc: 0.94
Batch: 440; loss: 0.11; acc: 0.94
Batch: 460; loss: 0.16; acc: 0.95
Batch: 480; loss: 0.06; acc: 0.98
Batch: 500; loss: 0.11; acc: 0.97
Batch: 520; loss: 0.02; acc: 1.0
Batch: 540; loss: 0.04; acc: 0.98
Batch: 560; loss: 0.07; acc: 0.97
Batch: 580; loss: 0.03; acc: 0.98
Batch: 600; loss: 0.1; acc: 0.95
Batch: 620; loss: 0.09; acc: 0.97
Batch: 640; loss: 0.14; acc: 0.94
Batch: 660; loss: 0.21; acc: 0.95
Batch: 680; loss: 0.07; acc: 0.97
Batch: 700; loss: 0.06; acc: 0.98
Batch: 720; loss: 0.12; acc: 0.95
Batch: 740; loss: 0.01; acc: 1.0
Batch: 760; loss: 0.1; acc: 0.95
Batch: 780; loss: 0.02; acc: 1.0
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

3.0263974622357637e-05
1.4295841538114473e-05
Batch: 0; loss: 0.06; acc: 0.98
Batch: 20; loss: 0.13; acc: 0.97
Batch: 40; loss: 0.04; acc: 0.97
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.02; acc: 0.98
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.27; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1066780237445406; val_accuracy: 0.966859076433121 

The current subspace-distance is: 1.4295841538114473e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.1; acc: 0.95
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.03; acc: 1.0
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.07; acc: 0.97
Batch: 140; loss: 0.04; acc: 0.98
Batch: 160; loss: 0.15; acc: 0.92
Batch: 180; loss: 0.17; acc: 0.97
Batch: 200; loss: 0.12; acc: 0.95
Batch: 220; loss: 0.01; acc: 1.0
Batch: 240; loss: 0.08; acc: 0.95
Batch: 260; loss: 0.08; acc: 0.97
Batch: 280; loss: 0.33; acc: 0.91
Batch: 300; loss: 0.03; acc: 0.98
Batch: 320; loss: 0.14; acc: 0.94
Batch: 340; loss: 0.12; acc: 0.97
Batch: 360; loss: 0.16; acc: 0.95
Batch: 380; loss: 0.2; acc: 0.97
Batch: 400; loss: 0.27; acc: 0.97
Batch: 420; loss: 0.12; acc: 0.97
Batch: 440; loss: 0.21; acc: 0.94
Batch: 460; loss: 0.09; acc: 0.98
Batch: 480; loss: 0.06; acc: 0.98
Batch: 500; loss: 0.14; acc: 0.95
Batch: 520; loss: 0.01; acc: 1.0
Batch: 540; loss: 0.05; acc: 0.98
Batch: 560; loss: 0.12; acc: 0.95
Batch: 580; loss: 0.06; acc: 0.98
Batch: 600; loss: 0.04; acc: 0.98
Batch: 620; loss: 0.06; acc: 0.97
Batch: 640; loss: 0.06; acc: 0.97
Batch: 660; loss: 0.04; acc: 0.98
Batch: 680; loss: 0.02; acc: 0.98
Batch: 700; loss: 0.18; acc: 0.95
Batch: 720; loss: 0.05; acc: 0.97
Batch: 740; loss: 0.02; acc: 1.0
Batch: 760; loss: 0.07; acc: 0.98
Batch: 780; loss: 0.09; acc: 0.98
Train Epoch over. train_loss: 0.08; train_accuracy: 0.97 

3.0133942345855758e-05
1.3526648217521142e-05
Batch: 0; loss: 0.02; acc: 0.98
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.02; acc: 0.98
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.27; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.09660293273390479; val_accuracy: 0.970640923566879 

The current subspace-distance is: 1.3526648217521142e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.08; acc: 0.95
Batch: 40; loss: 0.09; acc: 0.95
Batch: 60; loss: 0.07; acc: 0.97
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.19; acc: 0.97
Batch: 120; loss: 0.11; acc: 0.97
Batch: 140; loss: 0.02; acc: 1.0
Batch: 160; loss: 0.25; acc: 0.92
Batch: 180; loss: 0.07; acc: 0.98
Batch: 200; loss: 0.07; acc: 0.97
Batch: 220; loss: 0.09; acc: 0.97
Batch: 240; loss: 0.14; acc: 0.95
Batch: 260; loss: 0.05; acc: 0.97
Batch: 280; loss: 0.08; acc: 0.95
Batch: 300; loss: 0.15; acc: 0.95
Batch: 320; loss: 0.05; acc: 0.98
Batch: 340; loss: 0.04; acc: 0.98
Batch: 360; loss: 0.1; acc: 0.97
Batch: 380; loss: 0.08; acc: 0.98
Batch: 400; loss: 0.15; acc: 0.94
Batch: 420; loss: 0.13; acc: 0.95
Batch: 440; loss: 0.02; acc: 1.0
Batch: 460; loss: 0.07; acc: 0.98
Batch: 480; loss: 0.03; acc: 1.0
Batch: 500; loss: 0.04; acc: 0.98
Batch: 520; loss: 0.04; acc: 0.97
Batch: 540; loss: 0.07; acc: 0.95
Batch: 560; loss: 0.29; acc: 0.97
Batch: 580; loss: 0.05; acc: 0.97
Batch: 600; loss: 0.06; acc: 0.97
Batch: 620; loss: 0.04; acc: 0.98
Batch: 640; loss: 0.1; acc: 0.95
Batch: 660; loss: 0.12; acc: 0.95
Batch: 680; loss: 0.06; acc: 0.97
Batch: 700; loss: 0.0; acc: 1.0
Batch: 720; loss: 0.02; acc: 0.98
Batch: 740; loss: 0.09; acc: 0.97
Batch: 760; loss: 0.08; acc: 0.97
Batch: 780; loss: 0.17; acc: 0.94
Train Epoch over. train_loss: 0.08; train_accuracy: 0.97 

3.059602386201732e-05
1.4806077160756104e-05
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.19; acc: 0.95
Batch: 40; loss: 0.04; acc: 1.0
Batch: 60; loss: 0.2; acc: 0.95
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.11; acc: 0.95
Batch: 120; loss: 0.37; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1277579128220203; val_accuracy: 0.9596934713375797 

The current subspace-distance is: 1.4806077160756104e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.06; acc: 0.98
Batch: 20; loss: 0.01; acc: 1.0
Batch: 40; loss: 0.14; acc: 0.94
Batch: 60; loss: 0.05; acc: 0.98
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.04; acc: 1.0
Batch: 120; loss: 0.08; acc: 0.97
Batch: 140; loss: 0.07; acc: 0.97
Batch: 160; loss: 0.1; acc: 0.98
Batch: 180; loss: 0.09; acc: 0.94
Batch: 200; loss: 0.11; acc: 0.95
Batch: 220; loss: 0.02; acc: 1.0
Batch: 240; loss: 0.04; acc: 0.98
Batch: 260; loss: 0.11; acc: 0.95
Batch: 280; loss: 0.08; acc: 0.95
Batch: 300; loss: 0.19; acc: 0.97
Batch: 320; loss: 0.08; acc: 0.97
Batch: 340; loss: 0.05; acc: 0.97
Batch: 360; loss: 0.01; acc: 1.0
Batch: 380; loss: 0.02; acc: 0.98
Batch: 400; loss: 0.08; acc: 0.97
Batch: 420; loss: 0.04; acc: 0.97
Batch: 440; loss: 0.04; acc: 0.98
Batch: 460; loss: 0.03; acc: 1.0
Batch: 480; loss: 0.04; acc: 0.98
Batch: 500; loss: 0.04; acc: 0.98
Batch: 520; loss: 0.07; acc: 0.98
Batch: 540; loss: 0.06; acc: 0.98
Batch: 560; loss: 0.03; acc: 1.0
Batch: 580; loss: 0.12; acc: 0.94
Batch: 600; loss: 0.09; acc: 0.97
Batch: 620; loss: 0.02; acc: 1.0
Batch: 640; loss: 0.03; acc: 0.98
Batch: 660; loss: 0.04; acc: 0.98
Batch: 680; loss: 0.02; acc: 1.0
Batch: 700; loss: 0.17; acc: 0.97
Batch: 720; loss: 0.05; acc: 0.98
Batch: 740; loss: 0.08; acc: 0.97
Batch: 760; loss: 0.03; acc: 1.0
Batch: 780; loss: 0.02; acc: 0.98
Train Epoch over. train_loss: 0.08; train_accuracy: 0.97 

3.087183358729817e-05
1.4054109669814352e-05
Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.12; acc: 0.97
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.09; acc: 0.98
Batch: 120; loss: 0.31; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.09160040015247976; val_accuracy: 0.9726313694267515 

The current subspace-distance is: 1.4054109669814352e-05 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.09; acc: 0.95
Batch: 20; loss: 0.05; acc: 0.97
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.12; acc: 0.95
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.02; acc: 1.0
Batch: 140; loss: 0.22; acc: 0.89
Batch: 160; loss: 0.01; acc: 1.0
Batch: 180; loss: 0.17; acc: 0.95
Batch: 200; loss: 0.2; acc: 0.95
Batch: 220; loss: 0.11; acc: 0.95
Batch: 240; loss: 0.04; acc: 1.0
Batch: 260; loss: 0.22; acc: 0.95
Batch: 280; loss: 0.05; acc: 0.98
Batch: 300; loss: 0.03; acc: 0.98
Batch: 320; loss: 0.18; acc: 0.97
Batch: 340; loss: 0.11; acc: 0.95
Batch: 360; loss: 0.17; acc: 0.95
Batch: 380; loss: 0.02; acc: 1.0
Batch: 400; loss: 0.12; acc: 0.94
Batch: 420; loss: 0.05; acc: 0.98
Batch: 440; loss: 0.09; acc: 0.95
Batch: 460; loss: 0.06; acc: 0.97
Batch: 480; loss: 0.16; acc: 0.97
Batch: 500; loss: 0.12; acc: 0.97
Batch: 520; loss: 0.06; acc: 0.98
Batch: 540; loss: 0.05; acc: 0.98
Batch: 560; loss: 0.01; acc: 1.0
Batch: 580; loss: 0.15; acc: 0.97
Batch: 600; loss: 0.04; acc: 0.97
Batch: 620; loss: 0.1; acc: 0.97
Batch: 640; loss: 0.07; acc: 0.98
Batch: 660; loss: 0.02; acc: 0.98
Batch: 680; loss: 0.12; acc: 0.95
Batch: 700; loss: 0.04; acc: 0.98
Batch: 720; loss: 0.14; acc: 0.97
Batch: 740; loss: 0.06; acc: 0.97
Batch: 760; loss: 0.05; acc: 0.97
Batch: 780; loss: 0.07; acc: 0.98
Train Epoch over. train_loss: 0.08; train_accuracy: 0.97 

3.0563129257643595e-05
1.4393957826541737e-05
Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.16; acc: 0.94
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.07; acc: 0.98
Batch: 120; loss: 0.33; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.08777999963350357; val_accuracy: 0.9741242038216561 

The current subspace-distance is: 1.4393957826541737e-05 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.08; acc: 0.95
Batch: 40; loss: 0.18; acc: 0.97
Batch: 60; loss: 0.02; acc: 1.0
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.01; acc: 1.0
Batch: 120; loss: 0.09; acc: 0.98
Batch: 140; loss: 0.02; acc: 1.0
Batch: 160; loss: 0.09; acc: 0.98
Batch: 180; loss: 0.04; acc: 0.98
Batch: 200; loss: 0.17; acc: 0.98
Batch: 220; loss: 0.17; acc: 0.95
Batch: 240; loss: 0.01; acc: 1.0
Batch: 260; loss: 0.08; acc: 0.97
Batch: 280; loss: 0.05; acc: 0.98
Batch: 300; loss: 0.05; acc: 0.98
Batch: 320; loss: 0.2; acc: 0.95
Batch: 340; loss: 0.03; acc: 0.98
Batch: 360; loss: 0.07; acc: 0.97
Batch: 380; loss: 0.06; acc: 0.97
Batch: 400; loss: 0.08; acc: 0.98
Batch: 420; loss: 0.08; acc: 0.97
Batch: 440; loss: 0.04; acc: 0.98
Batch: 460; loss: 0.17; acc: 0.98
Batch: 480; loss: 0.04; acc: 0.98
Batch: 500; loss: 0.06; acc: 0.98
Batch: 520; loss: 0.09; acc: 0.97
Batch: 540; loss: 0.03; acc: 1.0
Batch: 560; loss: 0.23; acc: 0.97
Batch: 580; loss: 0.01; acc: 1.0
Batch: 600; loss: 0.1; acc: 0.97
Batch: 620; loss: 0.12; acc: 0.98
Batch: 640; loss: 0.06; acc: 0.97
Batch: 660; loss: 0.09; acc: 0.97
Batch: 680; loss: 0.13; acc: 0.97
Batch: 700; loss: 0.25; acc: 0.94
Batch: 720; loss: 0.16; acc: 0.97
Batch: 740; loss: 0.07; acc: 0.97
Batch: 760; loss: 0.17; acc: 0.97
Batch: 780; loss: 0.12; acc: 0.95
Train Epoch over. train_loss: 0.08; train_accuracy: 0.97 

3.067725265282206e-05
1.4352649486681912e-05
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.15; acc: 0.94
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.31; acc: 0.88
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.09558897515296176; val_accuracy: 0.9727308917197452 

The current subspace-distance is: 1.4352649486681912e-05 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.08; acc: 0.95
Batch: 20; loss: 0.07; acc: 0.97
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.06; acc: 1.0
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.03; acc: 0.98
Batch: 120; loss: 0.03; acc: 1.0
Batch: 140; loss: 0.04; acc: 0.98
Batch: 160; loss: 0.04; acc: 0.98
Batch: 180; loss: 0.04; acc: 0.98
Batch: 200; loss: 0.01; acc: 1.0
Batch: 220; loss: 0.04; acc: 0.98
Batch: 240; loss: 0.03; acc: 1.0
Batch: 260; loss: 0.07; acc: 0.98
Batch: 280; loss: 0.05; acc: 0.97
Batch: 300; loss: 0.11; acc: 0.95
Batch: 320; loss: 0.03; acc: 1.0
Batch: 340; loss: 0.03; acc: 1.0
Batch: 360; loss: 0.0; acc: 1.0
Batch: 380; loss: 0.05; acc: 0.97
Batch: 400; loss: 0.07; acc: 0.97
Batch: 420; loss: 0.06; acc: 0.98
Batch: 440; loss: 0.04; acc: 0.98
Batch: 460; loss: 0.01; acc: 1.0
Batch: 480; loss: 0.04; acc: 1.0
Batch: 500; loss: 0.04; acc: 0.98
Batch: 520; loss: 0.02; acc: 0.98
Batch: 540; loss: 0.02; acc: 1.0
Batch: 560; loss: 0.11; acc: 0.97
Batch: 580; loss: 0.02; acc: 1.0
Batch: 600; loss: 0.09; acc: 0.95
Batch: 620; loss: 0.15; acc: 0.97
Batch: 640; loss: 0.12; acc: 0.95
Batch: 660; loss: 0.02; acc: 1.0
Batch: 680; loss: 0.11; acc: 0.98
Batch: 700; loss: 0.02; acc: 1.0
Batch: 720; loss: 0.07; acc: 0.98
Batch: 740; loss: 0.02; acc: 1.0
Batch: 760; loss: 0.12; acc: 0.95
Batch: 780; loss: 0.11; acc: 0.97
Train Epoch over. train_loss: 0.08; train_accuracy: 0.98 

3.089725214522332e-05
1.4610141988669056e-05
Batch: 0; loss: 0.05; acc: 0.98
Batch: 20; loss: 0.12; acc: 0.97
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.22; acc: 0.95
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.08; acc: 0.97
Batch: 120; loss: 0.29; acc: 0.86
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.09023920116815598; val_accuracy: 0.973328025477707 

The current subspace-distance is: 1.4610141988669056e-05 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.02; acc: 1.0
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.01; acc: 1.0
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.13; acc: 0.97
Batch: 140; loss: 0.02; acc: 1.0
Batch: 160; loss: 0.13; acc: 0.94
Batch: 180; loss: 0.02; acc: 1.0
Batch: 200; loss: 0.23; acc: 0.95
Batch: 220; loss: 0.02; acc: 1.0
Batch: 240; loss: 0.01; acc: 1.0
Batch: 260; loss: 0.06; acc: 0.98
Batch: 280; loss: 0.02; acc: 1.0
Batch: 300; loss: 0.08; acc: 0.97
Batch: 320; loss: 0.2; acc: 0.95
Batch: 340; loss: 0.01; acc: 1.0
Batch: 360; loss: 0.07; acc: 0.95
Batch: 380; loss: 0.05; acc: 0.98
Batch: 400; loss: 0.08; acc: 0.97
Batch: 420; loss: 0.12; acc: 0.98
Batch: 440; loss: 0.07; acc: 0.98
Batch: 460; loss: 0.04; acc: 0.98
Batch: 480; loss: 0.03; acc: 1.0
Batch: 500; loss: 0.01; acc: 1.0
Batch: 520; loss: 0.28; acc: 0.95
Batch: 540; loss: 0.07; acc: 0.95
Batch: 560; loss: 0.03; acc: 1.0
Batch: 580; loss: 0.06; acc: 0.97
Batch: 600; loss: 0.01; acc: 1.0
Batch: 620; loss: 0.03; acc: 0.98
Batch: 640; loss: 0.06; acc: 0.98
Batch: 660; loss: 0.11; acc: 0.95
Batch: 680; loss: 0.05; acc: 0.98
Batch: 700; loss: 0.03; acc: 0.98
Batch: 720; loss: 0.02; acc: 1.0
Batch: 740; loss: 0.01; acc: 1.0
Batch: 760; loss: 0.06; acc: 0.97
Batch: 780; loss: 0.1; acc: 0.97
Train Epoch over. train_loss: 0.07; train_accuracy: 0.98 

3.076882057939656e-05
1.4871051462250762e-05
Batch: 0; loss: 0.05; acc: 0.98
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.02; acc: 0.98
Batch: 100; loss: 0.07; acc: 0.98
Batch: 120; loss: 0.29; acc: 0.86
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.09394665115815438; val_accuracy: 0.9713375796178344 

The current subspace-distance is: 1.4871051462250762e-05 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.09; acc: 0.95
Batch: 60; loss: 0.06; acc: 0.95
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.04; acc: 0.98
Batch: 120; loss: 0.36; acc: 0.94
Batch: 140; loss: 0.07; acc: 0.98
Batch: 160; loss: 0.03; acc: 1.0
Batch: 180; loss: 0.27; acc: 0.95
Batch: 200; loss: 0.09; acc: 0.95
Batch: 220; loss: 0.03; acc: 0.98
Batch: 240; loss: 0.07; acc: 0.98
Batch: 260; loss: 0.14; acc: 0.95
Batch: 280; loss: 0.03; acc: 1.0
Batch: 300; loss: 0.07; acc: 0.98
Batch: 320; loss: 0.16; acc: 0.94
Batch: 340; loss: 0.02; acc: 1.0
Batch: 360; loss: 0.05; acc: 0.98
Batch: 380; loss: 0.1; acc: 0.97
Batch: 400; loss: 0.04; acc: 0.98
Batch: 420; loss: 0.06; acc: 0.97
Batch: 440; loss: 0.29; acc: 0.92
Batch: 460; loss: 0.01; acc: 1.0
Batch: 480; loss: 0.05; acc: 0.98
Batch: 500; loss: 0.08; acc: 0.97
Batch: 520; loss: 0.23; acc: 0.94
Batch: 540; loss: 0.02; acc: 1.0
Batch: 560; loss: 0.19; acc: 0.95
Batch: 580; loss: 0.09; acc: 0.97
Batch: 600; loss: 0.06; acc: 0.98
Batch: 620; loss: 0.09; acc: 0.98
Batch: 640; loss: 0.05; acc: 0.98
Batch: 660; loss: 0.03; acc: 0.98
Batch: 680; loss: 0.04; acc: 0.98
Batch: 700; loss: 0.06; acc: 0.97
Batch: 720; loss: 0.04; acc: 0.98
Batch: 740; loss: 0.03; acc: 0.98
Batch: 760; loss: 0.01; acc: 1.0
Batch: 780; loss: 0.16; acc: 0.95
Train Epoch over. train_loss: 0.07; train_accuracy: 0.98 

3.0255241654231213e-05
1.4108505638432689e-05
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.21; acc: 0.95
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.08; acc: 0.98
Batch: 120; loss: 0.25; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.08944017470926996; val_accuracy: 0.9735270700636943 

The current subspace-distance is: 1.4108505638432689e-05 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.1; acc: 0.98
Batch: 20; loss: 0.06; acc: 0.98
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.16; acc: 0.98
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.03; acc: 1.0
Batch: 120; loss: 0.06; acc: 0.98
Batch: 140; loss: 0.15; acc: 0.91
Batch: 160; loss: 0.03; acc: 1.0
Batch: 180; loss: 0.08; acc: 0.97
Batch: 200; loss: 0.05; acc: 0.97
Batch: 220; loss: 0.14; acc: 0.95
Batch: 240; loss: 0.04; acc: 0.98
Batch: 260; loss: 0.07; acc: 0.97
Batch: 280; loss: 0.04; acc: 1.0
Batch: 300; loss: 0.07; acc: 0.97
Batch: 320; loss: 0.02; acc: 1.0
Batch: 340; loss: 0.06; acc: 0.97
Batch: 360; loss: 0.12; acc: 0.97
Batch: 380; loss: 0.03; acc: 1.0
Batch: 400; loss: 0.04; acc: 0.98
Batch: 420; loss: 0.05; acc: 0.98
Batch: 440; loss: 0.03; acc: 1.0
Batch: 460; loss: 0.04; acc: 1.0
Batch: 480; loss: 0.17; acc: 0.97
Batch: 500; loss: 0.07; acc: 0.97
Batch: 520; loss: 0.01; acc: 1.0
Batch: 540; loss: 0.09; acc: 0.98
Batch: 560; loss: 0.04; acc: 0.98
Batch: 580; loss: 0.06; acc: 0.98
Batch: 600; loss: 0.01; acc: 1.0
Batch: 620; loss: 0.04; acc: 1.0
Batch: 640; loss: 0.18; acc: 0.95
Batch: 660; loss: 0.08; acc: 0.98
Batch: 680; loss: 0.15; acc: 0.95
Batch: 700; loss: 0.04; acc: 0.97
Batch: 720; loss: 0.02; acc: 1.0
Batch: 740; loss: 0.18; acc: 0.94
Batch: 760; loss: 0.05; acc: 0.98
Batch: 780; loss: 0.1; acc: 0.97
Train Epoch over. train_loss: 0.07; train_accuracy: 0.98 

3.1074810976861045e-05
1.4488859960692935e-05
Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.08; acc: 0.97
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.07; acc: 0.98
Batch: 120; loss: 0.27; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.08566639864235927; val_accuracy: 0.9753184713375797 

The current subspace-distance is: 1.4488859960692935e-05 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.14; acc: 0.97
Batch: 20; loss: 0.23; acc: 0.95
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.02; acc: 0.98
Batch: 80; loss: 0.11; acc: 0.95
Batch: 100; loss: 0.11; acc: 0.97
Batch: 120; loss: 0.07; acc: 0.95
Batch: 140; loss: 0.09; acc: 0.97
Batch: 160; loss: 0.09; acc: 0.97
Batch: 180; loss: 0.11; acc: 0.97
Batch: 200; loss: 0.06; acc: 0.98
Batch: 220; loss: 0.04; acc: 0.97
Batch: 240; loss: 0.09; acc: 0.98
Batch: 260; loss: 0.02; acc: 1.0
Batch: 280; loss: 0.14; acc: 0.97
Batch: 300; loss: 0.02; acc: 0.98
Batch: 320; loss: 0.1; acc: 0.97
Batch: 340; loss: 0.03; acc: 1.0
Batch: 360; loss: 0.04; acc: 0.98
Batch: 380; loss: 0.16; acc: 0.95
Batch: 400; loss: 0.07; acc: 0.95
Batch: 420; loss: 0.05; acc: 0.97
Batch: 440; loss: 0.02; acc: 1.0
Batch: 460; loss: 0.13; acc: 0.97
Batch: 480; loss: 0.05; acc: 0.98
Batch: 500; loss: 0.11; acc: 0.98
Batch: 520; loss: 0.03; acc: 0.98
Batch: 540; loss: 0.17; acc: 0.95
Batch: 560; loss: 0.05; acc: 0.98
Batch: 580; loss: 0.03; acc: 0.98
Batch: 600; loss: 0.02; acc: 1.0
Batch: 620; loss: 0.03; acc: 0.98
Batch: 640; loss: 0.04; acc: 0.98
Batch: 660; loss: 0.08; acc: 0.97
Batch: 680; loss: 0.08; acc: 0.95
Batch: 700; loss: 0.16; acc: 0.98
Batch: 720; loss: 0.02; acc: 1.0
Batch: 740; loss: 0.08; acc: 0.98
Batch: 760; loss: 0.16; acc: 0.94
Batch: 780; loss: 0.06; acc: 0.98
Train Epoch over. train_loss: 0.07; train_accuracy: 0.98 

3.040220144612249e-05
1.412943129253108e-05
Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.02; acc: 0.98
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.28; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.08623558980454306; val_accuracy: 0.9741242038216561 

The current subspace-distance is: 1.412943129253108e-05 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.09; acc: 0.95
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.12; acc: 0.97
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.15; acc: 0.94
Batch: 120; loss: 0.03; acc: 0.98
Batch: 140; loss: 0.07; acc: 0.97
Batch: 160; loss: 0.06; acc: 0.95
Batch: 180; loss: 0.09; acc: 0.97
Batch: 200; loss: 0.03; acc: 1.0
Batch: 220; loss: 0.15; acc: 0.95
Batch: 240; loss: 0.11; acc: 0.95
Batch: 260; loss: 0.02; acc: 1.0
Batch: 280; loss: 0.08; acc: 0.97
Batch: 300; loss: 0.08; acc: 0.98
Batch: 320; loss: 0.03; acc: 0.98
Batch: 340; loss: 0.03; acc: 1.0
Batch: 360; loss: 0.08; acc: 0.95
Batch: 380; loss: 0.03; acc: 0.98
Batch: 400; loss: 0.05; acc: 0.97
Batch: 420; loss: 0.04; acc: 0.98
Batch: 440; loss: 0.01; acc: 1.0
Batch: 460; loss: 0.07; acc: 0.97
Batch: 480; loss: 0.07; acc: 0.98
Batch: 500; loss: 0.12; acc: 0.97
Batch: 520; loss: 0.07; acc: 0.97
Batch: 540; loss: 0.05; acc: 0.98
Batch: 560; loss: 0.02; acc: 1.0
Batch: 580; loss: 0.06; acc: 0.98
Batch: 600; loss: 0.07; acc: 0.97
Batch: 620; loss: 0.01; acc: 1.0
Batch: 640; loss: 0.2; acc: 0.95
Batch: 660; loss: 0.05; acc: 0.97
Batch: 680; loss: 0.02; acc: 1.0
Batch: 700; loss: 0.03; acc: 1.0
Batch: 720; loss: 0.03; acc: 0.98
Batch: 740; loss: 0.03; acc: 0.98
Batch: 760; loss: 0.1; acc: 0.97
Batch: 780; loss: 0.01; acc: 1.0
Train Epoch over. train_loss: 0.07; train_accuracy: 0.98 

3.0521798180416226e-05
1.3693079381482676e-05
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.21; acc: 0.95
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.09; acc: 0.98
Batch: 120; loss: 0.23; acc: 0.89
Batch: 140; loss: 0.01; acc: 0.98
Val Epoch over. val_loss: 0.09146835697684319; val_accuracy: 0.9730294585987261 

The current subspace-distance is: 1.3693079381482676e-05 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.06; acc: 0.98
Batch: 20; loss: 0.15; acc: 0.94
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.1; acc: 0.95
Batch: 80; loss: 0.12; acc: 0.94
Batch: 100; loss: 0.04; acc: 0.98
Batch: 120; loss: 0.03; acc: 1.0
Batch: 140; loss: 0.08; acc: 0.98
Batch: 160; loss: 0.13; acc: 0.95
Batch: 180; loss: 0.07; acc: 0.98
Batch: 200; loss: 0.04; acc: 0.98
Batch: 220; loss: 0.08; acc: 0.98
Batch: 240; loss: 0.03; acc: 1.0
Batch: 260; loss: 0.04; acc: 0.98
Batch: 280; loss: 0.08; acc: 0.97
Batch: 300; loss: 0.02; acc: 0.98
Batch: 320; loss: 0.03; acc: 0.98
Batch: 340; loss: 0.11; acc: 0.98
Batch: 360; loss: 0.06; acc: 0.98
Batch: 380; loss: 0.18; acc: 0.97
Batch: 400; loss: 0.01; acc: 1.0
Batch: 420; loss: 0.16; acc: 0.95
Batch: 440; loss: 0.01; acc: 1.0
Batch: 460; loss: 0.21; acc: 0.97
Batch: 480; loss: 0.06; acc: 0.95
Batch: 500; loss: 0.12; acc: 0.97
Batch: 520; loss: 0.11; acc: 0.98
Batch: 540; loss: 0.06; acc: 0.98
Batch: 560; loss: 0.14; acc: 0.97
Batch: 580; loss: 0.18; acc: 0.97
Batch: 600; loss: 0.09; acc: 0.97
Batch: 620; loss: 0.13; acc: 0.97
Batch: 640; loss: 0.03; acc: 1.0
Batch: 660; loss: 0.15; acc: 0.97
Batch: 680; loss: 0.09; acc: 0.97
Batch: 700; loss: 0.1; acc: 0.94
Batch: 720; loss: 0.03; acc: 0.98
Batch: 740; loss: 0.05; acc: 0.98
Batch: 760; loss: 0.14; acc: 0.95
Batch: 780; loss: 0.03; acc: 1.0
Train Epoch over. train_loss: 0.07; train_accuracy: 0.98 

3.125415969407186e-05
1.5024844287836459e-05
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.1; acc: 0.97
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.18; acc: 0.95
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.08; acc: 0.98
Batch: 120; loss: 0.28; acc: 0.91
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.08573303909106239; val_accuracy: 0.9749203821656051 

The current subspace-distance is: 1.5024844287836459e-05 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.05; acc: 0.98
Batch: 20; loss: 0.24; acc: 0.97
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.05; acc: 0.98
Batch: 80; loss: 0.06; acc: 0.97
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.02; acc: 0.98
Batch: 140; loss: 0.09; acc: 0.98
Batch: 160; loss: 0.02; acc: 1.0
Batch: 180; loss: 0.1; acc: 0.95
Batch: 200; loss: 0.02; acc: 1.0
Batch: 220; loss: 0.04; acc: 0.98
Batch: 240; loss: 0.11; acc: 0.95
Batch: 260; loss: 0.04; acc: 0.98
Batch: 280; loss: 0.01; acc: 1.0
Batch: 300; loss: 0.25; acc: 0.97
Batch: 320; loss: 0.01; acc: 1.0
Batch: 340; loss: 0.06; acc: 0.97
Batch: 360; loss: 0.23; acc: 0.95
Batch: 380; loss: 0.05; acc: 0.97
Batch: 400; loss: 0.03; acc: 0.98
Batch: 420; loss: 0.02; acc: 0.98
Batch: 440; loss: 0.14; acc: 0.95
Batch: 460; loss: 0.2; acc: 0.97
Batch: 480; loss: 0.08; acc: 0.98
Batch: 500; loss: 0.14; acc: 0.98
Batch: 520; loss: 0.13; acc: 0.97
Batch: 540; loss: 0.21; acc: 0.95
Batch: 560; loss: 0.08; acc: 0.97
Batch: 580; loss: 0.07; acc: 0.98
Batch: 600; loss: 0.04; acc: 0.98
Batch: 620; loss: 0.02; acc: 1.0
Batch: 640; loss: 0.0; acc: 1.0
Batch: 660; loss: 0.23; acc: 0.94
Batch: 680; loss: 0.03; acc: 0.98
Batch: 700; loss: 0.06; acc: 0.98
Batch: 720; loss: 0.01; acc: 1.0
Batch: 740; loss: 0.25; acc: 0.97
Batch: 760; loss: 0.13; acc: 0.97
Batch: 780; loss: 0.18; acc: 0.98
Train Epoch over. train_loss: 0.07; train_accuracy: 0.98 

3.092710176133551e-05
1.3679402400157414e-05
Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.1; acc: 0.97
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.2; acc: 0.94
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.27; acc: 0.89
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.08666616100461999; val_accuracy: 0.9738256369426752 

The current subspace-distance is: 1.3679402400157414e-05 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.05; acc: 0.97
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.05; acc: 0.98
Batch: 80; loss: 0.06; acc: 0.97
Batch: 100; loss: 0.03; acc: 0.98
Batch: 120; loss: 0.03; acc: 0.98
Batch: 140; loss: 0.06; acc: 0.97
Batch: 160; loss: 0.01; acc: 1.0
Batch: 180; loss: 0.02; acc: 0.98
Batch: 200; loss: 0.05; acc: 0.97
Batch: 220; loss: 0.03; acc: 1.0
Batch: 240; loss: 0.07; acc: 0.97
Batch: 260; loss: 0.13; acc: 0.95
Batch: 280; loss: 0.13; acc: 0.97
Batch: 300; loss: 0.03; acc: 1.0
Batch: 320; loss: 0.08; acc: 0.98
Batch: 340; loss: 0.05; acc: 0.98
Batch: 360; loss: 0.06; acc: 0.98
Batch: 380; loss: 0.21; acc: 0.97
Batch: 400; loss: 0.03; acc: 1.0
Batch: 420; loss: 0.02; acc: 1.0
Batch: 440; loss: 0.15; acc: 0.98
Batch: 460; loss: 0.04; acc: 1.0
Batch: 480; loss: 0.03; acc: 0.98
Batch: 500; loss: 0.01; acc: 1.0
Batch: 520; loss: 0.03; acc: 0.98
Batch: 540; loss: 0.04; acc: 0.97
Batch: 560; loss: 0.02; acc: 1.0
Batch: 580; loss: 0.07; acc: 0.97
Batch: 600; loss: 0.06; acc: 0.98
Batch: 620; loss: 0.02; acc: 1.0
Batch: 640; loss: 0.13; acc: 0.97
Batch: 660; loss: 0.02; acc: 1.0
Batch: 680; loss: 0.15; acc: 0.94
Batch: 700; loss: 0.02; acc: 1.0
Batch: 720; loss: 0.04; acc: 0.97
Batch: 740; loss: 0.07; acc: 0.98
Batch: 760; loss: 0.04; acc: 0.98
Batch: 780; loss: 0.02; acc: 1.0
Train Epoch over. train_loss: 0.07; train_accuracy: 0.98 

3.102781920460984e-05
1.4249470041249879e-05
Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.08; acc: 0.97
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.03; acc: 0.98
Batch: 100; loss: 0.09; acc: 0.98
Batch: 120; loss: 0.33; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.09425675669673142; val_accuracy: 0.9713375796178344 

The current subspace-distance is: 1.4249470041249879e-05 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.1; acc: 0.95
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.05; acc: 0.97
Batch: 120; loss: 0.04; acc: 0.98
Batch: 140; loss: 0.03; acc: 1.0
Batch: 160; loss: 0.12; acc: 0.97
Batch: 180; loss: 0.04; acc: 0.98
Batch: 200; loss: 0.02; acc: 1.0
Batch: 220; loss: 0.09; acc: 0.97
Batch: 240; loss: 0.02; acc: 0.98
Batch: 260; loss: 0.06; acc: 0.98
Batch: 280; loss: 0.02; acc: 1.0
Batch: 300; loss: 0.06; acc: 0.98
Batch: 320; loss: 0.09; acc: 0.97
Batch: 340; loss: 0.01; acc: 1.0
Batch: 360; loss: 0.08; acc: 0.98
Batch: 380; loss: 0.07; acc: 0.97
Batch: 400; loss: 0.04; acc: 0.98
Batch: 420; loss: 0.02; acc: 0.98
Batch: 440; loss: 0.18; acc: 0.95
Batch: 460; loss: 0.06; acc: 0.98
Batch: 480; loss: 0.01; acc: 1.0
Batch: 500; loss: 0.05; acc: 0.98
Batch: 520; loss: 0.1; acc: 0.97
Batch: 540; loss: 0.13; acc: 0.98
Batch: 560; loss: 0.03; acc: 0.98
Batch: 580; loss: 0.08; acc: 0.97
Batch: 600; loss: 0.07; acc: 0.97
Batch: 620; loss: 0.11; acc: 0.97
Batch: 640; loss: 0.24; acc: 0.95
Batch: 660; loss: 0.01; acc: 1.0
Batch: 680; loss: 0.12; acc: 0.97
Batch: 700; loss: 0.14; acc: 0.95
Batch: 720; loss: 0.05; acc: 0.98
Batch: 740; loss: 0.03; acc: 0.98
Batch: 760; loss: 0.03; acc: 0.98
Batch: 780; loss: 0.12; acc: 0.97
Train Epoch over. train_loss: 0.07; train_accuracy: 0.98 

3.104222196270712e-05
1.3958909221400972e-05
Batch: 0; loss: 0.02; acc: 0.98
Batch: 20; loss: 0.08; acc: 0.97
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.08; acc: 0.98
Batch: 120; loss: 0.26; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.08711888357569837; val_accuracy: 0.9749203821656051 

The current subspace-distance is: 1.3958909221400972e-05 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.04; acc: 0.98
Batch: 40; loss: 0.04; acc: 1.0
Batch: 60; loss: 0.05; acc: 0.98
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.08; acc: 0.97
Batch: 120; loss: 0.04; acc: 0.98
Batch: 140; loss: 0.16; acc: 0.92
Batch: 160; loss: 0.04; acc: 0.98
Batch: 180; loss: 0.01; acc: 1.0
Batch: 200; loss: 0.06; acc: 0.97
Batch: 220; loss: 0.12; acc: 0.97
Batch: 240; loss: 0.03; acc: 0.98
Batch: 260; loss: 0.02; acc: 1.0
Batch: 280; loss: 0.1; acc: 0.95
Batch: 300; loss: 0.07; acc: 0.97
Batch: 320; loss: 0.04; acc: 0.98
Batch: 340; loss: 0.11; acc: 0.95
Batch: 360; loss: 0.09; acc: 0.98
Batch: 380; loss: 0.02; acc: 0.98
Batch: 400; loss: 0.12; acc: 0.97
Batch: 420; loss: 0.08; acc: 0.95
Batch: 440; loss: 0.13; acc: 0.97
Batch: 460; loss: 0.12; acc: 0.95
Batch: 480; loss: 0.02; acc: 1.0
Batch: 500; loss: 0.0; acc: 1.0
Batch: 520; loss: 0.14; acc: 0.98
Batch: 540; loss: 0.04; acc: 0.98
Batch: 560; loss: 0.04; acc: 0.98
Batch: 580; loss: 0.09; acc: 0.97
Batch: 600; loss: 0.08; acc: 0.97
Batch: 620; loss: 0.01; acc: 1.0
Batch: 640; loss: 0.08; acc: 0.97
Batch: 660; loss: 0.03; acc: 0.98
Batch: 680; loss: 0.05; acc: 0.97
Batch: 700; loss: 0.07; acc: 0.97
Batch: 720; loss: 0.16; acc: 0.92
Batch: 740; loss: 0.02; acc: 1.0
Batch: 760; loss: 0.06; acc: 0.97
Batch: 780; loss: 0.04; acc: 0.98
Train Epoch over. train_loss: 0.07; train_accuracy: 0.98 

3.16509285767097e-05
1.4907225704519078e-05
Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.02; acc: 0.98
Batch: 100; loss: 0.07; acc: 0.98
Batch: 120; loss: 0.27; acc: 0.89
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.08410664640699222; val_accuracy: 0.9748208598726115 

The current subspace-distance is: 1.4907225704519078e-05 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.18; acc: 0.95
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.04; acc: 0.98
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.04; acc: 0.98
Batch: 120; loss: 0.09; acc: 0.97
Batch: 140; loss: 0.19; acc: 0.92
Batch: 160; loss: 0.06; acc: 0.97
Batch: 180; loss: 0.01; acc: 1.0
Batch: 200; loss: 0.03; acc: 1.0
Batch: 220; loss: 0.07; acc: 0.97
Batch: 240; loss: 0.05; acc: 0.98
Batch: 260; loss: 0.01; acc: 1.0
Batch: 280; loss: 0.15; acc: 0.95
Batch: 300; loss: 0.31; acc: 0.94
Batch: 320; loss: 0.01; acc: 1.0
Batch: 340; loss: 0.02; acc: 1.0
Batch: 360; loss: 0.13; acc: 0.98
Batch: 380; loss: 0.02; acc: 1.0
Batch: 400; loss: 0.07; acc: 0.98
Batch: 420; loss: 0.11; acc: 0.97
Batch: 440; loss: 0.07; acc: 0.95
Batch: 460; loss: 0.01; acc: 1.0
Batch: 480; loss: 0.04; acc: 0.98
Batch: 500; loss: 0.08; acc: 0.95
Batch: 520; loss: 0.03; acc: 0.98
Batch: 540; loss: 0.05; acc: 0.98
Batch: 560; loss: 0.1; acc: 0.97
Batch: 580; loss: 0.05; acc: 0.98
Batch: 600; loss: 0.01; acc: 1.0
Batch: 620; loss: 0.12; acc: 0.95
Batch: 640; loss: 0.14; acc: 0.98
Batch: 660; loss: 0.01; acc: 1.0
Batch: 680; loss: 0.07; acc: 0.98
Batch: 700; loss: 0.04; acc: 0.98
Batch: 720; loss: 0.01; acc: 1.0
Batch: 740; loss: 0.11; acc: 0.95
Batch: 760; loss: 0.04; acc: 0.97
Batch: 780; loss: 0.04; acc: 0.98
Train Epoch over. train_loss: 0.07; train_accuracy: 0.98 

3.083890624111518e-05
1.4028916666575242e-05
Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.21; acc: 0.94
Batch: 80; loss: 0.01; acc: 0.98
Batch: 100; loss: 0.08; acc: 0.98
Batch: 120; loss: 0.26; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.08641199062869048; val_accuracy: 0.974422770700637 

The current subspace-distance is: 1.4028916666575242e-05 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.06; acc: 0.98
Batch: 20; loss: 0.05; acc: 0.97
Batch: 40; loss: 0.04; acc: 1.0
Batch: 60; loss: 0.03; acc: 0.98
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.03; acc: 0.98
Batch: 120; loss: 0.02; acc: 1.0
Batch: 140; loss: 0.08; acc: 0.97
Batch: 160; loss: 0.05; acc: 0.98
Batch: 180; loss: 0.02; acc: 1.0
Batch: 200; loss: 0.04; acc: 0.98
Batch: 220; loss: 0.03; acc: 1.0
Batch: 240; loss: 0.11; acc: 0.97
Batch: 260; loss: 0.07; acc: 0.95
Batch: 280; loss: 0.03; acc: 0.98
Batch: 300; loss: 0.06; acc: 0.98
Batch: 320; loss: 0.02; acc: 0.98
Batch: 340; loss: 0.15; acc: 0.95
Batch: 360; loss: 0.01; acc: 1.0
Batch: 380; loss: 0.01; acc: 1.0
Batch: 400; loss: 0.05; acc: 0.98
Batch: 420; loss: 0.07; acc: 0.97
Batch: 440; loss: 0.24; acc: 0.94
Batch: 460; loss: 0.02; acc: 1.0
Batch: 480; loss: 0.02; acc: 1.0
Batch: 500; loss: 0.03; acc: 1.0
Batch: 520; loss: 0.01; acc: 1.0
Batch: 540; loss: 0.02; acc: 0.98
Batch: 560; loss: 0.06; acc: 0.97
Batch: 580; loss: 0.14; acc: 0.95
Batch: 600; loss: 0.05; acc: 0.98
Batch: 620; loss: 0.04; acc: 0.98
Batch: 640; loss: 0.04; acc: 0.98
Batch: 660; loss: 0.08; acc: 0.97
Batch: 680; loss: 0.22; acc: 0.97
Batch: 700; loss: 0.0; acc: 1.0
Batch: 720; loss: 0.04; acc: 0.98
Batch: 740; loss: 0.13; acc: 0.97
Batch: 760; loss: 0.01; acc: 1.0
Batch: 780; loss: 0.02; acc: 1.0
Train Epoch over. train_loss: 0.07; train_accuracy: 0.98 

3.1214334740070626e-05
1.4544837540597655e-05
Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.18; acc: 0.95
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.07; acc: 0.98
Batch: 120; loss: 0.25; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.0846644011415114; val_accuracy: 0.9755175159235668 

The current subspace-distance is: 1.4544837540597655e-05 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.22; acc: 0.97
Batch: 40; loss: 0.01; acc: 1.0
Batch: 60; loss: 0.12; acc: 0.97
Batch: 80; loss: 0.05; acc: 0.97
Batch: 100; loss: 0.14; acc: 0.97
Batch: 120; loss: 0.1; acc: 0.98
Batch: 140; loss: 0.06; acc: 0.98
Batch: 160; loss: 0.07; acc: 0.97
Batch: 180; loss: 0.02; acc: 1.0
Batch: 200; loss: 0.04; acc: 0.97
Batch: 220; loss: 0.06; acc: 0.97
Batch: 240; loss: 0.01; acc: 1.0
Batch: 260; loss: 0.04; acc: 0.98
Batch: 280; loss: 0.06; acc: 0.98
Batch: 300; loss: 0.03; acc: 0.98
Batch: 320; loss: 0.08; acc: 0.97
Batch: 340; loss: 0.1; acc: 0.97
Batch: 360; loss: 0.01; acc: 1.0
Batch: 380; loss: 0.02; acc: 1.0
Batch: 400; loss: 0.15; acc: 0.97
Batch: 420; loss: 0.07; acc: 0.98
Batch: 440; loss: 0.06; acc: 0.97
Batch: 460; loss: 0.05; acc: 0.98
Batch: 480; loss: 0.0; acc: 1.0
Batch: 500; loss: 0.04; acc: 0.98
Batch: 520; loss: 0.01; acc: 1.0
Batch: 540; loss: 0.12; acc: 0.95
Batch: 560; loss: 0.05; acc: 0.98
Batch: 580; loss: 0.06; acc: 0.97
Batch: 600; loss: 0.06; acc: 0.98
Batch: 620; loss: 0.05; acc: 0.97
Batch: 640; loss: 0.04; acc: 0.97
Batch: 660; loss: 0.18; acc: 0.92
Batch: 680; loss: 0.07; acc: 0.97
Batch: 700; loss: 0.13; acc: 0.98
Batch: 720; loss: 0.07; acc: 0.98
Batch: 740; loss: 0.03; acc: 1.0
Batch: 760; loss: 0.02; acc: 1.0
Batch: 780; loss: 0.08; acc: 0.98
Train Epoch over. train_loss: 0.07; train_accuracy: 0.98 

3.1195773772196844e-05
1.4524912330671214e-05
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.1; acc: 0.97
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.2; acc: 0.95
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.08; acc: 0.98
Batch: 120; loss: 0.25; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.08574474097532071; val_accuracy: 0.9749203821656051 

The current subspace-distance is: 1.4524912330671214e-05 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.03; acc: 0.98
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.03; acc: 0.98
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.05; acc: 0.97
Batch: 120; loss: 0.07; acc: 0.98
Batch: 140; loss: 0.02; acc: 1.0
Batch: 160; loss: 0.08; acc: 0.95
Batch: 180; loss: 0.02; acc: 0.98
Batch: 200; loss: 0.06; acc: 0.98
Batch: 220; loss: 0.07; acc: 0.97
Batch: 240; loss: 0.04; acc: 0.98
Batch: 260; loss: 0.03; acc: 1.0
Batch: 280; loss: 0.07; acc: 0.97
Batch: 300; loss: 0.03; acc: 1.0
Batch: 320; loss: 0.1; acc: 0.97
Batch: 340; loss: 0.04; acc: 0.98
Batch: 360; loss: 0.23; acc: 0.95
Batch: 380; loss: 0.09; acc: 0.97
Batch: 400; loss: 0.09; acc: 0.98
Batch: 420; loss: 0.02; acc: 1.0
Batch: 440; loss: 0.11; acc: 0.95
Batch: 460; loss: 0.05; acc: 0.98
Batch: 480; loss: 0.04; acc: 0.97
Batch: 500; loss: 0.01; acc: 1.0
Batch: 520; loss: 0.03; acc: 0.98
Batch: 540; loss: 0.16; acc: 0.97
Batch: 560; loss: 0.01; acc: 1.0
Batch: 580; loss: 0.11; acc: 0.98
Batch: 600; loss: 0.1; acc: 0.98
Batch: 620; loss: 0.02; acc: 1.0
Batch: 640; loss: 0.02; acc: 1.0
Batch: 660; loss: 0.01; acc: 1.0
Batch: 680; loss: 0.02; acc: 1.0
Batch: 700; loss: 0.04; acc: 0.98
Batch: 720; loss: 0.12; acc: 0.95
Batch: 740; loss: 0.04; acc: 0.98
Batch: 760; loss: 0.16; acc: 0.98
Batch: 780; loss: 0.11; acc: 0.97
Train Epoch over. train_loss: 0.07; train_accuracy: 0.98 

3.096025102422573e-05
1.3824546840623952e-05
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.02; acc: 0.98
Batch: 100; loss: 0.07; acc: 0.98
Batch: 120; loss: 0.24; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.08515175229092692; val_accuracy: 0.9749203821656051 

The current subspace-distance is: 1.3824546840623952e-05 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.09; acc: 0.98
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.01; acc: 1.0
Batch: 120; loss: 0.05; acc: 0.97
Batch: 140; loss: 0.08; acc: 0.97
Batch: 160; loss: 0.05; acc: 0.98
Batch: 180; loss: 0.1; acc: 0.95
Batch: 200; loss: 0.06; acc: 0.98
Batch: 220; loss: 0.02; acc: 1.0
Batch: 240; loss: 0.08; acc: 0.98
Batch: 260; loss: 0.08; acc: 0.97
Batch: 280; loss: 0.17; acc: 0.92
Batch: 300; loss: 0.11; acc: 0.95
Batch: 320; loss: 0.07; acc: 0.97
Batch: 340; loss: 0.14; acc: 0.97
Batch: 360; loss: 0.11; acc: 0.94
Batch: 380; loss: 0.02; acc: 0.98
Batch: 400; loss: 0.01; acc: 1.0
Batch: 420; loss: 0.07; acc: 0.95
Batch: 440; loss: 0.02; acc: 0.98
Batch: 460; loss: 0.08; acc: 0.97
Batch: 480; loss: 0.07; acc: 0.98
Batch: 500; loss: 0.05; acc: 0.98
Batch: 520; loss: 0.01; acc: 1.0
Batch: 540; loss: 0.19; acc: 0.95
Batch: 560; loss: 0.06; acc: 0.97
Batch: 580; loss: 0.1; acc: 0.98
Batch: 600; loss: 0.19; acc: 0.97
Batch: 620; loss: 0.04; acc: 0.98
Batch: 640; loss: 0.11; acc: 0.97
Batch: 660; loss: 0.19; acc: 0.98
Batch: 680; loss: 0.02; acc: 1.0
Batch: 700; loss: 0.06; acc: 0.97
Batch: 720; loss: 0.06; acc: 0.98
Batch: 740; loss: 0.05; acc: 0.98
Batch: 760; loss: 0.07; acc: 0.98
Batch: 780; loss: 0.01; acc: 1.0
Train Epoch over. train_loss: 0.07; train_accuracy: 0.98 

3.0822855478618294e-05
1.405361126671778e-05
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.1; acc: 0.97
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.02; acc: 0.98
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.25; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.0862768156584471; val_accuracy: 0.9743232484076433 

The current subspace-distance is: 1.405361126671778e-05 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.06; acc: 0.97
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.09; acc: 0.95
Batch: 60; loss: 0.09; acc: 0.98
Batch: 80; loss: 0.06; acc: 0.97
Batch: 100; loss: 0.03; acc: 1.0
Batch: 120; loss: 0.07; acc: 0.97
Batch: 140; loss: 0.0; acc: 1.0
Batch: 160; loss: 0.04; acc: 0.98
Batch: 180; loss: 0.08; acc: 0.98
Batch: 200; loss: 0.04; acc: 0.98
Batch: 220; loss: 0.08; acc: 0.98
Batch: 240; loss: 0.1; acc: 0.97
Batch: 260; loss: 0.06; acc: 0.98
Batch: 280; loss: 0.02; acc: 1.0
Batch: 300; loss: 0.1; acc: 0.97
Batch: 320; loss: 0.04; acc: 0.98
Batch: 340; loss: 0.14; acc: 0.92
Batch: 360; loss: 0.04; acc: 0.98
Batch: 380; loss: 0.01; acc: 1.0
Batch: 400; loss: 0.06; acc: 0.98
Batch: 420; loss: 0.01; acc: 1.0
Batch: 440; loss: 0.01; acc: 1.0
Batch: 460; loss: 0.04; acc: 0.98
Batch: 480; loss: 0.07; acc: 0.98
Batch: 500; loss: 0.05; acc: 0.97
Batch: 520; loss: 0.04; acc: 0.98
Batch: 540; loss: 0.22; acc: 0.95
Batch: 560; loss: 0.07; acc: 0.97
Batch: 580; loss: 0.15; acc: 0.97
Batch: 600; loss: 0.08; acc: 0.97
Batch: 620; loss: 0.11; acc: 0.97
Batch: 640; loss: 0.18; acc: 0.95
Batch: 660; loss: 0.02; acc: 1.0
Batch: 680; loss: 0.01; acc: 1.0
Batch: 700; loss: 0.08; acc: 0.98
Batch: 720; loss: 0.01; acc: 1.0
Batch: 740; loss: 0.05; acc: 0.97
Batch: 760; loss: 0.15; acc: 0.97
Batch: 780; loss: 0.06; acc: 0.98
Train Epoch over. train_loss: 0.07; train_accuracy: 0.98 

3.0836752557661384e-05
1.424992206011666e-05
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.1; acc: 0.97
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.2; acc: 0.94
Batch: 80; loss: 0.02; acc: 0.98
Batch: 100; loss: 0.07; acc: 0.98
Batch: 120; loss: 0.25; acc: 0.89
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.08519440398189672; val_accuracy: 0.9749203821656051 

The current subspace-distance is: 1.424992206011666e-05 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.07; acc: 0.97
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.08; acc: 0.98
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.06; acc: 0.97
Batch: 120; loss: 0.16; acc: 0.94
Batch: 140; loss: 0.06; acc: 0.98
Batch: 160; loss: 0.04; acc: 1.0
Batch: 180; loss: 0.02; acc: 1.0
Batch: 200; loss: 0.08; acc: 0.98
Batch: 220; loss: 0.09; acc: 0.98
Batch: 240; loss: 0.18; acc: 0.92
Batch: 260; loss: 0.04; acc: 0.98
Batch: 280; loss: 0.06; acc: 0.98
Batch: 300; loss: 0.04; acc: 0.98
Batch: 320; loss: 0.03; acc: 0.98
Batch: 340; loss: 0.01; acc: 1.0
Batch: 360; loss: 0.12; acc: 0.97
Batch: 380; loss: 0.04; acc: 0.98
Batch: 400; loss: 0.04; acc: 0.97
Batch: 420; loss: 0.05; acc: 0.97
Batch: 440; loss: 0.08; acc: 0.97
Batch: 460; loss: 0.05; acc: 0.98
Batch: 480; loss: 0.03; acc: 0.98
Batch: 500; loss: 0.02; acc: 1.0
Batch: 520; loss: 0.23; acc: 0.95
Batch: 540; loss: 0.04; acc: 0.98
Batch: 560; loss: 0.04; acc: 0.98
Batch: 580; loss: 0.0; acc: 1.0
Batch: 600; loss: 0.05; acc: 1.0
Batch: 620; loss: 0.02; acc: 1.0
Batch: 640; loss: 0.03; acc: 0.98
Batch: 660; loss: 0.03; acc: 1.0
Batch: 680; loss: 0.14; acc: 0.97
Batch: 700; loss: 0.12; acc: 0.97
Batch: 720; loss: 0.03; acc: 0.98
Batch: 740; loss: 0.08; acc: 0.97
Batch: 760; loss: 0.04; acc: 0.97
Batch: 780; loss: 0.17; acc: 0.97
Train Epoch over. train_loss: 0.07; train_accuracy: 0.98 

3.114589344477281e-05
1.4939045286155306e-05
Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.1; acc: 0.97
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.17; acc: 0.95
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.26; acc: 0.92
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.08495153649265219; val_accuracy: 0.974422770700637 

The current subspace-distance is: 1.4939045286155306e-05 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.07; acc: 0.97
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.01; acc: 1.0
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.12; acc: 0.98
Batch: 140; loss: 0.07; acc: 0.98
Batch: 160; loss: 0.05; acc: 0.98
Batch: 180; loss: 0.02; acc: 1.0
Batch: 200; loss: 0.12; acc: 0.95
Batch: 220; loss: 0.06; acc: 0.97
Batch: 240; loss: 0.07; acc: 0.98
Batch: 260; loss: 0.05; acc: 0.97
Batch: 280; loss: 0.01; acc: 1.0
Batch: 300; loss: 0.15; acc: 0.97
Batch: 320; loss: 0.13; acc: 0.97
Batch: 340; loss: 0.01; acc: 1.0
Batch: 360; loss: 0.01; acc: 1.0
Batch: 380; loss: 0.01; acc: 1.0
Batch: 400; loss: 0.12; acc: 0.97
Batch: 420; loss: 0.08; acc: 0.95
Batch: 440; loss: 0.03; acc: 1.0
Batch: 460; loss: 0.01; acc: 1.0
Batch: 480; loss: 0.01; acc: 1.0
Batch: 500; loss: 0.06; acc: 0.95
Batch: 520; loss: 0.06; acc: 0.98
Batch: 540; loss: 0.03; acc: 0.98
Batch: 560; loss: 0.1; acc: 0.95
Batch: 580; loss: 0.16; acc: 0.94
Batch: 600; loss: 0.03; acc: 1.0
Batch: 620; loss: 0.07; acc: 0.97
Batch: 640; loss: 0.02; acc: 1.0
Batch: 660; loss: 0.02; acc: 1.0
Batch: 680; loss: 0.01; acc: 1.0
Batch: 700; loss: 0.04; acc: 0.98
Batch: 720; loss: 0.03; acc: 0.98
Batch: 740; loss: 0.1; acc: 0.95
Batch: 760; loss: 0.06; acc: 0.98
Batch: 780; loss: 0.05; acc: 0.98
Train Epoch over. train_loss: 0.07; train_accuracy: 0.98 

3.11038238578476e-05
1.4824709069216624e-05
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.1; acc: 0.97
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.2; acc: 0.95
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.25; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.08531226300794607; val_accuracy: 0.9761146496815286 

The current subspace-distance is: 1.4824709069216624e-05 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.08; acc: 0.98
Batch: 40; loss: 0.05; acc: 0.97
Batch: 60; loss: 0.07; acc: 0.98
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.04; acc: 0.98
Batch: 120; loss: 0.02; acc: 1.0
Batch: 140; loss: 0.02; acc: 1.0
Batch: 160; loss: 0.04; acc: 0.98
Batch: 180; loss: 0.03; acc: 1.0
Batch: 200; loss: 0.04; acc: 0.98
Batch: 220; loss: 0.12; acc: 0.95
Batch: 240; loss: 0.05; acc: 0.98
Batch: 260; loss: 0.05; acc: 0.98
Batch: 280; loss: 0.03; acc: 0.98
Batch: 300; loss: 0.06; acc: 0.97
Batch: 320; loss: 0.02; acc: 1.0
Batch: 340; loss: 0.08; acc: 0.98
Batch: 360; loss: 0.08; acc: 0.98
Batch: 380; loss: 0.11; acc: 0.95
Batch: 400; loss: 0.03; acc: 1.0
Batch: 420; loss: 0.02; acc: 1.0
Batch: 440; loss: 0.05; acc: 0.98
Batch: 460; loss: 0.03; acc: 1.0
Batch: 480; loss: 0.05; acc: 0.95
Batch: 500; loss: 0.14; acc: 0.97
Batch: 520; loss: 0.02; acc: 0.98
Batch: 540; loss: 0.0; acc: 1.0
Batch: 560; loss: 0.04; acc: 0.98
Batch: 580; loss: 0.01; acc: 1.0
Batch: 600; loss: 0.01; acc: 1.0
Batch: 620; loss: 0.07; acc: 0.97
Batch: 640; loss: 0.11; acc: 0.97
Batch: 660; loss: 0.03; acc: 0.98
Batch: 680; loss: 0.25; acc: 0.91
Batch: 700; loss: 0.15; acc: 0.92
Batch: 720; loss: 0.07; acc: 0.97
Batch: 740; loss: 0.08; acc: 0.95
Batch: 760; loss: 0.03; acc: 0.98
Batch: 780; loss: 0.1; acc: 0.97
Train Epoch over. train_loss: 0.07; train_accuracy: 0.98 

3.118089443887584e-05
1.4500967154162936e-05
Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.02; acc: 0.98
Batch: 100; loss: 0.07; acc: 0.98
Batch: 120; loss: 0.24; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.08471441691278651; val_accuracy: 0.9755175159235668 

The current subspace-distance is: 1.4500967154162936e-05 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.07; acc: 0.97
Batch: 20; loss: 0.19; acc: 0.95
Batch: 40; loss: 0.02; acc: 0.98
Batch: 60; loss: 0.06; acc: 0.97
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.1; acc: 0.97
Batch: 140; loss: 0.01; acc: 1.0
Batch: 160; loss: 0.11; acc: 0.95
Batch: 180; loss: 0.05; acc: 0.97
Batch: 200; loss: 0.06; acc: 0.97
Batch: 220; loss: 0.19; acc: 0.92
Batch: 240; loss: 0.05; acc: 0.97
Batch: 260; loss: 0.01; acc: 1.0
Batch: 280; loss: 0.1; acc: 0.94
Batch: 300; loss: 0.02; acc: 0.98
Batch: 320; loss: 0.02; acc: 1.0
Batch: 340; loss: 0.01; acc: 1.0
Batch: 360; loss: 0.17; acc: 0.97
Batch: 380; loss: 0.07; acc: 0.97
Batch: 400; loss: 0.06; acc: 0.98
Batch: 420; loss: 0.05; acc: 0.98
Batch: 440; loss: 0.03; acc: 1.0
Batch: 460; loss: 0.05; acc: 0.98
Batch: 480; loss: 0.03; acc: 1.0
Batch: 500; loss: 0.01; acc: 1.0
Batch: 520; loss: 0.01; acc: 1.0
Batch: 540; loss: 0.02; acc: 1.0
Batch: 560; loss: 0.14; acc: 0.97
Batch: 580; loss: 0.02; acc: 1.0
Batch: 600; loss: 0.02; acc: 1.0
Batch: 620; loss: 0.02; acc: 1.0
Batch: 640; loss: 0.04; acc: 0.98
Batch: 660; loss: 0.11; acc: 0.95
Batch: 680; loss: 0.02; acc: 1.0
Batch: 700; loss: 0.07; acc: 0.97
Batch: 720; loss: 0.06; acc: 0.98
Batch: 740; loss: 0.05; acc: 0.98
Batch: 760; loss: 0.01; acc: 1.0
Batch: 780; loss: 0.01; acc: 1.0
Train Epoch over. train_loss: 0.07; train_accuracy: 0.98 

3.117582673439756e-05
1.3949477761343587e-05
Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.01; acc: 0.98
Batch: 100; loss: 0.07; acc: 0.98
Batch: 120; loss: 0.25; acc: 0.92
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.08430183121258286; val_accuracy: 0.9757165605095541 

The current subspace-distance is: 1.3949477761343587e-05 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.05; acc: 0.97
Batch: 20; loss: 0.01; acc: 1.0
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.11; acc: 0.95
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.11; acc: 0.95
Batch: 140; loss: 0.12; acc: 0.97
Batch: 160; loss: 0.22; acc: 0.94
Batch: 180; loss: 0.03; acc: 1.0
Batch: 200; loss: 0.05; acc: 0.98
Batch: 220; loss: 0.02; acc: 0.98
Batch: 240; loss: 0.03; acc: 1.0
Batch: 260; loss: 0.01; acc: 1.0
Batch: 280; loss: 0.05; acc: 0.97
Batch: 300; loss: 0.03; acc: 1.0
Batch: 320; loss: 0.09; acc: 0.95
Batch: 340; loss: 0.01; acc: 1.0
Batch: 360; loss: 0.06; acc: 0.98
Batch: 380; loss: 0.04; acc: 0.98
Batch: 400; loss: 0.06; acc: 0.95
Batch: 420; loss: 0.03; acc: 1.0
Batch: 440; loss: 0.09; acc: 0.95
Batch: 460; loss: 0.01; acc: 1.0
Batch: 480; loss: 0.01; acc: 1.0
Batch: 500; loss: 0.06; acc: 0.98
Batch: 520; loss: 0.11; acc: 0.98
Batch: 540; loss: 0.04; acc: 0.98
Batch: 560; loss: 0.08; acc: 0.97
Batch: 580; loss: 0.04; acc: 1.0
Batch: 600; loss: 0.08; acc: 0.97
Batch: 620; loss: 0.01; acc: 1.0
Batch: 640; loss: 0.02; acc: 1.0
Batch: 660; loss: 0.02; acc: 1.0
Batch: 680; loss: 0.04; acc: 0.98
Batch: 700; loss: 0.13; acc: 0.97
Batch: 720; loss: 0.05; acc: 0.97
Batch: 740; loss: 0.01; acc: 1.0
Batch: 760; loss: 0.04; acc: 0.97
Batch: 780; loss: 0.02; acc: 0.98
Train Epoch over. train_loss: 0.07; train_accuracy: 0.98 

3.142344576190226e-05
1.4355216990225017e-05
Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.07; acc: 0.98
Batch: 120; loss: 0.25; acc: 0.91
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.08376765477761722; val_accuracy: 0.9754179936305732 

The current subspace-distance is: 1.4355216990225017e-05 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.13; acc: 0.97
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.06; acc: 0.97
Batch: 80; loss: 0.03; acc: 0.98
Batch: 100; loss: 0.04; acc: 0.98
Batch: 120; loss: 0.07; acc: 0.97
Batch: 140; loss: 0.07; acc: 0.97
Batch: 160; loss: 0.02; acc: 1.0
Batch: 180; loss: 0.08; acc: 0.95
Batch: 200; loss: 0.01; acc: 1.0
Batch: 220; loss: 0.04; acc: 0.98
Batch: 240; loss: 0.13; acc: 0.97
Batch: 260; loss: 0.18; acc: 0.95
Batch: 280; loss: 0.04; acc: 0.98
Batch: 300; loss: 0.03; acc: 1.0
Batch: 320; loss: 0.04; acc: 1.0
Batch: 340; loss: 0.02; acc: 1.0
Batch: 360; loss: 0.09; acc: 0.97
Batch: 380; loss: 0.1; acc: 0.98
Batch: 400; loss: 0.03; acc: 0.98
Batch: 420; loss: 0.01; acc: 1.0
Batch: 440; loss: 0.01; acc: 1.0
Batch: 460; loss: 0.02; acc: 0.98
Batch: 480; loss: 0.05; acc: 0.98
Batch: 500; loss: 0.1; acc: 0.98
Batch: 520; loss: 0.21; acc: 0.95
Batch: 540; loss: 0.14; acc: 0.97
Batch: 560; loss: 0.03; acc: 0.98
Batch: 580; loss: 0.08; acc: 0.95
Batch: 600; loss: 0.03; acc: 1.0
Batch: 620; loss: 0.09; acc: 0.98
Batch: 640; loss: 0.02; acc: 1.0
Batch: 660; loss: 0.02; acc: 1.0
Batch: 680; loss: 0.13; acc: 0.97
Batch: 700; loss: 0.09; acc: 0.97
Batch: 720; loss: 0.18; acc: 0.98
Batch: 740; loss: 0.12; acc: 0.97
Batch: 760; loss: 0.02; acc: 0.98
Batch: 780; loss: 0.04; acc: 0.98
Train Epoch over. train_loss: 0.07; train_accuracy: 0.98 

3.075035783695057e-05
1.4461695172940381e-05
Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.2; acc: 0.94
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.07; acc: 0.98
Batch: 120; loss: 0.25; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.08484027949962647; val_accuracy: 0.975218949044586 

The current subspace-distance is: 1.4461695172940381e-05 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.01; acc: 1.0
Batch: 60; loss: 0.18; acc: 0.97
Batch: 80; loss: 0.02; acc: 0.98
Batch: 100; loss: 0.11; acc: 0.95
Batch: 120; loss: 0.06; acc: 0.95
Batch: 140; loss: 0.18; acc: 0.98
Batch: 160; loss: 0.14; acc: 0.97
Batch: 180; loss: 0.09; acc: 0.97
Batch: 200; loss: 0.03; acc: 1.0
Batch: 220; loss: 0.04; acc: 0.98
Batch: 240; loss: 0.08; acc: 0.95
Batch: 260; loss: 0.09; acc: 0.97
Batch: 280; loss: 0.05; acc: 0.98
Batch: 300; loss: 0.07; acc: 0.98
Batch: 320; loss: 0.14; acc: 0.97
Batch: 340; loss: 0.19; acc: 0.95
Batch: 360; loss: 0.05; acc: 0.97
Batch: 380; loss: 0.07; acc: 0.98
Batch: 400; loss: 0.19; acc: 0.92
Batch: 420; loss: 0.06; acc: 0.98
Batch: 440; loss: 0.05; acc: 0.98
Batch: 460; loss: 0.01; acc: 1.0
Batch: 480; loss: 0.16; acc: 0.92
Batch: 500; loss: 0.13; acc: 0.94
Batch: 520; loss: 0.16; acc: 0.97
Batch: 540; loss: 0.02; acc: 1.0
Batch: 560; loss: 0.08; acc: 0.98
Batch: 580; loss: 0.22; acc: 0.97
Batch: 600; loss: 0.1; acc: 0.98
Batch: 620; loss: 0.02; acc: 1.0
Batch: 640; loss: 0.04; acc: 0.98
Batch: 660; loss: 0.1; acc: 0.95
Batch: 680; loss: 0.03; acc: 0.98
Batch: 700; loss: 0.06; acc: 0.98
Batch: 720; loss: 0.19; acc: 0.95
Batch: 740; loss: 0.26; acc: 0.92
Batch: 760; loss: 0.06; acc: 0.97
Batch: 780; loss: 0.01; acc: 1.0
Train Epoch over. train_loss: 0.07; train_accuracy: 0.98 

3.107070006080903e-05
1.4509180800814647e-05
Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.07; acc: 0.98
Batch: 120; loss: 0.24; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.08457239402849583; val_accuracy: 0.9756170382165605 

The current subspace-distance is: 1.4509180800814647e-05 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.07; acc: 0.98
Batch: 40; loss: 0.01; acc: 1.0
Batch: 60; loss: 0.14; acc: 0.97
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.02; acc: 1.0
Batch: 120; loss: 0.11; acc: 0.95
Batch: 140; loss: 0.01; acc: 1.0
Batch: 160; loss: 0.01; acc: 1.0
Batch: 180; loss: 0.01; acc: 1.0
Batch: 200; loss: 0.18; acc: 0.98
Batch: 220; loss: 0.0; acc: 1.0
Batch: 240; loss: 0.16; acc: 0.97
Batch: 260; loss: 0.11; acc: 0.97
Batch: 280; loss: 0.18; acc: 0.94
Batch: 300; loss: 0.03; acc: 0.98
Batch: 320; loss: 0.03; acc: 1.0
Batch: 340; loss: 0.02; acc: 0.98
Batch: 360; loss: 0.11; acc: 0.97
Batch: 380; loss: 0.02; acc: 1.0
Batch: 400; loss: 0.02; acc: 0.98
Batch: 420; loss: 0.08; acc: 0.97
Batch: 440; loss: 0.02; acc: 1.0
Batch: 460; loss: 0.02; acc: 1.0
Batch: 480; loss: 0.12; acc: 0.95
Batch: 500; loss: 0.02; acc: 0.98
Batch: 520; loss: 0.01; acc: 1.0
Batch: 540; loss: 0.03; acc: 0.98
Batch: 560; loss: 0.01; acc: 1.0
Batch: 580; loss: 0.06; acc: 0.95
Batch: 600; loss: 0.13; acc: 0.98
Batch: 620; loss: 0.04; acc: 0.98
Batch: 640; loss: 0.01; acc: 1.0
Batch: 660; loss: 0.06; acc: 0.97
Batch: 680; loss: 0.02; acc: 0.98
Batch: 700; loss: 0.02; acc: 1.0
Batch: 720; loss: 0.21; acc: 0.92
Batch: 740; loss: 0.03; acc: 1.0
Batch: 760; loss: 0.04; acc: 0.98
Batch: 780; loss: 0.09; acc: 0.95
Train Epoch over. train_loss: 0.07; train_accuracy: 0.98 

3.1436848075827584e-05
1.4673499208583962e-05
Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.07; acc: 0.98
Batch: 120; loss: 0.25; acc: 0.92
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.0834328647299557; val_accuracy: 0.9759156050955414 

The current subspace-distance is: 1.4673499208583962e-05 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.08; acc: 0.97
Batch: 20; loss: 0.19; acc: 0.95
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.04; acc: 1.0
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.15; acc: 0.94
Batch: 120; loss: 0.04; acc: 0.97
Batch: 140; loss: 0.05; acc: 0.97
Batch: 160; loss: 0.15; acc: 0.97
Batch: 180; loss: 0.01; acc: 1.0
Batch: 200; loss: 0.02; acc: 1.0
Batch: 220; loss: 0.06; acc: 0.97
Batch: 240; loss: 0.1; acc: 0.97
Batch: 260; loss: 0.02; acc: 1.0
Batch: 280; loss: 0.12; acc: 0.98
Batch: 300; loss: 0.13; acc: 0.98
Batch: 320; loss: 0.21; acc: 0.97
Batch: 340; loss: 0.03; acc: 1.0
Batch: 360; loss: 0.12; acc: 0.97
Batch: 380; loss: 0.04; acc: 0.98
Batch: 400; loss: 0.06; acc: 0.97
Batch: 420; loss: 0.02; acc: 0.98
Batch: 440; loss: 0.04; acc: 1.0
Batch: 460; loss: 0.16; acc: 0.94
Batch: 480; loss: 0.1; acc: 0.95
Batch: 500; loss: 0.13; acc: 0.97
Batch: 520; loss: 0.13; acc: 0.97
Batch: 540; loss: 0.27; acc: 0.95
Batch: 560; loss: 0.12; acc: 0.94
Batch: 580; loss: 0.05; acc: 0.98
Batch: 600; loss: 0.01; acc: 1.0
Batch: 620; loss: 0.22; acc: 0.95
Batch: 640; loss: 0.01; acc: 1.0
Batch: 660; loss: 0.05; acc: 0.98
Batch: 680; loss: 0.01; acc: 1.0
Batch: 700; loss: 0.03; acc: 0.98
Batch: 720; loss: 0.02; acc: 1.0
Batch: 740; loss: 0.04; acc: 1.0
Batch: 760; loss: 0.09; acc: 0.95
Batch: 780; loss: 0.05; acc: 1.0
Train Epoch over. train_loss: 0.07; train_accuracy: 0.98 

3.150999691570178e-05
1.5155716937442776e-05
Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.18; acc: 0.95
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.24; acc: 0.92
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.08377891086089383; val_accuracy: 0.9762141719745223 

The current subspace-distance is: 1.5155716937442776e-05 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.02; acc: 1.0
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.08; acc: 0.97
Batch: 120; loss: 0.03; acc: 0.98
Batch: 140; loss: 0.08; acc: 0.97
Batch: 160; loss: 0.14; acc: 0.95
Batch: 180; loss: 0.14; acc: 0.98
Batch: 200; loss: 0.03; acc: 1.0
Batch: 220; loss: 0.12; acc: 0.97
Batch: 240; loss: 0.02; acc: 1.0
Batch: 260; loss: 0.12; acc: 0.95
Batch: 280; loss: 0.02; acc: 1.0
Batch: 300; loss: 0.04; acc: 0.98
Batch: 320; loss: 0.02; acc: 1.0
Batch: 340; loss: 0.13; acc: 0.98
Batch: 360; loss: 0.16; acc: 0.95
Batch: 380; loss: 0.01; acc: 1.0
Batch: 400; loss: 0.01; acc: 1.0
Batch: 420; loss: 0.03; acc: 0.98
Batch: 440; loss: 0.05; acc: 0.98
Batch: 460; loss: 0.05; acc: 0.97
Batch: 480; loss: 0.01; acc: 0.98
Batch: 500; loss: 0.01; acc: 1.0
Batch: 520; loss: 0.07; acc: 0.98
Batch: 540; loss: 0.07; acc: 0.95
Batch: 560; loss: 0.01; acc: 1.0
Batch: 580; loss: 0.02; acc: 0.98
Batch: 600; loss: 0.06; acc: 0.97
Batch: 620; loss: 0.12; acc: 0.95
Batch: 640; loss: 0.02; acc: 1.0
Batch: 660; loss: 0.04; acc: 0.98
Batch: 680; loss: 0.06; acc: 1.0
Batch: 700; loss: 0.11; acc: 0.98
Batch: 720; loss: 0.1; acc: 0.97
Batch: 740; loss: 0.04; acc: 0.98
Batch: 760; loss: 0.11; acc: 0.98
Batch: 780; loss: 0.16; acc: 0.98
Train Epoch over. train_loss: 0.07; train_accuracy: 0.98 

3.092618135269731e-05
1.4726339941262268e-05
Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.25; acc: 0.92
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.08376233877649733; val_accuracy: 0.9758160828025477 

The current subspace-distance is: 1.4726339941262268e-05 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.07; acc: 0.95
Batch: 40; loss: 0.0; acc: 1.0
Batch: 60; loss: 0.03; acc: 0.98
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.04; acc: 0.98
Batch: 120; loss: 0.1; acc: 0.95
Batch: 140; loss: 0.08; acc: 0.97
Batch: 160; loss: 0.02; acc: 1.0
Batch: 180; loss: 0.05; acc: 0.98
Batch: 200; loss: 0.06; acc: 0.98
Batch: 220; loss: 0.04; acc: 0.98
Batch: 240; loss: 0.02; acc: 1.0
Batch: 260; loss: 0.11; acc: 0.97
Batch: 280; loss: 0.04; acc: 0.98
Batch: 300; loss: 0.05; acc: 0.98
Batch: 320; loss: 0.08; acc: 0.98
Batch: 340; loss: 0.04; acc: 0.98
Batch: 360; loss: 0.04; acc: 1.0
Batch: 380; loss: 0.08; acc: 0.95
Batch: 400; loss: 0.05; acc: 0.98
Batch: 420; loss: 0.04; acc: 0.98
Batch: 440; loss: 0.03; acc: 0.98
Batch: 460; loss: 0.05; acc: 0.97
Batch: 480; loss: 0.1; acc: 0.98
Batch: 500; loss: 0.1; acc: 0.98
Batch: 520; loss: 0.03; acc: 0.98
Batch: 540; loss: 0.15; acc: 0.97
Batch: 560; loss: 0.15; acc: 0.94
Batch: 580; loss: 0.08; acc: 0.97
Batch: 600; loss: 0.17; acc: 0.97
Batch: 620; loss: 0.07; acc: 0.98
Batch: 640; loss: 0.05; acc: 0.98
Batch: 660; loss: 0.01; acc: 1.0
Batch: 680; loss: 0.03; acc: 1.0
Batch: 700; loss: 0.04; acc: 1.0
Batch: 720; loss: 0.02; acc: 1.0
Batch: 740; loss: 0.05; acc: 0.98
Batch: 760; loss: 0.03; acc: 0.98
Batch: 780; loss: 0.01; acc: 1.0
Train Epoch over. train_loss: 0.07; train_accuracy: 0.98 

3.098945671808906e-05
1.4437230674957391e-05
Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.07; acc: 0.98
Batch: 120; loss: 0.24; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.08439347869271685; val_accuracy: 0.9758160828025477 

The current subspace-distance is: 1.4437230674957391e-05 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.09; acc: 0.98
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.02; acc: 1.0
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.01; acc: 1.0
Batch: 120; loss: 0.03; acc: 0.98
Batch: 140; loss: 0.13; acc: 0.98
Batch: 160; loss: 0.1; acc: 0.94
Batch: 180; loss: 0.04; acc: 0.98
Batch: 200; loss: 0.05; acc: 0.97
Batch: 220; loss: 0.08; acc: 0.97
Batch: 240; loss: 0.01; acc: 1.0
Batch: 260; loss: 0.06; acc: 0.98
Batch: 280; loss: 0.19; acc: 0.94
Batch: 300; loss: 0.02; acc: 1.0
Batch: 320; loss: 0.01; acc: 1.0
Batch: 340; loss: 0.17; acc: 0.92
Batch: 360; loss: 0.04; acc: 0.98
Batch: 380; loss: 0.02; acc: 1.0
Batch: 400; loss: 0.04; acc: 0.98
Batch: 420; loss: 0.08; acc: 0.97
Batch: 440; loss: 0.06; acc: 0.98
Batch: 460; loss: 0.03; acc: 1.0
Batch: 480; loss: 0.1; acc: 0.94
Batch: 500; loss: 0.04; acc: 0.98
Batch: 520; loss: 0.19; acc: 0.97
Batch: 540; loss: 0.03; acc: 1.0
Batch: 560; loss: 0.08; acc: 0.97
Batch: 580; loss: 0.01; acc: 1.0
Batch: 600; loss: 0.04; acc: 0.97
Batch: 620; loss: 0.0; acc: 1.0
Batch: 640; loss: 0.2; acc: 0.95
Batch: 660; loss: 0.02; acc: 0.98
Batch: 680; loss: 0.07; acc: 0.98
Batch: 700; loss: 0.02; acc: 0.98
Batch: 720; loss: 0.09; acc: 0.98
Batch: 740; loss: 0.06; acc: 0.97
Batch: 760; loss: 0.12; acc: 0.97
Batch: 780; loss: 0.05; acc: 0.97
Train Epoch over. train_loss: 0.07; train_accuracy: 0.98 

3.1001571187516674e-05
1.4385424037755001e-05
Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.2; acc: 0.95
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.07; acc: 0.98
Batch: 120; loss: 0.25; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.08459113331831944; val_accuracy: 0.9754179936305732 

The current subspace-distance is: 1.4385424037755001e-05 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.02; acc: 0.98
Batch: 20; loss: 0.05; acc: 0.97
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.05; acc: 0.97
Batch: 80; loss: 0.13; acc: 0.98
Batch: 100; loss: 0.08; acc: 0.97
Batch: 120; loss: 0.06; acc: 0.98
Batch: 140; loss: 0.13; acc: 0.97
Batch: 160; loss: 0.19; acc: 0.97
Batch: 180; loss: 0.02; acc: 1.0
Batch: 200; loss: 0.04; acc: 0.97
Batch: 220; loss: 0.06; acc: 0.97
Batch: 240; loss: 0.1; acc: 0.97
Batch: 260; loss: 0.32; acc: 0.94
Batch: 280; loss: 0.02; acc: 1.0
Batch: 300; loss: 0.01; acc: 1.0
Batch: 320; loss: 0.07; acc: 0.97
Batch: 340; loss: 0.03; acc: 1.0
Batch: 360; loss: 0.08; acc: 0.98
Batch: 380; loss: 0.04; acc: 0.98
Batch: 400; loss: 0.09; acc: 0.95
Batch: 420; loss: 0.09; acc: 0.97
Batch: 440; loss: 0.01; acc: 1.0
Batch: 460; loss: 0.06; acc: 0.98
Batch: 480; loss: 0.1; acc: 0.98
Batch: 500; loss: 0.03; acc: 0.98
Batch: 520; loss: 0.06; acc: 0.98
Batch: 540; loss: 0.06; acc: 0.98
Batch: 560; loss: 0.28; acc: 0.95
Batch: 580; loss: 0.14; acc: 0.97
Batch: 600; loss: 0.11; acc: 0.95
Batch: 620; loss: 0.1; acc: 0.95
Batch: 640; loss: 0.01; acc: 1.0
Batch: 660; loss: 0.01; acc: 1.0
Batch: 680; loss: 0.22; acc: 0.95
Batch: 700; loss: 0.11; acc: 0.95
Batch: 720; loss: 0.03; acc: 0.98
Batch: 740; loss: 0.14; acc: 0.95
Batch: 760; loss: 0.05; acc: 0.98
Batch: 780; loss: 0.12; acc: 0.97
Train Epoch over. train_loss: 0.07; train_accuracy: 0.98 

3.120056135230698e-05
1.4404568901227321e-05
/home/llang/thesis-intrinsic-dimension/logging_helper.py:44: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax1 = plt.subplots()
Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.08; acc: 0.97
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.07; acc: 0.98
Batch: 120; loss: 0.24; acc: 0.91
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.08360893173724603; val_accuracy: 0.9754179936305732 

The current subspace-distance is: 1.4404568901227321e-05 

plots/subspace_training/reg_lenet_3/2020-01-22 20:51:04/d_dim_500_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
plots/subspace_training/reg_lenet_3/2020-01-22 20:51:04/d_dim_XXXXX_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
